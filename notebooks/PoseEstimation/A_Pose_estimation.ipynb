{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# get the FLOPs\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# get the FLOPs\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_table, parameter_count, flop_count_str\n",
    "import torchprofile\n",
    "# # decrease Cuda memory usage\n",
    "# from torch.cuda.amp import GradScaler, autocast # use gradscaler amd mixed precision training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking torch and tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.python.platform import build_info as tf_build_info\n",
    "#print(tf.__version__)\n",
    "#print(\"CUDA Version:\", tf_build_info.cuda_version)\n",
    "#print(\"cuDNN Version:\", tf_build_info.cudnn_version)\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version:',tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version:  11.2\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA version: \", tf.sysconfig.get_build_info()[\"cuda_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNN version:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"cuDNN version: \", tf.sysconfig.get_build_info()[\"cudnn_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 11:05:52.271759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-30 11:05:52.309717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-30 11:05:52.313048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11962/626668758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA version:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuDNN version:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print('CUDA version:',torch.version.cuda)\n",
    "print('cuDNN version:',torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available:  True\n",
      "Number of GPUs available:  1\n",
      "CUDA device name:  NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Is CUDA available: \", torch.cuda.is_available())\n",
    "print(\"Number of GPUs available: \", torch.cuda.device_count())\n",
    "print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc4...\n",
      "3.0.0rc4\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "print(deeplabcut.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda3/envs/DEEPLABCUT_PYTORCH_v2/lib/python3.10/site-packages/deeplabcut/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print(deeplabcut.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLC imports (used with DEEPLABCUT env)\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLEAP imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sleap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# check that we are using the cloned repository\n",
    "# output should read something like: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/__init__.py\n",
    "# if it is a path to the conda env lib, then it is incorrect\n",
    "print(sleap.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n"
     ]
    }
   ],
   "source": [
    "sleap.versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 13:19:54.918992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-04 13:19:54.952537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-04 13:19:54.955835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "sleap.system_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for model evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "mpl.style.use(\"seaborn-deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLC imports (used with DEEPLABCUT env)\n",
    "import pandas as pd\n",
    "import h5py\n",
    "# import os\n",
    "# import pickle\n",
    "# import json\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ids into list \n",
    "def load_file_to_list(file_path):\n",
    "    \"\"\"\n",
    "    loads a text file to a list with each entry on a new line becoming a new entry in the list.\n",
    "\n",
    "    :param file_path: Path to the file where the list should be saved.\n",
    "    :return list of data from file\n",
    "    \"\"\"\n",
    "    # Open the file for writing\n",
    "    lst = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Write each item on a new line\n",
    "        for line in file:\n",
    "            lst.append(line.strip())\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the image data into an arr\n",
    "# in the same order as the annotations and ids are stored (use id list for this)\n",
    "\n",
    "# The load image data function may take a while to run\n",
    "\n",
    "def load_image_data(ids_to_load, image_folder, crop_ext):\n",
    "\n",
    "  # list for loading image data\n",
    "  selected_imgs = []\n",
    "\n",
    "  # for loop for loading image data that is present in the list of ids\n",
    "  for i, img_id in enumerate(ids_to_load):\n",
    "\n",
    "    # load the image\n",
    "    img_path = os.path.join(image_folder, img_id+crop_ext)\n",
    "    #print(img_path)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    #print(img)\n",
    "\n",
    "    # change the img to RGB from BGR as plt uses RGB colour scale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # scaling the pixel values to [0, 1] (you don't need to scal them back)\n",
    "    img = img/255\n",
    "\n",
    "    selected_imgs.append(img)\n",
    "\n",
    "  # Convert the list of images to a NumPy array\n",
    "  selected_imgs_array = np.array(selected_imgs)\n",
    "  \n",
    "  return selected_imgs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_json(df, path):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame to a .json file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be converted to JSON.\n",
    "    path (str): The path (including file name) where the .json file will be saved.\n",
    "    \"\"\"\n",
    "    df.to_json(path, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_to_df(path):\n",
    "    \"\"\"\n",
    "    Converts a .json file to a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the .json file that will be read.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame created from the JSON file.\n",
    "    \"\"\"\n",
    "    #print(path)\n",
    "    df = pd.read_json(path, orient='records')\n",
    "    #print(f\"JSON file has been successfully converted to DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_lists(df_to_list, list_of_cols):\n",
    "\n",
    "  # create temp lists\n",
    "  keypoints_temp = []\n",
    "\n",
    "  # step through the rows and\n",
    "  for _, row in df_to_list.iterrows():\n",
    "\n",
    "    # extract the data arrays\n",
    "    keypoints_data = row[list_of_cols].values\n",
    "\n",
    "    # adding data to the list\n",
    "    keypoints_temp.append(keypoints_data)\n",
    "\n",
    "  # Convert the list to a NumPy array and make sure that they are float32\n",
    "  keypoints_array = np.array(keypoints_temp, dtype=np.float32)\n",
    "  \n",
    "  return keypoints_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dtypes_df_full_annotation_abs(df):\n",
    "    df['vid_id'] = df['vid_id'].astype(str)\n",
    "    df['img_id'] = df['img_id'].astype(str)\n",
    "    df['bbox_id'] = df['bbox_id'].astype(str)\n",
    "    df['bbox_c_x'] = df['bbox_c_x'].astype('float32')\n",
    "    df['bbox_c_y'] = df['bbox_c_y'].astype('float32')\n",
    "    df['bbox_w'] = df['bbox_w'].astype('float32')\n",
    "    df['bbox_h'] = df['bbox_h'].astype('float32')\n",
    "    df['Head_x'] = df['Head_x'].astype('float32')\n",
    "    df['Head_y'] = df['Head_y'].astype('float32')\n",
    "    df['Beak_x'] = df['Beak_x'].astype('float32')\n",
    "    df['Beak_y'] = df['Beak_y'].astype('float32')\n",
    "    df['Body_top_x'] = df['Body_top_x'].astype('float32')\n",
    "    df['Body_top_y'] = df['Body_top_y'].astype('float32')\n",
    "    df['RFlipper_mid_x'] = df['RFlipper_mid_x'].astype('float32')\n",
    "    df['RFlipper_mid_y'] = df['RFlipper_mid_y'].astype('float32')\n",
    "    df['LFlipper_mid_x'] = df['LFlipper_mid_x'].astype('float32')\n",
    "    df['LFlipper_mid_y'] = df['LFlipper_mid_y'].astype('float32')\n",
    "    df['Body_bottom_x'] = df['Body_bottom_x'].astype('float32')\n",
    "    df['Body_bottom_y'] = df['Body_bottom_y'].astype('float32')\n",
    "    df['RFoot_x'] = df['RFoot_x'].astype('float32')\n",
    "    df['RFoot_y'] = df['RFoot_y'].astype('float32')\n",
    "    df['LFoot_x'] = df['LFoot_x'].astype('float32')\n",
    "    df['LFoot_y'] = df['LFoot_y'].astype('float32')\n",
    "    df['kp_outside_best_bbox'] = df['kp_outside_best_bbox'].astype('float32')\n",
    "    df['kp_missing'] = df['kp_missing'].astype('float32')\n",
    "    df['kp_primary_missing'] = df['kp_primary_missing'].astype(bool)\n",
    "    df['img_width'] = df['img_width'].astype('float32')\n",
    "    df['img_height'] = df['img_height'].astype('float32')\n",
    "    df['bbox_max_h_w'] = df['bbox_max_h_w'].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnorm_keypoints(img_size, keypoints, kp_to_null=None):\n",
    "    \"\"\"\n",
    "    De-normalizes keypoints based on image size and returns the de-normalized keypoints along with \n",
    "    the positions of any missing or nullified keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    - img_size: Tuple of the image dimensions (height, width).\n",
    "    - keypoints: List of normalized keypoints (with values between -1 and 1).\n",
    "    - kp_to_null: Optional. List of indices where the keypoints should be nulled (set to NaN).\n",
    "\n",
    "    Returns:\n",
    "    - new_keypoints: List of de-normalized keypoints where each coordinate is scaled back to the \n",
    "                     image's pixel dimensions.\n",
    "    - missing_kp: List of indices where the keypoints were either originally set to -10 (indicating \n",
    "                  missing keypoints) or explicitly nullified by the kp_to_null list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract image width and height\n",
    "    readjust_x = img_size[0]  # width of the image\n",
    "    readjust_y = img_size[1]  # height of the image\n",
    "\n",
    "    new_keypoints = []  # List to store the de-normalized keypoints\n",
    "    missing_kp = []     # List to store the indices of missing or nullified keypoints\n",
    "\n",
    "    # Iterate through each keypoint\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        # Null keypoints if they are -10 or if they are specified in kp_to_null\n",
    "        if keypoint == -10 or (kp_to_null and i in kp_to_null):\n",
    "            keypoint = np.nan  # Set keypoint to NaN\n",
    "            missing_kp.append(i)  # Record the index of the missing or nullified keypoint\n",
    "\n",
    "        # De-normalize the x-coordinates\n",
    "        if i % 2 == 0:  # Even indices are x-coordinates\n",
    "            keypoint = keypoint * readjust_x + readjust_x / 2\n",
    "        # De-normalize the y-coordinates\n",
    "        else:  # Odd indices are y-coordinates\n",
    "            keypoint = keypoint * readjust_y + readjust_y / 2\n",
    "\n",
    "        new_keypoints.append(keypoint)  # Append the de-normalized keypoint to the list\n",
    "\n",
    "    return new_keypoints, missing_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_keypoints(img_size, keypoints):\n",
    "    \"\"\"\n",
    "    Normalizes keypoints based on image size and replaces any NaN values with -10.\n",
    "\n",
    "    Parameters:\n",
    "    - img_size: Tuple of the image dimensions (width, height).\n",
    "    - keypoints: List of de-normalized keypoints where each coordinate is in pixel dimensions.\n",
    "\n",
    "    Returns:\n",
    "    - norm_keypoints: List of normalized keypoints where each coordinate is scaled to the range \n",
    "                      [-1, 1] relative to the image size, with NaNs replaced by -10.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract image width and height\n",
    "    readjust_x = img_size[0]  # width of the image\n",
    "    readjust_y = img_size[1]  # height of the image\n",
    "\n",
    "    norm_keypoints = []  # List to store the normalized keypoints\n",
    "\n",
    "    # Iterate through each keypoint\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        # Replace NaN values with -10\n",
    "        if np.isnan(keypoint):\n",
    "            keypoint = -10.0\n",
    "        else:\n",
    "            # Normalize the x-coordinates\n",
    "            if i % 2 == 0:  # Even indices are x-coordinates\n",
    "                keypoint = (keypoint - readjust_x / 2) / readjust_x\n",
    "            # Normalize the y-coordinates\n",
    "            else:  # Odd indices are y-coordinates\n",
    "                keypoint = (keypoint - readjust_y / 2) / readjust_y\n",
    "\n",
    "        norm_keypoints.append(keypoint)  # Append the normalized keypoint to the list\n",
    "\n",
    "    return norm_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize keypoints for an array of images\n",
    "def unnorm_keypoints_arr(kp_arr, img_arr):\n",
    "    \"\"\"\n",
    "    Denormalizes keypoints for each image in the array based on the corresponding image size.\n",
    "    It converts normalized keypoints (range [-1, 1]) back to pixel coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - kp_arr: Array of normalized keypoints, where each entry is a list of keypoints for an image.\n",
    "              The keypoints are expected to be in the format [x1, y1, x2, y2, ...].\n",
    "    - img_arr: Array of images. The size of each image is used to scale the keypoints back \n",
    "               to their pixel coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - kp_abs_arr: Array of denormalized keypoints where each entry corresponds to the denormalized \n",
    "                  keypoints for the corresponding image in `img_arr`.\n",
    "    \"\"\"\n",
    "\n",
    "    kp_abs_list = []  # List to store the denormalized keypoints for each image\n",
    "\n",
    "    # Iterate through each set of keypoints and corresponding image\n",
    "    for i, kp in enumerate(kp_arr):\n",
    "        img_size = img_arr[i].shape  # Get the size of the current image (height, width, channels)\n",
    "\n",
    "        # Denormalize the keypoints based on the image size\n",
    "        kp_abs, missing_kp = unnorm_keypoints(img_size, kp_arr[i])\n",
    "\n",
    "        # Save the denormalized keypoints to the list\n",
    "        kp_abs_list.append(kp_abs)\n",
    "    \n",
    "    # Convert the list of denormalized keypoints to a NumPy array\n",
    "    kp_abs_arr = np.array(kp_abs_list)\n",
    "\n",
    "    return kp_abs_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize keypoints for an array of images\n",
    "def norm_keypoints_arr(kp_arr, img_arr):\n",
    "    \"\"\"\n",
    "    Normalizes keypoints for each image in the array based on the corresponding image size.\n",
    "    It converts keypoints from pixel coordinates back to normalized coordinates (range [-1, 1]).\n",
    "\n",
    "    Parameters:\n",
    "    - kp_arr: Array of keypoints, where each entry is a list of keypoints for an image.\n",
    "              The keypoints are expected to be in the format [x1, y1, x2, y2, ...] \n",
    "              with pixel coordinates.\n",
    "    - img_arr: Array of images. The size of each image is used to scale the keypoints \n",
    "               to normalized coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - kp_norm_arr: Array of normalized keypoints where each entry corresponds to the normalized \n",
    "                   keypoints for the corresponding image in `img_arr`.\n",
    "    \"\"\"\n",
    "        \n",
    "    kp_norm_list = []  # List to store the normalized keypoints for each image\n",
    "\n",
    "    # Iterate through each set of keypoints and corresponding image\n",
    "    for i, kp in enumerate(kp_arr):\n",
    "        img_size = img_arr[i].shape  # Get the size of the current image (height, width, channels)\n",
    "\n",
    "        # Normalize the keypoints based on the image size\n",
    "        kp_norm = norm_keypoints(img_size, kp_arr[i])\n",
    "\n",
    "        # Save the normalized keypoints to the list\n",
    "        kp_norm_list.append(kp_norm)\n",
    "    \n",
    "    # Convert the list of normalized keypoints to a NumPy array\n",
    "    kp_norm_arr = np.array(kp_norm_list)  \n",
    "\n",
    "    return kp_norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to images and keypoints\n",
    "def apply_aug(img_arr_orig, kp_arr_orig, aug, num_of_kp=8):\n",
    "    \"\"\"\n",
    "    Applies augmentation to a batch of images and their corresponding keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    - img_arr_orig: Original array of images. Shape should be (num_imgs, height, width, channels).\n",
    "    - kp_arr_orig: Original array of keypoints. Shape should be (num_imgs, num_of_kp*2), where each \n",
    "                   keypoint is represented by its x and y coordinates in pixel values.\n",
    "    - aug: An imgaug augmentation sequence or augmenter to apply to the images and keypoints.\n",
    "    - num_of_kp: Optional. Number of keypoints per image (default is 8).\n",
    "\n",
    "    Returns:\n",
    "    - img_arr_aug: Augmented array of images. Same shape as `img_arr_orig`.\n",
    "    - kp_arr_aug: Augmented array of keypoints. Same shape as `kp_arr_orig`.\n",
    "    \"\"\"\n",
    "    # print(img_arr_orig.shape)\n",
    "    #print(kp_arr_orig.shape)\n",
    "    \n",
    "    # Initialize lists to store augmented images and keypoints\n",
    "    aug_img = []  # List for augmented images\n",
    "    aug_kp = []   # List for augmented keypoints\n",
    "\n",
    "    # Get the number of images in the batch\n",
    "    num_imgs = img_arr_orig.shape[0]\n",
    "    #print(num_imgs)\n",
    "\n",
    "    # Loop over each image and its corresponding keypoints\n",
    "    for i in range(num_imgs):\n",
    "        image = img_arr_orig[i]  # Extract the i-th image\n",
    "        #print(image.shape)\n",
    "        \n",
    "        # Convert keypoints to KeypointsOnImage format for imgaug\n",
    "        keypoints = kp_arr_orig[i]\n",
    "        #print(keypoints)\n",
    "        kps = [Keypoint(x=keypoints[j*2], y=keypoints[j*2+1]) for j in range(num_of_kp)]\n",
    "        kps_on_image = KeypointsOnImage(kps, shape=image.shape)\n",
    "        \n",
    "        # Apply the augmentation to the image and keypoints\n",
    "        image_aug, kps_aug = aug(image=image, keypoints=kps_on_image)\n",
    "        \n",
    "        # Convert augmented keypoints back to the original flattened format [x1, y1, x2, y2, ...]\n",
    "        keypoints_aug = []\n",
    "        for kp in kps_aug.keypoints:\n",
    "            keypoints_aug.extend([kp.x, kp.y])\n",
    "        \n",
    "        # Append the augmented image and keypoints to their respective lists\n",
    "        aug_img.append(image_aug)\n",
    "        aug_kp.append(keypoints_aug)\n",
    "\n",
    "    # Convert the lists of augmented images and keypoints back to NumPy arrays\n",
    "    img_arr_aug = np.array(aug_img)\n",
    "    kp_arr_aug = np.array(aug_kp)\n",
    "\n",
    "    return img_arr_aug, kp_arr_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_padding(image):\n",
    "    \"\"\"\n",
    "    Detects if padding is on the x-axis (left and right) or y-axis (top and bottom)\n",
    "    of the image and calculates the padding size on one side.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A NumPy array representing the image. The shape should be (width, height, channels).\n",
    "\n",
    "    Returns:\n",
    "    - is_padding_x: True if padding is on the x-axis, False if padding is on the y-axis.\n",
    "    - padding_size: The size of the padding on one side in pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    width, height, _ = image.shape\n",
    "    \n",
    "    # Check for padding along the x-axis (left and right)\n",
    "    left_column = image[:, 0, :]#image[0, :, :]  # The first column (left side)\n",
    "    right_column = image[:, -1, :] #image[-1, :, :]  # The last column (right side)\n",
    "\n",
    "    # Check for padding along the y-axis (top and bottom)\n",
    "    top_row = image[:, 0, :]  # The first row (top side)\n",
    "    bottom_row = image[:, -1, :]  # The last row (bottom side)\n",
    "    #print(image[:, 5, :] *255)\n",
    "    #print(left_column*255)\n",
    "    \n",
    "    # Check if the columns are fully black (indicating padding)\n",
    "    if np.all(left_column*255 < 30) and np.all(right_column*255 < 30):\n",
    "        # Padding is along the x-axis\n",
    "        is_padding_x = True\n",
    "        #plot_img(image)\n",
    "        # Calculate padding size\n",
    "        #padding_size = np.sum(image[0, :, 0]*255 < 30) // 2  # Count black pixels on one side\n",
    "        # if padding_size > 60:\n",
    "        sum1 = np.sum(image[5, :, 0]*255 < 20) // 2\n",
    "        sum2 = np.sum(image[10, :, 0]*255 < 20) // 2\n",
    "        sum3 = np.sum(image[60, :, 0]*255 < 20) // 2\n",
    "        sum4 = np.sum(image[110, :, 0]*255 < 20) // 2\n",
    "        sum5 = np.sum(image[-60, :, 0]*255 < 20) // 2\n",
    "        sum6 = np.sum(image[-10, :, 0]*255 < 20) // 2\n",
    "        sum7 = np.sum(image[-5, :, 0]*255 < 20) // 2\n",
    "        padding_size = min(sum1, sum2, sum3, sum4, sum5, sum6, sum7)\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        # if padding_size > 60:\n",
    "        #     sum1 = np.sum(image[5, :, 0]*255 < 10) // 2\n",
    "        #     sum2 = np.sum(image[10, :, 0]*255 < 10) // 2\n",
    "        #     sum3 = np.sum(image[60, :, 0]*255 < 10) // 2\n",
    "        #     sum4 = np.sum(image[110, :, 0]*255 < 10) // 2\n",
    "        #     sum5 = np.sum(image[-60, :, 0]*255 < 10) // 2\n",
    "        #     sum6 = np.sum(image[-10, :, 0]*255 < 10) // 2\n",
    "        #     sum7 = np.sum(image[-5, :, 0]*255 < 10) // 2\n",
    "        #     average = (sum1 + sum2 + sum3 + sum4 + sum5 + sum6 + sum7) // 7  # Floor division for rounding down\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        if padding_size > 20: \n",
    "            padding_size = 20\n",
    "\n",
    "    else:\n",
    "        # Padding is along the y-axis (top and bottom)\n",
    "        is_padding_x = False\n",
    "        # Calculate padding size\n",
    "        padding_size = np.sum(image[:, 0, 0]*255 < 30) // 2  # Count black pixels on one side\n",
    "        # if padding_size > 60:\n",
    "        sum1 = np.sum(image[:, 5, 0]*255 < 20) // 2\n",
    "        sum2 = np.sum(image[:, 10, 0]*255 < 20) // 2\n",
    "        sum3 = np.sum(image[:, 60, 0]*255 < 20) // 2\n",
    "        sum4 = np.sum(image[:, 110, 0]*255 < 20) // 2\n",
    "        sum5 = np.sum(image[:, -60, 0]*255 < 20) // 2\n",
    "        sum6 = np.sum(image[:, -10, 0]*255 < 20) // 2\n",
    "        sum7 = np.sum(image[:, -5, 0]*255 < 20) // 2\n",
    "        padding_size = min(sum1, sum2, sum3, sum4, sum5, sum6, sum7)\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        # if padding_size > 60:\n",
    "        #     sum1 = np.sum(image[:, 5, 0]*255 < 10) // 2\n",
    "        #     sum2 = np.sum(image[:, 10, 0]*255 < 10) // 2\n",
    "        #     sum3 = np.sum(image[:, 60, 0]*255 < 10) // 2\n",
    "        #     sum4 = np.sum(image[:, 110, 0]*255 < 10) // 2\n",
    "        #     sum5 = np.sum(image[:, -60, 0]*255 < 10) // 2\n",
    "        #     sum6 = np.sum(image[:, -10, 0]*255 < 10) // 2\n",
    "        #     sum7 = np.sum(image[:, -5, 0]*255 < 10) // 2\n",
    "        #     average = (sum1 + sum2 + sum3 + sum4 + sum5 + sum6 + sum7) // 7  # Floor division for rounding down\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        if padding_size > 20: \n",
    "            padding_size = 20\n",
    "\n",
    "    return is_padding_x, padding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aug_translate(train_imgs_array, train_kp_array_abs):\n",
    "\n",
    "    \n",
    "    # Get the number of images in the batch\n",
    "    num_imgs = train_imgs_array.shape[0]\n",
    "    # print(num_imgs)\n",
    "\n",
    "    # creat empty arrays\n",
    "    train_imgs_array_aug_trans = np.empty((0, train_imgs_array.shape[1], train_imgs_array.shape[2], train_imgs_array.shape[3]), dtype=train_imgs_array.dtype)\n",
    "    train_kp_array_aug_trans = np.empty((0, train_kp_array_abs.shape[1]), dtype=train_kp_array_abs.dtype)\n",
    "\n",
    "    # print(train_imgs_array_aug_trans.shape)\n",
    "    # print(train_kp_array_aug_trans.shape)\n",
    "\n",
    "    # Loop over each image and its corresponding keypoints\n",
    "    for i in range(num_imgs):\n",
    "        image = train_imgs_array[i]  # Extract the i-th image\n",
    "        kp = train_kp_array_abs[i]\n",
    "        # print(i)\n",
    "        # print(image.shape)\n",
    "        # print(kp.shape)\n",
    "\n",
    "        is_padding_x, padding_size = detect_padding(image)\n",
    "        # print(f'this: {i}')\n",
    "        # print(is_padding_x)\n",
    "        # print(padding_size)\n",
    "\n",
    "        if is_padding_x:\n",
    "            seq_trans_x_left = iaa.Sequential([\n",
    "                iaa.TranslateX(px=(-padding_size, -padding_size)),\n",
    "            ])\n",
    "            seq_trans_x_right = iaa.Sequential([\n",
    "                iaa.TranslateX(px=(padding_size, padding_size)),\n",
    "            ])\n",
    "\n",
    "            # Convert to shape (1, 220, 220, 3) and (1, 16)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            #print(is_padding_x)\n",
    "            #print(image.shape)\n",
    "            #print(i)\n",
    "            kp = np.expand_dims(kp, axis=0)\n",
    "\n",
    "            # apply augmentations\n",
    "            single_trans_x_left_img_arr, single_trans_x_left_kp_arr = apply_aug(image, kp, seq_trans_x_left)\n",
    "            single_trans_x_right_img_arr, single_trans_x_right_kp_arr = apply_aug(image, kp, seq_trans_x_right)\n",
    "\n",
    "            #save to image array\n",
    "            train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_x_left_img_arr), axis=0)\n",
    "            train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_x_right_img_arr), axis=0)\n",
    "            #save to kp array\n",
    "            train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_x_left_kp_arr), axis=0)\n",
    "            train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_x_right_kp_arr), axis=0)\n",
    "\n",
    "        else :\n",
    "            seq_trans_y_up = iaa.Sequential([\n",
    "                iaa.TranslateY(px=(-padding_size, -padding_size)),\n",
    "            ])\n",
    "            seq_trans_y_down = iaa.Sequential([\n",
    "                iaa.TranslateY(px=(padding_size, padding_size)),\n",
    "            ])\n",
    "\n",
    "            # Convert to shape (1, 220, 220, 3) and (1, 16)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            #print(is_padding_x)\n",
    "            #print(image.shape)\n",
    "            #print(i)\n",
    "            kp = np.expand_dims(kp, axis=0)\n",
    "\n",
    "            # apply augmentations\n",
    "            single_trans_y_up_img_arr, single_trans_y_up_kp_arr = apply_aug(image, kp, seq_trans_y_up)\n",
    "            single_trans_y_down_img_arr, single_trans_y_down_kp_arr = apply_aug(image, kp, seq_trans_y_down)\n",
    "\n",
    "            #save to image array\n",
    "            train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_y_up_img_arr), axis=0)\n",
    "            train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_y_down_img_arr), axis=0)\n",
    "            #save to kp array\n",
    "            train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_y_up_kp_arr), axis=0)\n",
    "            train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_y_down_kp_arr), axis=0)\n",
    "\n",
    "\n",
    "    return train_imgs_array_aug_trans, train_kp_array_aug_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_out_of_img_kp(arr):\n",
    "    \"\"\"\n",
    "    Finds and replaces the elements in the array that are outside the frame but not the missing ones.\n",
    "    Specifically, elements greater than 0.5 are replaced with 0.5, and elements less than -0.5 but \n",
    "    greater than -9.0 are replaced with -0.5.\n",
    "\n",
    "    Parameters:\n",
    "    - arr: A NumPy array of shape (n, 16).\n",
    "\n",
    "    Returns:\n",
    "    - modified_arr: The modified NumPy array with replaced values.\n",
    "    - count_replacements: The number of elements that were replaced.\n",
    "    \"\"\"\n",
    "    # Make a copy of the array to avoid modifying the original array\n",
    "    modified_arr = arr.copy()\n",
    "\n",
    "    # Replace elements greater than 0.5 with 0.5\n",
    "    count_pos_replacements = np.sum(modified_arr > 0.5)\n",
    "    modified_arr[modified_arr > 0.5] = 0.49\n",
    "\n",
    "    # Replace elements less than -0.5 but greater than -9.0 with -0.5\n",
    "    count_neg_replacements = np.sum((modified_arr < -0.5) & (modified_arr > -9.0))\n",
    "    modified_arr[(modified_arr < -0.5) & (modified_arr > -9.0)] = -0.49\n",
    "\n",
    "    # Total count of replacements\n",
    "    count_replacements = count_pos_replacements + count_neg_replacements\n",
    "\n",
    "    return modified_arr, count_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_out_of_img_kp(arr):\n",
    "    \"\"\"\n",
    "    Finds and replaces the elements in the array that are outside the frame but not the missing ones.\n",
    "    Specifically, elements greater than 0.5 are replaced with 0.5, and elements less than -0.5 but \n",
    "    greater than -9.0 are replaced with -0.5.\n",
    "\n",
    "    Parameters:\n",
    "    - arr: A NumPy array of shape (n, 16).\n",
    "\n",
    "    Returns:\n",
    "    - modified_arr: The modified NumPy array with replaced values.\n",
    "    - count_replacements: The number of elements that were replaced.\n",
    "    \"\"\"\n",
    "    # Make a copy of the array to avoid modifying the original array\n",
    "    modified_arr = arr.copy()\n",
    "\n",
    "    # Replace elements greater than 0.5 with 0.5\n",
    "    count_pos_replacements = np.sum(modified_arr > 0.5)\n",
    "    modified_arr[modified_arr > 0.5] = 0.49\n",
    "\n",
    "    # Replace elements less than -0.5 but greater than -9.0 with -0.5\n",
    "    count_neg_replacements = np.sum((modified_arr < -0.5) & (modified_arr > -9.0))\n",
    "    modified_arr[(modified_arr < -0.5) & (modified_arr > -9.0)] = -0.49\n",
    "\n",
    "    # Total count of replacements\n",
    "    count_replacements = count_pos_replacements + count_neg_replacements\n",
    "\n",
    "    return modified_arr, count_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error, ignoring the invisible keypoints.\n",
    "    Assuming that -10.0 indicates an invisible keypoint.\n",
    "    \"\"\"\n",
    "    # Create a mask where keypoints are visible\n",
    "    mask = (y_true != -10.0).float().to(y_true.device)\n",
    "\n",
    "    # Apply the mask to filter out invisible keypoints from both\n",
    "    # the predictions and the true values\n",
    "    y_true_masked = y_true * mask\n",
    "    y_pred_masked = y_pred * mask\n",
    "\n",
    "    # Compute the Mean Squared Error only on the visible keypoints\n",
    "    mse = F.mse_loss(y_pred_masked, y_true_masked, reduction='sum') / mask.sum()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCK\n",
    "# put in a function that will use the max bbox if primary kp is missing\n",
    "def pck_metric(y_true, y_pred, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Computes the Percentage of Correct Keypoints (PCK) metric.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (torch.Tensor): The ground truth keypoints (batch_size, num_keypoints*2).\n",
    "    y_pred (torch.Tensor): The predicted keypoints (batch_size, num_keypoints*2).\n",
    "    threshold (float): The distance threshold for a keypoint to be considered correct.\n",
    "                       Typically set relative to the size of the bounding box (e.g., 0.2).\n",
    "    \n",
    "    Returns:\n",
    "    float: The percentage of correct keypoints.\n",
    "    \"\"\"\n",
    "    # Create a mask where keypoints are visible (not equal to -10)\n",
    "    mask = (y_true != -10.0).float().to(y_true.device)\n",
    "    #print(mask)\n",
    "\n",
    "    # Apply the mask to filter out invisible keypoints\n",
    "    y_true_masked = y_true * mask\n",
    "    y_pred_masked = y_pred * mask\n",
    "\n",
    "    # print(y_true_masked)\n",
    "    # print(y_pred_masked)\n",
    "\n",
    "    # Compute the Euclidean distance between the predicted and true keypoints\n",
    "    distances = torch.sqrt((y_pred_masked[:, ::2] - y_true_masked[:, ::2]) ** 2 +\n",
    "                           (y_pred_masked[:, 1::2] - y_true_masked[:, 1::2]) ** 2)\n",
    "    \n",
    "    #print(distances)\n",
    "    \n",
    "    # Normalize the distances (relative to the max and min y coord)\n",
    "    Norm_max_min_kp = torch.max(y_true_masked[:, 1::2], dim=1)[0] - torch.min(y_true_masked[:, 1::2], dim=1)[0]\n",
    "    # Normalise based on the distance between the head and the bottom of the body (position 0, 1 and )\n",
    "    #print(y_true[:, 0],y_true[:,10],y_true[:, 1],y_true[:, 11])\n",
    "    #print((y_true[:, 0] - y_true[:,10]) ** 2)\n",
    "    #print((y_true[:, 1] - y_true[:, 11]) ** 2)\n",
    "    Norm_head_lowerbody = torch.sqrt((y_true[:, 0] - y_true[:,10]) ** 2 +\n",
    "                        (y_true[:, 1] - y_true[:, 11]) ** 2)\n",
    "    #print(Norm_head_lowerbody)\n",
    "    normalized_distances = distances / Norm_head_lowerbody[:, None]\n",
    "    #print(distances)\n",
    "    #print(normalized_distances)\n",
    "\n",
    "    # Count the correct keypoints (distance <= threshold)\n",
    "    correct_keypoints = (normalized_distances <= threshold).float() * mask[:, ::2]\n",
    "    #print(correct_keypoints)\n",
    "\n",
    "    # Calculate the PCK as the percentage of correct keypoints\n",
    "    pck = correct_keypoints.sum() / mask[:, ::2].sum()\n",
    "    return pck#.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPoseModel(nn.Module):\n",
    "    def __init__(self, nkeypoints=8):\n",
    "        # Initializes the DeepPoseModel with the dataset and training configuration.\n",
    "        super(DeepPoseModel, self).__init__()\n",
    "        \n",
    "        # The feature extractor part of the model, composed of several convolutional layers.\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv2d: Input channels = 3 (RGB image), Output channels = 96, kernel size = 11x11,\n",
    "            # stride = 4, padding = 4. \n",
    "            # Input: (batch_size, 3, 220, 220)\n",
    "            # Output: (batch_size, 96, 55, 55)\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=4),\n",
    "            \n",
    "            # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "            nn.LocalResponseNorm(5),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            # output size: (batch_size, 96, 27, 27)\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv2d: Input channels = 96, Output channels = 256, kernel size = 5x5,\n",
    "            # stride = 2, padding = 2.\n",
    "            # Input: (batch_size, 96, 27, 27)\n",
    "            # Output: (batch_size, 256, 27, 27)\n",
    "            nn.Conv2d(48, 128, kernel_size=5, stride=1, padding=2),\n",
    "            \n",
    "            # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "            nn.LocalResponseNorm(5),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            # output size: (batch_size, 96, 13, 13)\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv2d: Input channels = 256, Output channels = 384, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 256, 13, 13)\n",
    "            # Output: (batch_size, 384, 13, 13)\n",
    "            nn.Conv2d(128, 192, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv2d: Input channels = 384, Output channels = 384, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 384, 13, 13)\n",
    "            # Output: (batch_size, 384, 13, 13)\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv2d: Input channels = 384, Output channels = 256, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 384, 13, 13)\n",
    "            # Output: (batch_size, 256, 13, 13)\n",
    "            nn.Conv2d(192, 128, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # MaxPool2d: Kernel size = 3x3, stride = 2.\n",
    "            # Input: (batch_size, 256, 13, 13)\n",
    "            # Output: (batch_size, 256, 6, 6)\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # The classifier part of the model, composed of fully connected layers.\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Flatten the input tensor\n",
    "            # Input: (batch_size, 256, 6, 6)\n",
    "            # Output: (batch_size, 256 * 6 * 6) = (batch_size, 9216)\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # Linear layer with input size 6400 and output size 4096\n",
    "            # Input: (batch_size, 6400)\n",
    "            # Output: (batch_size, 4096)\n",
    "            nn.Linear(128 * 6 * 6, 4096),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Dropout layer with 60% dropout rate\n",
    "            nn.Dropout(0.6),\n",
    "            \n",
    "            # Linear layer with input size 4096 and output size 4096\n",
    "            # Input: (batch_size, 4096)\n",
    "            # Output: (batch_size, 4096)\n",
    "            nn.Linear(4096, 4096),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Dropout layer with 60% dropout rate\n",
    "            nn.Dropout(0.6),\n",
    "            \n",
    "            # Final linear layer with input size 4096 and output size nkeypoints * 2\n",
    "            # Output is (nkeypoints * 2) coordinates (x, y) for each keypoint\n",
    "            # Input: (batch_size, 4096)\n",
    "            # Output: (batch_size, nkeypoints * 2)\n",
    "            nn.Linear(4096, nkeypoints * 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass through the network.\n",
    "        # Pass input `x` through the feature extractor\n",
    "        x = self.features(x)\n",
    "        # Pass the result through the classifier to get the final output\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_PyTorch(img_arr, kp_arr, batch_size, train_flag=True):\n",
    "#     '''\n",
    "#     conLoad data into PT dataLoader in specified batch size\n",
    "    \n",
    "#     Params\n",
    "#     img_arr: images loaded into an array (i,255,255,3) and are converted to (i,3,255,255)\n",
    "#     kp_arr: array of keypoints (i, num_kp*2)\n",
    "#     batch_size: batch size \n",
    "\n",
    "#     Return:\n",
    "#     PT_Dataset: containing input (x) and groundtruth (y)\n",
    "#     PT_DataLoader: Dataloader containing dataset and batch size\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     # create tensors from arrays and load them to the GPU\n",
    "#     img_tensor = torch.tensor(img_arr, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "#     kp_tensor = torch.tensor(kp_arr, dtype=torch.float32)#.to('cuda')\n",
    "\n",
    "#     # Create a TensorDataset and DataLoader for training data\n",
    "#     dataset = TensorDataset(img_tensor, kp_tensor)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=train_flag)\n",
    "\n",
    "#     return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamped_dir(descriptor, base_dir='/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/'):\n",
    "    \"\"\"\n",
    "    Creates a directory with a timestamp appended to the base directory name.\n",
    "    Returns the path to the created directory.\n",
    "    \n",
    "    Parameters:\n",
    "    descriptor: string describing the run generally model_dataDescriptor\n",
    "    base_dir (str): The base directory name. Default is './training_results'.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the created directory.\n",
    "    \"\"\"\n",
    "    # Get the current datetime and format it as YYYY-MM-DD_HH-MM-SS\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    base_dir_descriptor = f\"{base_dir}{descriptor}\"\n",
    "    \n",
    "    # Create the final directory name with the timestamp\n",
    "    final_dir = f\"{base_dir_descriptor}_{timestamp}\"\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "    \n",
    "    return final_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_data, val_data, save_dir, data_descriptor='Loss', show_plot=False):\n",
    "    # Plot the loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data, label=f'Training {data_descriptor}')\n",
    "    plt.plot(val_data, label=f'Validation {data_descriptor}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(f'{data_descriptor}')\n",
    "    plt.title(f'Training and Validation {data_descriptor} Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(save_dir, f'{data_descriptor}_plot.png')\n",
    "    plt.savefig(plot_path)\n",
    "    #print(f'{data_descriptor} plot saved to {plot_path}')\n",
    "\n",
    "    # Optionally, display the plot\n",
    "    if show_plot == True:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats_and_models(model, epoch, val_loss, val_pck, save_dir, \n",
    "                     best_val_loss=None, best_val_pck=None, \n",
    "                     final_model=False, train_loss_list=None, val_loss_list=None, train_pck_list=None, val_pck_list=None):\n",
    "    \"\"\"\n",
    "    Saves the best models based on validation loss, PCK value, and final model.\n",
    "    Saves the train and val curves and results for training\n",
    "    \n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The PyTorch model to be saved.\n",
    "    - epoch (int): The current epoch number.\n",
    "    - val_loss (float): The current validation loss.\n",
    "    - val_pck (float): The current validation PCK value.\n",
    "    - save_dir (str): The directory where the models will be saved.\n",
    "    - best_val_loss (float): The best validation loss seen so far.\n",
    "    - best_val_pck (float): The best validation PCK value seen so far.\n",
    "    - final_model (bool): If True, saves the final model after all epochs.\n",
    "    - train_loss_list (list): List of all the loss values from each epoch\n",
    "    \n",
    "    Returns:\n",
    "    - best_val_loss (float): Updated best validation loss.\n",
    "    - best_val_pck (float): Updated best validation PCK value.\n",
    "    - model_save_path_best_val_loss\n",
    "    - model_save_path_best_val_pck\n",
    "    - final_model_path\n",
    "    \"\"\"\n",
    "    model_save_path_best_val_loss = None\n",
    "    model_save_path_best_val_pck = None\n",
    "    \n",
    "    # Check if the current model has the lowest validation loss\n",
    "    if best_val_loss is None or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model_name = f'best_val_loss_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth'\n",
    "        model_save_path_best_val_loss = os.path.join(save_dir, model_name)\n",
    "        torch.save(model.state_dict(), model_save_path_best_val_loss)\n",
    "        print(f'New best model saved with lowest validation loss to {model_save_path_best_val_loss}')\n",
    "    \n",
    "    # Check if the current model has the highest validation PCK\n",
    "    if best_val_pck is None or val_pck > best_val_pck:\n",
    "        best_val_pck = val_pck\n",
    "        model_save_path_best_val_pck = os.path.join(save_dir, f'best_val_pck_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path_best_val_pck)\n",
    "        print(f'New best model saved with highest validation PCK to {model_save_path_best_val_pck}')\n",
    "    \n",
    "    # Save the final model and perform final stats evaluation and save\n",
    "    if final_model:\n",
    "        final_model_path = os.path.join(save_dir, f'final_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        print(f'Final model saved to {final_model_path}')\n",
    "        plot_training_curves(train_loss_list, val_loss_list, save_dir, 'Loss', show_plot=True)\n",
    "        plot_training_curves(train_pck_list, val_pck_list, save_dir, data_descriptor='PCK@0.1', show_plot=True)\n",
    "        return best_val_loss, best_val_pck, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path\n",
    "    \n",
    "    return best_val_loss, best_val_pck, model_save_path_best_val_loss, model_save_path_best_val_pck, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(aug, train_imgs_array, train_kp_array): \n",
    "    #\n",
    "    print('augmenting data...')\n",
    "    \n",
    "    # unnorm kp\n",
    "    train_kp_array_abs = unnorm_keypoints_arr(train_kp_array, train_imgs_array)\n",
    "\n",
    "    # specify augmentations\n",
    "    # lrflip\n",
    "    seq_lrflip = iaa.Sequential([\n",
    "        iaa.Fliplr(1.0)\n",
    "    ])\n",
    "    # rotate clock\n",
    "    seq_rotate_clock = iaa.Sequential([\n",
    "        iaa.Affine(rotate=(5, 20)),\n",
    "    ])\n",
    "    #rotate anticlock\n",
    "    seq_rotate_anticlock = iaa.Sequential([\n",
    "        iaa.Affine(rotate=(-20, -5)),\n",
    "    ])\n",
    "\n",
    "    # apply augmentation\n",
    "    #lrflip\n",
    "    train_imgs_array_aug_lrflip, train_kp_array_aug_lrflip_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_lrflip)\n",
    "    # rotate clock\n",
    "    train_imgs_array_aug_rclock, train_kp_array_aug_rclock_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_rotate_clock)\n",
    "    #rotate anticlock\n",
    "    train_imgs_array_aug_ranticlock, train_kp_array_aug_ranticlock_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_rotate_anticlock)\n",
    "    #translat\n",
    "    train_imgs_array_aug_trans, train_kp_array_aug_trans = apply_aug_translate(train_imgs_array, train_kp_array_abs)\n",
    "\n",
    "    # norm the aug kp\n",
    "    #lrflip\n",
    "    train_kp_array_aug_lrflip_norm = norm_keypoints_arr(train_kp_array_aug_lrflip_abs, train_imgs_array_aug_lrflip)  \n",
    "    # rotate clock\n",
    "    train_kp_array_aug_rclock_norm = norm_keypoints_arr(train_kp_array_aug_rclock_abs, train_imgs_array_aug_rclock)\n",
    "    #rotate anticlock\n",
    "    train_kp_array_aug_ranticlock_norm = norm_keypoints_arr(train_kp_array_aug_ranticlock_abs, train_imgs_array_aug_ranticlock)\n",
    "    #translat\n",
    "    train_kp_array_aug_trans_norm = norm_keypoints_arr(train_kp_array_aug_trans, train_imgs_array_aug_trans)\n",
    "\n",
    "    # combine augmented arrays to original array\n",
    "    #save to image array\n",
    "    train_imgs_array_aug = np.concatenate((train_imgs_array, train_imgs_array_aug_lrflip), axis=0)\n",
    "    train_imgs_array_aug = np.concatenate((train_imgs_array_aug, train_imgs_array_aug_rclock), axis=0)\n",
    "    train_imgs_array_aug = np.concatenate((train_imgs_array_aug, train_imgs_array_aug_ranticlock), axis=0)\n",
    "    train_imgs_array_aug = np.concatenate((train_imgs_array_aug, train_imgs_array_aug_trans), axis=0)\n",
    "    #save to kp array\n",
    "    train_kp_array_aug = np.concatenate((train_kp_array, train_kp_array_aug_lrflip_norm), axis=0)\n",
    "    train_kp_array_aug = np.concatenate((train_kp_array_aug, train_kp_array_aug_rclock_norm), axis=0)\n",
    "    train_kp_array_aug = np.concatenate((train_kp_array_aug, train_kp_array_aug_ranticlock_norm), axis=0)\n",
    "    train_kp_array_aug = np.concatenate((train_kp_array_aug, train_kp_array_aug_trans_norm), axis=0)\n",
    "\n",
    "    if aug == 2:\n",
    "        #put additional augmentations here and then concat the arrays\n",
    "        pass\n",
    "\n",
    "    return train_imgs_array_aug, train_kp_array_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, augmentation, crop_extension):\n",
    "\n",
    "    print('laoding data ...')\n",
    "\n",
    "    DATA_PARENT_PATH = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/'\n",
    "\n",
    "    if dataset == 1: # Simple dataset \n",
    "\n",
    "        # variables\n",
    "        dataset_name = 'PE_Simple'\n",
    "        crop_extension = '_crop_220x220.jpg'# cropsize extension\n",
    "\n",
    "        # loading ids to a list\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_test_bbox.txt'\n",
    "        ids_test_bbox = load_file_to_list(path)\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_val_bbox.txt'\n",
    "        ids_val_bbox=load_file_to_list(path)\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_train_bbox.txt'\n",
    "        ids_train_bbox=load_file_to_list(path)\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_test.txt'\n",
    "        ids_test=load_file_to_list(path)\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_val.txt'\n",
    "        ids_val=load_file_to_list(path)\n",
    "        path = DATA_PARENT_PATH + dataset_name + '/ids_train.txt'\n",
    "        ids_train=load_file_to_list(path)\n",
    "\n",
    "        # load image data to array \n",
    "        img_dir = '/images'\n",
    "        path = DATA_PARENT_PATH + dataset_name + img_dir + '/test'\n",
    "        test_imgs_array = load_image_data(ids_test_bbox, path, crop_extension)\n",
    "        path = DATA_PARENT_PATH + dataset_name + img_dir + '/val'\n",
    "        val_imgs_array = load_image_data(ids_val_bbox, path, crop_extension)\n",
    "        path = DATA_PARENT_PATH + dataset_name + img_dir + '/train'\n",
    "        train_imgs_array = load_image_data(ids_train_bbox, path, crop_extension)\n",
    "\n",
    "        # load annoation to df and set datatyoes\n",
    "        anno_dir = '/annotation'\n",
    "        path = DATA_PARENT_PATH + dataset_name + anno_dir + '/test_annotation_simple.json'\n",
    "        df_full_annotation_norm_test = json_to_df(path)\n",
    "        df_full_annotation_norm_test = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_test)\n",
    "        path = DATA_PARENT_PATH + dataset_name + anno_dir + '/val_annotation_simple.json'\n",
    "        df_full_annotation_norm_val = json_to_df(path)\n",
    "        df_full_annotation_norm_val = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_val)\n",
    "        path = DATA_PARENT_PATH + dataset_name + anno_dir + '/train_annotation_simple.json'\n",
    "        df_full_annotation_norm_train = json_to_df(path)\n",
    "        df_full_annotation_norm_train = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_train)\n",
    "\n",
    "        # create lists with col names (potentially remove)\n",
    "        id_cols = df_full_annotation_norm_test.iloc[:, :3].columns.to_list()\n",
    "        bbox_cols = df_full_annotation_norm_test.iloc[:, 3:7].columns.to_list()\n",
    "        kp_cols = df_full_annotation_norm_test.iloc[:, 7:23].columns.to_list()\n",
    "\n",
    "        # load the kps to arrays\n",
    "        test_kp_array = create_data_lists(df_full_annotation_norm_test, kp_cols)\n",
    "        val_kp_array = create_data_lists(df_full_annotation_norm_val, kp_cols)\n",
    "        train_kp_array = create_data_lists(df_full_annotation_norm_train, kp_cols)\n",
    "\n",
    "        if augmentation > 1: \n",
    "            train_imgs_array, train_kp_array = augment_data(augmentation, train_imgs_array, train_kp_array)\n",
    "        \n",
    "        train_kp_array, _ = replace_out_of_img_kp(train_kp_array)\n",
    "\n",
    "        return train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, dataset, aug, optimizer, lr, batch_size, num_epochs, crop_extension):\n",
    "\n",
    "    print('training ...')\n",
    "\n",
    "    # load data\n",
    "    train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array = load_data(dataset, aug, crop_extension)\n",
    "\n",
    "    # define model\n",
    "    if model == 1:\n",
    "        model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "        descriptor = 'DeepPose'\n",
    "    \n",
    "    if dataset == 1:\n",
    "        descriptor = descriptor + '_Simple'\n",
    "    \n",
    "    if aug == 1:\n",
    "        descriptor = descriptor + '_noAug'\n",
    "    if aug == 2:\n",
    "        descriptor = descriptor + '_simpleAug'\n",
    "    if aug == 3:\n",
    "        descriptor = descriptor + '_largeAug'\n",
    "\n",
    "    if optimizer == 1:\n",
    "        # Define your optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        descriptor = descriptor + '_Adam'\n",
    "    \n",
    "    # get naming convention\n",
    "    descriptor = descriptor + '_' + str(lr) + '_' + str(batch_size) + '_' + str(num_epochs)\n",
    "    # create save dir\n",
    "    save_dir = create_timestamped_dir(descriptor)\n",
    "    \n",
    "    # create tensors from arrays and load to a PT dataloader\n",
    "    #train\n",
    "    train_imgs_tensor = torch.tensor(train_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "    train_kp_tensor = torch.tensor(train_kp_array, dtype=torch.float32)\n",
    "    train_dataset = TensorDataset(train_imgs_tensor, train_kp_tensor)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    #val\n",
    "    val_imgs_tensor = torch.tensor(val_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "    val_kp_tensor = torch.tensor(val_kp_array, dtype=torch.float32)#.to('cuda')\n",
    "    val_dataset = TensorDataset(val_imgs_tensor, val_kp_tensor)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)# shuffle omly needs to be true for traing\n",
    "    #test\n",
    "    test_imgs_tensor = torch.tensor(test_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "    test_kp_tensor = torch.tensor(test_kp_array, dtype=torch.float32)#.to('cuda')\n",
    "    test_dataset = TensorDataset(test_imgs_tensor, test_kp_tensor)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)# shuffle omly needs to be true for traing\n",
    "        \n",
    "    # Lists to store the training and validation loss for each epoch\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_pck_list = []\n",
    "    val_pck_list = []\n",
    "    best_val_loss = None\n",
    "    best_val_pck = None\n",
    "    model_save_path_best_val_loss = None\n",
    "    model_save_path_best_val_pck = None\n",
    "\n",
    "    print('start training loop ...')\n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        running_pck_01 = 0.0\n",
    "        running_pck_val_01 = 0.0\n",
    "\n",
    "        # loop for a single batch\n",
    "        for batch_images, batch_keypoints in train_dataloader:\n",
    "\n",
    "            # Move the data to the GPU\n",
    "            batch_images = batch_images.to('cuda')\n",
    "            batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_images)\n",
    "            # Compute the loss\n",
    "            loss = masked_mse(batch_keypoints, outputs)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            # compute metrics\n",
    "            pck_01 = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "\n",
    "            # accumulate metrics\n",
    "            running_pck_01 += pck_01.item()\n",
    "\n",
    "        # calculate average loss for epoch\n",
    "        avg_train_loss = running_train_loss / len(train_dataloader)\n",
    "        # calculate average pck for epoch\n",
    "        avg_pck_01 = running_pck_01 / len(train_dataloader)\n",
    "    \n",
    "        # populate train losses list for evaluation\n",
    "        train_losses.append(avg_train_loss)\n",
    "        # populate train pck list for evaluation\n",
    "        train_pck_list.append(avg_pck_01)\n",
    "\n",
    "        # evalution for training phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad(): # dont update weights\n",
    "\n",
    "            # evaluation loop for a single batch\n",
    "            for batch_images, batch_keypoints in val_dataloader:\n",
    "\n",
    "                # Move the data to the GPU\n",
    "                batch_images = batch_images.to('cuda')\n",
    "                batch_keypoints = batch_keypoints.to('cuda')\n",
    "                \n",
    "                # forward pass\n",
    "                outputs = model(batch_images)\n",
    "                # Compute the loss\n",
    "                loss = masked_mse(batch_keypoints, outputs)\n",
    "\n",
    "                # Accumulate the loss\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # compute metrics\n",
    "                pck_01_val = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "\n",
    "                # accumulate metrics\n",
    "                running_pck_val_01 += pck_01_val.item()\n",
    "\n",
    "        # calculate average loss for epoch\n",
    "        avg_val_loss = running_val_loss / len(val_dataloader)\n",
    "        # calculate average pck for epoch\n",
    "        avg_val_pck_01 = running_pck_val_01 / len(val_dataloader)\n",
    "\n",
    "        # populate train losses list for evaluation\n",
    "        val_losses.append(avg_val_loss)\n",
    "        # populate train pck list for evaluation\n",
    "        val_pck_list.append(avg_val_pck_01)\n",
    "\n",
    "        # save best performing models based on the PCK and loss as well as the stats\n",
    "        best_val_loss, best_val_pck, model_save_path_best_val_loss_temp, model_save_path_best_val_pck_temp, _ = save_stats_and_models(\n",
    "        model, epoch + 1, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "        best_val_loss, best_val_pck)\n",
    "\n",
    "        if model_save_path_best_val_loss_temp:\n",
    "            model_save_path_best_val_loss = model_save_path_best_val_loss_temp\n",
    "        \n",
    "        if model_save_path_best_val_pck_temp:\n",
    "            model_save_path_best_val_pck = model_save_path_best_val_pck_temp\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Train PCK0.1: {avg_pck_01:.4f}, Val PCK0.1: {avg_val_pck_01:.4f}')\n",
    "        \n",
    "    best_val_loss, best_val_pck, _, _, final_model_path = save_stats_and_models(model, num_epochs, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "                    best_val_loss, best_val_pck, final_model=True, train_loss_list=train_losses, \n",
    "                    val_loss_list=val_losses, train_pck_list=train_pck_list, val_pck_list=val_pck_list)\n",
    "    \n",
    "    return save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, val_dataloader, test_dataloader,\\\n",
    "        train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_eval(model_path, model_class, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads a PyTorch model from a .pth file.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path (str): The path to the .pth model file.\n",
    "    - model_class (torch.nn.Module): The class of the model to instantiate.\n",
    "    - device (str): The device to load the model onto ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - model (torch.nn.Module): The loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    # Instantiate the model class\n",
    "    model = model_class().to(device)\n",
    "    \n",
    "    # Load the state dictionary into the model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pck(model, dataloader, threshold=0.2, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluates the average PCK over an entire dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - dataloader: A DataLoader providing the data to evaluate on.\n",
    "    - threshold: The PCK threshold distance (default is 0.2).\n",
    "    - device: The device to perform computations on (default is 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - average_pck: The average PCK over the entire dataset.\n",
    "    \"\"\"\n",
    "    total_pck = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_images, batch_keypoints in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_keypoints = batch_keypoints.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(batch_images)\n",
    "\n",
    "            # Compute PCK for the current batch\n",
    "            pck = pck_metric(batch_keypoints, outputs, threshold)\n",
    "            total_pck += pck.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    average_pck = total_pck / num_batches\n",
    "    \n",
    "    return average_pck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pck_per_keypoint(model, dataloader, num_keypoints=8, threshold=0.2, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluates the average PCK for each keypoint individually.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - dataloader: A DataLoader providing the data to evaluate on.\n",
    "    - num_keypoints: The number of keypoints in the dataset.\n",
    "    - threshold: The PCK threshold distance (default is 0.2).\n",
    "    - device: The device to perform computations on (default is 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - keypoint_pcks: A list of average PCK values for each keypoint.\n",
    "    \"\"\"\n",
    "    #model.eval()  # Set the model to evaluation mode\n",
    "    total_pck_per_keypoint = torch.zeros(num_keypoints, device=device)\n",
    "    total_visable_kp = torch.zeros(num_keypoints, device=device)\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_images, batch_keypoints in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_keypoints = batch_keypoints.to(device)\n",
    "\n",
    "            # Get model predictions\n",
    "            outputs = model(batch_images)\n",
    "\n",
    "            # Create a mask for visible keypoints\n",
    "            mask = (batch_keypoints != -10.0).float().to(device)\n",
    "\n",
    "            # Compute the Euclidean distances for each keypoint\n",
    "            distances = torch.sqrt((outputs[:, ::2] - batch_keypoints[:, ::2]) ** 2 +\n",
    "                                   (outputs[:, 1::2] - batch_keypoints[:, 1::2]) ** 2)\n",
    "\n",
    "            # Normalize the distances\n",
    "            Norm_head_lowerbody = torch.sqrt((batch_keypoints[:, 0] - batch_keypoints[:,10]) ** 2 +\n",
    "                                             (batch_keypoints[:, 1] - batch_keypoints[:, 11]) ** 2)\n",
    "            normalized_distances = distances / Norm_head_lowerbody[:, None]\n",
    "\n",
    "            # Compute correct keypoints (distance <= threshold) for each keypoint\n",
    "            correct_keypoints_per_keypoint = (normalized_distances <= threshold).float() * mask[:, ::2]\n",
    "\n",
    "            # Accumulate PCK per keypoint\n",
    "            total_pck_per_keypoint += correct_keypoints_per_keypoint.sum(dim=0)\n",
    "            total_visable_kp += mask[:, ::2].sum(dim=0)\n",
    "            num_batches += 1\n",
    "\n",
    "    # Average PCK per keypoint\n",
    "    #keypoint_pcks = (total_pck_per_keypoint / mask[:, ::2].sum(dim=0)).cpu().numpy()\n",
    "    keypoint_pcks = (total_pck_per_keypoint / total_visable_kp).cpu().numpy()\n",
    "    return keypoint_pcks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pck_evaluation(model, val_dataloader, test_dataloader):\n",
    "\n",
    "    print('calculating PCK ...')\n",
    "\n",
    "    # create lists for pck at different thresholds\n",
    "    avg_pck_test_list = []\n",
    "    avg_pck_val_list = []\n",
    "    avg_pck_per_kp_val_list = []\n",
    "    avg_pck_per_kp_test_list = []\n",
    "    \n",
    "    # create a for loop to get PCK at 0.01 to 0.2\n",
    "    for i in range (1, 21):\n",
    "\n",
    "        # get pck threshold\n",
    "        pck_threshold = (i/100)\n",
    "\n",
    "        # calculate average pck\n",
    "        avg_pck_val = evaluate_pck(model, val_dataloader, threshold=pck_threshold)\n",
    "        avg_pck_test = evaluate_pck(model, test_dataloader, threshold=pck_threshold)\n",
    "\n",
    "        # calculate average pck per kp\n",
    "        avg_pck_per_kp_val = evaluate_pck_per_keypoint(model, val_dataloader, threshold=pck_threshold)\n",
    "        avg_pck_per_kp_test = evaluate_pck_per_keypoint(model, test_dataloader, threshold=pck_threshold)\n",
    "\n",
    "        if i == 5:\n",
    "            # capture pck@0.05\n",
    "            avg_pck_val_005 = avg_pck_val\n",
    "            avg_pck_test_005 = avg_pck_test\n",
    "\n",
    "        if i == 10:\n",
    "            # capture pck@0.1\n",
    "            avg_pck_val_01 = avg_pck_val\n",
    "            avg_pck_test_01 = avg_pck_test\n",
    "\n",
    "        if i == 20:\n",
    "            # capture pck@0.2\n",
    "            avg_pck_val_02 = avg_pck_val\n",
    "            avg_pck_test_02 = avg_pck_test\n",
    "\n",
    "        # save to lists\n",
    "        avg_pck_test_list.append(avg_pck_test)\n",
    "        avg_pck_val_list.append(avg_pck_val)\n",
    "        avg_pck_per_kp_val_list.append(avg_pck_per_kp_val)\n",
    "        avg_pck_per_kp_test_list.append(avg_pck_per_kp_test)\n",
    "\n",
    "    return avg_pck_val_list, avg_pck_test_list, avg_pck_per_kp_val_list, avg_pck_per_kp_test_list, \\\n",
    "        avg_pck_val_005, avg_pck_test_005, avg_pck_val_01, avg_pck_test_01, avg_pck_val_02, avg_pck_test_02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_inference_time(model, dummy_input):\n",
    "        \n",
    "    # Warm up GPU to avoid initial overheads\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "    # Synchronize GPU and measure the time\n",
    "    torch.cuda.synchronize()  # Ensure all previous CUDA operations are complete\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "    torch.cuda.synchronize()  # Wait for all CUDA operations to finish\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    return (end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_inference_time(model, dummy_input):\n",
    "\n",
    "    # move model and dummy data to cpu\n",
    "    model.to('cpu')\n",
    "    dummy_input = dummy_input.to('cpu')\n",
    "\n",
    "    # Warm up to avoid initial overheads affecting the time\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "    # Time the forward pass\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model(dummy_input)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # move model and dummy iput back to gpu\n",
    "    model.to('cuda')\n",
    "    dummy_input.to('cuda')\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    return (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pck_to_dict(arr_list):\n",
    "        \n",
    "    # Define the keys for the dictionary\n",
    "    keys = ['head', 'beak', 'body_top', 'rflipper', 'lflipper', 'body_bottom', 'rfoot', 'lfoot']\n",
    "\n",
    "    # Initialize the dictionary with empty lists for each key\n",
    "    results_dict = {key: [] for key in keys}\n",
    "\n",
    "    # Populate the dictionary with values from the arrays\n",
    "    for array in arr_list:\n",
    "        for i, key in enumerate(keys):\n",
    "            results_dict[key].append(array[i])\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_to_dict(save_dir, avg_pck_val_005, avg_pck_test_005, avg_pck_val_01, avg_pck_test_01, avg_pck_val_02, avg_pck_test_02,\n",
    "                         total_params, total_flops, gpu_inf_time, cpu_inf_time, param_dict, flops_extend, avg_pck_test_list, \n",
    "                         avg_pck_per_kp_test_list, avg_pck_val_list, avg_pck_per_kp_val_list, num_train_imgs, num_val_imgs, num_test_imgs):\n",
    "\n",
    "    description = save_dir.split('/')[-1]\n",
    "    #print(description)\n",
    "\n",
    "    #avg_pck_test_dict = load_pck_to_dict(avg_pck_test_list)\n",
    "    avg_pck_per_kp_test_dict = load_pck_to_dict(avg_pck_per_kp_test_list)\n",
    "    #avg_pck_val_dict = load_pck_to_dict(avg_pck_val_list)\n",
    "    avg_pck_per_kp_val_dict = load_pck_to_dict(avg_pck_per_kp_val_list)\n",
    "\n",
    "    results_dict = {\n",
    "    'description': '',  # Placeholder for a string description\n",
    "    'pck005': None,  # Placeholder for PCK@0.05 variable\n",
    "    'pck01': None,  # Placeholder for PCK@0.1 variable\n",
    "    'pck02': None,  # Placeholder for PCK@0.2 variable\n",
    "    'total_params': None,  # Placeholder for total parameters variable\n",
    "    'GFLOPs': None,  # Placeholder for GFLOPs variable\n",
    "    'GPU_inf(ms)': None,  # Placeholder for GPU inference time variable\n",
    "    'CPU_inf(ms)': None,  # Placeholder for CPU inference time variable\n",
    "    'param_dict': {},  # Placeholder for parameter dictionary\n",
    "    'flops_dict': {},  # Placeholder for FLOPs dictionary\n",
    "    'PCK001-02': [],  # Placeholder for PCK@0.01-0.2 list\n",
    "    'PCK001-02_per_kp': {},  # Placeholder for PCK per joint dictionary\n",
    "    'val_PCK001-02': [],  # Placeholder for PCK@0.01-0.2 list\n",
    "    'val_PCK001-02_per_kp': {},  # Placeholder for PCK per joint dictionary\n",
    "    'val_pck005': None,  # Placeholder for PCK@0.05 variable\n",
    "    'val_pck01': None,  # Placeholder for PCK@0.1 variable\n",
    "    'val_pck02': None,  # Placeholder for PCK@0.2 variable\n",
    "    'num_train_imgs': None, # number of train imgs\n",
    "    'num_val_imgs': None, # number of train imgs\n",
    "    'num_test_imgs': None, # number of train imgs\n",
    "}\n",
    "    \n",
    "    results_dict['description'] = description\n",
    "    results_dict['pck005'] = avg_pck_test_005 \n",
    "    results_dict['pck01'] = avg_pck_test_01  \n",
    "    results_dict['pck02'] = avg_pck_test_02 \n",
    "    results_dict['total_params'] = total_params  \n",
    "    results_dict['GFLOPs'] = (total_flops/1e9)\n",
    "    results_dict['GPU_inf(ms)'] = gpu_inf_time*1000  \n",
    "    results_dict['CPU_inf(ms)'] = cpu_inf_time*1000  \n",
    "    results_dict['param_dict'] = param_dict  \n",
    "    results_dict['flops_dict'] = flops_extend \n",
    "    results_dict['PCK001-02'] = avg_pck_test_list\n",
    "    results_dict['PCK001-02_per_kp'] = avg_pck_per_kp_test_dict\n",
    "    results_dict['val_PCK001-02'] = avg_pck_val_list\n",
    "    results_dict['val_PCK001-02_per_kp'] = avg_pck_per_kp_val_dict\n",
    "    results_dict['val_pck005'] = avg_pck_val_005 \n",
    "    results_dict['val_pck01'] = avg_pck_val_01  \n",
    "    results_dict['val_pck02'] = avg_pck_val_02\n",
    "    results_dict['num_train_imgs'] = num_train_imgs\n",
    "    results_dict['num_val_imgs'] = num_val_imgs\n",
    "    results_dict['num_test_imgs'] = num_test_imgs\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numpy_types(obj):\n",
    "    \"\"\"\n",
    "    Convert numpy types in an object to their native Python equivalents.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert numpy arrays to lists\n",
    "    elif isinstance(obj, np.generic):\n",
    "        return obj.item()  # Convert numpy scalars to native Python types\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(element) for element in obj]\n",
    "    else:\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_json(data_dict, save_dir):\n",
    "    \"\"\"\n",
    "    Saves a dictionary to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict: The dictionary to save.\n",
    "    - save_dir: The directory path where the JSON file will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Convert any numpy types in the dictionary to native Python types\n",
    "    data_dict = convert_numpy_types(data_dict)\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(os.path.dirname(save_dir), exist_ok=True)\n",
    "\n",
    "    # json name\n",
    "    results_json = save_dir+'/results.json'\n",
    "    \n",
    "    # Save the dictionary to a JSON file\n",
    "    with open(results_json, 'w') as json_file:\n",
    "        json.dump(data_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_comparison(img, pred_keypoints, true_keypoints, save_dir, img_num, nkeypoints=8, keypoint_labels=None, connections = [(0, 1), (0, 2), (2, 3), (2, 4), (2, 5), (5, 6), (5, 7)]):\n",
    "#     \"\"\"\n",
    "#     Plots predicted keypoints vs. ground truth keypoints on the same image.\n",
    "\n",
    "#     Parameters:\n",
    "#     - img: The image on which to plot the keypoints.\n",
    "#     - pred_keypoints: The predicted keypoints (flattened x, y coordinates).\n",
    "#     - true_keypoints: The ground truth keypoints (flattened x, y coordinates).\n",
    "#     - save_dir: Directory to save the result to\n",
    "#     - img_num: image number that is getting compared\n",
    "#     - nkeypoints:  Optional The number of keypoints (default=8).\n",
    "#     - keypoint_labels: Optional list of keypoint labels to display next to the keypoints.\n",
    "#     - connections: OPtional list of tupels defining the connections between kps\n",
    "#     \"\"\"\n",
    "\n",
    "#     fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "#     plt.imshow(img)\n",
    "    \n",
    "#     # Extract x and y coordinates for predicted keypoints\n",
    "#     pred_x_keypoints = pred_keypoints[::2]\n",
    "#     pred_y_keypoints = pred_keypoints[1::2]\n",
    "    \n",
    "#     # Extract x and y coordinates for ground truth keypoints\n",
    "#     true_x_keypoints = true_keypoints[::2]\n",
    "#     true_y_keypoints = true_keypoints[1::2]\n",
    "\n",
    "#     # Plot skeleton for true keypoints\n",
    "#     for (i, j) in connections:\n",
    "#         plt.plot([true_x_keypoints[i], true_x_keypoints[j]], \n",
    "#                  [true_y_keypoints[i], true_y_keypoints[j]], \n",
    "#                  'r-', linewidth=1)\n",
    "\n",
    "#     # Plot skeleton for predicted keypoints\n",
    "#     for (i, j) in connections:\n",
    "#         plt.plot([pred_x_keypoints[i], pred_x_keypoints[j]], \n",
    "#                  [pred_y_keypoints[i], pred_y_keypoints[j]], \n",
    "#                  'g-', linewidth=1)\n",
    "    \n",
    "#     # Plot predicted keypoints\n",
    "#     plt.scatter(pred_x_keypoints, pred_y_keypoints, marker='o', c='g', s=100, label='Predicted', edgecolor='black')\n",
    "    \n",
    "#     # Plot ground truth keypoints\n",
    "#     plt.scatter(true_x_keypoints, true_y_keypoints, marker='x', c='r', s=100, label='Ground Truth')\n",
    "    \n",
    "#     # If labels are provided, add them to the plot\n",
    "#     if keypoint_labels is not None:\n",
    "#         for i, (x, y) in enumerate(zip(true_x_keypoints, true_y_keypoints)):\n",
    "#             plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "#                      bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "#     # If labels are provided, add them to the plot\n",
    "#     if keypoint_labels is not None:\n",
    "#         for i, (x, y) in enumerate(zip(pred_x_keypoints, pred_y_keypoints)):\n",
    "#             plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "#                      bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "#     # Add a legend to differentiate between predicted and ground truth keypoints\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Save the plot\n",
    "#     plot_path = os.path.join(save_dir, f'Comparison of predicted and ground truth for img {img_num}.png')\n",
    "#     plt.savefig(plot_path)\n",
    "#     #print(f'{data_descriptor} plot saved to {plot_path}')\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_and_plot(model_path, start_img, end_img, model_class=DeepPoseModel, device='cuda'):\n",
    "#     \"\"\"\n",
    "#     Loads a model, predicts keypoints for a range of images, and plots the predicted keypoints \n",
    "#     versus ground truth keypoints on the same image. The images with plotted keypoints are then \n",
    "#     saved to a specified directory.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model_path: The file path to the saved model's .pth file.\n",
    "#     - start_img: The starting index of the images in the validation set to process.\n",
    "#     - end_img: The ending index of the images in the validation set to process (exclusive).\n",
    "#     - model_class: Optional. The class of the model architecture to instantiate and load \n",
    "#                    with the saved weights (default=DeepPoseModel).\n",
    "#     - device: Optional. The device to run the model on ('cuda' for GPU, 'cpu' for CPU; default='cuda').\n",
    "    \n",
    "#     Returns:\n",
    "#     - None. The function saves the images with plotted keypoints to the directory derived from the \n",
    "#             model path.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # get img lists\n",
    "#     img_arr = val_imgs_array[start_img:end_img,:,:,:]\n",
    "#     true_kp_arr = val_kp_array[start_img:end_img,:]\n",
    "\n",
    "#     # Load the model\n",
    "#     model = load_model(model_path, model_class, device=device)\n",
    "\n",
    "#     # Get predictions\n",
    "#     predictions = predict(model, img_arr, device=device)\n",
    "#     #print(predictions)\n",
    "\n",
    "#     # DeNorm predictions \n",
    "#     predictions_abs = []\n",
    "#     true_kp_arr_abs = []\n",
    "#     for i, kp in enumerate(predictions):\n",
    "\n",
    "#         img_size = img_arr[i].shape\n",
    "#         #print(img_size)\n",
    "\n",
    "#         #unNorm each prediction\n",
    "#         true_kp_abs, missing_kp = unnorm_keypoints(img_size, true_kp_arr[i])\n",
    "#         #print(missing_kp)\n",
    "#         kp_abs, missing_kp = unnorm_keypoints(img_size, kp, kp_to_null=missing_kp)\n",
    "#         #print(missing_kp)\n",
    "        \n",
    "\n",
    "#         # save result to new list\n",
    "#         predictions_abs.append(kp_abs)\n",
    "#         true_kp_arr_abs.append(true_kp_abs)\n",
    "\n",
    "#     #print(predictions_abs)\n",
    "\n",
    "#     # get the save directory parent (where the images will be saved)\n",
    "#     save_dir = model_path.rsplit('/',1)[0]\n",
    "\n",
    "#     # labels\n",
    "#     labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "\n",
    "#     for i, kp in enumerate(predictions_abs):\n",
    "\n",
    "#         plot_comparison(img_arr[i], predictions_abs[i], true_kp_arr_abs[i], save_dir, img_num=i+start_img)#, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, images, img_is_tensor=False, device='cuda'):\n",
    "#     \"\"\"\n",
    "#     Generates predictions from a PyTorch model given an array of images.\n",
    "\n",
    "#     Parameters:\n",
    "#     - model (torch.nn.Module): The PyTorch model to use for predictions.\n",
    "#     - images (np.array): Array of images (e.g., shape: (num_images, 220, 220, 3)).\n",
    "#     - device (str): The device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "#     Returns:\n",
    "#     - predictions (np.array): Array of predictions (e.g., keypoints for each image).\n",
    "#     \"\"\"\n",
    "#     # Convert images to PyTorch tensor and move to the specified device\n",
    "#     if not img_is_tensor:\n",
    "#         images_tensor = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "#     # Forward pass through the model to get predictions\n",
    "#     with torch.no_grad():\n",
    "#         predictions = model(images_tensor)\n",
    "    \n",
    "#     # Convert predictions back to a NumPy array and move to CPU if necessary\n",
    "#     predictions = predictions.cpu().numpy() if device == 'cuda' else predictions.numpy()\n",
    "    \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, images, img_is_tensor=False, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generates predictions from a PyTorch model given an array of images.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The PyTorch model to use for predictions.\n",
    "    - images (np.array): Array of images (e.g., shape: (num_images, 220, 220, 3)).\n",
    "    - device (str): The device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - predictions (np.array): Array of predictions (e.g., keypoints for each image).\n",
    "    \"\"\"\n",
    "    # Convert images to PyTorch tensor and move to the specified device\n",
    "    if not img_is_tensor:\n",
    "        images_tensor = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "    # Forward pass through the model to get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images_tensor)\n",
    "    \n",
    "    # Convert predictions back to a NumPy array and move to CPU if necessary\n",
    "    predictions = predictions.cpu().numpy() if device == 'cuda' else predictions.numpy()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(img, pred_keypoints, true_keypoints, save_dir, img_num, nkeypoints=8, keypoint_labels=None, connections = [(0, 1), (0, 2), (2, 3), (2, 4), (2, 5), (5, 6), (5, 7)]):\n",
    "    \"\"\"\n",
    "    Plots predicted keypoints vs. ground truth keypoints on the same image.\n",
    "\n",
    "    Parameters:\n",
    "    - img: The image on which to plot the keypoints.\n",
    "    - pred_keypoints: The predicted keypoints (flattened x, y coordinates).\n",
    "    - true_keypoints: The ground truth keypoints (flattened x, y coordinates).\n",
    "    - save_dir: Directory to save the result to\n",
    "    - img_num: image number that is getting compared\n",
    "    - nkeypoints:  Optional The number of keypoints (default=8).\n",
    "    - keypoint_labels: Optional list of keypoint labels to display next to the keypoints.\n",
    "    - connections: OPtional list of tupels defining the connections between kps\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Extract x and y coordinates for predicted keypoints\n",
    "    pred_x_keypoints = pred_keypoints[::2]\n",
    "    pred_y_keypoints = pred_keypoints[1::2]\n",
    "    \n",
    "    # Extract x and y coordinates for ground truth keypoints\n",
    "    true_x_keypoints = true_keypoints[::2]\n",
    "    true_y_keypoints = true_keypoints[1::2]\n",
    "\n",
    "    # Plot skeleton for true keypoints\n",
    "    for (i, j) in connections:\n",
    "        plt.plot([true_x_keypoints[i], true_x_keypoints[j]], \n",
    "                 [true_y_keypoints[i], true_y_keypoints[j]], \n",
    "                 'r-', linewidth=1)\n",
    "\n",
    "    # Plot skeleton for predicted keypoints\n",
    "    for (i, j) in connections:\n",
    "        plt.plot([pred_x_keypoints[i], pred_x_keypoints[j]], \n",
    "                 [pred_y_keypoints[i], pred_y_keypoints[j]], \n",
    "                 'g-', linewidth=1)\n",
    "    \n",
    "    # Plot predicted keypoints\n",
    "    plt.scatter(pred_x_keypoints, pred_y_keypoints, marker='o', c='g', s=100, label='Predicted', edgecolor='black')\n",
    "    \n",
    "    # Plot ground truth keypoints\n",
    "    plt.scatter(true_x_keypoints, true_y_keypoints, marker='x', c='r', s=100, label='Ground Truth')\n",
    "    \n",
    "    # If labels are provided, add them to the plot\n",
    "    if keypoint_labels is not None:\n",
    "        for i, (x, y) in enumerate(zip(true_x_keypoints, true_y_keypoints)):\n",
    "            plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "                     bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "    # If labels are provided, add them to the plot\n",
    "    if keypoint_labels is not None:\n",
    "        for i, (x, y) in enumerate(zip(pred_x_keypoints, pred_y_keypoints)):\n",
    "            plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "                     bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "    # Add a legend to differentiate between predicted and ground truth keypoints\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Save the plot\n",
    "    part = save_dir.split('/')[-1]\n",
    "    plot_path = os.path.join(save_dir, f'{part}_vs_GT_img_{img_num}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    #print(f'{data_descriptor} plot saved to {plot_path}')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(model, img_arr, kp_arr, start_img, end_img, save_dir, keypoint_display=False, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads a model, predicts keypoints for a range of images, and plots the predicted keypoints \n",
    "    versus ground truth keypoints on the same image. The images with plotted keypoints are then \n",
    "    saved to a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: The file path to the saved model's .pth file.\n",
    "    - start_img: The starting index of the images in the validation set to process.\n",
    "    - end_img: The ending index of the images in the validation set to process (exclusive).\n",
    "    - model_class: Optional. The class of the model architecture to instantiate and load \n",
    "                   with the saved weights (default=DeepPoseModel).\n",
    "    - device: Optional. The device to run the model on ('cuda' for GPU, 'cpu' for CPU; default='cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - None. The function saves the images with plotted keypoints to the directory derived from the \n",
    "            model path.\n",
    "    \"\"\"\n",
    "\n",
    "    # get img lists\n",
    "    img_arr = img_arr[start_img:end_img,:,:,:]\n",
    "    true_kp_arr = kp_arr[start_img:end_img,:]\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = predict(model, img_arr, device=device)\n",
    "    #print(predictions)\n",
    "\n",
    "    # DeNorm predictions \n",
    "    predictions_abs = []\n",
    "    true_kp_arr_abs = []\n",
    "    for i, kp in enumerate(predictions):\n",
    "\n",
    "        img_size = img_arr[i].shape\n",
    "        #print(img_size)\n",
    "\n",
    "        #unNorm each prediction\n",
    "        true_kp_abs, missing_kp = unnorm_keypoints(img_size, true_kp_arr[i])\n",
    "        #print(missing_kp)\n",
    "        kp_abs, missing_kp = unnorm_keypoints(img_size, kp, kp_to_null=missing_kp)\n",
    "        #print(missing_kp)\n",
    "        \n",
    "\n",
    "        # save result to new list\n",
    "        predictions_abs.append(kp_abs)\n",
    "        true_kp_arr_abs.append(true_kp_abs)\n",
    "\n",
    "    # labels\n",
    "    labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "\n",
    "    for i, kp in enumerate(predictions_abs):\n",
    "\n",
    "        if keypoint_display:\n",
    "            plot_comparison(img_arr[i], predictions_abs[i], true_kp_arr_abs[i], save_dir, img_num=i+start_img, keypoint_labels=labels)\n",
    "        else:\n",
    "            plot_comparison(img_arr[i], predictions_abs[i], true_kp_arr_abs[i], save_dir, img_num=i+start_img)#, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not running directly off the back of training then set this to true\n",
    "# straight_eval = True\n",
    "def run_eval(save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, model=None, val_dataloader=None, \\\n",
    "             test_dataloader=None, train_imgs_array=None, val_imgs_array=None, test_imgs_array=None, val_kp_array=None, \\\n",
    "                test_kp_array=None, straight_eval=True):\n",
    "    if straight_eval:\n",
    "        # run just evalutation\n",
    "\n",
    "        # set model paths\n",
    "        save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/DeepPose_Simple_SimpleAug_batch16_2024-08-22_16-34-02'\n",
    "        model_save_path_best_val_loss = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/DeepPose_Simple_SimpleAug_batch16_2024-08-22_16-34-02/best_val_loss_model_epoch_22_PCK_0.6433_loss_0.0053.pth'\n",
    "        model_save_path_best_val_pck = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/DeepPose_Simple_SimpleAug_batch16_2024-08-22_16-34-02/best_val_loss_model_epoch_22_PCK_0.6433_loss_0.0053.pth'\n",
    "        final_model_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/DeepPose_Simple_SimpleAug_batch16_2024-08-22_16-34-02/final_model_epoch_30_PCK_0.5835_loss_0.0076.pth'\n",
    "\n",
    "        # load the data\n",
    "        train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array = load_data(1, 1, crop_extension)\n",
    "        #val\n",
    "        val_imgs_tensor = torch.tensor(val_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "        val_kp_tensor = torch.tensor(val_kp_array, dtype=torch.float32)#.to('cuda')\n",
    "        val_dataset = TensorDataset(val_imgs_tensor, val_kp_tensor)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)# shuffle omly needs to be true for traing\n",
    "        #test\n",
    "        test_imgs_tensor = torch.tensor(test_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "        test_kp_tensor = torch.tensor(test_kp_array, dtype=torch.float32)#.to('cuda')\n",
    "        test_dataset = TensorDataset(test_imgs_tensor, test_kp_tensor)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)# shuffle omly needs to be true for traing\n",
    "\n",
    "    # create evaluation dir\n",
    "    save_dir_eval = create_timestamped_dir('/evaluation', save_dir)\n",
    "\n",
    "    if model == 1:\n",
    "        model_class = DeepPoseModel\n",
    "        input_size = (1, 3, 220, 220)#(torch.randn((1,3,220,220)),)\n",
    "\n",
    "    # load model for evaluation\n",
    "    model = load_model_eval(model_save_path_best_val_pck, model_class)\n",
    "\n",
    "    avg_pck_val_list, avg_pck_test_list, avg_pck_per_kp_val_list, avg_pck_per_kp_test_list,\\\n",
    "        avg_pck_val_005, avg_pck_test_005, avg_pck_val_01, avg_pck_test_01, avg_pck_val_02, avg_pck_test_02 \\\n",
    "        = full_pck_evaluation(model, val_dataloader, test_dataloader)\n",
    "\n",
    "    print('Finding other metrics ...')\n",
    "\n",
    "    # Calculate number of FLOPs\n",
    "    dummy_input = torch.randn(input_size).to('cuda') # move the dummy input to GPU\n",
    "    flops = FlopCountAnalysis(model, dummy_input)\n",
    "    total_flops = flops.total()\n",
    "    flops_extend = flops.by_module_and_operator() * 2\n",
    "    flops_2 = torchprofile.profile_macs(model, dummy_input) * 2\n",
    "    print(f'Total FLOPs: {flops_2}')\n",
    "    print(flop_count_table(flops))\n",
    "\n",
    "    # Calculate the number of params\n",
    "    param_dict = parameter_count(model)\n",
    "    total_params = param_dict['']\n",
    "    # print(total_params)\n",
    "\n",
    "    # Calculate inference time GPU\n",
    "    gpu_inf_time = gpu_inference_time(model, dummy_input)\n",
    "    # print(gpu_inf_time)\n",
    "    # print(gpu_inf_time*1e3)\n",
    "\n",
    "    # Calculate inference time CPU\n",
    "    cpu_inf_time = cpu_inference_time(model, dummy_input)\n",
    "    # print(cpu_inf_time)\n",
    "    # print(cpu_inf_time*1e3)\n",
    "\n",
    "    # load results to a dict\n",
    "    results = load_results_to_dict(save_dir, avg_pck_val_005, avg_pck_test_005, avg_pck_val_01, avg_pck_test_01, avg_pck_val_02, avg_pck_test_02,\\\n",
    "                        total_params, total_flops, gpu_inf_time, cpu_inf_time, param_dict, flops_extend, avg_pck_test_list, \\\n",
    "                        avg_pck_per_kp_test_list, avg_pck_val_list, avg_pck_per_kp_val_list, train_imgs_array.shape[0], \\\n",
    "                        val_imgs_array.shape[0], test_imgs_array.shape[0])\n",
    "\n",
    "    # save \n",
    "    print('saving metrics ...')\n",
    "    save_dict_to_json(results, save_dir_eval)\n",
    "\n",
    "    # plot and save images\n",
    "    print('plotting and saving some result images ...')\n",
    "    # get random images with seed so that it is consistant\n",
    "    # Set a fixed seed for reproducibility\n",
    "    fixed_seed = 42\n",
    "    random.seed(fixed_seed)\n",
    "\n",
    "    # val - create loop to produce and save 5 random images to the save dir\n",
    "    # Generate unique random numbers for validation\n",
    "    val_random_nums = random.sample(range(val_imgs_array.shape[0]), 5)\n",
    "\n",
    "    for i, random_num in enumerate(val_random_nums):\n",
    "\n",
    "        print('VALIDATION', i)\n",
    "        predict_and_plot(model, val_imgs_array, val_kp_array, random_num, random_num+1, save_dir_eval+'/val_predictions')\n",
    "\n",
    "    # test - create loop to produce and save 5 random images to the save dir\n",
    "    # Generate unique random numbers for testing\n",
    "    test_random_nums = random.sample(range(test_imgs_array.shape[0]), 15)\n",
    "    for i, random_num in enumerate(test_random_nums):\n",
    "        print(f'TEST {i}')\n",
    "        # get a random image in the list\n",
    "        predict_and_plot(model, test_imgs_array, test_kp_array, random_num, random_num+1, save_dir_eval+'/test_predictions')\n",
    "\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_keypoint(img, keypoints, nkeypoints=8, keypoint_labels=None):\n",
    "  fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "  plt.imshow(img)\n",
    "  #print(keypoints)\n",
    "  x_keypoints = keypoints[::2]\n",
    "  y_keypoints = keypoints[1::2]\n",
    "  #print(x_keypoints)\n",
    "  #print(y_keypoints)\n",
    "  plt.scatter(x_keypoints, y_keypoints, marker='.', c=np.arange(nkeypoints), cmap='jet')\n",
    "\n",
    "    # If labels are provided, add them to the plot\n",
    "  if keypoint_labels is not None:\n",
    "      for i, (x, y) in enumerate(zip(x_keypoints, y_keypoints)):\n",
    "          plt.text(x, y, keypoint_labels[i], fontsize=12, color='white', \n",
    "                    bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_cols(df):\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1. Model input and run train and evalutaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a model\n",
    "model = 1 # 1. DeepPose\n",
    "dataset = 1 # 1. Simple - need to think how to handle crop image size - this should be moved to the model rather maybe\n",
    "augmentation = 2 # 1. no aug, 2. simple aug, 3. large aug*\n",
    "batch_size = 16\n",
    "num_epochs = 300\n",
    "learning_rate = 0.00005\n",
    "optimizer = 1 # 1. Adam\n",
    "crop_extension = '_crop_220x220.jpg'# cropsize extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run just train\n",
    "save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, val_dataloader, test_dataloader, \\\n",
    "    train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array\\\n",
    "        = run_train(model, dataset, augmentation, optimizer, learning_rate, batch_size, num_epochs, crop_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run just evaluation\n",
    "run_eval(save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run both train and evaluation\n",
    "\n",
    "# train\n",
    "save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, val_dataloader, test_dataloader, \\\n",
    "    train_imgs_array, val_imgs_array, test_imgs_array, train_kp_array, val_kp_array, test_kp_array\\\n",
    "        = run_train(model, dataset, augmentation, optimizer, learning_rate, batch_size, num_epochs, crop_extension)\n",
    "\n",
    "# evaluate\n",
    "run_eval(save_dir, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path, model=model, val_dataloader=val_dataloader, \\\n",
    "             test_dataloader=test_dataloader, train_imgs_array=train_imgs_array, val_imgs_array=val_imgs_array, test_imgs_array=test_imgs_array,\\\n",
    "                 val_kp_array=val_kp_array, test_kp_array=test_kp_array, straight_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a SLEAP model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. some info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sleap.ai/guides/gui.html\n",
    "GUI Functionality:\n",
    " - .slp files contain the information about the labels (annotations)\n",
    " - file open project to open a .slp file\n",
    " - file import to import a DLC annotation (can use the .yaml file for all the annotations from a project or a csv file for a single video)\n",
    " - file export analysis to csv/h5 exports\n",
    " - file merge data from: USE THIS WHEN OPENING UP A PREDICTIONS FILE THAT YOU WANT TO ADD TO A TRAINING DATASET\n",
    " - labels: has functionality for labeling videos - review when using for labelling\n",
    " - Predict >> Evaluation of Model >> select model >> view metrics: shows all the various metrics (how can we access these?)\n",
    " - Predict >> Export labeled frames: exports frames to a .slp file (can do just labeled or +suggested or +predicted+suggested)\n",
    " - Predict >> inference: allows you to select a model and run inference. Can export the config files and the training job package (contains a bash command for inference, a yaml file with some info and paths, the .slp file (which is over 1GB in size))?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_config.json\n",
    "- data >> labels >> training_inds/validation_inds: has the indices of the training and val images\n",
    "- data >> preprocessing: has image size \n",
    "- data >> instance cropping: has the centre point and crop size (640) and the padding (16)\n",
    "- model: has model parameters, backbone: unet, heads: centered_instance\n",
    "- optimization >> augmentation_config: all the augs (only rotation of 15 deg and random flip used)\n",
    "- optimization: has hyperparameters such as batch_size, epochs, optimizer (adam), lr, early stopping \n",
    "- outputs: saving outputs, has a tensorboard option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkg.slp file\n",
    " - contains all the lables and frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_model.h5 \n",
    " - this is the best model parameters I assume (to check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line instances\n",
    "https://sleap.ai/guides/cli.html \n",
    "\n",
    "I think these will be the most important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Mock project creation (following the tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run sleap-label in the teminal to open GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1. Create a project\n",
    "https://sleap.ai/tutorials/new-project.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.2. Define animal skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.3. Select frames for labelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.4. Manual labelling of frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.5. Training model using labelled frames\n",
    "see configuring models: https://sleap.ai/guides/choosing-models.html#choosing-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.6. Inference on unlabelled frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.7. Refining predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.8. Importing additional videos from your experiment, and applying the trained model to predict animal poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tracking - we are not doing this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.9. Exporting data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.10. SLEAP data structures notebook\n",
    "https://sleap.ai/notebooks/Data_structures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.11. SLEAP customised workflows for training SLEAP notebook\n",
    "https://sleap.ai/notebooks/Interactive_and_resumable_training.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.12. SLEAP real time inference notebook\n",
    "https://sleap.ai/notebooks/Interactive_and_realtime_inference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.13 SLEAP model evaluation notebook\n",
    "https://sleap.ai/notebooks/Model_evaluation.html\n",
    "https://sleap.ai/notebooks/Analysis_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Some exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Checking out the model.h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'tables'.  Use pip or conda to install tables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_213671/61748373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/models/test_run240930_124502.centered_instance.n=10/best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;31m# can't auto open/close if we are using an iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# so delegate to the iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format is not a defined argument for HDFStore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomplib\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_complibs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'tables'.  Use pip or conda to install tables."
     ]
    }
   ],
   "source": [
    "df = pd.read_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/models/test_run240930_124502.centered_instance.n=10/best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. viewing the .slp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sleap.load_file(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels_simpleDataset_DLC_labels.v001.slp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels(labeled_frames=500, videos=50, skeletons=1, tracks=50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 500\n",
      "Tracks: 50\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk89/img021.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen50/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk66/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap7/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand4/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest8/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest15/img027.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand19/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk57/img046.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand9/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen46/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap3/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk86/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest30/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen35/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap4/img025.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand75/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest39/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest24/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand11/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap12/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap14/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand69/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest19/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand2/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk62/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen31/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk82/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk6/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand72/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand6/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk68/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest47/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand67/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/videos/flap1.mp4\n",
      "    labeled frames: 10\n",
      "    labeled frames from 10 to 136\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen30/img011.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen37/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen48/img012.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen33/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk64/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/videos/flap2.mp4\n",
      "    labeled frames: 10\n",
      "    labeled frames from 1 to 149\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen84/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest65/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest44/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand82/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/rest42/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/stand79/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/walk80/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/preen40/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap13/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 500\n"
     ]
    }
   ],
   "source": [
    "import sleap.info\n",
    "import sleap.info.labels\n",
    "\n",
    "\n",
    "sleap.info.labels.describe_labels(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels_simpleDataset_DLC_labels.v001.slp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 500\n",
      "Tracks: 50\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 10 to 136\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 1 to 149\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 500\n"
     ]
    }
   ],
   "source": [
    "sleap.info.labels.describe_labels(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/Test_outputs_1Oct/labels_simpleDataset_DLC_labels.v001_pr_sug.pkg.slp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. attempting to train the simple model using command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. creating the sleap datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to the DLC data\n",
    "train_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train'\n",
    "val_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val'\n",
    "test_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a .yaml files for each of the dataset (adjusting the config.yaml accordingly)\n",
    " - (DONT NEED THIS) make sure it only has the correct frames in the video list\n",
    " - changing the project path to the data folder and recreating the folder structure (path to the correct folder (eg train_path))\n",
    " - copy the label-data folders to the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created 3 datasets now: train, test and val\n",
    "slp_train_dataset_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp'\n",
    "slp_val_dataset_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp'\n",
    "slp_test_dataset_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Using the CLI to run the training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an altered config file. /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/models/training_config_1Oct.json\n",
    "\n",
    "kept the same from initial training with a change in paths and nulls in the labels section (except for the skeleton). Used the created centriod_instance.json to adjust the label\n",
    "\n",
    "I will be passing the label data through the CLI command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usage: sleap-train [-h] [--video-paths VIDEO_PATHS] [--val_labels VAL_LABELS]\n",
    "                   [--test_labels TEST_LABELS] [--tensorboard] [--save_viz]\n",
    "                   [--zmq] [--run_name RUN_NAME] [--prefix PREFIX]\n",
    "                   [--suffix SUFFIX]\n",
    "                   training_job_path [labels_path]\n",
    "\n",
    "positional arguments:\n",
    "  training_job_path     Path to training job profile JSON file.\n",
    "  labels_path           Path to labels file to use for training. If specified,\n",
    "                        overrides the path specified in the training job\n",
    "                        config.\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --video-paths VIDEO_PATHS\n",
    "                        List of paths for finding videos in case paths inside\n",
    "                        labels file are not accessible.\n",
    "  --val_labels VAL_LABELS, --val VAL_LABELS\n",
    "                        Path to labels file to use for validation. If\n",
    "                        specified, overrides the path specified in the\n",
    "                        training job config.\n",
    "  --test_labels TEST_LABELS, --test TEST_LABELS\n",
    "                        Path to labels file to use for test. If specified,\n",
    "                        overrides the path specified in the training job\n",
    "                        config.\n",
    "  --base_checkpoint BASE_CHECKPOINT\n",
    "                        Path to base checkpoint (directory containing best_model.h5)\n",
    "                        to resume training from.\n",
    "  --tensorboard         Enable TensorBoard logging to the run path if not\n",
    "                        already specified in the training job config.\n",
    "  --save_viz            Enable saving of prediction visualizations to the run\n",
    "                        folder if not already specified in the training job\n",
    "                        config.\n",
    "  --zmq                 Enable ZMQ logging (for GUI) if not already specified\n",
    "                        in the training job config.\n",
    "  --run_name RUN_NAME   Run name to use when saving file, overrides other run\n",
    "                        name settings.\n",
    "  --prefix PREFIX       Prefix to prepend to run name.\n",
    "  --suffix SUFFIX       Suffix to append to run name.\n",
    "  --cpu                 Run training only on CPU. If not specified, will use\n",
    "                        available GPU.\n",
    "  --first-gpu           Run training on the first GPU, if available.\n",
    "  --last-gpu            Run training on the last GPU, if available.\n",
    "  --gpu GPU             Run training on the i-th GPU on the system. If 'auto', run on\n",
    "                        the GPU with the highest percentage of available memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attermpt 1: All Oct1 results. Did not work.\n",
    "\n",
    "sleap-train /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/models/training_config_1Oct.json /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp --val_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp --test_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp --run_name Oct1TestRun100Epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 2: Oct2_test1. Try using the baseline .json file\n",
    "\n",
    "centriod model\n",
    "\n",
    "sleap-train baseline.centroid.json /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp --val_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp --test_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp --run_name Oct2_test1_centroid_50Epoch \n",
    "\n",
    "centered-instance model\n",
    "\n",
    "sleap-train baseline_medium_rf.topdown.json /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp --val_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp --test_labels /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp --run_name Oct2_test1_centeredInstance_50Epoch \n",
    "\n",
    "I created a new baseline_medium_rf.topdown.json and baseline.centroid.json with _adjusted attached\n",
    "*move them from this folder /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/baseline.configs_adjusted to this folder /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/training_profiles\n",
    "\n",
    "and remove them after! or certain functions don't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "INFO:sleap.nn.training:Training labels file: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Training profile: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/training_profiles/baseline.centroid_adjusted.json\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Arguments:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"training_job_path\": \"baseline.centroid_adjusted.json\",\n",
      "    \"labels_path\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\",\n",
      "    \"video_paths\": [\n",
      "        \"\"\n",
      "    ],\n",
      "    \"val_labels\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\",\n",
      "    \"test_labels\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\",\n",
      "    \"base_checkpoint\": null,\n",
      "    \"tensorboard\": false,\n",
      "    \"save_viz\": false,\n",
      "    \"keep_viz\": false,\n",
      "    \"zmq\": false,\n",
      "    \"publish_port\": 9001,\n",
      "    \"controller_port\": 9000,\n",
      "    \"run_name\": \"Oct2_test1_centroid_50Epoch\",\n",
      "    \"prefix\": \"\",\n",
      "    \"suffix\": \"\",\n",
      "    \"cpu\": false,\n",
      "    \"first_gpu\": false,\n",
      "    \"last_gpu\": false,\n",
      "    \"gpu\": \"auto\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Training job:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"data\": {\n",
      "        \"labels\": {\n",
      "            \"training_labels\": null,\n",
      "            \"validation_labels\": null,\n",
      "            \"validation_fraction\": 0.1,\n",
      "            \"test_labels\": null,\n",
      "            \"split_by_inds\": false,\n",
      "            \"training_inds\": null,\n",
      "            \"validation_inds\": null,\n",
      "            \"test_inds\": null,\n",
      "            \"search_path_hints\": [],\n",
      "            \"skeletons\": []\n",
      "        },\n",
      "        \"preprocessing\": {\n",
      "            \"ensure_rgb\": false,\n",
      "            \"ensure_grayscale\": false,\n",
      "            \"imagenet_mode\": null,\n",
      "            \"input_scaling\": 0.5,\n",
      "            \"pad_to_stride\": null,\n",
      "            \"resize_and_pad_to_target\": true,\n",
      "            \"target_height\": null,\n",
      "            \"target_width\": null\n",
      "        },\n",
      "        \"instance_cropping\": {\n",
      "            \"center_on_part\": null,\n",
      "            \"crop_size\": null,\n",
      "            \"crop_size_detection_padding\": 16\n",
      "        }\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"backbone\": {\n",
      "            \"leap\": null,\n",
      "            \"unet\": {\n",
      "                \"stem_stride\": null,\n",
      "                \"max_stride\": 16,\n",
      "                \"output_stride\": 2,\n",
      "                \"filters\": 16,\n",
      "                \"filters_rate\": 2.0,\n",
      "                \"middle_block\": true,\n",
      "                \"up_interpolate\": true,\n",
      "                \"stacks\": 1\n",
      "            },\n",
      "            \"hourglass\": null,\n",
      "            \"resnet\": null,\n",
      "            \"pretrained_encoder\": null\n",
      "        },\n",
      "        \"heads\": {\n",
      "            \"single_instance\": null,\n",
      "            \"centroid\": {\n",
      "                \"anchor_part\": null,\n",
      "                \"sigma\": 2.5,\n",
      "                \"output_stride\": 2,\n",
      "                \"loss_weight\": 1.0,\n",
      "                \"offset_refinement\": false\n",
      "            },\n",
      "            \"centered_instance\": null,\n",
      "            \"multi_instance\": null,\n",
      "            \"multi_class_bottomup\": null,\n",
      "            \"multi_class_topdown\": null\n",
      "        },\n",
      "        \"base_checkpoint\": null\n",
      "    },\n",
      "    \"optimization\": {\n",
      "        \"preload_data\": true,\n",
      "        \"augmentation_config\": {\n",
      "            \"rotate\": true,\n",
      "            \"rotation_min_angle\": -15.0,\n",
      "            \"rotation_max_angle\": 15.0,\n",
      "            \"translate\": false,\n",
      "            \"translate_min\": -5,\n",
      "            \"translate_max\": 5,\n",
      "            \"scale\": false,\n",
      "            \"scale_min\": 0.9,\n",
      "            \"scale_max\": 1.1,\n",
      "            \"uniform_noise\": false,\n",
      "            \"uniform_noise_min_val\": 0.0,\n",
      "            \"uniform_noise_max_val\": 10.0,\n",
      "            \"gaussian_noise\": false,\n",
      "            \"gaussian_noise_mean\": 5.0,\n",
      "            \"gaussian_noise_stddev\": 1.0,\n",
      "            \"contrast\": false,\n",
      "            \"contrast_min_gamma\": 0.5,\n",
      "            \"contrast_max_gamma\": 2.0,\n",
      "            \"brightness\": false,\n",
      "            \"brightness_min_val\": 0.0,\n",
      "            \"brightness_max_val\": 10.0,\n",
      "            \"random_crop\": false,\n",
      "            \"random_crop_height\": 256,\n",
      "            \"random_crop_width\": 256,\n",
      "            \"random_flip\": false,\n",
      "            \"flip_horizontal\": true\n",
      "        },\n",
      "        \"online_shuffling\": true,\n",
      "        \"shuffle_buffer_size\": 128,\n",
      "        \"prefetch\": true,\n",
      "        \"batch_size\": 1,\n",
      "        \"batches_per_epoch\": null,\n",
      "        \"min_batches_per_epoch\": 200,\n",
      "        \"val_batches_per_epoch\": null,\n",
      "        \"min_val_batches_per_epoch\": 10,\n",
      "        \"epochs\": 20,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"initial_learning_rate\": 0.0001,\n",
      "        \"learning_rate_schedule\": {\n",
      "            \"reduce_on_plateau\": true,\n",
      "            \"reduction_factor\": 0.5,\n",
      "            \"plateau_min_delta\": 1e-08,\n",
      "            \"plateau_patience\": 5,\n",
      "            \"plateau_cooldown\": 3,\n",
      "            \"min_learning_rate\": 1e-08\n",
      "        },\n",
      "        \"hard_keypoint_mining\": {\n",
      "            \"online_mining\": false,\n",
      "            \"hard_to_easy_ratio\": 2.0,\n",
      "            \"min_hard_keypoints\": 2,\n",
      "            \"max_hard_keypoints\": null,\n",
      "            \"loss_scale\": 5.0\n",
      "        },\n",
      "        \"early_stopping\": {\n",
      "            \"stop_training_on_plateau\": true,\n",
      "            \"plateau_min_delta\": 1e-08,\n",
      "            \"plateau_patience\": 20\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"save_outputs\": true,\n",
      "        \"run_name\": \"Oct2_test1_centroid_50Epoch\",\n",
      "        \"run_name_prefix\": \"\",\n",
      "        \"run_name_suffix\": null,\n",
      "        \"runs_folder\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models\",\n",
      "        \"tags\": [],\n",
      "        \"save_visualizations\": true,\n",
      "        \"keep_viz_images\": false,\n",
      "        \"zip_outputs\": false,\n",
      "        \"log_to_csv\": true,\n",
      "        \"checkpointing\": {\n",
      "            \"initial_model\": false,\n",
      "            \"best_model\": true,\n",
      "            \"every_epoch\": false,\n",
      "            \"latest_model\": false,\n",
      "            \"final_model\": false\n",
      "        },\n",
      "        \"tensorboard\": {\n",
      "            \"write_logs\": false,\n",
      "            \"loss_frequency\": \"epoch\",\n",
      "            \"architecture_graph\": false,\n",
      "            \"profile_graph\": false,\n",
      "            \"visualizations\": true\n",
      "        },\n",
      "        \"zmq\": {\n",
      "            \"subscribe_to_controller\": false,\n",
      "            \"controller_address\": \"tcp://127.0.0.1:9000\",\n",
      "            \"controller_polling_timeout\": 10,\n",
      "            \"publish_updates\": false,\n",
      "            \"publish_address\": \"tcp://127.0.0.1:9001\"\n",
      "        }\n",
      "    },\n",
      "    \"name\": \"\",\n",
      "    \"description\": \"\",\n",
      "    \"sleap_version\": \"1.4.1a2\",\n",
      "    \"filename\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/training_profiles/baseline.centroid_adjusted.json\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "2024-10-02 16:12:22.894958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:22.912146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:22.917555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.training:Auto-selected GPU 0 with 3199 MiB of free memory.\n",
      "INFO:sleap.nn.training:Using GPU 0 for acceleration.\n",
      "INFO:sleap.nn.training:Disabled GPU memory pre-allocation.\n",
      "INFO:sleap.nn.training:System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Initializing trainer...\n",
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n",
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "2024-10-02 16:12:23.789178: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 16:12:23.790669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:23.792999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:23.794933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:24.168686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:24.169903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:24.171427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:12:24.172628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1362 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "INFO:sleap.nn.training:Loaded test example. [1.672s]\n",
      "INFO:sleap.nn.training:  Input shape: (544, 960, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=16, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=4, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 16\n",
      "INFO:sleap.nn.training:  Parameters: 1,953,393\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CentroidConfmapsHead(anchor_part=None, sigma=2.5, output_stride=2, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 272, 480, 1), dtype=tf.float32, name=None), name='CentroidConfmapsHead/BiasAdd:0', description=\"created by layer 'CentroidConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=20)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [4.5s]\n",
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [31.0s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/20\n",
      "2024-10-02 16:13:02.004703: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 16:13:02.833993: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:02.834103: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.651121: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.651199: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.716734: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 16:13:03.816651: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.816710: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.838502: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 16:13:03.982833: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:03.982882: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:04.133637: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:04.133685: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:13:39.602817: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "360/360 - 41s - loss: 1.5295e-04 - val_loss: 1.5117e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 2/20\n",
      "360/360 - 31s - loss: 1.5035e-04 - val_loss: 1.5054e-04 - lr: 1.0000e-04 - 31s/epoch - 86ms/step\n",
      "Epoch 3/20\n",
      "360/360 - 32s - loss: 1.5018e-04 - val_loss: 1.5030e-04 - lr: 1.0000e-04 - 32s/epoch - 90ms/step\n",
      "Epoch 4/20\n",
      "360/360 - 33s - loss: 1.4970e-04 - val_loss: 1.4975e-04 - lr: 1.0000e-04 - 33s/epoch - 92ms/step\n",
      "Epoch 5/20\n",
      "360/360 - 32s - loss: 1.4968e-04 - val_loss: 1.4945e-04 - lr: 1.0000e-04 - 32s/epoch - 88ms/step\n",
      "Epoch 6/20\n",
      "360/360 - 32s - loss: 1.4970e-04 - val_loss: 1.5022e-04 - lr: 1.0000e-04 - 32s/epoch - 88ms/step\n",
      "Epoch 7/20\n",
      "360/360 - 32s - loss: 1.5008e-04 - val_loss: 1.5014e-04 - lr: 1.0000e-04 - 32s/epoch - 90ms/step\n",
      "Epoch 8/20\n",
      "360/360 - 33s - loss: 1.4963e-04 - val_loss: 1.5022e-04 - lr: 1.0000e-04 - 33s/epoch - 91ms/step\n",
      "Epoch 9/20\n",
      "360/360 - 30s - loss: 1.4944e-04 - val_loss: 1.5007e-04 - lr: 1.0000e-04 - 30s/epoch - 84ms/step\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "360/360 - 30s - loss: 1.4975e-04 - val_loss: 1.5006e-04 - lr: 1.0000e-04 - 30s/epoch - 84ms/step\n",
      "Epoch 11/20\n",
      "360/360 - 31s - loss: 1.4571e-04 - val_loss: 1.5353e-04 - lr: 5.0000e-05 - 31s/epoch - 86ms/step\n",
      "Epoch 12/20\n",
      "360/360 - 33s - loss: 1.4493e-04 - val_loss: 1.5025e-04 - lr: 5.0000e-05 - 33s/epoch - 91ms/step\n",
      "Epoch 13/20\n",
      "360/360 - 34s - loss: 1.4597e-04 - val_loss: 1.4876e-04 - lr: 5.0000e-05 - 34s/epoch - 95ms/step\n",
      "Epoch 14/20\n",
      "360/360 - 31s - loss: 1.4113e-04 - val_loss: 1.4997e-04 - lr: 5.0000e-05 - 31s/epoch - 87ms/step\n",
      "Epoch 15/20\n",
      "360/360 - 31s - loss: 1.4169e-04 - val_loss: 1.4977e-04 - lr: 5.0000e-05 - 31s/epoch - 86ms/step\n",
      "Epoch 16/20\n",
      "360/360 - 33s - loss: 1.3818e-04 - val_loss: 1.5117e-04 - lr: 5.0000e-05 - 33s/epoch - 93ms/step\n",
      "Epoch 17/20\n",
      "360/360 - 34s - loss: 1.3615e-04 - val_loss: 1.5285e-04 - lr: 5.0000e-05 - 34s/epoch - 93ms/step\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "360/360 - 34s - loss: 1.3412e-04 - val_loss: 1.5159e-04 - lr: 5.0000e-05 - 34s/epoch - 94ms/step\n",
      "Epoch 19/20\n",
      "360/360 - 34s - loss: 1.2973e-04 - val_loss: 1.5337e-04 - lr: 2.5000e-05 - 34s/epoch - 94ms/step\n",
      "Epoch 20/20\n",
      "360/360 - 31s - loss: 1.2743e-04 - val_loss: 1.5089e-04 - lr: 2.5000e-05 - 31s/epoch - 85ms/step\n",
      "INFO:sleap.nn.training:Finished training loop. [10.9 min]\n",
      "INFO:sleap.nn.training:Deleting visualization directory: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/viz\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m13.1 FPS\u001b[0m1 FPS\u001b[0m0 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.039604\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m19.7 FPS\u001b[0m \u001b[31m20.7 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.059406\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m16.0 FPS\u001b[0m \u001b[31m16.3 FPS\u001b[0m\n",
      "\u001b[?25h/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/evals.py:539: RuntimeWarning: Mean of empty slice\n",
      "  \"dist.avg\": np.nanmean(dists),\n",
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/evals.py:572: RuntimeWarning: Mean of empty slice.\n",
      "  mPCK = mPCK_parts.mean()\n",
      "/home/matthew/anaconda3/envs/sleap/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/evals.py:666: RuntimeWarning: Mean of empty slice.\n",
      "  pair_pck = metrics[\"pck.pcks\"].mean(axis=-1).mean(axis=-1)\n",
      "/home/matthew/anaconda3/envs/sleap/lib/python3.7/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/evals.py:668: RuntimeWarning: Mean of empty slice.\n",
      "  metrics[\"oks.mOKS\"] = pair_oks.mean()\n",
      "WARNING:sleap.nn.evals:Failed to compute metrics.\n",
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.test.slp\n"
     ]
    }
   ],
   "source": [
    "# you need to move the adjusted baselines into the correc\n",
    "!sleap-train baseline.centroid_adjusted.json \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\" --val_labels \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\" --test_labels \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\" --run_name \"Oct2_test1_centroid_50Epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "INFO:sleap.nn.training:Training labels file: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Training profile: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/training_profiles/baseline_medium_rf.topdown_adjusted.json\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Arguments:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"training_job_path\": \"baseline_medium_rf.topdown_adjusted.json\",\n",
      "    \"labels_path\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\",\n",
      "    \"video_paths\": [\n",
      "        \"\"\n",
      "    ],\n",
      "    \"val_labels\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\",\n",
      "    \"test_labels\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\",\n",
      "    \"base_checkpoint\": null,\n",
      "    \"tensorboard\": false,\n",
      "    \"save_viz\": false,\n",
      "    \"keep_viz\": false,\n",
      "    \"zmq\": false,\n",
      "    \"publish_port\": 9001,\n",
      "    \"controller_port\": 9000,\n",
      "    \"run_name\": \"Oct2_test1_medium_rf.topdown_50Epoch\",\n",
      "    \"prefix\": \"\",\n",
      "    \"suffix\": \"\",\n",
      "    \"cpu\": false,\n",
      "    \"first_gpu\": false,\n",
      "    \"last_gpu\": false,\n",
      "    \"gpu\": \"auto\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Training job:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"data\": {\n",
      "        \"labels\": {\n",
      "            \"training_labels\": null,\n",
      "            \"validation_labels\": null,\n",
      "            \"validation_fraction\": 0.1,\n",
      "            \"test_labels\": null,\n",
      "            \"split_by_inds\": false,\n",
      "            \"training_inds\": null,\n",
      "            \"validation_inds\": null,\n",
      "            \"test_inds\": null,\n",
      "            \"search_path_hints\": [],\n",
      "            \"skeletons\": []\n",
      "        },\n",
      "        \"preprocessing\": {\n",
      "            \"ensure_rgb\": false,\n",
      "            \"ensure_grayscale\": false,\n",
      "            \"imagenet_mode\": null,\n",
      "            \"input_scaling\": 1.0,\n",
      "            \"pad_to_stride\": null,\n",
      "            \"resize_and_pad_to_target\": true,\n",
      "            \"target_height\": null,\n",
      "            \"target_width\": null\n",
      "        },\n",
      "        \"instance_cropping\": {\n",
      "            \"center_on_part\": null,\n",
      "            \"crop_size\": null,\n",
      "            \"crop_size_detection_padding\": 16\n",
      "        }\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"backbone\": {\n",
      "            \"leap\": null,\n",
      "            \"unet\": {\n",
      "                \"stem_stride\": null,\n",
      "                \"max_stride\": 16,\n",
      "                \"output_stride\": 4,\n",
      "                \"filters\": 24,\n",
      "                \"filters_rate\": 2.0,\n",
      "                \"middle_block\": true,\n",
      "                \"up_interpolate\": true,\n",
      "                \"stacks\": 1\n",
      "            },\n",
      "            \"hourglass\": null,\n",
      "            \"resnet\": null,\n",
      "            \"pretrained_encoder\": null\n",
      "        },\n",
      "        \"heads\": {\n",
      "            \"single_instance\": null,\n",
      "            \"centroid\": null,\n",
      "            \"centered_instance\": {\n",
      "                \"anchor_part\": null,\n",
      "                \"part_names\": null,\n",
      "                \"sigma\": 2.5,\n",
      "                \"output_stride\": 4,\n",
      "                \"loss_weight\": 1.0,\n",
      "                \"offset_refinement\": false\n",
      "            },\n",
      "            \"multi_instance\": null,\n",
      "            \"multi_class_bottomup\": null,\n",
      "            \"multi_class_topdown\": null\n",
      "        },\n",
      "        \"base_checkpoint\": null\n",
      "    },\n",
      "    \"optimization\": {\n",
      "        \"preload_data\": true,\n",
      "        \"augmentation_config\": {\n",
      "            \"rotate\": true,\n",
      "            \"rotation_min_angle\": -15.0,\n",
      "            \"rotation_max_angle\": 15.0,\n",
      "            \"translate\": false,\n",
      "            \"translate_min\": -5,\n",
      "            \"translate_max\": 5,\n",
      "            \"scale\": false,\n",
      "            \"scale_min\": 0.9,\n",
      "            \"scale_max\": 1.1,\n",
      "            \"uniform_noise\": false,\n",
      "            \"uniform_noise_min_val\": 0.0,\n",
      "            \"uniform_noise_max_val\": 10.0,\n",
      "            \"gaussian_noise\": false,\n",
      "            \"gaussian_noise_mean\": 5.0,\n",
      "            \"gaussian_noise_stddev\": 1.0,\n",
      "            \"contrast\": false,\n",
      "            \"contrast_min_gamma\": 0.5,\n",
      "            \"contrast_max_gamma\": 2.0,\n",
      "            \"brightness\": false,\n",
      "            \"brightness_min_val\": 0.0,\n",
      "            \"brightness_max_val\": 10.0,\n",
      "            \"random_crop\": false,\n",
      "            \"random_crop_height\": 256,\n",
      "            \"random_crop_width\": 256,\n",
      "            \"random_flip\": false,\n",
      "            \"flip_horizontal\": true\n",
      "        },\n",
      "        \"online_shuffling\": true,\n",
      "        \"shuffle_buffer_size\": 128,\n",
      "        \"prefetch\": true,\n",
      "        \"batch_size\": 1,\n",
      "        \"batches_per_epoch\": null,\n",
      "        \"min_batches_per_epoch\": 200,\n",
      "        \"val_batches_per_epoch\": null,\n",
      "        \"min_val_batches_per_epoch\": 10,\n",
      "        \"epochs\": 20,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"initial_learning_rate\": 0.0001,\n",
      "        \"learning_rate_schedule\": {\n",
      "            \"reduce_on_plateau\": true,\n",
      "            \"reduction_factor\": 0.5,\n",
      "            \"plateau_min_delta\": 1e-08,\n",
      "            \"plateau_patience\": 5,\n",
      "            \"plateau_cooldown\": 3,\n",
      "            \"min_learning_rate\": 1e-08\n",
      "        },\n",
      "        \"hard_keypoint_mining\": {\n",
      "            \"online_mining\": false,\n",
      "            \"hard_to_easy_ratio\": 2.0,\n",
      "            \"min_hard_keypoints\": 2,\n",
      "            \"max_hard_keypoints\": null,\n",
      "            \"loss_scale\": 5.0\n",
      "        },\n",
      "        \"early_stopping\": {\n",
      "            \"stop_training_on_plateau\": true,\n",
      "            \"plateau_min_delta\": 1e-08,\n",
      "            \"plateau_patience\": 10\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"save_outputs\": true,\n",
      "        \"run_name\": \"Oct2_test1_medium_rf.topdown_50Epoch\",\n",
      "        \"run_name_prefix\": \"\",\n",
      "        \"run_name_suffix\": null,\n",
      "        \"runs_folder\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models\",\n",
      "        \"tags\": [],\n",
      "        \"save_visualizations\": true,\n",
      "        \"keep_viz_images\": false,\n",
      "        \"zip_outputs\": false,\n",
      "        \"log_to_csv\": true,\n",
      "        \"checkpointing\": {\n",
      "            \"initial_model\": false,\n",
      "            \"best_model\": true,\n",
      "            \"every_epoch\": false,\n",
      "            \"latest_model\": false,\n",
      "            \"final_model\": false\n",
      "        },\n",
      "        \"tensorboard\": {\n",
      "            \"write_logs\": false,\n",
      "            \"loss_frequency\": \"epoch\",\n",
      "            \"architecture_graph\": true,\n",
      "            \"profile_graph\": false,\n",
      "            \"visualizations\": true\n",
      "        },\n",
      "        \"zmq\": {\n",
      "            \"subscribe_to_controller\": false,\n",
      "            \"controller_address\": \"tcp://127.0.0.1:9000\",\n",
      "            \"controller_polling_timeout\": 10,\n",
      "            \"publish_updates\": false,\n",
      "            \"publish_address\": \"tcp://127.0.0.1:9001\"\n",
      "        }\n",
      "    },\n",
      "    \"name\": \"\",\n",
      "    \"description\": \"\",\n",
      "    \"sleap_version\": \"1.4.1a2\",\n",
      "    \"filename\": \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/training_profiles/baseline_medium_rf.topdown_adjusted.json\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "2024-10-02 16:42:02.410229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:02.419251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:02.422133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.training:Auto-selected GPU 0 with 3033 MiB of free memory.\n",
      "INFO:sleap.nn.training:Using GPU 0 for acceleration.\n",
      "INFO:sleap.nn.training:Disabled GPU memory pre-allocation.\n",
      "INFO:sleap.nn.training:System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Initializing trainer...\n",
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n",
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "2024-10-02 16:42:03.277412: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 16:42:03.278825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.282998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.285793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.897396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.898804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.900038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 16:42:03.901289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "INFO:sleap.nn.training:Loaded test example. [2.520s]\n",
      "INFO:sleap.nn.training:  Input shape: (976, 976, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=24, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=4, middle_block=True, up_blocks=2, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 16\n",
      "INFO:sleap.nn.training:  Parameters: 4,311,392\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CenteredInstanceConfmapsHead(part_names=['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot'], anchor_part=None, sigma=2.5, output_stride=4, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 244, 244, 8), dtype=tf.float32, name=None), name='CenteredInstanceConfmapsHead/BiasAdd:0', description=\"created by layer 'CenteredInstanceConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=10)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [4.5s]\n",
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [31.7s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/20\n",
      "2024-10-02 16:42:42.846358: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 16:42:44.009630: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:44.009978: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:44.923169: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.90MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:44.923228: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.90MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.117504: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.117553: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.298020: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.298068: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.361959: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:42:45.362015: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.31GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 16:43:41.834522: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 16:43:42.660028: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "360/360 - 65s - loss: 2.8515e-04 - Head: 3.2415e-04 - Beak: 3.0691e-04 - Body_top: 3.1802e-04 - RFlipper_mid: 2.4756e-04 - LFlipper_mid: 2.4997e-04 - Body_bottom: 3.1775e-04 - RFoot: 2.6860e-04 - LFoot: 2.4824e-04 - val_loss: 2.7725e-04 - val_Head: 3.2349e-04 - val_Beak: 2.6330e-04 - val_Body_top: 3.2758e-04 - val_RFlipper_mid: 2.1957e-04 - val_LFlipper_mid: 3.2816e-04 - val_Body_bottom: 3.2871e-04 - val_RFoot: 2.1382e-04 - val_LFoot: 2.1339e-04 - lr: 1.0000e-04 - 65s/epoch - 181ms/step\n",
      "Epoch 2/20\n",
      "360/360 - 55s - loss: 2.8365e-04 - Head: 3.2260e-04 - Beak: 3.0419e-04 - Body_top: 3.1667e-04 - RFlipper_mid: 2.4705e-04 - LFlipper_mid: 2.4915e-04 - Body_bottom: 3.1719e-04 - RFoot: 2.6570e-04 - LFoot: 2.4663e-04 - val_loss: 2.7746e-04 - val_Head: 3.2367e-04 - val_Beak: 2.6320e-04 - val_Body_top: 3.2892e-04 - val_RFlipper_mid: 2.1913e-04 - val_LFlipper_mid: 3.2786e-04 - val_Body_bottom: 3.2922e-04 - val_RFoot: 2.1395e-04 - val_LFoot: 2.1376e-04 - lr: 1.0000e-04 - 55s/epoch - 152ms/step\n",
      "Epoch 3/20\n",
      "360/360 - 56s - loss: 2.8365e-04 - Head: 3.2273e-04 - Beak: 3.0483e-04 - Body_top: 3.1607e-04 - RFlipper_mid: 2.4639e-04 - LFlipper_mid: 2.4835e-04 - Body_bottom: 3.1637e-04 - RFoot: 2.6719e-04 - LFoot: 2.4723e-04 - val_loss: 2.7661e-04 - val_Head: 3.2831e-04 - val_Beak: 2.6342e-04 - val_Body_top: 3.2226e-04 - val_RFlipper_mid: 2.1918e-04 - val_LFlipper_mid: 3.2725e-04 - val_Body_bottom: 3.2914e-04 - val_RFoot: 2.1223e-04 - val_LFoot: 2.1108e-04 - lr: 1.0000e-04 - 56s/epoch - 157ms/step\n",
      "Epoch 4/20\n",
      "360/360 - 57s - loss: 2.8185e-04 - Head: 3.1368e-04 - Beak: 3.0524e-04 - Body_top: 3.1374e-04 - RFlipper_mid: 2.4589e-04 - LFlipper_mid: 2.4745e-04 - Body_bottom: 3.1768e-04 - RFoot: 2.6479e-04 - LFoot: 2.4634e-04 - val_loss: 2.7625e-04 - val_Head: 3.2228e-04 - val_Beak: 2.6370e-04 - val_Body_top: 3.2260e-04 - val_RFlipper_mid: 2.1884e-04 - val_LFlipper_mid: 3.2847e-04 - val_Body_bottom: 3.2862e-04 - val_RFoot: 2.1271e-04 - val_LFoot: 2.1281e-04 - lr: 1.0000e-04 - 57s/epoch - 158ms/step\n",
      "Epoch 5/20\n",
      "360/360 - 58s - loss: 2.8099e-04 - Head: 3.1478e-04 - Beak: 3.0666e-04 - Body_top: 3.1174e-04 - RFlipper_mid: 2.4529e-04 - LFlipper_mid: 2.4644e-04 - Body_bottom: 3.1840e-04 - RFoot: 2.6081e-04 - LFoot: 2.4381e-04 - val_loss: 2.7297e-04 - val_Head: 3.0546e-04 - val_Beak: 2.6355e-04 - val_Body_top: 3.1973e-04 - val_RFlipper_mid: 2.1819e-04 - val_LFlipper_mid: 3.2656e-04 - val_Body_bottom: 3.2942e-04 - val_RFoot: 2.1219e-04 - val_LFoot: 2.0868e-04 - lr: 1.0000e-04 - 58s/epoch - 161ms/step\n",
      "Epoch 6/20\n",
      "360/360 - 57s - loss: 2.7428e-04 - Head: 2.9125e-04 - Beak: 3.0391e-04 - Body_top: 3.0681e-04 - RFlipper_mid: 2.4315e-04 - LFlipper_mid: 2.4451e-04 - Body_bottom: 3.1712e-04 - RFoot: 2.5147e-04 - LFoot: 2.3599e-04 - val_loss: 2.7054e-04 - val_Head: 2.7985e-04 - val_Beak: 2.6383e-04 - val_Body_top: 3.2169e-04 - val_RFlipper_mid: 2.1449e-04 - val_LFlipper_mid: 3.3197e-04 - val_Body_bottom: 3.2860e-04 - val_RFoot: 2.1366e-04 - val_LFoot: 2.1025e-04 - lr: 1.0000e-04 - 57s/epoch - 159ms/step\n",
      "Epoch 7/20\n",
      "360/360 - 56s - loss: 2.6868e-04 - Head: 2.7467e-04 - Beak: 3.0122e-04 - Body_top: 2.9817e-04 - RFlipper_mid: 2.4220e-04 - LFlipper_mid: 2.4182e-04 - Body_bottom: 3.1753e-04 - RFoot: 2.3949e-04 - LFoot: 2.3437e-04 - val_loss: 2.6498e-04 - val_Head: 2.8668e-04 - val_Beak: 2.6301e-04 - val_Body_top: 3.0552e-04 - val_RFlipper_mid: 2.1278e-04 - val_LFlipper_mid: 3.3004e-04 - val_Body_bottom: 3.3008e-04 - val_RFoot: 1.9923e-04 - val_LFoot: 1.9252e-04 - lr: 1.0000e-04 - 56s/epoch - 156ms/step\n",
      "Epoch 8/20\n",
      "360/360 - 56s - loss: 2.6115e-04 - Head: 2.6146e-04 - Beak: 3.0116e-04 - Body_top: 2.9205e-04 - RFlipper_mid: 2.4195e-04 - LFlipper_mid: 2.3864e-04 - Body_bottom: 3.1738e-04 - RFoot: 2.1416e-04 - LFoot: 2.2243e-04 - val_loss: 2.6291e-04 - val_Head: 2.8536e-04 - val_Beak: 2.6169e-04 - val_Body_top: 3.1398e-04 - val_RFlipper_mid: 2.1144e-04 - val_LFlipper_mid: 3.3126e-04 - val_Body_bottom: 3.2977e-04 - val_RFoot: 1.8538e-04 - val_LFoot: 1.8441e-04 - lr: 1.0000e-04 - 56s/epoch - 157ms/step\n",
      "Epoch 9/20\n",
      "360/360 - 56s - loss: 2.4914e-04 - Head: 2.2624e-04 - Beak: 2.9275e-04 - Body_top: 2.7946e-04 - RFlipper_mid: 2.3490e-04 - LFlipper_mid: 2.3714e-04 - Body_bottom: 3.1878e-04 - RFoot: 1.9516e-04 - LFoot: 2.0873e-04 - val_loss: 2.7080e-04 - val_Head: 2.7529e-04 - val_Beak: 2.8132e-04 - val_Body_top: 3.8793e-04 - val_RFlipper_mid: 2.1640e-04 - val_LFlipper_mid: 3.3340e-04 - val_Body_bottom: 3.2973e-04 - val_RFoot: 1.6020e-04 - val_LFoot: 1.8212e-04 - lr: 1.0000e-04 - 56s/epoch - 155ms/step\n",
      "Epoch 10/20\n",
      "360/360 - 58s - loss: 2.4035e-04 - Head: 2.2406e-04 - Beak: 2.7320e-04 - Body_top: 2.6487e-04 - RFlipper_mid: 2.3396e-04 - LFlipper_mid: 2.2401e-04 - Body_bottom: 3.1616e-04 - RFoot: 1.8580e-04 - LFoot: 2.0075e-04 - val_loss: 2.7065e-04 - val_Head: 2.5833e-04 - val_Beak: 2.6352e-04 - val_Body_top: 3.7228e-04 - val_RFlipper_mid: 2.2314e-04 - val_LFlipper_mid: 3.3537e-04 - val_Body_bottom: 3.2893e-04 - val_RFoot: 1.9002e-04 - val_LFoot: 1.9359e-04 - lr: 1.0000e-04 - 58s/epoch - 160ms/step\n",
      "Epoch 11/20\n",
      "360/360 - 54s - loss: 2.2410e-04 - Head: 2.0005e-04 - Beak: 2.4961e-04 - Body_top: 2.4946e-04 - RFlipper_mid: 2.2992e-04 - LFlipper_mid: 2.0732e-04 - Body_bottom: 3.1590e-04 - RFoot: 1.6587e-04 - LFoot: 1.7465e-04 - val_loss: 2.5499e-04 - val_Head: 2.5696e-04 - val_Beak: 2.4461e-04 - val_Body_top: 3.0428e-04 - val_RFlipper_mid: 2.0840e-04 - val_LFlipper_mid: 3.2805e-04 - val_Body_bottom: 3.3003e-04 - val_RFoot: 1.8045e-04 - val_LFoot: 1.8710e-04 - lr: 1.0000e-04 - 54s/epoch - 149ms/step\n",
      "Epoch 12/20\n",
      "360/360 - 54s - loss: 2.1399e-04 - Head: 1.8935e-04 - Beak: 2.1652e-04 - Body_top: 2.3490e-04 - RFlipper_mid: 2.2607e-04 - LFlipper_mid: 2.1254e-04 - Body_bottom: 3.1240e-04 - RFoot: 1.5841e-04 - LFoot: 1.6171e-04 - val_loss: 2.5575e-04 - val_Head: 2.5416e-04 - val_Beak: 2.5181e-04 - val_Body_top: 3.1828e-04 - val_RFlipper_mid: 2.1659e-04 - val_LFlipper_mid: 3.3457e-04 - val_Body_bottom: 3.2866e-04 - val_RFoot: 1.5963e-04 - val_LFoot: 1.8230e-04 - lr: 1.0000e-04 - 54s/epoch - 150ms/step\n",
      "Epoch 13/20\n",
      "360/360 - 55s - loss: 2.0233e-04 - Head: 1.8093e-04 - Beak: 1.9691e-04 - Body_top: 2.2990e-04 - RFlipper_mid: 2.1859e-04 - LFlipper_mid: 1.9143e-04 - Body_bottom: 3.1089e-04 - RFoot: 1.4242e-04 - LFoot: 1.4759e-04 - val_loss: 2.4614e-04 - val_Head: 2.1562e-04 - val_Beak: 2.3457e-04 - val_Body_top: 3.1003e-04 - val_RFlipper_mid: 2.0572e-04 - val_LFlipper_mid: 3.1660e-04 - val_Body_bottom: 3.2941e-04 - val_RFoot: 1.7173e-04 - val_LFoot: 1.8540e-04 - lr: 1.0000e-04 - 55s/epoch - 152ms/step\n",
      "Epoch 14/20\n",
      "360/360 - 57s - loss: 1.9430e-04 - Head: 1.6538e-04 - Beak: 1.8434e-04 - Body_top: 2.1532e-04 - RFlipper_mid: 2.1415e-04 - LFlipper_mid: 1.7999e-04 - Body_bottom: 3.0967e-04 - RFoot: 1.3932e-04 - LFoot: 1.4627e-04 - val_loss: 2.4486e-04 - val_Head: 2.1625e-04 - val_Beak: 2.2271e-04 - val_Body_top: 3.2307e-04 - val_RFlipper_mid: 2.0897e-04 - val_LFlipper_mid: 3.1658e-04 - val_Body_bottom: 3.2965e-04 - val_RFoot: 1.5376e-04 - val_LFoot: 1.8791e-04 - lr: 1.0000e-04 - 57s/epoch - 159ms/step\n",
      "Epoch 15/20\n",
      "360/360 - 58s - loss: 1.8672e-04 - Head: 1.6049e-04 - Beak: 1.6594e-04 - Body_top: 2.1704e-04 - RFlipper_mid: 2.0541e-04 - LFlipper_mid: 1.8129e-04 - Body_bottom: 2.9907e-04 - RFoot: 1.2614e-04 - LFoot: 1.3841e-04 - val_loss: 2.4577e-04 - val_Head: 2.1623e-04 - val_Beak: 2.1734e-04 - val_Body_top: 3.0423e-04 - val_RFlipper_mid: 2.1361e-04 - val_LFlipper_mid: 3.1864e-04 - val_Body_bottom: 3.4008e-04 - val_RFoot: 1.7297e-04 - val_LFoot: 1.8311e-04 - lr: 1.0000e-04 - 58s/epoch - 162ms/step\n",
      "Epoch 16/20\n",
      "360/360 - 55s - loss: 1.7726e-04 - Head: 1.5162e-04 - Beak: 1.5398e-04 - Body_top: 1.9774e-04 - RFlipper_mid: 1.9864e-04 - LFlipper_mid: 1.7503e-04 - Body_bottom: 2.8643e-04 - RFoot: 1.2078e-04 - LFoot: 1.3384e-04 - val_loss: 2.4815e-04 - val_Head: 2.1550e-04 - val_Beak: 2.1119e-04 - val_Body_top: 3.1058e-04 - val_RFlipper_mid: 2.0482e-04 - val_LFlipper_mid: 3.7173e-04 - val_Body_bottom: 3.3329e-04 - val_RFoot: 1.6068e-04 - val_LFoot: 1.7744e-04 - lr: 1.0000e-04 - 55s/epoch - 153ms/step\n",
      "Epoch 17/20\n",
      "360/360 - 55s - loss: 1.6908e-04 - Head: 1.4302e-04 - Beak: 1.4073e-04 - Body_top: 1.9279e-04 - RFlipper_mid: 1.9959e-04 - LFlipper_mid: 1.6838e-04 - Body_bottom: 2.6533e-04 - RFoot: 1.1506e-04 - LFoot: 1.2772e-04 - val_loss: 2.4195e-04 - val_Head: 2.3230e-04 - val_Beak: 2.1104e-04 - val_Body_top: 3.1387e-04 - val_RFlipper_mid: 2.1707e-04 - val_LFlipper_mid: 3.1108e-04 - val_Body_bottom: 3.2483e-04 - val_RFoot: 1.4787e-04 - val_LFoot: 1.7750e-04 - lr: 1.0000e-04 - 55s/epoch - 152ms/step\n",
      "Epoch 18/20\n",
      "360/360 - 54s - loss: 1.6157e-04 - Head: 1.2944e-04 - Beak: 1.4012e-04 - Body_top: 1.7992e-04 - RFlipper_mid: 1.8211e-04 - LFlipper_mid: 1.6377e-04 - Body_bottom: 2.6255e-04 - RFoot: 1.1420e-04 - LFoot: 1.2043e-04 - val_loss: 2.4253e-04 - val_Head: 2.0392e-04 - val_Beak: 2.0353e-04 - val_Body_top: 3.1230e-04 - val_RFlipper_mid: 2.0910e-04 - val_LFlipper_mid: 3.1003e-04 - val_Body_bottom: 3.6914e-04 - val_RFoot: 1.5277e-04 - val_LFoot: 1.7945e-04 - lr: 1.0000e-04 - 54s/epoch - 151ms/step\n",
      "Epoch 19/20\n",
      "360/360 - 54s - loss: 1.5524e-04 - Head: 1.2514e-04 - Beak: 1.3006e-04 - Body_top: 1.7709e-04 - RFlipper_mid: 1.7619e-04 - LFlipper_mid: 1.6219e-04 - Body_bottom: 2.4674e-04 - RFoot: 1.1028e-04 - LFoot: 1.1419e-04 - val_loss: 2.3655e-04 - val_Head: 2.0938e-04 - val_Beak: 1.9144e-04 - val_Body_top: 3.1768e-04 - val_RFlipper_mid: 2.0393e-04 - val_LFlipper_mid: 3.1068e-04 - val_Body_bottom: 3.3613e-04 - val_RFoot: 1.4984e-04 - val_LFoot: 1.7335e-04 - lr: 1.0000e-04 - 54s/epoch - 151ms/step\n",
      "Epoch 20/20\n",
      "360/360 - 54s - loss: 1.5279e-04 - Head: 1.2214e-04 - Beak: 1.2366e-04 - Body_top: 1.7180e-04 - RFlipper_mid: 1.7555e-04 - LFlipper_mid: 1.5851e-04 - Body_bottom: 2.5163e-04 - RFoot: 1.0587e-04 - LFoot: 1.1315e-04 - val_loss: 2.4001e-04 - val_Head: 2.1305e-04 - val_Beak: 1.9596e-04 - val_Body_top: 3.0353e-04 - val_RFlipper_mid: 2.1987e-04 - val_LFlipper_mid: 3.1930e-04 - val_Body_bottom: 3.3975e-04 - val_RFoot: 1.4992e-04 - val_LFoot: 1.7874e-04 - lr: 1.0000e-04 - 54s/epoch - 150ms/step\n",
      "INFO:sleap.nn.training:Finished training loop. [18.8 min]\n",
      "INFO:sleap.nn.training:Deleting visualization directory: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/viz\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 17:01:27.135180: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m10.2 FPS\u001b[0m4 FPS\u001b[0m3 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.265319\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m12.3 FPS\u001b[0m \u001b[31m12.6 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.000741\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m10.3 FPS\u001b[0m \u001b[31m10.5 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.test.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.test.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.067142\n"
     ]
    }
   ],
   "source": [
    "!sleap-train baseline_medium_rf.topdown_adjusted.json \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\" --val_labels \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\" --test_labels \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\" --run_name \"Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to run inference. I will pass a video this time\n",
    "*potentially change to a directory with images\n",
    "\n",
    "!sleap-track \"dataset/drosophila-melanogaster-courtship/20190128_113421.mp4\" --frames 0-100 -m \"models/courtship.centroid\" -m \"models/courtship.topdown_confmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 17:38:38.786980\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 17:38:38.823485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.844646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.857289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 2984 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\n",
      "2024-10-02 17:38:38.941508: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 17:38:38.942767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.956094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.960123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.587590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.588900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.590020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.591594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1202 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 17:38:44.285992: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 17:38:45.373395: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:45.373460: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.166344: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.166405: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.227468: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.227531: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.319752: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.319815: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.338854: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 17:38:46.475251: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.475324: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m16.7 FPS\u001b[0m6 FPS\u001b[0m8 FPS\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 17:38:54.060876\n",
      "Total runtime: 15.273920774459839 secs\n",
      "Predicted frames: 147/147\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4 -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m15.273920774459839\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 17:38:38.786980'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 17:38:54.060876'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 18:10:06.164381\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 18:10:06.199842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:06.209992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:06.213740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 3010 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "2024-10-02 18:10:07.002319: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 18:10:07.004256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.009966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.013208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.400909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.402140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.404059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.405052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1240 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 18:10:12.291944: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 18:10:13.060962: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.061037: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.560261: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.560317: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.622518: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.622576: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.712253: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.712307: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.731610: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 18:10:13.869447: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.869510: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m30.1 FPS\u001b[0m \u001b[31m31.1 FPS\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:10:17.849119\n",
      "Total runtime: 11.684762954711914 secs\n",
      "Predicted frames: 80/80\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m11.684762954711914\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:10:06.164381'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:10:17.849119'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 18:13:19.469232\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 18:13:19.505449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.514820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.519676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 3014 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.jpg\n",
      "2024-10-02 18:13:19.594895: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 18:13:19.596475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.600353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.606516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.992065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.993300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.994395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.995436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1227 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 18:13:24.120600: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 18:13:24.856016: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:24.856096: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.388804: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.388850: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.430346: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 18:13:25.536140: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.536191: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.558197: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.558248: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.622059: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.622109: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.678448: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:26.449140\n",
      "Total runtime: 6.979929685592651 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m6.979929685592651\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:26.449140'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:28.637856\n",
      "Total runtime: 9.168640375137329 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m9.168640375137329\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:28.637856'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:30.034574\n",
      "Total runtime: 10.5653555393219 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m10.5653555393219\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:30.034574'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:31.712635\n",
      "Total runtime: 12.243422269821167 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m12.243422269821167\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:31.712635'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0mWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2efc373ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:33.151504\n",
      "Total runtime: 13.682286977767944 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m13.682286977767944\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:33.151504'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0mWARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2efc1eedd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:34.562574\n",
      "Total runtime: 15.093356370925903 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m15.093356370925903\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:34.562574'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:36.409931\n",
      "Total runtime: 16.94071340560913 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m16.94071340560913\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:36.409931'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:37.829495\n",
      "Total runtime: 18.36027765274048 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m18.36027765274048\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:37.829495'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:39.336149\n",
      "Total runtime: 19.86693286895752 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m19.86693286895752\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:39.336149'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:40.814249\n",
      "Total runtime: 21.345032215118408 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m21.345032215118408\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:40.814249'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I will inspect the predicted frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 147\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\n",
      "    labeled frames: 147\n",
      "    labeled frames from 0 to 146\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "Total user labeled frames: 0\n",
      "\n",
      "Provenance:\n",
      "  model_paths: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json']\n",
      "  predictor: TopDownPredictor\n",
      "  sleap_version: 1.4.1a2\n",
      "  platform: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "  command: /home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4 -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\n",
      "  data_path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\n",
      "  output_path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp\n",
      "  total_elapsed: 15.273920774459839\n",
      "  start_timestamp: 2024-10-02 17:38:38.786980\n",
      "  finish_timestamp: 2024-10-02 17:38:54.060876\n",
      "  args: {'data_path': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4', 'models': ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'], 'frames': '', 'only_labeled_frames': False, 'only_suggested_frames': False, 'output': None, 'no_empty_frames': False, 'verbosity': 'rich', 'video.dataset': None, 'video.input_format': 'channels_last', 'video.index': '', 'cpu': False, 'first_gpu': False, 'last_gpu': False, 'gpu': 'auto', 'max_edge_length_ratio': 0.25, 'dist_penalty_weight': 1.0, 'batch_size': 4, 'open_in_gui': False, 'peak_threshold': 0.2, 'max_instances': None, 'tracking.tracker': None, 'tracking.max_tracking': None, 'tracking.max_tracks': None, 'tracking.target_instance_count': None, 'tracking.pre_cull_to_target': None, 'tracking.pre_cull_iou_threshold': None, 'tracking.post_connect_single_breaks': None, 'tracking.clean_instance_count': None, 'tracking.clean_iou_threshold': None, 'tracking.similarity': None, 'tracking.match': None, 'tracking.robust': None, 'tracking.track_window': None, 'tracking.min_new_track_points': None, 'tracking.min_match_points': None, 'tracking.img_scale': None, 'tracking.of_window_size': None, 'tracking.of_max_levels': None, 'tracking.save_shifted_instances': None, 'tracking.kf_node_indices': None, 'tracking.kf_init_frame_count': None, 'tracking.oks_errors': None, 'tracking.oks_score_weighting': None, 'tracking.oks_normalization': None}\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets inspect the training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 360\n",
      "Tracks: 36\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest44/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen37/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk62/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap4/img025.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand72/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk89/img021.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap3/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap7/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand82/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest65/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen84/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk80/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand79/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk82/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap12/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand67/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen31/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen33/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap2/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand4/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen50/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap14/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk68/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk64/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk57/img046.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest19/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk86/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen48/img012.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest42/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest30/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest39/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen35/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand11/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest24/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand6/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand75/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 360\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 360\n",
      "Tracks: 36\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest44/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen37/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk62/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap4/img025.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand72/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk89/img021.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap3/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap7/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand82/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest65/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen84/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk80/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand79/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk82/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap12/img002.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand67/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen31/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen33/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap2/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand4/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen50/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/flap14/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk68/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk64/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk57/img046.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest19/img005.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/walk86/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen48/img012.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest42/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest30/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest39/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/preen35/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand11/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/rest24/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand6/img009.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/train/labeled-data/stand75/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 360\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_gt.train.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 80\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand69/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/walk66/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/flap13/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/preen46/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand9/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand19/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/rest47/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/preen40/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 0\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.test.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 80\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand9/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand69/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/walk66/img004.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/rest47/img001.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/preen40/img006.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/stand19/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/flap13/img003.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/test/labeled-data/preen46/img008.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "Total user labeled frames: 0\n",
      "\n",
      "Provenance:\n",
      "  model_paths: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json']\n",
      "  predictor: TopDownPredictor\n",
      "  sleap_version: 1.4.1a2\n",
      "  platform: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "  command: /home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\n",
      "  data_path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp\n",
      "  output_path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp\n",
      "  total_elapsed: 11.684762954711914\n",
      "  start_timestamp: 2024-10-02 18:10:06.164381\n",
      "  finish_timestamp: 2024-10-02 18:10:17.849119\n",
      "  args: {'data_path': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp', 'models': ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'], 'frames': '', 'only_labeled_frames': False, 'only_suggested_frames': False, 'output': None, 'no_empty_frames': False, 'verbosity': 'rich', 'video.dataset': None, 'video.input_format': 'channels_last', 'video.index': '', 'cpu': False, 'first_gpu': False, 'last_gpu': False, 'gpu': 'auto', 'max_edge_length_ratio': 0.25, 'dist_penalty_weight': 1.0, 'batch_size': 4, 'open_in_gui': False, 'peak_threshold': 0.2, 'max_instances': None, 'tracking.tracker': None, 'tracking.max_tracking': None, 'tracking.max_tracks': None, 'tracking.target_instance_count': None, 'tracking.pre_cull_to_target': None, 'tracking.pre_cull_iou_threshold': None, 'tracking.post_connect_single_breaks': None, 'tracking.clean_instance_count': None, 'tracking.clean_iou_threshold': None, 'tracking.similarity': None, 'tracking.match': None, 'tracking.robust': None, 'tracking.track_window': None, 'tracking.min_new_track_points': None, 'tracking.min_match_points': None, 'tracking.img_scale': None, 'tracking.of_window_size': None, 'tracking.of_max_levels': None, 'tracking.save_shifted_instances': None, 'tracking.kf_node_indices': None, 'tracking.kf_init_frame_count': None, 'tracking.oks_errors': None, 'tracking.oks_score_weighting': None, 'tracking.oks_normalization': None}\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Using the python script to run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am trying to improve this the Oct2_test1 results with suggestions from here:\n",
    "https://github.com/talmolab/sleap/discussions/1595\n",
    "\n",
    "I also increased the plateau patience to 75 to avoid early stopping at roughly 20 epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to improve on Oct2_test2 by increasing  the plateau patience further and selecting a centroid (the Body_top)\n",
    "\n",
    "Trying to improve on Oct3_test1 by saving the final model as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "cfg = sleap.load_config(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/baseline.configs_adjusted/baseline.centroid_adjusted_python.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust config file with all model and data adjustments\n",
    "cfg.data.preprocessing.input_scaling = 0.5\n",
    "cfg.model.backbone.unet.max_stride = 32\n",
    "cfg.model.backbone.unet.filters = 24\n",
    "cfg.model.backbone.unet.filters_rate = 1.5\n",
    "cfg.model.heads.centroid.output_stride = 4\n",
    "\n",
    "# provide centroid position\n",
    "cfg.data.instance_cropping.center_on_part = 'Body_top'  #swap cnf with trainer.config\n",
    "cfg.model.heads.centroid.anchor_part = 'Body_top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n"
     ]
    }
   ],
   "source": [
    "trainer = sleap.nn.training.Trainer.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase number of epochs\n",
    "trainer.config.optimization.epochs = 200\n",
    "# keep the ouput images\n",
    "trainer.config.outputs.keep_viz_images = True\n",
    "# name of run\n",
    "trainer.config.outputs.run_name = 'Oct3_test1_centroid_200Epoch'\n",
    "# changes suggested by post\n",
    "###### THERE IS AN ISSUE WITH SETTING UP THE MODEL AFTER CREATING THE TRAINER... MOVE THIS TO BEFORE #### seems it is just the model set up that is an issue\n",
    "# trainer.config.data.preprocessing.input_scaling = 0.5\n",
    "# trainer.config.model.backbone.unet.max_stride = 32\n",
    "# trainer.config.model.backbone.unet.filters = 24\n",
    "# trainer.config.model.backbone.unet.filters_rate = 1.5\n",
    "# trainer.config.model.heads.centroid.output_stride = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final model\n",
    "trainer.config.outputs.checkpointing.latest_model = True\n",
    "trainer.config.outputs.checkpointing.final_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the early stopping\n",
    "trainer.config.optimization.early_stopping.plateau_patience = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALSO MOVING THESE TO BEFORE FOR SAFETY\n",
    "# provide centroid position\n",
    "# trainer.config.data.instance_cropping.center_on_part = 'Body_top'  #swap cnf with trainer.config\n",
    "# trainer.config.model.heads.centroid.anchor_part = 'Body_top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.config.save_json('check_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "INFO:sleap.nn.training:Loaded test example. [0.738s]\n",
      "INFO:sleap.nn.training:  Input shape: (544, 960, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=24, filters_rate=1.5, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=5, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 32\n",
      "INFO:sleap.nn.training:  Parameters: 1,645,179\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CentroidConfmapsHead(anchor_part='Body_top', sigma=2.5, output_stride=4, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 136, 240, 1), dtype=tf.float32, name=None), name='CentroidConfmapsHead/BiasAdd:0', description=\"created by layer 'CentroidConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=150)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [2.9s]\n"
     ]
    }
   ],
   "source": [
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the randomly initialized weights with the saved weights.\n",
    "#trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [34.1s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n",
      "360/360 - 34s - loss: 5.9138e-04 - val_loss: 5.7431e-04 - lr: 1.0000e-04 - 34s/epoch - 94ms/step\n",
      "Epoch 2/200\n",
      "360/360 - 29s - loss: 5.9036e-04 - val_loss: 5.8039e-04 - lr: 1.0000e-04 - 29s/epoch - 80ms/step\n",
      "Epoch 3/200\n",
      "360/360 - 27s - loss: 5.8219e-04 - val_loss: 5.5280e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 4/200\n",
      "360/360 - 29s - loss: 5.8243e-04 - val_loss: 5.4611e-04 - lr: 1.0000e-04 - 29s/epoch - 81ms/step\n",
      "Epoch 5/200\n",
      "360/360 - 26s - loss: 5.6993e-04 - val_loss: 5.6671e-04 - lr: 1.0000e-04 - 26s/epoch - 73ms/step\n",
      "Epoch 6/200\n",
      "360/360 - 27s - loss: 5.5594e-04 - val_loss: 5.1777e-04 - lr: 1.0000e-04 - 27s/epoch - 75ms/step\n",
      "Epoch 7/200\n",
      "360/360 - 27s - loss: 5.2325e-04 - val_loss: 5.1302e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 8/200\n",
      "360/360 - 27s - loss: 4.9841e-04 - val_loss: 5.3235e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 9/200\n",
      "360/360 - 27s - loss: 4.3034e-04 - val_loss: 4.8553e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 10/200\n",
      "360/360 - 29s - loss: 3.6894e-04 - val_loss: 4.6863e-04 - lr: 1.0000e-04 - 29s/epoch - 80ms/step\n",
      "Epoch 11/200\n",
      "360/360 - 26s - loss: 3.3371e-04 - val_loss: 4.5467e-04 - lr: 1.0000e-04 - 26s/epoch - 73ms/step\n",
      "Epoch 12/200\n",
      "360/360 - 27s - loss: 3.0269e-04 - val_loss: 4.6067e-04 - lr: 1.0000e-04 - 27s/epoch - 75ms/step\n",
      "Epoch 13/200\n",
      "360/360 - 29s - loss: 2.9503e-04 - val_loss: 4.4980e-04 - lr: 1.0000e-04 - 29s/epoch - 81ms/step\n",
      "Epoch 14/200\n",
      "360/360 - 27s - loss: 2.5955e-04 - val_loss: 4.8807e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 15/200\n",
      "360/360 - 27s - loss: 2.4479e-04 - val_loss: 6.0677e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 16/200\n",
      "360/360 - 29s - loss: 2.4209e-04 - val_loss: 4.8810e-04 - lr: 1.0000e-04 - 29s/epoch - 80ms/step\n",
      "Epoch 17/200\n",
      "360/360 - 27s - loss: 2.3819e-04 - val_loss: 4.3028e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 18/200\n",
      "360/360 - 29s - loss: 2.0290e-04 - val_loss: 5.0944e-04 - lr: 1.0000e-04 - 29s/epoch - 80ms/step\n",
      "Epoch 19/200\n",
      "360/360 - 26s - loss: 2.0759e-04 - val_loss: 4.5746e-04 - lr: 1.0000e-04 - 26s/epoch - 72ms/step\n",
      "Epoch 20/200\n",
      "360/360 - 29s - loss: 1.7132e-04 - val_loss: 4.6309e-04 - lr: 1.0000e-04 - 29s/epoch - 81ms/step\n",
      "Epoch 21/200\n",
      "360/360 - 29s - loss: 1.6447e-04 - val_loss: 4.7495e-04 - lr: 1.0000e-04 - 29s/epoch - 80ms/step\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "360/360 - 27s - loss: 1.5094e-04 - val_loss: 5.2237e-04 - lr: 1.0000e-04 - 27s/epoch - 74ms/step\n",
      "Epoch 23/200\n",
      "360/360 - 27s - loss: 1.2256e-04 - val_loss: 4.6171e-04 - lr: 5.0000e-05 - 27s/epoch - 74ms/step\n",
      "Epoch 24/200\n",
      "360/360 - 26s - loss: 1.1389e-04 - val_loss: 5.2912e-04 - lr: 5.0000e-05 - 26s/epoch - 73ms/step\n",
      "Epoch 25/200\n",
      "360/360 - 30s - loss: 1.0429e-04 - val_loss: 5.5380e-04 - lr: 5.0000e-05 - 30s/epoch - 82ms/step\n",
      "Epoch 26/200\n",
      "360/360 - 29s - loss: 9.7523e-05 - val_loss: 4.5192e-04 - lr: 5.0000e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 27/200\n",
      "360/360 - 29s - loss: 9.2095e-05 - val_loss: 4.7424e-04 - lr: 5.0000e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 28/200\n",
      "360/360 - 29s - loss: 9.0825e-05 - val_loss: 4.9945e-04 - lr: 5.0000e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "360/360 - 28s - loss: 8.0616e-05 - val_loss: 5.5909e-04 - lr: 5.0000e-05 - 28s/epoch - 79ms/step\n",
      "Epoch 30/200\n",
      "360/360 - 27s - loss: 6.5157e-05 - val_loss: 4.7145e-04 - lr: 2.5000e-05 - 27s/epoch - 74ms/step\n",
      "Epoch 31/200\n",
      "360/360 - 26s - loss: 6.4205e-05 - val_loss: 4.8022e-04 - lr: 2.5000e-05 - 26s/epoch - 73ms/step\n",
      "Epoch 32/200\n",
      "360/360 - 26s - loss: 6.0638e-05 - val_loss: 4.8415e-04 - lr: 2.5000e-05 - 26s/epoch - 72ms/step\n",
      "Epoch 33/200\n",
      "360/360 - 26s - loss: 5.9437e-05 - val_loss: 4.7917e-04 - lr: 2.5000e-05 - 26s/epoch - 73ms/step\n",
      "Epoch 34/200\n",
      "360/360 - 29s - loss: 5.6328e-05 - val_loss: 4.9246e-04 - lr: 2.5000e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 35/200\n",
      "360/360 - 29s - loss: 5.5681e-05 - val_loss: 4.6840e-04 - lr: 2.5000e-05 - 29s/epoch - 81ms/step\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "360/360 - 29s - loss: 5.5815e-05 - val_loss: 4.9719e-04 - lr: 2.5000e-05 - 29s/epoch - 81ms/step\n",
      "Epoch 37/200\n",
      "360/360 - 27s - loss: 4.9164e-05 - val_loss: 4.7482e-04 - lr: 1.2500e-05 - 27s/epoch - 75ms/step\n",
      "Epoch 38/200\n",
      "360/360 - 26s - loss: 4.9152e-05 - val_loss: 5.0144e-04 - lr: 1.2500e-05 - 26s/epoch - 73ms/step\n",
      "Epoch 39/200\n",
      "360/360 - 29s - loss: 4.5163e-05 - val_loss: 4.4696e-04 - lr: 1.2500e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 40/200\n",
      "360/360 - 29s - loss: 4.6504e-05 - val_loss: 4.8828e-04 - lr: 1.2500e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 41/200\n",
      "360/360 - 28s - loss: 4.3917e-05 - val_loss: 4.9430e-04 - lr: 1.2500e-05 - 28s/epoch - 78ms/step\n",
      "Epoch 42/200\n",
      "360/360 - 28s - loss: 4.2808e-05 - val_loss: 5.0749e-04 - lr: 1.2500e-05 - 28s/epoch - 78ms/step\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "360/360 - 29s - loss: 4.1586e-05 - val_loss: 4.9676e-04 - lr: 1.2500e-05 - 29s/epoch - 80ms/step\n",
      "Epoch 44/200\n",
      "360/360 - 26s - loss: 3.9963e-05 - val_loss: 4.9014e-04 - lr: 6.2500e-06 - 26s/epoch - 73ms/step\n",
      "Epoch 45/200\n",
      "360/360 - 28s - loss: 4.0186e-05 - val_loss: 4.8653e-04 - lr: 6.2500e-06 - 28s/epoch - 79ms/step\n",
      "Epoch 46/200\n",
      "360/360 - 27s - loss: 3.9122e-05 - val_loss: 5.2502e-04 - lr: 6.2500e-06 - 27s/epoch - 75ms/step\n",
      "Epoch 47/200\n",
      "360/360 - 29s - loss: 3.8249e-05 - val_loss: 4.9221e-04 - lr: 6.2500e-06 - 29s/epoch - 81ms/step\n",
      "Epoch 48/200\n",
      "360/360 - 29s - loss: 3.9998e-05 - val_loss: 5.0264e-04 - lr: 6.2500e-06 - 29s/epoch - 82ms/step\n",
      "Epoch 49/200\n",
      "360/360 - 27s - loss: 3.7623e-05 - val_loss: 5.0359e-04 - lr: 6.2500e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "360/360 - 27s - loss: 3.9328e-05 - val_loss: 4.6531e-04 - lr: 6.2500e-06 - 27s/epoch - 75ms/step\n",
      "Epoch 51/200\n",
      "360/360 - 27s - loss: 3.7462e-05 - val_loss: 5.2076e-04 - lr: 3.1250e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 52/200\n",
      "360/360 - 27s - loss: 3.6220e-05 - val_loss: 5.1589e-04 - lr: 3.1250e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 53/200\n",
      "360/360 - 27s - loss: 3.6652e-05 - val_loss: 4.7594e-04 - lr: 3.1250e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 54/200\n",
      "360/360 - 26s - loss: 3.6092e-05 - val_loss: 5.0980e-04 - lr: 3.1250e-06 - 26s/epoch - 73ms/step\n",
      "Epoch 55/200\n",
      "360/360 - 29s - loss: 3.6422e-05 - val_loss: 5.1934e-04 - lr: 3.1250e-06 - 29s/epoch - 81ms/step\n",
      "Epoch 56/200\n",
      "360/360 - 29s - loss: 3.7627e-05 - val_loss: 5.0528e-04 - lr: 3.1250e-06 - 29s/epoch - 81ms/step\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "360/360 - 26s - loss: 3.6169e-05 - val_loss: 4.8419e-04 - lr: 3.1250e-06 - 26s/epoch - 73ms/step\n",
      "Epoch 58/200\n",
      "360/360 - 26s - loss: 3.4924e-05 - val_loss: 5.0650e-04 - lr: 1.5625e-06 - 26s/epoch - 73ms/step\n",
      "Epoch 59/200\n",
      "360/360 - 27s - loss: 3.5457e-05 - val_loss: 5.3308e-04 - lr: 1.5625e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 60/200\n",
      "360/360 - 27s - loss: 3.4943e-05 - val_loss: 5.0931e-04 - lr: 1.5625e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 61/200\n",
      "360/360 - 27s - loss: 3.6037e-05 - val_loss: 5.1264e-04 - lr: 1.5625e-06 - 27s/epoch - 74ms/step\n",
      "Epoch 62/200\n",
      "360/360 - 29s - loss: 3.3508e-05 - val_loss: 5.0286e-04 - lr: 1.5625e-06 - 29s/epoch - 80ms/step\n",
      "Epoch 63/200\n",
      "360/360 - 29s - loss: 3.5185e-05 - val_loss: 4.9212e-04 - lr: 1.5625e-06 - 29s/epoch - 80ms/step\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "360/360 - 29s - loss: 3.5798e-05 - val_loss: 4.9759e-04 - lr: 1.5625e-06 - 29s/epoch - 80ms/step\n",
      "Epoch 65/200\n",
      "360/360 - 29s - loss: 3.6114e-05 - val_loss: 5.1426e-04 - lr: 7.8125e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 66/200\n",
      "360/360 - 29s - loss: 3.5425e-05 - val_loss: 5.0300e-04 - lr: 7.8125e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 67/200\n",
      "360/360 - 27s - loss: 3.5250e-05 - val_loss: 4.9444e-04 - lr: 7.8125e-07 - 27s/epoch - 74ms/step\n",
      "Epoch 68/200\n",
      "360/360 - 27s - loss: 3.5773e-05 - val_loss: 5.0544e-04 - lr: 7.8125e-07 - 27s/epoch - 74ms/step\n",
      "Epoch 69/200\n",
      "360/360 - 27s - loss: 3.4939e-05 - val_loss: 5.1886e-04 - lr: 7.8125e-07 - 27s/epoch - 74ms/step\n",
      "Epoch 70/200\n",
      "360/360 - 29s - loss: 3.5945e-05 - val_loss: 4.8508e-04 - lr: 7.8125e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "360/360 - 29s - loss: 3.5081e-05 - val_loss: 5.3118e-04 - lr: 7.8125e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 72/200\n",
      "360/360 - 29s - loss: 3.4289e-05 - val_loss: 5.0918e-04 - lr: 3.9062e-07 - 29s/epoch - 81ms/step\n",
      "Epoch 73/200\n",
      "360/360 - 29s - loss: 3.4148e-05 - val_loss: 4.8377e-04 - lr: 3.9062e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 74/200\n",
      "360/360 - 29s - loss: 3.2838e-05 - val_loss: 5.0606e-04 - lr: 3.9062e-07 - 29s/epoch - 81ms/step\n",
      "Epoch 75/200\n",
      "360/360 - 26s - loss: 3.3616e-05 - val_loss: 4.9871e-04 - lr: 3.9062e-07 - 26s/epoch - 74ms/step\n",
      "Epoch 76/200\n",
      "360/360 - 29s - loss: 3.5127e-05 - val_loss: 4.9424e-04 - lr: 3.9062e-07 - 29s/epoch - 81ms/step\n",
      "Epoch 77/200\n",
      "360/360 - 29s - loss: 3.3898e-05 - val_loss: 5.2100e-04 - lr: 3.9062e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "360/360 - 26s - loss: 3.6000e-05 - val_loss: 5.0977e-04 - lr: 3.9062e-07 - 26s/epoch - 73ms/step\n",
      "Epoch 79/200\n",
      "360/360 - 26s - loss: 3.4706e-05 - val_loss: 5.0333e-04 - lr: 1.9531e-07 - 26s/epoch - 73ms/step\n",
      "Epoch 80/200\n",
      "360/360 - 27s - loss: 3.4677e-05 - val_loss: 4.9357e-04 - lr: 1.9531e-07 - 27s/epoch - 74ms/step\n",
      "Epoch 81/200\n",
      "360/360 - 29s - loss: 3.3872e-05 - val_loss: 5.0781e-04 - lr: 1.9531e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 82/200\n",
      "360/360 - 27s - loss: 3.1713e-05 - val_loss: 4.6011e-04 - lr: 1.9531e-07 - 27s/epoch - 75ms/step\n",
      "Epoch 83/200\n",
      "360/360 - 29s - loss: 3.4282e-05 - val_loss: 5.0539e-04 - lr: 1.9531e-07 - 29s/epoch - 80ms/step\n",
      "Epoch 84/200\n",
      "360/360 - 26s - loss: 3.2940e-05 - val_loss: 5.2367e-04 - lr: 1.9531e-07 - 26s/epoch - 72ms/step\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "360/360 - 27s - loss: 3.2983e-05 - val_loss: 5.0212e-04 - lr: 1.9531e-07 - 27s/epoch - 74ms/step\n",
      "Epoch 86/200\n",
      "360/360 - 26s - loss: 3.3437e-05 - val_loss: 5.0287e-04 - lr: 9.7656e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 87/200\n",
      "360/360 - 29s - loss: 3.4757e-05 - val_loss: 5.2124e-04 - lr: 9.7656e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 88/200\n",
      "360/360 - 26s - loss: 3.5513e-05 - val_loss: 5.2100e-04 - lr: 9.7656e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 89/200\n",
      "360/360 - 27s - loss: 3.4326e-05 - val_loss: 4.9122e-04 - lr: 9.7656e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 90/200\n",
      "360/360 - 27s - loss: 3.4522e-05 - val_loss: 5.1898e-04 - lr: 9.7656e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 91/200\n",
      "360/360 - 27s - loss: 3.5148e-05 - val_loss: 5.1367e-04 - lr: 9.7656e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "360/360 - 26s - loss: 3.4906e-05 - val_loss: 5.0338e-04 - lr: 9.7656e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 93/200\n",
      "360/360 - 29s - loss: 3.2929e-05 - val_loss: 5.2297e-04 - lr: 4.8828e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 94/200\n",
      "360/360 - 26s - loss: 3.2558e-05 - val_loss: 4.8164e-04 - lr: 4.8828e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 95/200\n",
      "360/360 - 29s - loss: 3.2970e-05 - val_loss: 5.0243e-04 - lr: 4.8828e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 96/200\n",
      "360/360 - 29s - loss: 3.3073e-05 - val_loss: 5.2219e-04 - lr: 4.8828e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 97/200\n",
      "360/360 - 29s - loss: 3.3022e-05 - val_loss: 5.1648e-04 - lr: 4.8828e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 98/200\n",
      "360/360 - 29s - loss: 3.3494e-05 - val_loss: 4.8450e-04 - lr: 4.8828e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 99/200\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "360/360 - 26s - loss: 3.4069e-05 - val_loss: 5.0807e-04 - lr: 4.8828e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 100/200\n",
      "360/360 - 29s - loss: 3.3126e-05 - val_loss: 4.9901e-04 - lr: 2.4414e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 101/200\n",
      "360/360 - 29s - loss: 3.3721e-05 - val_loss: 4.8610e-04 - lr: 2.4414e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 102/200\n",
      "360/360 - 29s - loss: 3.3928e-05 - val_loss: 4.8065e-04 - lr: 2.4414e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 103/200\n",
      "360/360 - 28s - loss: 3.2737e-05 - val_loss: 5.2047e-04 - lr: 2.4414e-08 - 28s/epoch - 79ms/step\n",
      "Epoch 104/200\n",
      "360/360 - 29s - loss: 3.4208e-05 - val_loss: 5.3046e-04 - lr: 2.4414e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 105/200\n",
      "360/360 - 29s - loss: 3.4100e-05 - val_loss: 5.2120e-04 - lr: 2.4414e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 106/200\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "360/360 - 27s - loss: 3.3851e-05 - val_loss: 4.6726e-04 - lr: 2.4414e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 107/200\n",
      "360/360 - 25s - loss: 3.3684e-05 - val_loss: 5.1764e-04 - lr: 1.2207e-08 - 25s/epoch - 70ms/step\n",
      "Epoch 108/200\n",
      "360/360 - 29s - loss: 3.3904e-05 - val_loss: 5.0682e-04 - lr: 1.2207e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 109/200\n",
      "360/360 - 26s - loss: 3.4337e-05 - val_loss: 4.7640e-04 - lr: 1.2207e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 110/200\n",
      "360/360 - 26s - loss: 3.3300e-05 - val_loss: 4.9250e-04 - lr: 1.2207e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 111/200\n",
      "360/360 - 29s - loss: 3.5150e-05 - val_loss: 4.8261e-04 - lr: 1.2207e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 112/200\n",
      "360/360 - 26s - loss: 3.3697e-05 - val_loss: 5.0144e-04 - lr: 1.2207e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 113/200\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "360/360 - 27s - loss: 3.3021e-05 - val_loss: 4.9156e-04 - lr: 1.2207e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 114/200\n",
      "360/360 - 29s - loss: 3.3941e-05 - val_loss: 4.8131e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 115/200\n",
      "360/360 - 28s - loss: 3.3735e-05 - val_loss: 4.6020e-04 - lr: 1.0000e-08 - 28s/epoch - 79ms/step\n",
      "Epoch 116/200\n",
      "360/360 - 27s - loss: 3.1357e-05 - val_loss: 5.2169e-04 - lr: 1.0000e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 117/200\n",
      "360/360 - 26s - loss: 3.2724e-05 - val_loss: 4.9198e-04 - lr: 1.0000e-08 - 26s/epoch - 74ms/step\n",
      "Epoch 118/200\n",
      "360/360 - 29s - loss: 3.4146e-05 - val_loss: 5.1964e-04 - lr: 1.0000e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 119/200\n",
      "360/360 - 29s - loss: 3.5138e-05 - val_loss: 5.1863e-04 - lr: 1.0000e-08 - 29s/epoch - 79ms/step\n",
      "Epoch 120/200\n",
      "360/360 - 29s - loss: 3.2895e-05 - val_loss: 5.0836e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 121/200\n",
      "360/360 - 26s - loss: 3.3533e-05 - val_loss: 5.2626e-04 - lr: 1.0000e-08 - 26s/epoch - 72ms/step\n",
      "Epoch 122/200\n",
      "360/360 - 26s - loss: 3.1886e-05 - val_loss: 5.0519e-04 - lr: 1.0000e-08 - 26s/epoch - 72ms/step\n",
      "Epoch 123/200\n",
      "360/360 - 29s - loss: 3.2567e-05 - val_loss: 5.1701e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 124/200\n",
      "360/360 - 29s - loss: 3.3550e-05 - val_loss: 5.1583e-04 - lr: 1.0000e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 125/200\n",
      "360/360 - 27s - loss: 3.2501e-05 - val_loss: 4.8989e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 126/200\n",
      "360/360 - 27s - loss: 3.3651e-05 - val_loss: 4.9455e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 127/200\n",
      "360/360 - 29s - loss: 3.4015e-05 - val_loss: 5.0673e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 128/200\n",
      "360/360 - 29s - loss: 3.4924e-05 - val_loss: 4.8435e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 129/200\n",
      "360/360 - 27s - loss: 3.3562e-05 - val_loss: 5.2757e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 130/200\n",
      "360/360 - 29s - loss: 3.4925e-05 - val_loss: 4.9309e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 131/200\n",
      "360/360 - 25s - loss: 3.4543e-05 - val_loss: 4.9655e-04 - lr: 1.0000e-08 - 25s/epoch - 69ms/step\n",
      "Epoch 132/200\n",
      "360/360 - 30s - loss: 3.2496e-05 - val_loss: 4.8982e-04 - lr: 1.0000e-08 - 30s/epoch - 82ms/step\n",
      "Epoch 133/200\n",
      "360/360 - 29s - loss: 3.3592e-05 - val_loss: 5.2003e-04 - lr: 1.0000e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 134/200\n",
      "360/360 - 28s - loss: 3.4510e-05 - val_loss: 5.1718e-04 - lr: 1.0000e-08 - 28s/epoch - 79ms/step\n",
      "Epoch 135/200\n",
      "360/360 - 26s - loss: 3.3027e-05 - val_loss: 5.0520e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 136/200\n",
      "360/360 - 29s - loss: 3.5476e-05 - val_loss: 4.9884e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 137/200\n",
      "360/360 - 27s - loss: 3.5395e-05 - val_loss: 5.1916e-04 - lr: 1.0000e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 138/200\n",
      "360/360 - 29s - loss: 3.4347e-05 - val_loss: 5.0274e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 139/200\n",
      "360/360 - 29s - loss: 3.3933e-05 - val_loss: 5.3137e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 140/200\n",
      "360/360 - 26s - loss: 3.4448e-05 - val_loss: 5.0868e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 141/200\n",
      "360/360 - 27s - loss: 3.2137e-05 - val_loss: 5.1304e-04 - lr: 1.0000e-08 - 27s/epoch - 74ms/step\n",
      "Epoch 142/200\n",
      "360/360 - 27s - loss: 3.3285e-05 - val_loss: 5.0844e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 143/200\n",
      "360/360 - 26s - loss: 3.4650e-05 - val_loss: 5.0020e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 144/200\n",
      "360/360 - 26s - loss: 3.3259e-05 - val_loss: 5.1731e-04 - lr: 1.0000e-08 - 26s/epoch - 72ms/step\n",
      "Epoch 145/200\n",
      "360/360 - 25s - loss: 3.4108e-05 - val_loss: 4.9955e-04 - lr: 1.0000e-08 - 25s/epoch - 71ms/step\n",
      "Epoch 146/200\n",
      "360/360 - 28s - loss: 3.5352e-05 - val_loss: 5.0474e-04 - lr: 1.0000e-08 - 28s/epoch - 78ms/step\n",
      "Epoch 147/200\n",
      "360/360 - 25s - loss: 3.3127e-05 - val_loss: 5.1851e-04 - lr: 1.0000e-08 - 25s/epoch - 69ms/step\n",
      "Epoch 148/200\n",
      "360/360 - 26s - loss: 3.4293e-05 - val_loss: 5.2046e-04 - lr: 1.0000e-08 - 26s/epoch - 71ms/step\n",
      "Epoch 149/200\n",
      "360/360 - 26s - loss: 3.5856e-05 - val_loss: 5.0056e-04 - lr: 1.0000e-08 - 26s/epoch - 71ms/step\n",
      "Epoch 150/200\n",
      "360/360 - 25s - loss: 3.4517e-05 - val_loss: 5.0436e-04 - lr: 1.0000e-08 - 25s/epoch - 70ms/step\n",
      "Epoch 151/200\n",
      "360/360 - 27s - loss: 3.3832e-05 - val_loss: 4.9967e-04 - lr: 1.0000e-08 - 27s/epoch - 76ms/step\n",
      "Epoch 152/200\n",
      "360/360 - 28s - loss: 3.4365e-05 - val_loss: 4.7931e-04 - lr: 1.0000e-08 - 28s/epoch - 79ms/step\n",
      "Epoch 153/200\n",
      "360/360 - 28s - loss: 3.5709e-05 - val_loss: 4.8626e-04 - lr: 1.0000e-08 - 28s/epoch - 79ms/step\n",
      "Epoch 154/200\n",
      "360/360 - 27s - loss: 3.3811e-05 - val_loss: 5.1803e-04 - lr: 1.0000e-08 - 27s/epoch - 76ms/step\n",
      "Epoch 155/200\n",
      "360/360 - 28s - loss: 3.4822e-05 - val_loss: 5.2221e-04 - lr: 1.0000e-08 - 28s/epoch - 78ms/step\n",
      "Epoch 156/200\n",
      "360/360 - 26s - loss: 3.3895e-05 - val_loss: 5.0621e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 157/200\n",
      "360/360 - 26s - loss: 3.4891e-05 - val_loss: 5.0213e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 158/200\n",
      "360/360 - 26s - loss: 3.3612e-05 - val_loss: 5.1704e-04 - lr: 1.0000e-08 - 26s/epoch - 72ms/step\n",
      "Epoch 159/200\n",
      "360/360 - 29s - loss: 3.3801e-05 - val_loss: 5.2039e-04 - lr: 1.0000e-08 - 29s/epoch - 80ms/step\n",
      "Epoch 160/200\n",
      "360/360 - 27s - loss: 3.2729e-05 - val_loss: 5.0370e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 161/200\n",
      "360/360 - 27s - loss: 3.4631e-05 - val_loss: 5.1699e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 162/200\n",
      "360/360 - 27s - loss: 3.2879e-05 - val_loss: 5.0707e-04 - lr: 1.0000e-08 - 27s/epoch - 76ms/step\n",
      "Epoch 163/200\n",
      "360/360 - 30s - loss: 3.3611e-05 - val_loss: 5.0065e-04 - lr: 1.0000e-08 - 30s/epoch - 83ms/step\n",
      "Epoch 164/200\n",
      "360/360 - 26s - loss: 3.3611e-05 - val_loss: 5.0805e-04 - lr: 1.0000e-08 - 26s/epoch - 73ms/step\n",
      "Epoch 165/200\n",
      "360/360 - 29s - loss: 3.3737e-05 - val_loss: 4.8456e-04 - lr: 1.0000e-08 - 29s/epoch - 81ms/step\n",
      "Epoch 166/200\n",
      "360/360 - 27s - loss: 3.3961e-05 - val_loss: 5.1951e-04 - lr: 1.0000e-08 - 27s/epoch - 75ms/step\n",
      "Epoch 167/200\n",
      "360/360 - 26s - loss: 3.4143e-05 - val_loss: 5.2658e-04 - lr: 1.0000e-08 - 26s/epoch - 72ms/step\n",
      "Epoch 00167: early stopping\n",
      "INFO:sleap.nn.training:Finished training loop. [76.8 min]\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2dbba64947943669563c463874dedbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.435644\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ae4f6859304de8afb6e563902de7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.584158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b706dbd67742f2a30d882ccd3fbf36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.test.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/metrics.test.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.534653\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "cfg = sleap.load_config(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/baseline.configs_adjusted/baseline_medium_rf.topdown_adjusted_python.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Oct3_test3 removed the input scaling of 0.5 as this could not run, error:\n",
    "Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(1, 256, 256, 3)\n",
    "\n",
    "{\n",
    "\t\"name\": \"ValueError\",\n",
    "\t\"message\": \"Exception encountered when calling layer \\\"find_instance_peaks_2\\\" (type FindInstancePeaks).\n",
    "\n",
    "Input 0 of layer \\\"model_17\\\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(1, 256, 256, 3)\n",
    "\n",
    "Call arguments received:\n",
    "   inputs=tf.Tensor(shape=(1, 512, 512, 3), dtype=float32)\",\n",
    "\t\"stack\": \"---------------------------------------------------------------------------\n",
    "ValueError                                Traceback (most recent call last)\n",
    "/tmp/ipykernel_3052/4032920361.py in <module>\n",
    "----> 1 trainer.train()\n",
    "\n",
    "~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py in train(self)\n",
    "    939             validation_steps=self.config.optimization.val_batches_per_epoch,\n",
    "    940             callbacks=self.callbacks,\n",
    "--> 941             verbose=2,\n",
    "    942         )\n",
    "    943         logger.info(f\\\"Finished training loop. [{(time() - t0) / 60:.1f} min]\\\")\n",
    "\n",
    "~/anaconda3/envs/sleap/lib/python3.7/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)\n",
    "     65     except Exception as e:  # pylint: disable=broad-except\n",
    "     66       filtered_tb = _process_traceback_frames(e.__traceback__)\n",
    "---> 67       raise e.with_traceback(filtered_tb) from None\n",
    "     68     finally:\n",
    "     69       del filtered_tb\n",
    "\n",
    "~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/callbacks.py in on_epoch_end(self, epoch, logs)\n",
    "    278         \\\"\\\"\\\"Save figure at the end of each epoch.\\\"\\\"\\\"\n",
    "    279         # Call plotting function.\n",
    "--> 280         figure = self.plot_fn()\n",
    "    281 \n",
    "    282         # Check if output folder exists.\n",
    "\n",
    "~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py in <lambda>()\n",
    "   1344                 self.config.outputs,\n",
    "   1345                 run_path=self.run_path,\n",
    "-> 1346                 viz_fn=lambda: visualize_example(next(training_viz_ds_iter)),\n",
    "   1347                 name=\\\"train\\\",\n",
    "   1348             )\n",
    "\n",
    "~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py in visualize_example(example)\n",
    "   1324         def visualize_example(example):\n",
    "   1325             # Find peaks by evaluating model.\n",
    "-> 1326             preds = find_peaks(tf.expand_dims(example[\\\"instance_image\\\"], axis=0))\n",
    "   1327             img = example[\\\"instance_image\\\"].numpy()\n",
    "   1328             cms = preds[\\\"instance_confmaps\\\"][0][0].numpy()\n",
    "\n",
    "~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/inference.py in call(self, inputs)\n",
    "   2097 \n",
    "   2098         # Network forward pass.\n",
    "-> 2099         out = self.keras_model(crops)\n",
    "   2100 \n",
    "   2101         # Sort outputs.\n",
    "\n",
    "ValueError: Exception encountered when calling layer \\\"find_instance_peaks_2\\\" (type FindInstancePeaks).\n",
    "\n",
    "Input 0 of layer \\\"model_17\\\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(1, 256, 256, 3)\n",
    "\n",
    "Call arguments received:\n",
    "   inputs=tf.Tensor(shape=(1, 512, 512, 3), dtype=float32)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg.data.preprocessing.input_scaling = 0.5\n",
    "cfg.model.backbone.unet.max_stride = 32\n",
    "cfg.model.backbone.unet.filters = 24\n",
    "# Okay removing the input scaling. There is clearly an issue with it... \n",
    "cfg.model.backbone.unet.filters_rate = 1.5\n",
    "\n",
    "# trying centring on a body part\n",
    "#cfg.model.heads.centered_instance.anchor_part = \"Body_top\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to change crop size to because running into input issue with input_scaling = 0.5\n",
    "# cfg.data.instance_cropping.crop_size = 976\n",
    "# THE ABOVE CREATED ISSUES, TRYING TO CENTRE ON BODY PART RATHER\n",
    "#cfg.data.instance_cropping.center_on_part = \"Body_top\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n"
     ]
    }
   ],
   "source": [
    "# Create and initialize the trainer. prt1\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the randomly initialized weights with the saved weights.\n",
    "#trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.config.optimization.epochs = 200\n",
    "trainer.config.outputs.keep_viz_images = True\n",
    "trainer.config.outputs.run_name = 'Oct3_test3_medium_rf.topdown_200Epoch'\n",
    "#trainer.config.data.preprocessing.input_scaling = 0.5\n",
    "#trainer.config.model.backbone.unet.max_stride = 32\n",
    "#trainer.config.model.backbone.unet.filters = 24\n",
    "#trainer.config.model.backbone.unet.filters_rate = 1.5\n",
    "#trainer.config.model.heads.centroid.output_stride = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final model\n",
    "trainer.config.outputs.checkpointing.latest_model = True\n",
    "trainer.config.outputs.checkpointing.final_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.config.optimization.early_stopping.plateau_patience = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 12:41:19.929988: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 12:41:19.931082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:19.935907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:19.939122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:20.319386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:20.320612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:20.321722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-03 12:41:20.322806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1597 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Loaded test example. [2.236s]\n",
      "INFO:sleap.nn.training:  Input shape: (992, 992, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=24, filters_rate=1.5, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=5, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 32\n",
      "INFO:sleap.nn.training:  Parameters: 1,645,564\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CenteredInstanceConfmapsHead(part_names=['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot'], anchor_part=None, sigma=2.5, output_stride=4, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 248, 248, 8), dtype=tf.float32, name=None), name='CenteredInstanceConfmapsHead/BiasAdd:0', description=\"created by layer 'CenteredInstanceConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=150)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [4.5s]\n"
     ]
    }
   ],
   "source": [
    "# Create and initialize the trainer. prt2\n",
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [36.1s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 12:42:23.392534: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-03 12:42:24.145884: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:24.145971: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.58GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:24.929026: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:24.929103: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.00GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.055704: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.055796: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.39GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.232253: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.232337: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.48GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.698320: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:42:25.698396: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-03 12:43:09.499170: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 - 52s - loss: 2.7759e-04 - Head: 3.1522e-04 - Beak: 2.9902e-04 - Body_top: 3.0871e-04 - RFlipper_mid: 2.4032e-04 - LFlipper_mid: 2.4417e-04 - Body_bottom: 3.0986e-04 - RFoot: 2.6115e-04 - LFoot: 2.4228e-04 - val_loss: 2.6827e-04 - val_Head: 3.1258e-04 - val_Beak: 2.5478e-04 - val_Body_top: 3.1708e-04 - val_RFlipper_mid: 2.1224e-04 - val_LFlipper_mid: 3.1746e-04 - val_Body_bottom: 3.1802e-04 - val_RFoot: 2.0722e-04 - val_LFoot: 2.0679e-04 - lr: 1.0000e-04 - 52s/epoch - 143ms/step\n",
      "Epoch 2/200\n",
      "360/360 - 41s - loss: 2.7584e-04 - Head: 3.1433e-04 - Beak: 2.9763e-04 - Body_top: 3.0681e-04 - RFlipper_mid: 2.3898e-04 - LFlipper_mid: 2.4063e-04 - Body_bottom: 3.0960e-04 - RFoot: 2.5906e-04 - LFoot: 2.3967e-04 - val_loss: 2.6807e-04 - val_Head: 3.1146e-04 - val_Beak: 2.5474e-04 - val_Body_top: 3.1546e-04 - val_RFlipper_mid: 2.1236e-04 - val_LFlipper_mid: 3.1659e-04 - val_Body_bottom: 3.1828e-04 - val_RFoot: 2.0885e-04 - val_LFoot: 2.0681e-04 - lr: 1.0000e-04 - 41s/epoch - 114ms/step\n",
      "Epoch 3/200\n",
      "360/360 - 42s - loss: 2.7502e-04 - Head: 3.1161e-04 - Beak: 2.9790e-04 - Body_top: 3.0529e-04 - RFlipper_mid: 2.3853e-04 - LFlipper_mid: 2.3890e-04 - Body_bottom: 3.0829e-04 - RFoot: 2.5985e-04 - LFoot: 2.3978e-04 - val_loss: 2.6775e-04 - val_Head: 3.1152e-04 - val_Beak: 2.5430e-04 - val_Body_top: 3.1424e-04 - val_RFlipper_mid: 2.1112e-04 - val_LFlipper_mid: 3.1647e-04 - val_Body_bottom: 3.1869e-04 - val_RFoot: 2.0895e-04 - val_LFoot: 2.0671e-04 - lr: 1.0000e-04 - 42s/epoch - 116ms/step\n",
      "Epoch 4/200\n",
      "360/360 - 41s - loss: 2.7329e-04 - Head: 3.0282e-04 - Beak: 2.9785e-04 - Body_top: 3.0370e-04 - RFlipper_mid: 2.3804e-04 - LFlipper_mid: 2.3694e-04 - Body_bottom: 3.0834e-04 - RFoot: 2.5901e-04 - LFoot: 2.3962e-04 - val_loss: 2.6736e-04 - val_Head: 3.0851e-04 - val_Beak: 2.5525e-04 - val_Body_top: 3.1388e-04 - val_RFlipper_mid: 2.1047e-04 - val_LFlipper_mid: 3.1653e-04 - val_Body_bottom: 3.1827e-04 - val_RFoot: 2.0855e-04 - val_LFoot: 2.0743e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 5/200\n",
      "360/360 - 41s - loss: 2.7113e-04 - Head: 2.9567e-04 - Beak: 2.9620e-04 - Body_top: 3.0125e-04 - RFlipper_mid: 2.3764e-04 - LFlipper_mid: 2.3386e-04 - Body_bottom: 3.0913e-04 - RFoot: 2.5564e-04 - LFoot: 2.3961e-04 - val_loss: 2.6382e-04 - val_Head: 2.8653e-04 - val_Beak: 2.5583e-04 - val_Body_top: 3.1180e-04 - val_RFlipper_mid: 2.0903e-04 - val_LFlipper_mid: 3.1529e-04 - val_Body_bottom: 3.1829e-04 - val_RFoot: 2.0606e-04 - val_LFoot: 2.0770e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 6/200\n",
      "360/360 - 39s - loss: 2.6951e-04 - Head: 2.8954e-04 - Beak: 2.9553e-04 - Body_top: 2.9794e-04 - RFlipper_mid: 2.3775e-04 - LFlipper_mid: 2.3410e-04 - Body_bottom: 3.0706e-04 - RFoot: 2.5554e-04 - LFoot: 2.3861e-04 - val_loss: 2.6901e-04 - val_Head: 3.0324e-04 - val_Beak: 2.5584e-04 - val_Body_top: 3.0969e-04 - val_RFlipper_mid: 2.1123e-04 - val_LFlipper_mid: 3.3991e-04 - val_Body_bottom: 3.1918e-04 - val_RFoot: 2.0601e-04 - val_LFoot: 2.0696e-04 - lr: 1.0000e-04 - 39s/epoch - 108ms/step\n",
      "Epoch 7/200\n",
      "360/360 - 39s - loss: 2.6203e-04 - Head: 2.6692e-04 - Beak: 2.9338e-04 - Body_top: 2.9119e-04 - RFlipper_mid: 2.3563e-04 - LFlipper_mid: 2.2175e-04 - Body_bottom: 3.0738e-04 - RFoot: 2.4325e-04 - LFoot: 2.3675e-04 - val_loss: 2.6109e-04 - val_Head: 2.8235e-04 - val_Beak: 2.5519e-04 - val_Body_top: 3.1216e-04 - val_RFlipper_mid: 2.0621e-04 - val_LFlipper_mid: 3.1980e-04 - val_Body_bottom: 3.1898e-04 - val_RFoot: 1.8968e-04 - val_LFoot: 2.0431e-04 - lr: 1.0000e-04 - 39s/epoch - 109ms/step\n",
      "Epoch 8/200\n",
      "360/360 - 41s - loss: 2.5951e-04 - Head: 2.5814e-04 - Beak: 2.9448e-04 - Body_top: 2.7814e-04 - RFlipper_mid: 2.3407e-04 - LFlipper_mid: 2.1699e-04 - Body_bottom: 3.0867e-04 - RFoot: 2.4830e-04 - LFoot: 2.3729e-04 - val_loss: 2.7344e-04 - val_Head: 2.9889e-04 - val_Beak: 2.5634e-04 - val_Body_top: 3.1780e-04 - val_RFlipper_mid: 2.1817e-04 - val_LFlipper_mid: 3.6847e-04 - val_Body_bottom: 3.1962e-04 - val_RFoot: 2.0068e-04 - val_LFoot: 2.0756e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 9/200\n",
      "360/360 - 39s - loss: 2.4826e-04 - Head: 2.3536e-04 - Beak: 2.8674e-04 - Body_top: 2.6193e-04 - RFlipper_mid: 2.3020e-04 - LFlipper_mid: 1.9938e-04 - Body_bottom: 3.0808e-04 - RFoot: 2.2987e-04 - LFoot: 2.3451e-04 - val_loss: 2.5766e-04 - val_Head: 2.5473e-04 - val_Beak: 2.4724e-04 - val_Body_top: 3.0779e-04 - val_RFlipper_mid: 2.0506e-04 - val_LFlipper_mid: 3.6545e-04 - val_Body_bottom: 3.2011e-04 - val_RFoot: 1.6011e-04 - val_LFoot: 2.0076e-04 - lr: 1.0000e-04 - 39s/epoch - 109ms/step\n",
      "Epoch 10/200\n",
      "360/360 - 41s - loss: 2.3788e-04 - Head: 2.2221e-04 - Beak: 2.7107e-04 - Body_top: 2.4507e-04 - RFlipper_mid: 2.3047e-04 - LFlipper_mid: 1.8596e-04 - Body_bottom: 3.0609e-04 - RFoot: 2.1229e-04 - LFoot: 2.2988e-04 - val_loss: 2.5671e-04 - val_Head: 2.8113e-04 - val_Beak: 2.6697e-04 - val_Body_top: 2.8247e-04 - val_RFlipper_mid: 2.0258e-04 - val_LFlipper_mid: 3.3142e-04 - val_Body_bottom: 3.2059e-04 - val_RFoot: 1.7307e-04 - val_LFoot: 1.9541e-04 - lr: 1.0000e-04 - 41s/epoch - 114ms/step\n",
      "Epoch 11/200\n",
      "360/360 - 41s - loss: 2.2611e-04 - Head: 2.0849e-04 - Beak: 2.4745e-04 - Body_top: 2.3800e-04 - RFlipper_mid: 2.1998e-04 - LFlipper_mid: 1.8951e-04 - Body_bottom: 3.0497e-04 - RFoot: 1.8436e-04 - LFoot: 2.1609e-04 - val_loss: 2.5088e-04 - val_Head: 2.7500e-04 - val_Beak: 2.3703e-04 - val_Body_top: 2.8769e-04 - val_RFlipper_mid: 2.1493e-04 - val_LFlipper_mid: 3.1937e-04 - val_Body_bottom: 3.1995e-04 - val_RFoot: 1.7314e-04 - val_LFoot: 1.7989e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 12/200\n",
      "360/360 - 42s - loss: 2.1084e-04 - Head: 1.9597e-04 - Beak: 2.1824e-04 - Body_top: 2.1763e-04 - RFlipper_mid: 2.1285e-04 - LFlipper_mid: 1.7697e-04 - Body_bottom: 2.9764e-04 - RFoot: 1.6589e-04 - LFoot: 2.0151e-04 - val_loss: 2.5188e-04 - val_Head: 2.5010e-04 - val_Beak: 2.5692e-04 - val_Body_top: 2.9993e-04 - val_RFlipper_mid: 2.0718e-04 - val_LFlipper_mid: 3.1106e-04 - val_Body_bottom: 3.3820e-04 - val_RFoot: 1.7031e-04 - val_LFoot: 1.8133e-04 - lr: 1.0000e-04 - 42s/epoch - 117ms/step\n",
      "Epoch 13/200\n",
      "360/360 - 43s - loss: 1.9855e-04 - Head: 1.8713e-04 - Beak: 1.9274e-04 - Body_top: 2.0591e-04 - RFlipper_mid: 2.0173e-04 - LFlipper_mid: 1.6455e-04 - Body_bottom: 2.8673e-04 - RFoot: 1.5926e-04 - LFoot: 1.9035e-04 - val_loss: 2.5576e-04 - val_Head: 2.5022e-04 - val_Beak: 2.3395e-04 - val_Body_top: 3.6297e-04 - val_RFlipper_mid: 2.1716e-04 - val_LFlipper_mid: 3.0324e-04 - val_Body_bottom: 3.2005e-04 - val_RFoot: 1.7371e-04 - val_LFoot: 1.8480e-04 - lr: 1.0000e-04 - 43s/epoch - 119ms/step\n",
      "Epoch 14/200\n",
      "360/360 - 42s - loss: 1.8757e-04 - Head: 1.7704e-04 - Beak: 1.8694e-04 - Body_top: 1.9410e-04 - RFlipper_mid: 1.9004e-04 - LFlipper_mid: 1.5246e-04 - Body_bottom: 2.6686e-04 - RFoot: 1.4835e-04 - LFoot: 1.8472e-04 - val_loss: 2.4205e-04 - val_Head: 2.4269e-04 - val_Beak: 2.2067e-04 - val_Body_top: 2.9303e-04 - val_RFlipper_mid: 1.9999e-04 - val_LFlipper_mid: 3.1410e-04 - val_Body_bottom: 3.2789e-04 - val_RFoot: 1.5992e-04 - val_LFoot: 1.7813e-04 - lr: 1.0000e-04 - 42s/epoch - 116ms/step\n",
      "Epoch 15/200\n",
      "360/360 - 42s - loss: 1.8114e-04 - Head: 1.6955e-04 - Beak: 1.7097e-04 - Body_top: 1.9274e-04 - RFlipper_mid: 1.8058e-04 - LFlipper_mid: 1.5764e-04 - Body_bottom: 2.5788e-04 - RFoot: 1.4329e-04 - LFoot: 1.7649e-04 - val_loss: 2.4216e-04 - val_Head: 2.5250e-04 - val_Beak: 2.1777e-04 - val_Body_top: 2.7725e-04 - val_RFlipper_mid: 2.0866e-04 - val_LFlipper_mid: 3.0670e-04 - val_Body_bottom: 3.6275e-04 - val_RFoot: 1.4065e-04 - val_LFoot: 1.7100e-04 - lr: 1.0000e-04 - 42s/epoch - 116ms/step\n",
      "Epoch 16/200\n",
      "360/360 - 39s - loss: 1.7113e-04 - Head: 1.5975e-04 - Beak: 1.5600e-04 - Body_top: 1.7780e-04 - RFlipper_mid: 1.7362e-04 - LFlipper_mid: 1.4668e-04 - Body_bottom: 2.4450e-04 - RFoot: 1.3968e-04 - LFoot: 1.7098e-04 - val_loss: 2.4317e-04 - val_Head: 2.6140e-04 - val_Beak: 2.2740e-04 - val_Body_top: 2.8986e-04 - val_RFlipper_mid: 2.0142e-04 - val_LFlipper_mid: 3.0030e-04 - val_Body_bottom: 3.2284e-04 - val_RFoot: 1.7167e-04 - val_LFoot: 1.7045e-04 - lr: 1.0000e-04 - 39s/epoch - 110ms/step\n",
      "Epoch 17/200\n",
      "360/360 - 41s - loss: 1.6500e-04 - Head: 1.5516e-04 - Beak: 1.4911e-04 - Body_top: 1.7563e-04 - RFlipper_mid: 1.6929e-04 - LFlipper_mid: 1.4390e-04 - Body_bottom: 2.3437e-04 - RFoot: 1.2866e-04 - LFoot: 1.6389e-04 - val_loss: 2.3861e-04 - val_Head: 2.3654e-04 - val_Beak: 2.1035e-04 - val_Body_top: 2.9719e-04 - val_RFlipper_mid: 2.0999e-04 - val_LFlipper_mid: 3.0757e-04 - val_Body_bottom: 3.2071e-04 - val_RFoot: 1.5744e-04 - val_LFoot: 1.6911e-04 - lr: 1.0000e-04 - 41s/epoch - 115ms/step\n",
      "Epoch 18/200\n",
      "360/360 - 40s - loss: 1.6078e-04 - Head: 1.5372e-04 - Beak: 1.4684e-04 - Body_top: 1.6639e-04 - RFlipper_mid: 1.6439e-04 - LFlipper_mid: 1.4091e-04 - Body_bottom: 2.2545e-04 - RFoot: 1.2943e-04 - LFoot: 1.5908e-04 - val_loss: 2.4160e-04 - val_Head: 2.3001e-04 - val_Beak: 2.0830e-04 - val_Body_top: 2.9334e-04 - val_RFlipper_mid: 2.0670e-04 - val_LFlipper_mid: 3.0333e-04 - val_Body_bottom: 3.4565e-04 - val_RFoot: 1.6064e-04 - val_LFoot: 1.8480e-04 - lr: 1.0000e-04 - 40s/epoch - 110ms/step\n",
      "Epoch 19/200\n",
      "360/360 - 39s - loss: 1.5543e-04 - Head: 1.4549e-04 - Beak: 1.4074e-04 - Body_top: 1.6823e-04 - RFlipper_mid: 1.5711e-04 - LFlipper_mid: 1.3958e-04 - Body_bottom: 2.1965e-04 - RFoot: 1.2256e-04 - LFoot: 1.5007e-04 - val_loss: 2.3635e-04 - val_Head: 2.4223e-04 - val_Beak: 2.0735e-04 - val_Body_top: 2.9433e-04 - val_RFlipper_mid: 1.8885e-04 - val_LFlipper_mid: 3.0088e-04 - val_Body_bottom: 3.2027e-04 - val_RFoot: 1.4055e-04 - val_LFoot: 1.9633e-04 - lr: 1.0000e-04 - 39s/epoch - 109ms/step\n",
      "Epoch 20/200\n",
      "360/360 - 39s - loss: 1.4891e-04 - Head: 1.3494e-04 - Beak: 1.3106e-04 - Body_top: 1.6208e-04 - RFlipper_mid: 1.5606e-04 - LFlipper_mid: 1.3194e-04 - Body_bottom: 2.1895e-04 - RFoot: 1.2013e-04 - LFoot: 1.3610e-04 - val_loss: 2.2857e-04 - val_Head: 2.2299e-04 - val_Beak: 2.0369e-04 - val_Body_top: 2.9724e-04 - val_RFlipper_mid: 1.8600e-04 - val_LFlipper_mid: 2.9417e-04 - val_Body_bottom: 3.2059e-04 - val_RFoot: 1.3509e-04 - val_LFoot: 1.6878e-04 - lr: 1.0000e-04 - 39s/epoch - 108ms/step\n",
      "Epoch 21/200\n",
      "360/360 - 42s - loss: 1.4463e-04 - Head: 1.2952e-04 - Beak: 1.3182e-04 - Body_top: 1.5427e-04 - RFlipper_mid: 1.4771e-04 - LFlipper_mid: 1.3089e-04 - Body_bottom: 2.1293e-04 - RFoot: 1.1664e-04 - LFoot: 1.3327e-04 - val_loss: 2.2996e-04 - val_Head: 2.2130e-04 - val_Beak: 2.0395e-04 - val_Body_top: 2.8020e-04 - val_RFlipper_mid: 2.0423e-04 - val_LFlipper_mid: 2.9480e-04 - val_Body_bottom: 3.1887e-04 - val_RFoot: 1.4326e-04 - val_LFoot: 1.7308e-04 - lr: 1.0000e-04 - 42s/epoch - 115ms/step\n",
      "Epoch 22/200\n",
      "360/360 - 39s - loss: 1.4010e-04 - Head: 1.2538e-04 - Beak: 1.1880e-04 - Body_top: 1.5207e-04 - RFlipper_mid: 1.4528e-04 - LFlipper_mid: 1.3065e-04 - Body_bottom: 2.1377e-04 - RFoot: 1.1017e-04 - LFoot: 1.2469e-04 - val_loss: 2.2651e-04 - val_Head: 2.1160e-04 - val_Beak: 1.8821e-04 - val_Body_top: 2.8727e-04 - val_RFlipper_mid: 2.0001e-04 - val_LFlipper_mid: 3.0037e-04 - val_Body_bottom: 3.3223e-04 - val_RFoot: 1.3376e-04 - val_LFoot: 1.5861e-04 - lr: 1.0000e-04 - 39s/epoch - 108ms/step\n",
      "Epoch 23/200\n",
      "360/360 - 40s - loss: 1.3768e-04 - Head: 1.2316e-04 - Beak: 1.1467e-04 - Body_top: 1.5192e-04 - RFlipper_mid: 1.4557e-04 - LFlipper_mid: 1.2768e-04 - Body_bottom: 2.1078e-04 - RFoot: 1.0751e-04 - LFoot: 1.2013e-04 - val_loss: 2.2039e-04 - val_Head: 2.2543e-04 - val_Beak: 1.5740e-04 - val_Body_top: 2.5538e-04 - val_RFlipper_mid: 1.9488e-04 - val_LFlipper_mid: 2.9635e-04 - val_Body_bottom: 3.2146e-04 - val_RFoot: 1.3512e-04 - val_LFoot: 1.7709e-04 - lr: 1.0000e-04 - 40s/epoch - 111ms/step\n",
      "Epoch 24/200\n",
      "360/360 - 42s - loss: 1.3635e-04 - Head: 1.1961e-04 - Beak: 1.1892e-04 - Body_top: 1.5437e-04 - RFlipper_mid: 1.3971e-04 - LFlipper_mid: 1.2754e-04 - Body_bottom: 2.0622e-04 - RFoot: 1.0802e-04 - LFoot: 1.1637e-04 - val_loss: 2.2849e-04 - val_Head: 2.1315e-04 - val_Beak: 1.8813e-04 - val_Body_top: 3.0316e-04 - val_RFlipper_mid: 2.0033e-04 - val_LFlipper_mid: 3.0129e-04 - val_Body_bottom: 3.2075e-04 - val_RFoot: 1.3080e-04 - val_LFoot: 1.7035e-04 - lr: 1.0000e-04 - 42s/epoch - 118ms/step\n",
      "Epoch 25/200\n",
      "360/360 - 41s - loss: 1.3117e-04 - Head: 1.1240e-04 - Beak: 1.1179e-04 - Body_top: 1.3967e-04 - RFlipper_mid: 1.3678e-04 - LFlipper_mid: 1.2482e-04 - Body_bottom: 2.0450e-04 - RFoot: 1.0551e-04 - LFoot: 1.1388e-04 - val_loss: 2.3316e-04 - val_Head: 2.0751e-04 - val_Beak: 1.8156e-04 - val_Body_top: 3.0251e-04 - val_RFlipper_mid: 2.1358e-04 - val_LFlipper_mid: 2.9537e-04 - val_Body_bottom: 3.2000e-04 - val_RFoot: 1.4860e-04 - val_LFoot: 1.9615e-04 - lr: 1.0000e-04 - 41s/epoch - 113ms/step\n",
      "Epoch 26/200\n",
      "360/360 - 40s - loss: 1.2782e-04 - Head: 1.0790e-04 - Beak: 1.1049e-04 - Body_top: 1.3871e-04 - RFlipper_mid: 1.3157e-04 - LFlipper_mid: 1.2215e-04 - Body_bottom: 1.9891e-04 - RFoot: 1.0282e-04 - LFoot: 1.0999e-04 - val_loss: 2.2974e-04 - val_Head: 2.2376e-04 - val_Beak: 1.8243e-04 - val_Body_top: 3.0929e-04 - val_RFlipper_mid: 2.1004e-04 - val_LFlipper_mid: 2.9697e-04 - val_Body_bottom: 3.1948e-04 - val_RFoot: 1.3386e-04 - val_LFoot: 1.6207e-04 - lr: 1.0000e-04 - 40s/epoch - 112ms/step\n",
      "Epoch 27/200\n",
      "360/360 - 38s - loss: 1.2562e-04 - Head: 1.0708e-04 - Beak: 1.0562e-04 - Body_top: 1.3631e-04 - RFlipper_mid: 1.3373e-04 - LFlipper_mid: 1.1891e-04 - Body_bottom: 1.9788e-04 - RFoot: 9.7536e-05 - LFoot: 1.0790e-04 - val_loss: 2.2743e-04 - val_Head: 2.1374e-04 - val_Beak: 2.0349e-04 - val_Body_top: 2.8367e-04 - val_RFlipper_mid: 2.0701e-04 - val_LFlipper_mid: 2.9387e-04 - val_Body_bottom: 3.1892e-04 - val_RFoot: 1.3898e-04 - val_LFoot: 1.5979e-04 - lr: 1.0000e-04 - 38s/epoch - 106ms/step\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "360/360 - 40s - loss: 1.2234e-04 - Head: 1.0063e-04 - Beak: 1.0127e-04 - Body_top: 1.3702e-04 - RFlipper_mid: 1.2460e-04 - LFlipper_mid: 1.1762e-04 - Body_bottom: 1.9958e-04 - RFoot: 9.4026e-05 - LFoot: 1.0397e-04 - val_loss: 2.2396e-04 - val_Head: 2.1692e-04 - val_Beak: 1.7410e-04 - val_Body_top: 2.7773e-04 - val_RFlipper_mid: 2.0545e-04 - val_LFlipper_mid: 3.0505e-04 - val_Body_bottom: 3.1684e-04 - val_RFoot: 1.3126e-04 - val_LFoot: 1.6434e-04 - lr: 1.0000e-04 - 40s/epoch - 111ms/step\n",
      "Epoch 29/200\n",
      "360/360 - 40s - loss: 1.1325e-04 - Head: 9.2038e-05 - Beak: 8.9699e-05 - Body_top: 1.2539e-04 - RFlipper_mid: 1.1663e-04 - LFlipper_mid: 1.1320e-04 - Body_bottom: 1.8679e-04 - RFoot: 8.8492e-05 - LFoot: 9.3772e-05 - val_loss: 2.1676e-04 - val_Head: 2.0778e-04 - val_Beak: 1.6719e-04 - val_Body_top: 2.7076e-04 - val_RFlipper_mid: 1.7929e-04 - val_LFlipper_mid: 2.9657e-04 - val_Body_bottom: 3.1668e-04 - val_RFoot: 1.2676e-04 - val_LFoot: 1.6908e-04 - lr: 5.0000e-05 - 40s/epoch - 110ms/step\n",
      "Epoch 30/200\n",
      "360/360 - 42s - loss: 1.0989e-04 - Head: 9.0541e-05 - Beak: 8.7344e-05 - Body_top: 1.2104e-04 - RFlipper_mid: 1.1424e-04 - LFlipper_mid: 1.0809e-04 - Body_bottom: 1.8688e-04 - RFoot: 8.1443e-05 - LFoot: 8.9554e-05 - val_loss: 2.1838e-04 - val_Head: 2.1159e-04 - val_Beak: 1.7672e-04 - val_Body_top: 2.6453e-04 - val_RFlipper_mid: 1.9287e-04 - val_LFlipper_mid: 2.9053e-04 - val_Body_bottom: 3.1868e-04 - val_RFoot: 1.3184e-04 - val_LFoot: 1.6030e-04 - lr: 5.0000e-05 - 42s/epoch - 116ms/step\n",
      "Epoch 31/200\n",
      "360/360 - 39s - loss: 1.0793e-04 - Head: 8.4779e-05 - Beak: 8.5812e-05 - Body_top: 1.1928e-04 - RFlipper_mid: 1.1268e-04 - LFlipper_mid: 1.0721e-04 - Body_bottom: 1.8216e-04 - RFoot: 8.3547e-05 - LFoot: 8.7979e-05 - val_loss: 2.2011e-04 - val_Head: 2.1895e-04 - val_Beak: 1.6760e-04 - val_Body_top: 2.8839e-04 - val_RFlipper_mid: 1.8712e-04 - val_LFlipper_mid: 2.9087e-04 - val_Body_bottom: 3.1610e-04 - val_RFoot: 1.2847e-04 - val_LFoot: 1.6336e-04 - lr: 5.0000e-05 - 39s/epoch - 108ms/step\n",
      "Epoch 32/200\n",
      "360/360 - 41s - loss: 1.0776e-04 - Head: 8.8013e-05 - Beak: 8.2777e-05 - Body_top: 1.2070e-04 - RFlipper_mid: 1.1174e-04 - LFlipper_mid: 1.0834e-04 - Body_bottom: 1.8474e-04 - RFoot: 8.0755e-05 - LFoot: 8.4995e-05 - val_loss: 2.1843e-04 - val_Head: 1.9680e-04 - val_Beak: 1.6204e-04 - val_Body_top: 2.8347e-04 - val_RFlipper_mid: 1.8474e-04 - val_LFlipper_mid: 2.9470e-04 - val_Body_bottom: 3.1989e-04 - val_RFoot: 1.3868e-04 - val_LFoot: 1.6713e-04 - lr: 5.0000e-05 - 41s/epoch - 113ms/step\n",
      "Epoch 33/200\n",
      "360/360 - 38s - loss: 1.0503e-04 - Head: 8.0186e-05 - Beak: 8.2408e-05 - Body_top: 1.1435e-04 - RFlipper_mid: 1.0818e-04 - LFlipper_mid: 1.0583e-04 - Body_bottom: 1.8301e-04 - RFoot: 8.1512e-05 - LFoot: 8.4739e-05 - val_loss: 2.1903e-04 - val_Head: 2.1118e-04 - val_Beak: 1.7104e-04 - val_Body_top: 2.7302e-04 - val_RFlipper_mid: 1.9553e-04 - val_LFlipper_mid: 2.9273e-04 - val_Body_bottom: 3.1498e-04 - val_RFoot: 1.2866e-04 - val_LFoot: 1.6509e-04 - lr: 5.0000e-05 - 38s/epoch - 106ms/step\n",
      "Epoch 34/200\n",
      "360/360 - 37s - loss: 1.0545e-04 - Head: 8.3815e-05 - Beak: 8.3619e-05 - Body_top: 1.1818e-04 - RFlipper_mid: 1.0837e-04 - LFlipper_mid: 1.0535e-04 - Body_bottom: 1.8138e-04 - RFoot: 7.7487e-05 - LFoot: 8.5362e-05 - val_loss: 2.1585e-04 - val_Head: 2.1049e-04 - val_Beak: 1.6599e-04 - val_Body_top: 2.6536e-04 - val_RFlipper_mid: 1.9246e-04 - val_LFlipper_mid: 2.9143e-04 - val_Body_bottom: 3.1303e-04 - val_RFoot: 1.3226e-04 - val_LFoot: 1.5580e-04 - lr: 5.0000e-05 - 37s/epoch - 103ms/step\n",
      "Epoch 35/200\n",
      "360/360 - 36s - loss: 1.0382e-04 - Head: 8.0903e-05 - Beak: 8.0012e-05 - Body_top: 1.1608e-04 - RFlipper_mid: 1.0789e-04 - LFlipper_mid: 1.0607e-04 - Body_bottom: 1.7898e-04 - RFoot: 7.9334e-05 - LFoot: 8.1274e-05 - val_loss: 2.1576e-04 - val_Head: 2.0723e-04 - val_Beak: 1.6794e-04 - val_Body_top: 2.6915e-04 - val_RFlipper_mid: 1.9258e-04 - val_LFlipper_mid: 2.9443e-04 - val_Body_bottom: 3.1249e-04 - val_RFoot: 1.2628e-04 - val_LFoot: 1.5593e-04 - lr: 5.0000e-05 - 36s/epoch - 101ms/step\n",
      "Epoch 36/200\n",
      "360/360 - 39s - loss: 1.0252e-04 - Head: 8.2909e-05 - Beak: 8.2245e-05 - Body_top: 1.1325e-04 - RFlipper_mid: 1.0815e-04 - LFlipper_mid: 1.0285e-04 - Body_bottom: 1.7549e-04 - RFoot: 7.4445e-05 - LFoot: 8.0824e-05 - val_loss: 2.2183e-04 - val_Head: 2.1932e-04 - val_Beak: 1.5903e-04 - val_Body_top: 2.6279e-04 - val_RFlipper_mid: 2.0206e-04 - val_LFlipper_mid: 2.9654e-04 - val_Body_bottom: 3.1847e-04 - val_RFoot: 1.4623e-04 - val_LFoot: 1.7023e-04 - lr: 5.0000e-05 - 39s/epoch - 109ms/step\n",
      "Epoch 37/200\n",
      "360/360 - 39s - loss: 1.0066e-04 - Head: 8.3611e-05 - Beak: 7.9506e-05 - Body_top: 1.1451e-04 - RFlipper_mid: 1.0373e-04 - LFlipper_mid: 1.0029e-04 - Body_bottom: 1.7342e-04 - RFoot: 7.4768e-05 - LFoot: 7.5466e-05 - val_loss: 2.1625e-04 - val_Head: 2.0242e-04 - val_Beak: 1.5551e-04 - val_Body_top: 2.7082e-04 - val_RFlipper_mid: 2.0561e-04 - val_LFlipper_mid: 2.9605e-04 - val_Body_bottom: 3.0925e-04 - val_RFoot: 1.3497e-04 - val_LFoot: 1.5534e-04 - lr: 5.0000e-05 - 39s/epoch - 109ms/step\n",
      "Epoch 38/200\n",
      "360/360 - 39s - loss: 9.9993e-05 - Head: 8.0701e-05 - Beak: 7.3213e-05 - Body_top: 1.1307e-04 - RFlipper_mid: 1.0590e-04 - LFlipper_mid: 1.0479e-04 - Body_bottom: 1.7333e-04 - RFoot: 7.4348e-05 - LFoot: 7.4592e-05 - val_loss: 2.2068e-04 - val_Head: 2.2503e-04 - val_Beak: 1.6753e-04 - val_Body_top: 2.6641e-04 - val_RFlipper_mid: 1.9838e-04 - val_LFlipper_mid: 2.9387e-04 - val_Body_bottom: 3.1766e-04 - val_RFoot: 1.3104e-04 - val_LFoot: 1.6551e-04 - lr: 5.0000e-05 - 39s/epoch - 109ms/step\n",
      "Epoch 39/200\n",
      "360/360 - 37s - loss: 9.7131e-05 - Head: 7.7227e-05 - Beak: 7.1388e-05 - Body_top: 1.1047e-04 - RFlipper_mid: 1.0291e-04 - LFlipper_mid: 9.9543e-05 - Body_bottom: 1.7047e-04 - RFoot: 7.2722e-05 - LFoot: 7.2318e-05 - val_loss: 2.2332e-04 - val_Head: 2.2411e-04 - val_Beak: 1.7028e-04 - val_Body_top: 2.9387e-04 - val_RFlipper_mid: 2.0281e-04 - val_LFlipper_mid: 2.9156e-04 - val_Body_bottom: 3.1619e-04 - val_RFoot: 1.3151e-04 - val_LFoot: 1.5626e-04 - lr: 5.0000e-05 - 37s/epoch - 103ms/step\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "360/360 - 37s - loss: 9.7465e-05 - Head: 7.6341e-05 - Beak: 7.1414e-05 - Body_top: 1.0785e-04 - RFlipper_mid: 1.0334e-04 - LFlipper_mid: 1.0164e-04 - Body_bottom: 1.7385e-04 - RFoot: 7.1567e-05 - LFoot: 7.3726e-05 - val_loss: 2.1977e-04 - val_Head: 2.2085e-04 - val_Beak: 1.6401e-04 - val_Body_top: 2.7359e-04 - val_RFlipper_mid: 1.9881e-04 - val_LFlipper_mid: 2.9393e-04 - val_Body_bottom: 3.1546e-04 - val_RFoot: 1.3321e-04 - val_LFoot: 1.5833e-04 - lr: 5.0000e-05 - 37s/epoch - 102ms/step\n",
      "Epoch 41/200\n",
      "360/360 - 37s - loss: 9.2328e-05 - Head: 7.1703e-05 - Beak: 6.8453e-05 - Body_top: 1.0312e-04 - RFlipper_mid: 9.7031e-05 - LFlipper_mid: 9.7151e-05 - Body_bottom: 1.6683e-04 - RFoot: 6.8200e-05 - LFoot: 6.6143e-05 - val_loss: 2.1736e-04 - val_Head: 2.0114e-04 - val_Beak: 1.6591e-04 - val_Body_top: 2.7341e-04 - val_RFlipper_mid: 2.0330e-04 - val_LFlipper_mid: 2.9134e-04 - val_Body_bottom: 3.1798e-04 - val_RFoot: 1.3057e-04 - val_LFoot: 1.5527e-04 - lr: 2.5000e-05 - 37s/epoch - 102ms/step\n",
      "Epoch 42/200\n",
      "360/360 - 40s - loss: 8.9796e-05 - Head: 6.8465e-05 - Beak: 6.7978e-05 - Body_top: 1.0161e-04 - RFlipper_mid: 9.3393e-05 - LFlipper_mid: 9.3446e-05 - Body_bottom: 1.6390e-04 - RFoot: 6.5062e-05 - LFoot: 6.4511e-05 - val_loss: 2.1837e-04 - val_Head: 2.0428e-04 - val_Beak: 1.6553e-04 - val_Body_top: 2.7922e-04 - val_RFlipper_mid: 2.0440e-04 - val_LFlipper_mid: 2.8721e-04 - val_Body_bottom: 3.1592e-04 - val_RFoot: 1.2935e-04 - val_LFoot: 1.6106e-04 - lr: 2.5000e-05 - 40s/epoch - 110ms/step\n",
      "Epoch 43/200\n",
      "360/360 - 37s - loss: 9.0416e-05 - Head: 7.0547e-05 - Beak: 6.7846e-05 - Body_top: 1.0082e-04 - RFlipper_mid: 9.5905e-05 - LFlipper_mid: 9.3892e-05 - Body_bottom: 1.6437e-04 - RFoot: 6.4890e-05 - LFoot: 6.5057e-05 - val_loss: 2.1909e-04 - val_Head: 2.1022e-04 - val_Beak: 1.6909e-04 - val_Body_top: 2.7545e-04 - val_RFlipper_mid: 2.0378e-04 - val_LFlipper_mid: 2.9494e-04 - val_Body_bottom: 3.1231e-04 - val_RFoot: 1.3273e-04 - val_LFoot: 1.5420e-04 - lr: 2.5000e-05 - 37s/epoch - 103ms/step\n",
      "Epoch 44/200\n",
      "360/360 - 40s - loss: 8.9225e-05 - Head: 6.7596e-05 - Beak: 6.6032e-05 - Body_top: 1.0003e-04 - RFlipper_mid: 9.2677e-05 - LFlipper_mid: 9.5618e-05 - Body_bottom: 1.6387e-04 - RFoot: 6.3950e-05 - LFoot: 6.4026e-05 - val_loss: 2.1878e-04 - val_Head: 2.0915e-04 - val_Beak: 1.7113e-04 - val_Body_top: 2.7251e-04 - val_RFlipper_mid: 2.0131e-04 - val_LFlipper_mid: 2.9275e-04 - val_Body_bottom: 3.1561e-04 - val_RFoot: 1.3218e-04 - val_LFoot: 1.5556e-04 - lr: 2.5000e-05 - 40s/epoch - 111ms/step\n",
      "Epoch 45/200\n",
      "360/360 - 39s - loss: 8.8447e-05 - Head: 6.9350e-05 - Beak: 6.7903e-05 - Body_top: 9.9226e-05 - RFlipper_mid: 9.2564e-05 - LFlipper_mid: 9.3393e-05 - Body_bottom: 1.6177e-04 - RFoot: 6.3174e-05 - LFoot: 6.0200e-05 - val_loss: 2.1998e-04 - val_Head: 2.0795e-04 - val_Beak: 1.6558e-04 - val_Body_top: 2.8384e-04 - val_RFlipper_mid: 2.0466e-04 - val_LFlipper_mid: 2.9268e-04 - val_Body_bottom: 3.1127e-04 - val_RFoot: 1.3349e-04 - val_LFoot: 1.6035e-04 - lr: 2.5000e-05 - 39s/epoch - 107ms/step\n",
      "Epoch 46/200\n",
      "360/360 - 38s - loss: 8.8633e-05 - Head: 6.9841e-05 - Beak: 6.5794e-05 - Body_top: 9.8581e-05 - RFlipper_mid: 9.2482e-05 - LFlipper_mid: 9.3691e-05 - Body_bottom: 1.6423e-04 - RFoot: 6.3691e-05 - LFoot: 6.0753e-05 - val_loss: 2.1878e-04 - val_Head: 2.1080e-04 - val_Beak: 1.6478e-04 - val_Body_top: 2.7114e-04 - val_RFlipper_mid: 2.0263e-04 - val_LFlipper_mid: 2.9159e-04 - val_Body_bottom: 3.1736e-04 - val_RFoot: 1.3637e-04 - val_LFoot: 1.5556e-04 - lr: 2.5000e-05 - 38s/epoch - 105ms/step\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "360/360 - 40s - loss: 8.7074e-05 - Head: 6.7631e-05 - Beak: 6.1374e-05 - Body_top: 9.7823e-05 - RFlipper_mid: 9.1282e-05 - LFlipper_mid: 9.2540e-05 - Body_bottom: 1.6284e-04 - RFoot: 6.1476e-05 - LFoot: 6.1624e-05 - val_loss: 2.1709e-04 - val_Head: 2.0578e-04 - val_Beak: 1.5098e-04 - val_Body_top: 2.7120e-04 - val_RFlipper_mid: 2.0489e-04 - val_LFlipper_mid: 2.9622e-04 - val_Body_bottom: 3.1369e-04 - val_RFoot: 1.3818e-04 - val_LFoot: 1.5579e-04 - lr: 2.5000e-05 - 40s/epoch - 111ms/step\n",
      "Epoch 48/200\n",
      "360/360 - 39s - loss: 8.4411e-05 - Head: 6.5025e-05 - Beak: 6.1944e-05 - Body_top: 9.5163e-05 - RFlipper_mid: 8.8539e-05 - LFlipper_mid: 8.8842e-05 - Body_bottom: 1.5880e-04 - RFoot: 5.9026e-05 - LFoot: 5.7941e-05 - val_loss: 2.1742e-04 - val_Head: 2.0397e-04 - val_Beak: 1.6019e-04 - val_Body_top: 2.7778e-04 - val_RFlipper_mid: 2.0204e-04 - val_LFlipper_mid: 2.9312e-04 - val_Body_bottom: 3.1307e-04 - val_RFoot: 1.3538e-04 - val_LFoot: 1.5378e-04 - lr: 1.2500e-05 - 39s/epoch - 109ms/step\n",
      "Epoch 49/200\n",
      "360/360 - 37s - loss: 8.4610e-05 - Head: 6.4614e-05 - Beak: 6.4341e-05 - Body_top: 9.3672e-05 - RFlipper_mid: 8.8956e-05 - LFlipper_mid: 8.9465e-05 - Body_bottom: 1.5840e-04 - RFoot: 5.9870e-05 - LFoot: 5.7561e-05 - val_loss: 2.1680e-04 - val_Head: 2.0325e-04 - val_Beak: 1.6298e-04 - val_Body_top: 2.7982e-04 - val_RFlipper_mid: 1.9915e-04 - val_LFlipper_mid: 2.9124e-04 - val_Body_bottom: 3.0989e-04 - val_RFoot: 1.3439e-04 - val_LFoot: 1.5369e-04 - lr: 1.2500e-05 - 37s/epoch - 104ms/step\n",
      "Epoch 50/200\n",
      "360/360 - 38s - loss: 8.3763e-05 - Head: 6.2204e-05 - Beak: 6.1912e-05 - Body_top: 9.4104e-05 - RFlipper_mid: 8.7374e-05 - LFlipper_mid: 8.8719e-05 - Body_bottom: 1.5856e-04 - RFoot: 5.9740e-05 - LFoot: 5.7489e-05 - val_loss: 2.1838e-04 - val_Head: 2.0018e-04 - val_Beak: 1.7133e-04 - val_Body_top: 2.6899e-04 - val_RFlipper_mid: 2.0685e-04 - val_LFlipper_mid: 2.9409e-04 - val_Body_bottom: 3.1280e-04 - val_RFoot: 1.3947e-04 - val_LFoot: 1.5331e-04 - lr: 1.2500e-05 - 38s/epoch - 105ms/step\n",
      "Epoch 51/200\n",
      "360/360 - 39s - loss: 8.3331e-05 - Head: 6.3096e-05 - Beak: 5.9381e-05 - Body_top: 9.2250e-05 - RFlipper_mid: 8.7968e-05 - LFlipper_mid: 9.0302e-05 - Body_bottom: 1.5767e-04 - RFoot: 5.8013e-05 - LFoot: 5.7970e-05 - val_loss: 2.1719e-04 - val_Head: 1.9687e-04 - val_Beak: 1.6090e-04 - val_Body_top: 2.7810e-04 - val_RFlipper_mid: 2.0582e-04 - val_LFlipper_mid: 2.9381e-04 - val_Body_bottom: 3.0951e-04 - val_RFoot: 1.4120e-04 - val_LFoot: 1.5133e-04 - lr: 1.2500e-05 - 39s/epoch - 109ms/step\n",
      "Epoch 52/200\n",
      "360/360 - 38s - loss: 8.2475e-05 - Head: 6.2996e-05 - Beak: 5.8994e-05 - Body_top: 9.2686e-05 - RFlipper_mid: 8.6151e-05 - LFlipper_mid: 8.8085e-05 - Body_bottom: 1.5748e-04 - RFoot: 5.7514e-05 - LFoot: 5.5887e-05 - val_loss: 2.1752e-04 - val_Head: 2.0911e-04 - val_Beak: 1.6769e-04 - val_Body_top: 2.7561e-04 - val_RFlipper_mid: 2.0037e-04 - val_LFlipper_mid: 2.9402e-04 - val_Body_bottom: 3.0733e-04 - val_RFoot: 1.3618e-04 - val_LFoot: 1.4986e-04 - lr: 1.2500e-05 - 38s/epoch - 105ms/step\n",
      "Epoch 53/200\n",
      "360/360 - 39s - loss: 8.2549e-05 - Head: 6.2600e-05 - Beak: 6.1394e-05 - Body_top: 9.2856e-05 - RFlipper_mid: 8.6183e-05 - LFlipper_mid: 8.7805e-05 - Body_bottom: 1.5649e-04 - RFoot: 5.8581e-05 - LFoot: 5.4490e-05 - val_loss: 2.1882e-04 - val_Head: 2.2064e-04 - val_Beak: 1.6085e-04 - val_Body_top: 2.6906e-04 - val_RFlipper_mid: 2.0342e-04 - val_LFlipper_mid: 2.9499e-04 - val_Body_bottom: 3.1574e-04 - val_RFoot: 1.3623e-04 - val_LFoot: 1.4962e-04 - lr: 1.2500e-05 - 39s/epoch - 107ms/step\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "360/360 - 37s - loss: 8.1943e-05 - Head: 6.1519e-05 - Beak: 6.0107e-05 - Body_top: 9.1124e-05 - RFlipper_mid: 8.5580e-05 - LFlipper_mid: 8.7938e-05 - Body_bottom: 1.5660e-04 - RFoot: 5.8833e-05 - LFoot: 5.3846e-05 - val_loss: 2.1734e-04 - val_Head: 2.0102e-04 - val_Beak: 1.6159e-04 - val_Body_top: 2.6203e-04 - val_RFlipper_mid: 2.0040e-04 - val_LFlipper_mid: 2.9498e-04 - val_Body_bottom: 3.1582e-04 - val_RFoot: 1.4598e-04 - val_LFoot: 1.5689e-04 - lr: 1.2500e-05 - 37s/epoch - 103ms/step\n",
      "Epoch 55/200\n",
      "360/360 - 37s - loss: 8.1180e-05 - Head: 6.0075e-05 - Beak: 5.9875e-05 - Body_top: 9.0801e-05 - RFlipper_mid: 8.5530e-05 - LFlipper_mid: 8.6918e-05 - Body_bottom: 1.5562e-04 - RFoot: 5.6699e-05 - LFoot: 5.3922e-05 - val_loss: 2.1480e-04 - val_Head: 2.0234e-04 - val_Beak: 1.5985e-04 - val_Body_top: 2.5975e-04 - val_RFlipper_mid: 2.0106e-04 - val_LFlipper_mid: 2.9403e-04 - val_Body_bottom: 3.1212e-04 - val_RFoot: 1.3871e-04 - val_LFoot: 1.5052e-04 - lr: 6.2500e-06 - 37s/epoch - 103ms/step\n",
      "Epoch 56/200\n",
      "360/360 - 39s - loss: 8.0519e-05 - Head: 5.8105e-05 - Beak: 5.9115e-05 - Body_top: 9.0868e-05 - RFlipper_mid: 8.3248e-05 - LFlipper_mid: 8.6625e-05 - Body_bottom: 1.5561e-04 - RFoot: 5.6317e-05 - LFoot: 5.4264e-05 - val_loss: 2.1471e-04 - val_Head: 2.0308e-04 - val_Beak: 1.5937e-04 - val_Body_top: 2.6370e-04 - val_RFlipper_mid: 2.0346e-04 - val_LFlipper_mid: 2.9180e-04 - val_Body_bottom: 3.1275e-04 - val_RFoot: 1.3711e-04 - val_LFoot: 1.4641e-04 - lr: 6.2500e-06 - 39s/epoch - 108ms/step\n",
      "Epoch 57/200\n",
      "360/360 - 38s - loss: 7.9999e-05 - Head: 5.7936e-05 - Beak: 5.8265e-05 - Body_top: 8.9440e-05 - RFlipper_mid: 8.3222e-05 - LFlipper_mid: 8.5651e-05 - Body_bottom: 1.5430e-04 - RFoot: 5.6821e-05 - LFoot: 5.4360e-05 - val_loss: 2.1901e-04 - val_Head: 2.0581e-04 - val_Beak: 1.6165e-04 - val_Body_top: 2.7605e-04 - val_RFlipper_mid: 2.0922e-04 - val_LFlipper_mid: 2.9533e-04 - val_Body_bottom: 3.1387e-04 - val_RFoot: 1.4004e-04 - val_LFoot: 1.5012e-04 - lr: 6.2500e-06 - 38s/epoch - 106ms/step\n",
      "Epoch 58/200\n",
      "360/360 - 37s - loss: 8.0243e-05 - Head: 5.9065e-05 - Beak: 5.9859e-05 - Body_top: 9.0109e-05 - RFlipper_mid: 8.2596e-05 - LFlipper_mid: 8.6366e-05 - Body_bottom: 1.5368e-04 - RFoot: 5.6224e-05 - LFoot: 5.4049e-05 - val_loss: 2.1852e-04 - val_Head: 2.1386e-04 - val_Beak: 1.6500e-04 - val_Body_top: 2.6835e-04 - val_RFlipper_mid: 2.0347e-04 - val_LFlipper_mid: 2.9509e-04 - val_Body_bottom: 3.1381e-04 - val_RFoot: 1.3904e-04 - val_LFoot: 1.4953e-04 - lr: 6.2500e-06 - 37s/epoch - 104ms/step\n",
      "Epoch 59/200\n",
      "360/360 - 37s - loss: 8.0660e-05 - Head: 6.1008e-05 - Beak: 5.8952e-05 - Body_top: 9.0412e-05 - RFlipper_mid: 8.3061e-05 - LFlipper_mid: 8.6014e-05 - Body_bottom: 1.5584e-04 - RFoot: 5.6289e-05 - LFoot: 5.3704e-05 - val_loss: 2.1692e-04 - val_Head: 2.0310e-04 - val_Beak: 1.6367e-04 - val_Body_top: 2.7058e-04 - val_RFlipper_mid: 2.0162e-04 - val_LFlipper_mid: 2.9517e-04 - val_Body_bottom: 3.0973e-04 - val_RFoot: 1.3606e-04 - val_LFoot: 1.5547e-04 - lr: 6.2500e-06 - 37s/epoch - 103ms/step\n",
      "Epoch 60/200\n",
      "360/360 - 40s - loss: 7.9619e-05 - Head: 5.9509e-05 - Beak: 5.7984e-05 - Body_top: 8.9565e-05 - RFlipper_mid: 8.2890e-05 - LFlipper_mid: 8.5429e-05 - Body_bottom: 1.5349e-04 - RFoot: 5.5475e-05 - LFoot: 5.2612e-05 - val_loss: 2.1936e-04 - val_Head: 2.1212e-04 - val_Beak: 1.6433e-04 - val_Body_top: 2.7405e-04 - val_RFlipper_mid: 2.1098e-04 - val_LFlipper_mid: 2.9779e-04 - val_Body_bottom: 3.1026e-04 - val_RFoot: 1.3961e-04 - val_LFoot: 1.4571e-04 - lr: 6.2500e-06 - 40s/epoch - 110ms/step\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "360/360 - 37s - loss: 7.9580e-05 - Head: 5.9366e-05 - Beak: 5.6199e-05 - Body_top: 9.0771e-05 - RFlipper_mid: 8.3317e-05 - LFlipper_mid: 8.5653e-05 - Body_bottom: 1.5258e-04 - RFoot: 5.5112e-05 - LFoot: 5.3636e-05 - val_loss: 2.1959e-04 - val_Head: 2.0917e-04 - val_Beak: 1.7408e-04 - val_Body_top: 2.6285e-04 - val_RFlipper_mid: 2.0408e-04 - val_LFlipper_mid: 2.9549e-04 - val_Body_bottom: 3.1532e-04 - val_RFoot: 1.3986e-04 - val_LFoot: 1.5588e-04 - lr: 6.2500e-06 - 37s/epoch - 104ms/step\n",
      "Epoch 62/200\n",
      "360/360 - 40s - loss: 7.8813e-05 - Head: 5.9929e-05 - Beak: 5.8099e-05 - Body_top: 8.8715e-05 - RFlipper_mid: 8.1393e-05 - LFlipper_mid: 8.3376e-05 - Body_bottom: 1.5323e-04 - RFoot: 5.5390e-05 - LFoot: 5.0372e-05 - val_loss: 2.1659e-04 - val_Head: 2.0345e-04 - val_Beak: 1.5930e-04 - val_Body_top: 2.6846e-04 - val_RFlipper_mid: 1.9840e-04 - val_LFlipper_mid: 2.9614e-04 - val_Body_bottom: 3.1433e-04 - val_RFoot: 1.3875e-04 - val_LFoot: 1.5385e-04 - lr: 3.1250e-06 - 40s/epoch - 110ms/step\n",
      "Epoch 63/200\n",
      "360/360 - 37s - loss: 7.8955e-05 - Head: 5.8880e-05 - Beak: 5.7226e-05 - Body_top: 8.8646e-05 - RFlipper_mid: 8.1964e-05 - LFlipper_mid: 8.6102e-05 - Body_bottom: 1.5362e-04 - RFoot: 5.3773e-05 - LFoot: 5.1429e-05 - val_loss: 2.1547e-04 - val_Head: 2.0759e-04 - val_Beak: 1.5919e-04 - val_Body_top: 2.6293e-04 - val_RFlipper_mid: 1.9965e-04 - val_LFlipper_mid: 2.9097e-04 - val_Body_bottom: 3.1135e-04 - val_RFoot: 1.4045e-04 - val_LFoot: 1.5164e-04 - lr: 3.1250e-06 - 37s/epoch - 104ms/step\n",
      "Epoch 64/200\n",
      "360/360 - 38s - loss: 7.8956e-05 - Head: 5.8772e-05 - Beak: 5.7956e-05 - Body_top: 8.9730e-05 - RFlipper_mid: 8.2173e-05 - LFlipper_mid: 8.4015e-05 - Body_bottom: 1.5239e-04 - RFoot: 5.5433e-05 - LFoot: 5.1174e-05 - val_loss: 2.1761e-04 - val_Head: 2.1187e-04 - val_Beak: 1.6079e-04 - val_Body_top: 2.7337e-04 - val_RFlipper_mid: 1.9925e-04 - val_LFlipper_mid: 2.9389e-04 - val_Body_bottom: 3.1372e-04 - val_RFoot: 1.3799e-04 - val_LFoot: 1.4997e-04 - lr: 3.1250e-06 - 38s/epoch - 106ms/step\n",
      "Epoch 65/200\n",
      "360/360 - 37s - loss: 7.7896e-05 - Head: 5.8102e-05 - Beak: 5.6392e-05 - Body_top: 8.7688e-05 - RFlipper_mid: 7.9332e-05 - LFlipper_mid: 8.3665e-05 - Body_bottom: 1.5164e-04 - RFoot: 5.4382e-05 - LFoot: 5.1970e-05 - val_loss: 2.1779e-04 - val_Head: 2.0518e-04 - val_Beak: 1.6299e-04 - val_Body_top: 2.7050e-04 - val_RFlipper_mid: 2.0543e-04 - val_LFlipper_mid: 2.9559e-04 - val_Body_bottom: 3.1352e-04 - val_RFoot: 1.3995e-04 - val_LFoot: 1.4918e-04 - lr: 3.1250e-06 - 37s/epoch - 102ms/step\n",
      "Epoch 66/200\n",
      "360/360 - 37s - loss: 7.9060e-05 - Head: 5.8371e-05 - Beak: 5.8332e-05 - Body_top: 8.8411e-05 - RFlipper_mid: 8.1444e-05 - LFlipper_mid: 8.4863e-05 - Body_bottom: 1.5456e-04 - RFoot: 5.5379e-05 - LFoot: 5.1121e-05 - val_loss: 2.1753e-04 - val_Head: 1.9968e-04 - val_Beak: 1.6869e-04 - val_Body_top: 2.6610e-04 - val_RFlipper_mid: 2.0537e-04 - val_LFlipper_mid: 2.9462e-04 - val_Body_bottom: 3.1249e-04 - val_RFoot: 1.4223e-04 - val_LFoot: 1.5104e-04 - lr: 3.1250e-06 - 37s/epoch - 103ms/step\n",
      "Epoch 67/200\n",
      "360/360 - 37s - loss: 7.9032e-05 - Head: 5.9683e-05 - Beak: 5.9165e-05 - Body_top: 9.0575e-05 - RFlipper_mid: 8.0558e-05 - LFlipper_mid: 8.3807e-05 - Body_bottom: 1.5229e-04 - RFoot: 5.3778e-05 - LFoot: 5.2396e-05 - val_loss: 2.1748e-04 - val_Head: 2.0437e-04 - val_Beak: 1.6350e-04 - val_Body_top: 2.6876e-04 - val_RFlipper_mid: 2.0886e-04 - val_LFlipper_mid: 2.9505e-04 - val_Body_bottom: 3.1372e-04 - val_RFoot: 1.3758e-04 - val_LFoot: 1.4802e-04 - lr: 3.1250e-06 - 37s/epoch - 102ms/step\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "360/360 - 39s - loss: 7.8444e-05 - Head: 6.0098e-05 - Beak: 5.6850e-05 - Body_top: 8.9380e-05 - RFlipper_mid: 8.1308e-05 - LFlipper_mid: 8.3486e-05 - Body_bottom: 1.5282e-04 - RFoot: 5.3140e-05 - LFoot: 5.0471e-05 - val_loss: 2.1948e-04 - val_Head: 2.1439e-04 - val_Beak: 1.6629e-04 - val_Body_top: 2.6819e-04 - val_RFlipper_mid: 2.0880e-04 - val_LFlipper_mid: 2.9469e-04 - val_Body_bottom: 3.1532e-04 - val_RFoot: 1.3949e-04 - val_LFoot: 1.4869e-04 - lr: 3.1250e-06 - 39s/epoch - 108ms/step\n",
      "Epoch 69/200\n",
      "360/360 - 39s - loss: 7.7636e-05 - Head: 5.5999e-05 - Beak: 5.6402e-05 - Body_top: 8.8429e-05 - RFlipper_mid: 7.9092e-05 - LFlipper_mid: 8.3537e-05 - Body_bottom: 1.5181e-04 - RFoot: 5.4924e-05 - LFoot: 5.0903e-05 - val_loss: 2.1621e-04 - val_Head: 2.0700e-04 - val_Beak: 1.6385e-04 - val_Body_top: 2.6913e-04 - val_RFlipper_mid: 2.0208e-04 - val_LFlipper_mid: 2.9249e-04 - val_Body_bottom: 3.0990e-04 - val_RFoot: 1.3789e-04 - val_LFoot: 1.4731e-04 - lr: 1.5625e-06 - 39s/epoch - 107ms/step\n",
      "Epoch 70/200\n",
      "360/360 - 37s - loss: 7.7185e-05 - Head: 5.9515e-05 - Beak: 5.5324e-05 - Body_top: 8.7507e-05 - RFlipper_mid: 7.8895e-05 - LFlipper_mid: 8.2585e-05 - Body_bottom: 1.5125e-04 - RFoot: 5.2882e-05 - LFoot: 4.9522e-05 - val_loss: 2.1657e-04 - val_Head: 2.0914e-04 - val_Beak: 1.6018e-04 - val_Body_top: 2.6177e-04 - val_RFlipper_mid: 2.0266e-04 - val_LFlipper_mid: 2.9368e-04 - val_Body_bottom: 3.1464e-04 - val_RFoot: 1.4307e-04 - val_LFoot: 1.4739e-04 - lr: 1.5625e-06 - 37s/epoch - 103ms/step\n",
      "Epoch 71/200\n",
      "360/360 - 36s - loss: 7.7578e-05 - Head: 5.7254e-05 - Beak: 5.6619e-05 - Body_top: 8.8372e-05 - RFlipper_mid: 8.1171e-05 - LFlipper_mid: 8.3864e-05 - Body_bottom: 1.5097e-04 - RFoot: 5.2708e-05 - LFoot: 4.9671e-05 - val_loss: 2.1741e-04 - val_Head: 2.0066e-04 - val_Beak: 1.6347e-04 - val_Body_top: 2.6526e-04 - val_RFlipper_mid: 2.1049e-04 - val_LFlipper_mid: 2.9410e-04 - val_Body_bottom: 3.1252e-04 - val_RFoot: 1.3986e-04 - val_LFoot: 1.5290e-04 - lr: 1.5625e-06 - 36s/epoch - 100ms/step\n",
      "Epoch 72/200\n",
      "360/360 - 38s - loss: 7.8642e-05 - Head: 5.8870e-05 - Beak: 5.9427e-05 - Body_top: 8.7793e-05 - RFlipper_mid: 8.0692e-05 - LFlipper_mid: 8.5853e-05 - Body_bottom: 1.5260e-04 - RFoot: 5.3363e-05 - LFoot: 5.0538e-05 - val_loss: 2.1660e-04 - val_Head: 2.0748e-04 - val_Beak: 1.6051e-04 - val_Body_top: 2.6278e-04 - val_RFlipper_mid: 2.0649e-04 - val_LFlipper_mid: 2.9127e-04 - val_Body_bottom: 3.1442e-04 - val_RFoot: 1.4145e-04 - val_LFoot: 1.4844e-04 - lr: 1.5625e-06 - 38s/epoch - 105ms/step\n",
      "Epoch 73/200\n",
      "360/360 - 39s - loss: 7.7242e-05 - Head: 5.6727e-05 - Beak: 5.5614e-05 - Body_top: 8.9368e-05 - RFlipper_mid: 7.9359e-05 - LFlipper_mid: 8.3340e-05 - Body_bottom: 1.5112e-04 - RFoot: 5.3035e-05 - LFoot: 4.9372e-05 - val_loss: 2.1852e-04 - val_Head: 2.1337e-04 - val_Beak: 1.6088e-04 - val_Body_top: 2.6364e-04 - val_RFlipper_mid: 2.0945e-04 - val_LFlipper_mid: 2.9356e-04 - val_Body_bottom: 3.1565e-04 - val_RFoot: 1.3959e-04 - val_LFoot: 1.5199e-04 - lr: 1.5625e-06 - 39s/epoch - 109ms/step\n",
      "Epoch 74/200\n",
      "360/360 - 37s - loss: 7.7743e-05 - Head: 5.8601e-05 - Beak: 5.7796e-05 - Body_top: 8.7136e-05 - RFlipper_mid: 7.9642e-05 - LFlipper_mid: 8.4637e-05 - Body_bottom: 1.5136e-04 - RFoot: 5.2620e-05 - LFoot: 5.0152e-05 - val_loss: 2.1529e-04 - val_Head: 1.9363e-04 - val_Beak: 1.5936e-04 - val_Body_top: 2.6651e-04 - val_RFlipper_mid: 2.0560e-04 - val_LFlipper_mid: 2.9434e-04 - val_Body_bottom: 3.1342e-04 - val_RFoot: 1.3961e-04 - val_LFoot: 1.4984e-04 - lr: 1.5625e-06 - 37s/epoch - 103ms/step\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "360/360 - 37s - loss: 7.7364e-05 - Head: 5.7569e-05 - Beak: 5.6883e-05 - Body_top: 8.8020e-05 - RFlipper_mid: 7.9320e-05 - LFlipper_mid: 8.3922e-05 - Body_bottom: 1.5216e-04 - RFoot: 5.2133e-05 - LFoot: 4.8902e-05 - val_loss: 2.1595e-04 - val_Head: 1.9469e-04 - val_Beak: 1.6011e-04 - val_Body_top: 2.6463e-04 - val_RFlipper_mid: 2.0686e-04 - val_LFlipper_mid: 2.9208e-04 - val_Body_bottom: 3.1567e-04 - val_RFoot: 1.4109e-04 - val_LFoot: 1.5245e-04 - lr: 1.5625e-06 - 37s/epoch - 102ms/step\n",
      "Epoch 76/200\n",
      "360/360 - 37s - loss: 7.8231e-05 - Head: 6.0195e-05 - Beak: 5.9440e-05 - Body_top: 8.8599e-05 - RFlipper_mid: 7.9802e-05 - LFlipper_mid: 8.2792e-05 - Body_bottom: 1.5106e-04 - RFoot: 5.2755e-05 - LFoot: 5.1205e-05 - val_loss: 2.1699e-04 - val_Head: 2.0661e-04 - val_Beak: 1.6378e-04 - val_Body_top: 2.6431e-04 - val_RFlipper_mid: 2.0478e-04 - val_LFlipper_mid: 2.9195e-04 - val_Body_bottom: 3.1424e-04 - val_RFoot: 1.4108e-04 - val_LFoot: 1.4916e-04 - lr: 7.8125e-07 - 37s/epoch - 102ms/step\n",
      "Epoch 77/200\n",
      "360/360 - 40s - loss: 7.6400e-05 - Head: 5.5819e-05 - Beak: 5.6980e-05 - Body_top: 8.7145e-05 - RFlipper_mid: 7.8097e-05 - LFlipper_mid: 8.2598e-05 - Body_bottom: 1.5172e-04 - RFoot: 5.1471e-05 - LFoot: 4.7368e-05 - val_loss: 2.1722e-04 - val_Head: 2.0698e-04 - val_Beak: 1.6038e-04 - val_Body_top: 2.6709e-04 - val_RFlipper_mid: 2.0212e-04 - val_LFlipper_mid: 2.9606e-04 - val_Body_bottom: 3.1575e-04 - val_RFoot: 1.3918e-04 - val_LFoot: 1.5018e-04 - lr: 7.8125e-07 - 40s/epoch - 110ms/step\n",
      "Epoch 78/200\n",
      "360/360 - 39s - loss: 7.7261e-05 - Head: 5.7023e-05 - Beak: 5.6506e-05 - Body_top: 8.7649e-05 - RFlipper_mid: 8.0160e-05 - LFlipper_mid: 8.2952e-05 - Body_bottom: 1.5125e-04 - RFoot: 5.3556e-05 - LFoot: 4.8996e-05 - val_loss: 2.1622e-04 - val_Head: 1.9838e-04 - val_Beak: 1.6694e-04 - val_Body_top: 2.6518e-04 - val_RFlipper_mid: 2.0427e-04 - val_LFlipper_mid: 2.9493e-04 - val_Body_bottom: 3.1301e-04 - val_RFoot: 1.3879e-04 - val_LFoot: 1.4824e-04 - lr: 7.8125e-07 - 39s/epoch - 108ms/step\n",
      "Epoch 79/200\n",
      "360/360 - 37s - loss: 7.7113e-05 - Head: 5.7748e-05 - Beak: 5.5346e-05 - Body_top: 8.7808e-05 - RFlipper_mid: 8.0042e-05 - LFlipper_mid: 8.3384e-05 - Body_bottom: 1.5096e-04 - RFoot: 5.3124e-05 - LFoot: 4.8498e-05 - val_loss: 2.1727e-04 - val_Head: 2.1547e-04 - val_Beak: 1.6173e-04 - val_Body_top: 2.6382e-04 - val_RFlipper_mid: 2.0440e-04 - val_LFlipper_mid: 2.9236e-04 - val_Body_bottom: 3.1407e-04 - val_RFoot: 1.3913e-04 - val_LFoot: 1.4716e-04 - lr: 7.8125e-07 - 37s/epoch - 103ms/step\n",
      "Epoch 80/200\n",
      "360/360 - 37s - loss: 7.8049e-05 - Head: 5.9812e-05 - Beak: 5.8388e-05 - Body_top: 8.7636e-05 - RFlipper_mid: 8.0751e-05 - LFlipper_mid: 8.3753e-05 - Body_bottom: 1.5053e-04 - RFoot: 5.4472e-05 - LFoot: 4.9054e-05 - val_loss: 2.1586e-04 - val_Head: 1.9653e-04 - val_Beak: 1.7151e-04 - val_Body_top: 2.7088e-04 - val_RFlipper_mid: 2.0522e-04 - val_LFlipper_mid: 2.9151e-04 - val_Body_bottom: 3.0879e-04 - val_RFoot: 1.3604e-04 - val_LFoot: 1.4639e-04 - lr: 7.8125e-07 - 37s/epoch - 103ms/step\n",
      "Epoch 81/200\n",
      "360/360 - 39s - loss: 7.7418e-05 - Head: 5.8548e-05 - Beak: 5.7973e-05 - Body_top: 8.8453e-05 - RFlipper_mid: 8.0320e-05 - LFlipper_mid: 8.2128e-05 - Body_bottom: 1.4994e-04 - RFoot: 5.2692e-05 - LFoot: 4.9290e-05 - val_loss: 2.1539e-04 - val_Head: 1.9649e-04 - val_Beak: 1.6655e-04 - val_Body_top: 2.6505e-04 - val_RFlipper_mid: 2.0140e-04 - val_LFlipper_mid: 2.9229e-04 - val_Body_bottom: 3.1314e-04 - val_RFoot: 1.3682e-04 - val_LFoot: 1.5140e-04 - lr: 7.8125e-07 - 39s/epoch - 108ms/step\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "360/360 - 37s - loss: 7.7307e-05 - Head: 5.8749e-05 - Beak: 5.8794e-05 - Body_top: 8.6783e-05 - RFlipper_mid: 7.8583e-05 - LFlipper_mid: 8.3706e-05 - Body_bottom: 1.5132e-04 - RFoot: 5.2378e-05 - LFoot: 4.8150e-05 - val_loss: 2.1731e-04 - val_Head: 2.0473e-04 - val_Beak: 1.6086e-04 - val_Body_top: 2.6437e-04 - val_RFlipper_mid: 2.1269e-04 - val_LFlipper_mid: 2.9246e-04 - val_Body_bottom: 3.1482e-04 - val_RFoot: 1.3793e-04 - val_LFoot: 1.5065e-04 - lr: 7.8125e-07 - 37s/epoch - 102ms/step\n",
      "Epoch 83/200\n",
      "360/360 - 39s - loss: 7.7065e-05 - Head: 5.6713e-05 - Beak: 5.5768e-05 - Body_top: 8.7665e-05 - RFlipper_mid: 7.9546e-05 - LFlipper_mid: 8.2594e-05 - Body_bottom: 1.5138e-04 - RFoot: 5.2652e-05 - LFoot: 5.0199e-05 - val_loss: 2.1763e-04 - val_Head: 2.0872e-04 - val_Beak: 1.7064e-04 - val_Body_top: 2.6449e-04 - val_RFlipper_mid: 2.0473e-04 - val_LFlipper_mid: 2.9176e-04 - val_Body_bottom: 3.1200e-04 - val_RFoot: 1.3925e-04 - val_LFoot: 1.4947e-04 - lr: 3.9062e-07 - 39s/epoch - 109ms/step\n",
      "Epoch 84/200\n",
      "360/360 - 39s - loss: 7.6347e-05 - Head: 5.7244e-05 - Beak: 5.6636e-05 - Body_top: 8.6094e-05 - RFlipper_mid: 7.7529e-05 - LFlipper_mid: 8.2614e-05 - Body_bottom: 1.5000e-04 - RFoot: 5.1289e-05 - LFoot: 4.9367e-05 - val_loss: 2.1708e-04 - val_Head: 2.0225e-04 - val_Beak: 1.6465e-04 - val_Body_top: 2.6825e-04 - val_RFlipper_mid: 2.0431e-04 - val_LFlipper_mid: 2.9197e-04 - val_Body_bottom: 3.1180e-04 - val_RFoot: 1.4344e-04 - val_LFoot: 1.4998e-04 - lr: 3.9062e-07 - 39s/epoch - 108ms/step\n",
      "Epoch 85/200\n",
      "360/360 - 37s - loss: 7.6550e-05 - Head: 5.5887e-05 - Beak: 5.6564e-05 - Body_top: 8.6916e-05 - RFlipper_mid: 7.8853e-05 - LFlipper_mid: 8.1433e-05 - Body_bottom: 1.5083e-04 - RFoot: 5.1975e-05 - LFoot: 4.9935e-05 - val_loss: 2.1735e-04 - val_Head: 2.0646e-04 - val_Beak: 1.7217e-04 - val_Body_top: 2.6449e-04 - val_RFlipper_mid: 2.0842e-04 - val_LFlipper_mid: 2.9256e-04 - val_Body_bottom: 3.0900e-04 - val_RFoot: 1.4034e-04 - val_LFoot: 1.4541e-04 - lr: 3.9062e-07 - 37s/epoch - 102ms/step\n",
      "Epoch 86/200\n",
      "360/360 - 38s - loss: 7.7130e-05 - Head: 5.7670e-05 - Beak: 5.6703e-05 - Body_top: 8.8201e-05 - RFlipper_mid: 7.9493e-05 - LFlipper_mid: 8.3132e-05 - Body_bottom: 1.5120e-04 - RFoot: 5.1720e-05 - LFoot: 4.8921e-05 - val_loss: 2.1993e-04 - val_Head: 2.1383e-04 - val_Beak: 1.7162e-04 - val_Body_top: 2.6996e-04 - val_RFlipper_mid: 2.0557e-04 - val_LFlipper_mid: 2.9214e-04 - val_Body_bottom: 3.1189e-04 - val_RFoot: 1.4136e-04 - val_LFoot: 1.5305e-04 - lr: 3.9062e-07 - 38s/epoch - 105ms/step\n",
      "Epoch 87/200\n",
      "360/360 - 37s - loss: 7.6595e-05 - Head: 5.6510e-05 - Beak: 5.5616e-05 - Body_top: 8.6849e-05 - RFlipper_mid: 7.8600e-05 - LFlipper_mid: 8.2470e-05 - Body_bottom: 1.5104e-04 - RFoot: 5.2425e-05 - LFoot: 4.9251e-05 - val_loss: 2.1799e-04 - val_Head: 2.0708e-04 - val_Beak: 1.6596e-04 - val_Body_top: 2.7018e-04 - val_RFlipper_mid: 2.0481e-04 - val_LFlipper_mid: 2.9400e-04 - val_Body_bottom: 3.1215e-04 - val_RFoot: 1.4279e-04 - val_LFoot: 1.4696e-04 - lr: 3.9062e-07 - 37s/epoch - 102ms/step\n",
      "Epoch 88/200\n",
      "360/360 - 39s - loss: 7.7867e-05 - Head: 5.7802e-05 - Beak: 5.7689e-05 - Body_top: 8.8010e-05 - RFlipper_mid: 8.1288e-05 - LFlipper_mid: 8.4362e-05 - Body_bottom: 1.5106e-04 - RFoot: 5.2922e-05 - LFoot: 4.9796e-05 - val_loss: 2.1595e-04 - val_Head: 1.9749e-04 - val_Beak: 1.7220e-04 - val_Body_top: 2.6359e-04 - val_RFlipper_mid: 2.0314e-04 - val_LFlipper_mid: 2.9255e-04 - val_Body_bottom: 3.0989e-04 - val_RFoot: 1.3830e-04 - val_LFoot: 1.5042e-04 - lr: 3.9062e-07 - 39s/epoch - 108ms/step\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "360/360 - 38s - loss: 7.7699e-05 - Head: 6.0447e-05 - Beak: 5.8284e-05 - Body_top: 8.6637e-05 - RFlipper_mid: 8.0153e-05 - LFlipper_mid: 8.2217e-05 - Body_bottom: 1.5168e-04 - RFoot: 5.2362e-05 - LFoot: 4.9818e-05 - val_loss: 2.1763e-04 - val_Head: 2.1205e-04 - val_Beak: 1.5714e-04 - val_Body_top: 2.7108e-04 - val_RFlipper_mid: 2.0446e-04 - val_LFlipper_mid: 2.9326e-04 - val_Body_bottom: 3.1093e-04 - val_RFoot: 1.3843e-04 - val_LFoot: 1.5368e-04 - lr: 3.9062e-07 - 38s/epoch - 105ms/step\n",
      "Epoch 90/200\n",
      "360/360 - 38s - loss: 7.6814e-05 - Head: 5.6314e-05 - Beak: 5.6246e-05 - Body_top: 8.8021e-05 - RFlipper_mid: 7.9079e-05 - LFlipper_mid: 8.3833e-05 - Body_bottom: 1.4987e-04 - RFoot: 5.2796e-05 - LFoot: 4.8360e-05 - val_loss: 2.1822e-04 - val_Head: 2.0430e-04 - val_Beak: 1.5818e-04 - val_Body_top: 2.6902e-04 - val_RFlipper_mid: 2.1090e-04 - val_LFlipper_mid: 2.9646e-04 - val_Body_bottom: 3.1459e-04 - val_RFoot: 1.4284e-04 - val_LFoot: 1.4945e-04 - lr: 1.9531e-07 - 38s/epoch - 105ms/step\n",
      "Epoch 91/200\n",
      "360/360 - 38s - loss: 7.6680e-05 - Head: 5.7762e-05 - Beak: 5.7938e-05 - Body_top: 8.7206e-05 - RFlipper_mid: 7.8856e-05 - LFlipper_mid: 8.1577e-05 - Body_bottom: 1.5089e-04 - RFoot: 5.1187e-05 - LFoot: 4.8031e-05 - val_loss: 2.1804e-04 - val_Head: 2.0829e-04 - val_Beak: 1.6720e-04 - val_Body_top: 2.7251e-04 - val_RFlipper_mid: 2.0326e-04 - val_LFlipper_mid: 2.9240e-04 - val_Body_bottom: 3.1206e-04 - val_RFoot: 1.4154e-04 - val_LFoot: 1.4707e-04 - lr: 1.9531e-07 - 38s/epoch - 104ms/step\n",
      "Epoch 92/200\n",
      "360/360 - 37s - loss: 7.7443e-05 - Head: 5.6192e-05 - Beak: 5.7715e-05 - Body_top: 8.8542e-05 - RFlipper_mid: 7.9839e-05 - LFlipper_mid: 8.2819e-05 - Body_bottom: 1.5138e-04 - RFoot: 5.2876e-05 - LFoot: 5.0179e-05 - val_loss: 2.1927e-04 - val_Head: 2.0052e-04 - val_Beak: 1.7085e-04 - val_Body_top: 2.7647e-04 - val_RFlipper_mid: 2.0781e-04 - val_LFlipper_mid: 2.9370e-04 - val_Body_bottom: 3.1466e-04 - val_RFoot: 1.4052e-04 - val_LFoot: 1.4963e-04 - lr: 1.9531e-07 - 37s/epoch - 102ms/step\n",
      "Epoch 93/200\n",
      "360/360 - 37s - loss: 7.8753e-05 - Head: 6.0721e-05 - Beak: 5.9925e-05 - Body_top: 8.8313e-05 - RFlipper_mid: 8.0627e-05 - LFlipper_mid: 8.3595e-05 - Body_bottom: 1.5204e-04 - RFoot: 5.3713e-05 - LFoot: 5.1089e-05 - val_loss: 2.1872e-04 - val_Head: 1.9776e-04 - val_Beak: 1.7406e-04 - val_Body_top: 2.7294e-04 - val_RFlipper_mid: 2.0550e-04 - val_LFlipper_mid: 2.9224e-04 - val_Body_bottom: 3.1756e-04 - val_RFoot: 1.3993e-04 - val_LFoot: 1.4974e-04 - lr: 1.9531e-07 - 37s/epoch - 103ms/step\n",
      "Epoch 94/200\n",
      "360/360 - 37s - loss: 7.7085e-05 - Head: 5.7687e-05 - Beak: 5.7413e-05 - Body_top: 8.6491e-05 - RFlipper_mid: 7.9890e-05 - LFlipper_mid: 8.2382e-05 - Body_bottom: 1.5042e-04 - RFoot: 5.3043e-05 - LFoot: 4.9356e-05 - val_loss: 2.1847e-04 - val_Head: 2.0494e-04 - val_Beak: 1.6706e-04 - val_Body_top: 2.6985e-04 - val_RFlipper_mid: 2.0660e-04 - val_LFlipper_mid: 2.9626e-04 - val_Body_bottom: 3.1105e-04 - val_RFoot: 1.4046e-04 - val_LFoot: 1.5156e-04 - lr: 1.9531e-07 - 37s/epoch - 103ms/step\n",
      "Epoch 95/200\n",
      "360/360 - 39s - loss: 7.7097e-05 - Head: 5.8116e-05 - Beak: 5.7710e-05 - Body_top: 8.7008e-05 - RFlipper_mid: 7.9563e-05 - LFlipper_mid: 8.2252e-05 - Body_bottom: 1.5035e-04 - RFoot: 5.1646e-05 - LFoot: 5.0128e-05 - val_loss: 2.1861e-04 - val_Head: 2.0256e-04 - val_Beak: 1.7463e-04 - val_Body_top: 2.6582e-04 - val_RFlipper_mid: 2.0734e-04 - val_LFlipper_mid: 2.9357e-04 - val_Body_bottom: 3.1306e-04 - val_RFoot: 1.4161e-04 - val_LFoot: 1.5030e-04 - lr: 1.9531e-07 - 39s/epoch - 109ms/step\n",
      "Epoch 96/200\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "360/360 - 39s - loss: 7.7310e-05 - Head: 5.8355e-05 - Beak: 5.6759e-05 - Body_top: 8.7151e-05 - RFlipper_mid: 7.9030e-05 - LFlipper_mid: 8.3331e-05 - Body_bottom: 1.5030e-04 - RFoot: 5.3187e-05 - LFoot: 5.0370e-05 - val_loss: 2.1934e-04 - val_Head: 2.0566e-04 - val_Beak: 1.7273e-04 - val_Body_top: 2.7143e-04 - val_RFlipper_mid: 2.0827e-04 - val_LFlipper_mid: 2.9448e-04 - val_Body_bottom: 3.1496e-04 - val_RFoot: 1.4002e-04 - val_LFoot: 1.4718e-04 - lr: 1.9531e-07 - 39s/epoch - 109ms/step\n",
      "Epoch 97/200\n",
      "360/360 - 39s - loss: 7.5605e-05 - Head: 5.3876e-05 - Beak: 5.4232e-05 - Body_top: 8.6432e-05 - RFlipper_mid: 7.8426e-05 - LFlipper_mid: 8.1605e-05 - Body_bottom: 1.5068e-04 - RFoot: 5.2440e-05 - LFoot: 4.7151e-05 - val_loss: 2.1652e-04 - val_Head: 2.0773e-04 - val_Beak: 1.6031e-04 - val_Body_top: 2.6392e-04 - val_RFlipper_mid: 2.0490e-04 - val_LFlipper_mid: 2.9391e-04 - val_Body_bottom: 3.1279e-04 - val_RFoot: 1.3986e-04 - val_LFoot: 1.4873e-04 - lr: 9.7656e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 98/200\n",
      "360/360 - 39s - loss: 7.6812e-05 - Head: 5.7199e-05 - Beak: 5.5193e-05 - Body_top: 8.7492e-05 - RFlipper_mid: 7.8394e-05 - LFlipper_mid: 8.2595e-05 - Body_bottom: 1.5156e-04 - RFoot: 5.2445e-05 - LFoot: 4.9617e-05 - val_loss: 2.1654e-04 - val_Head: 2.0174e-04 - val_Beak: 1.6497e-04 - val_Body_top: 2.6687e-04 - val_RFlipper_mid: 2.0474e-04 - val_LFlipper_mid: 2.9394e-04 - val_Body_bottom: 3.1282e-04 - val_RFoot: 1.3799e-04 - val_LFoot: 1.4926e-04 - lr: 9.7656e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 99/200\n",
      "360/360 - 37s - loss: 7.6975e-05 - Head: 5.6789e-05 - Beak: 5.5569e-05 - Body_top: 8.6691e-05 - RFlipper_mid: 7.8891e-05 - LFlipper_mid: 8.3244e-05 - Body_bottom: 1.5153e-04 - RFoot: 5.2604e-05 - LFoot: 5.0482e-05 - val_loss: 2.1743e-04 - val_Head: 2.0332e-04 - val_Beak: 1.5928e-04 - val_Body_top: 2.6858e-04 - val_RFlipper_mid: 2.0645e-04 - val_LFlipper_mid: 2.9053e-04 - val_Body_bottom: 3.1266e-04 - val_RFoot: 1.4293e-04 - val_LFoot: 1.5567e-04 - lr: 9.7656e-08 - 37s/epoch - 104ms/step\n",
      "Epoch 100/200\n",
      "360/360 - 37s - loss: 7.5985e-05 - Head: 5.7500e-05 - Beak: 5.3926e-05 - Body_top: 8.6426e-05 - RFlipper_mid: 7.8094e-05 - LFlipper_mid: 8.1333e-05 - Body_bottom: 1.5128e-04 - RFoot: 5.1573e-05 - LFoot: 4.7753e-05 - val_loss: 2.1767e-04 - val_Head: 2.0750e-04 - val_Beak: 1.7364e-04 - val_Body_top: 2.6435e-04 - val_RFlipper_mid: 2.0702e-04 - val_LFlipper_mid: 2.9310e-04 - val_Body_bottom: 3.1167e-04 - val_RFoot: 1.3764e-04 - val_LFoot: 1.4642e-04 - lr: 9.7656e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 101/200\n",
      "360/360 - 39s - loss: 7.5900e-05 - Head: 5.4263e-05 - Beak: 5.5578e-05 - Body_top: 8.6247e-05 - RFlipper_mid: 8.0229e-05 - LFlipper_mid: 8.2331e-05 - Body_bottom: 1.5038e-04 - RFoot: 5.0115e-05 - LFoot: 4.8059e-05 - val_loss: 2.1543e-04 - val_Head: 1.9995e-04 - val_Beak: 1.6238e-04 - val_Body_top: 2.6519e-04 - val_RFlipper_mid: 2.0834e-04 - val_LFlipper_mid: 2.9047e-04 - val_Body_bottom: 3.1094e-04 - val_RFoot: 1.3756e-04 - val_LFoot: 1.4861e-04 - lr: 9.7656e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 102/200\n",
      "360/360 - 38s - loss: 7.7037e-05 - Head: 5.8094e-05 - Beak: 5.8154e-05 - Body_top: 8.7331e-05 - RFlipper_mid: 7.8932e-05 - LFlipper_mid: 8.1556e-05 - Body_bottom: 1.4944e-04 - RFoot: 5.3434e-05 - LFoot: 4.9350e-05 - val_loss: 2.1491e-04 - val_Head: 1.9413e-04 - val_Beak: 1.6002e-04 - val_Body_top: 2.6589e-04 - val_RFlipper_mid: 2.0201e-04 - val_LFlipper_mid: 2.9469e-04 - val_Body_bottom: 3.1306e-04 - val_RFoot: 1.4183e-04 - val_LFoot: 1.4762e-04 - lr: 9.7656e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 103/200\n",
      "360/360 - 39s - loss: 7.7743e-05 - Head: 5.8407e-05 - Beak: 5.7877e-05 - Body_top: 8.7512e-05 - RFlipper_mid: 7.9543e-05 - LFlipper_mid: 8.3778e-05 - Body_bottom: 1.5099e-04 - RFoot: 5.3884e-05 - LFoot: 4.9956e-05 - val_loss: 2.1446e-04 - val_Head: 1.9835e-04 - val_Beak: 1.5735e-04 - val_Body_top: 2.6637e-04 - val_RFlipper_mid: 2.0156e-04 - val_LFlipper_mid: 2.9220e-04 - val_Body_bottom: 3.1190e-04 - val_RFoot: 1.4056e-04 - val_LFoot: 1.4740e-04 - lr: 9.7656e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 104/200\n",
      "360/360 - 39s - loss: 7.6568e-05 - Head: 5.5621e-05 - Beak: 5.6291e-05 - Body_top: 8.6414e-05 - RFlipper_mid: 7.8854e-05 - LFlipper_mid: 8.1806e-05 - Body_bottom: 1.5133e-04 - RFoot: 5.1341e-05 - LFoot: 5.0890e-05 - val_loss: 2.1949e-04 - val_Head: 2.1146e-04 - val_Beak: 1.6179e-04 - val_Body_top: 2.6585e-04 - val_RFlipper_mid: 2.0423e-04 - val_LFlipper_mid: 2.9479e-04 - val_Body_bottom: 3.1687e-04 - val_RFoot: 1.4208e-04 - val_LFoot: 1.5885e-04 - lr: 9.7656e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 105/200\n",
      "360/360 - 38s - loss: 7.6636e-05 - Head: 5.6009e-05 - Beak: 5.6405e-05 - Body_top: 8.6691e-05 - RFlipper_mid: 7.8633e-05 - LFlipper_mid: 8.1993e-05 - Body_bottom: 1.5096e-04 - RFoot: 5.1728e-05 - LFoot: 5.0664e-05 - val_loss: 2.1777e-04 - val_Head: 2.0327e-04 - val_Beak: 1.7151e-04 - val_Body_top: 2.6873e-04 - val_RFlipper_mid: 2.0196e-04 - val_LFlipper_mid: 2.9246e-04 - val_Body_bottom: 3.1382e-04 - val_RFoot: 1.4153e-04 - val_LFoot: 1.4885e-04 - lr: 9.7656e-08 - 38s/epoch - 107ms/step\n",
      "Epoch 106/200\n",
      "360/360 - 39s - loss: 7.7087e-05 - Head: 5.7708e-05 - Beak: 5.6270e-05 - Body_top: 8.7057e-05 - RFlipper_mid: 7.8592e-05 - LFlipper_mid: 8.3406e-05 - Body_bottom: 1.5025e-04 - RFoot: 5.4520e-05 - LFoot: 4.8899e-05 - val_loss: 2.1748e-04 - val_Head: 2.0158e-04 - val_Beak: 1.6870e-04 - val_Body_top: 2.7014e-04 - val_RFlipper_mid: 2.0589e-04 - val_LFlipper_mid: 2.9329e-04 - val_Body_bottom: 3.1157e-04 - val_RFoot: 1.3862e-04 - val_LFoot: 1.5003e-04 - lr: 9.7656e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 107/200\n",
      "360/360 - 38s - loss: 7.6216e-05 - Head: 5.4139e-05 - Beak: 5.4186e-05 - Body_top: 8.7112e-05 - RFlipper_mid: 7.8803e-05 - LFlipper_mid: 8.3144e-05 - Body_bottom: 1.5155e-04 - RFoot: 5.3228e-05 - LFoot: 4.7569e-05 - val_loss: 2.1780e-04 - val_Head: 2.0199e-04 - val_Beak: 1.6306e-04 - val_Body_top: 2.6976e-04 - val_RFlipper_mid: 2.0858e-04 - val_LFlipper_mid: 2.9570e-04 - val_Body_bottom: 3.1250e-04 - val_RFoot: 1.3897e-04 - val_LFoot: 1.5184e-04 - lr: 9.7656e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 108/200\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "360/360 - 39s - loss: 7.6349e-05 - Head: 5.5474e-05 - Beak: 5.5616e-05 - Body_top: 8.6900e-05 - RFlipper_mid: 7.8830e-05 - LFlipper_mid: 8.3184e-05 - Body_bottom: 1.4995e-04 - RFoot: 5.1436e-05 - LFoot: 4.9409e-05 - val_loss: 2.1616e-04 - val_Head: 2.0684e-04 - val_Beak: 1.5925e-04 - val_Body_top: 2.6027e-04 - val_RFlipper_mid: 2.0717e-04 - val_LFlipper_mid: 2.9327e-04 - val_Body_bottom: 3.1486e-04 - val_RFoot: 1.3811e-04 - val_LFoot: 1.4948e-04 - lr: 9.7656e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 109/200\n",
      "360/360 - 39s - loss: 7.6662e-05 - Head: 5.8194e-05 - Beak: 5.7755e-05 - Body_top: 8.7029e-05 - RFlipper_mid: 7.7231e-05 - LFlipper_mid: 8.3067e-05 - Body_bottom: 1.5007e-04 - RFoot: 5.2680e-05 - LFoot: 4.7270e-05 - val_loss: 2.1620e-04 - val_Head: 2.0636e-04 - val_Beak: 1.5973e-04 - val_Body_top: 2.6942e-04 - val_RFlipper_mid: 2.0303e-04 - val_LFlipper_mid: 2.9346e-04 - val_Body_bottom: 3.1032e-04 - val_RFoot: 1.3917e-04 - val_LFoot: 1.4810e-04 - lr: 4.8828e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 110/200\n",
      "360/360 - 39s - loss: 7.7355e-05 - Head: 5.6267e-05 - Beak: 5.4812e-05 - Body_top: 8.8984e-05 - RFlipper_mid: 7.9240e-05 - LFlipper_mid: 8.3993e-05 - Body_bottom: 1.5176e-04 - RFoot: 5.3665e-05 - LFoot: 5.0127e-05 - val_loss: 2.1538e-04 - val_Head: 1.9986e-04 - val_Beak: 1.6667e-04 - val_Body_top: 2.6021e-04 - val_RFlipper_mid: 2.0545e-04 - val_LFlipper_mid: 2.9287e-04 - val_Body_bottom: 3.1101e-04 - val_RFoot: 1.3696e-04 - val_LFoot: 1.5003e-04 - lr: 4.8828e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 111/200\n",
      "360/360 - 40s - loss: 7.5620e-05 - Head: 5.4772e-05 - Beak: 5.3609e-05 - Body_top: 8.5486e-05 - RFlipper_mid: 7.8336e-05 - LFlipper_mid: 8.3765e-05 - Body_bottom: 1.4970e-04 - RFoot: 5.1001e-05 - LFoot: 4.8291e-05 - val_loss: 2.1601e-04 - val_Head: 1.9991e-04 - val_Beak: 1.6504e-04 - val_Body_top: 2.6643e-04 - val_RFlipper_mid: 2.0287e-04 - val_LFlipper_mid: 2.9205e-04 - val_Body_bottom: 3.1272e-04 - val_RFoot: 1.4051e-04 - val_LFoot: 1.4854e-04 - lr: 4.8828e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 112/200\n",
      "360/360 - 40s - loss: 7.6629e-05 - Head: 5.6851e-05 - Beak: 5.5286e-05 - Body_top: 8.7648e-05 - RFlipper_mid: 7.8693e-05 - LFlipper_mid: 8.1953e-05 - Body_bottom: 1.5119e-04 - RFoot: 5.1954e-05 - LFoot: 4.9460e-05 - val_loss: 2.1742e-04 - val_Head: 1.9243e-04 - val_Beak: 1.6581e-04 - val_Body_top: 2.6823e-04 - val_RFlipper_mid: 2.0862e-04 - val_LFlipper_mid: 2.9489e-04 - val_Body_bottom: 3.1430e-04 - val_RFoot: 1.4316e-04 - val_LFoot: 1.5194e-04 - lr: 4.8828e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 113/200\n",
      "360/360 - 37s - loss: 7.6891e-05 - Head: 5.6676e-05 - Beak: 5.5932e-05 - Body_top: 8.6511e-05 - RFlipper_mid: 7.8980e-05 - LFlipper_mid: 8.3414e-05 - Body_bottom: 1.5175e-04 - RFoot: 5.2782e-05 - LFoot: 4.9089e-05 - val_loss: 2.1935e-04 - val_Head: 2.1653e-04 - val_Beak: 1.6582e-04 - val_Body_top: 2.6763e-04 - val_RFlipper_mid: 2.0778e-04 - val_LFlipper_mid: 2.9387e-04 - val_Body_bottom: 3.1142e-04 - val_RFoot: 1.3901e-04 - val_LFoot: 1.5271e-04 - lr: 4.8828e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 114/200\n",
      "360/360 - 39s - loss: 7.7055e-05 - Head: 5.5147e-05 - Beak: 5.6109e-05 - Body_top: 8.6954e-05 - RFlipper_mid: 7.9147e-05 - LFlipper_mid: 8.4537e-05 - Body_bottom: 1.5210e-04 - RFoot: 5.1676e-05 - LFoot: 5.0773e-05 - val_loss: 2.1710e-04 - val_Head: 2.0888e-04 - val_Beak: 1.6525e-04 - val_Body_top: 2.6608e-04 - val_RFlipper_mid: 2.1153e-04 - val_LFlipper_mid: 2.9069e-04 - val_Body_bottom: 3.1073e-04 - val_RFoot: 1.3696e-04 - val_LFoot: 1.4672e-04 - lr: 4.8828e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 115/200\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "360/360 - 36s - loss: 7.6838e-05 - Head: 5.6678e-05 - Beak: 5.4224e-05 - Body_top: 8.7365e-05 - RFlipper_mid: 7.8499e-05 - LFlipper_mid: 8.2313e-05 - Body_bottom: 1.5150e-04 - RFoot: 5.3438e-05 - LFoot: 5.0692e-05 - val_loss: 2.1758e-04 - val_Head: 2.0800e-04 - val_Beak: 1.6402e-04 - val_Body_top: 2.6222e-04 - val_RFlipper_mid: 2.0531e-04 - val_LFlipper_mid: 2.9298e-04 - val_Body_bottom: 3.1402e-04 - val_RFoot: 1.3985e-04 - val_LFoot: 1.5428e-04 - lr: 4.8828e-08 - 36s/epoch - 99ms/step\n",
      "Epoch 116/200\n",
      "360/360 - 40s - loss: 7.5801e-05 - Head: 5.4889e-05 - Beak: 5.4588e-05 - Body_top: 8.6858e-05 - RFlipper_mid: 7.7242e-05 - LFlipper_mid: 8.2441e-05 - Body_bottom: 1.5028e-04 - RFoot: 5.2268e-05 - LFoot: 4.7844e-05 - val_loss: 2.1777e-04 - val_Head: 2.0643e-04 - val_Beak: 1.7298e-04 - val_Body_top: 2.7253e-04 - val_RFlipper_mid: 1.9998e-04 - val_LFlipper_mid: 2.9196e-04 - val_Body_bottom: 3.1455e-04 - val_RFoot: 1.4033e-04 - val_LFoot: 1.4343e-04 - lr: 2.4414e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 117/200\n",
      "360/360 - 39s - loss: 7.6035e-05 - Head: 5.5306e-05 - Beak: 5.4177e-05 - Body_top: 8.7137e-05 - RFlipper_mid: 7.8211e-05 - LFlipper_mid: 8.2208e-05 - Body_bottom: 1.5101e-04 - RFoot: 5.2740e-05 - LFoot: 4.7487e-05 - val_loss: 2.1657e-04 - val_Head: 2.0133e-04 - val_Beak: 1.6159e-04 - val_Body_top: 2.6605e-04 - val_RFlipper_mid: 2.0246e-04 - val_LFlipper_mid: 2.9377e-04 - val_Body_bottom: 3.1661e-04 - val_RFoot: 1.4127e-04 - val_LFoot: 1.4946e-04 - lr: 2.4414e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 118/200\n",
      "360/360 - 40s - loss: 7.6415e-05 - Head: 5.5612e-05 - Beak: 5.5157e-05 - Body_top: 8.6929e-05 - RFlipper_mid: 8.0493e-05 - LFlipper_mid: 8.2558e-05 - Body_bottom: 1.5079e-04 - RFoot: 5.1742e-05 - LFoot: 4.8043e-05 - val_loss: 2.1790e-04 - val_Head: 2.0284e-04 - val_Beak: 1.7902e-04 - val_Body_top: 2.6727e-04 - val_RFlipper_mid: 2.0305e-04 - val_LFlipper_mid: 2.9332e-04 - val_Body_bottom: 3.0877e-04 - val_RFoot: 1.4027e-04 - val_LFoot: 1.4863e-04 - lr: 2.4414e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 119/200\n",
      "360/360 - 39s - loss: 7.6940e-05 - Head: 5.6796e-05 - Beak: 5.5868e-05 - Body_top: 8.7146e-05 - RFlipper_mid: 7.8982e-05 - LFlipper_mid: 8.3342e-05 - Body_bottom: 1.5173e-04 - RFoot: 5.2406e-05 - LFoot: 4.9252e-05 - val_loss: 2.1634e-04 - val_Head: 2.0465e-04 - val_Beak: 1.5858e-04 - val_Body_top: 2.6631e-04 - val_RFlipper_mid: 2.0129e-04 - val_LFlipper_mid: 2.9106e-04 - val_Body_bottom: 3.1460e-04 - val_RFoot: 1.4129e-04 - val_LFoot: 1.5293e-04 - lr: 2.4414e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 120/200\n",
      "360/360 - 37s - loss: 7.7040e-05 - Head: 5.6851e-05 - Beak: 5.6637e-05 - Body_top: 8.7263e-05 - RFlipper_mid: 7.8986e-05 - LFlipper_mid: 8.3083e-05 - Body_bottom: 1.5149e-04 - RFoot: 5.2888e-05 - LFoot: 4.9120e-05 - val_loss: 2.1928e-04 - val_Head: 2.1238e-04 - val_Beak: 1.6471e-04 - val_Body_top: 2.7389e-04 - val_RFlipper_mid: 2.1027e-04 - val_LFlipper_mid: 2.9390e-04 - val_Body_bottom: 3.1098e-04 - val_RFoot: 1.3918e-04 - val_LFoot: 1.4892e-04 - lr: 2.4414e-08 - 37s/epoch - 102ms/step\n",
      "Epoch 121/200\n",
      "360/360 - 37s - loss: 7.6966e-05 - Head: 5.4542e-05 - Beak: 5.6212e-05 - Body_top: 8.6818e-05 - RFlipper_mid: 7.9808e-05 - LFlipper_mid: 8.4341e-05 - Body_bottom: 1.5198e-04 - RFoot: 5.2344e-05 - LFoot: 4.9684e-05 - val_loss: 2.1629e-04 - val_Head: 1.9717e-04 - val_Beak: 1.6845e-04 - val_Body_top: 2.6598e-04 - val_RFlipper_mid: 2.0630e-04 - val_LFlipper_mid: 2.9655e-04 - val_Body_bottom: 3.1332e-04 - val_RFoot: 1.3691e-04 - val_LFoot: 1.4562e-04 - lr: 2.4414e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 122/200\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "360/360 - 36s - loss: 7.7962e-05 - Head: 6.0098e-05 - Beak: 5.9647e-05 - Body_top: 8.7982e-05 - RFlipper_mid: 7.8484e-05 - LFlipper_mid: 8.1620e-05 - Body_bottom: 1.5088e-04 - RFoot: 5.3873e-05 - LFoot: 5.1108e-05 - val_loss: 2.1650e-04 - val_Head: 1.9582e-04 - val_Beak: 1.6412e-04 - val_Body_top: 2.6944e-04 - val_RFlipper_mid: 2.0732e-04 - val_LFlipper_mid: 2.9197e-04 - val_Body_bottom: 3.1288e-04 - val_RFoot: 1.4111e-04 - val_LFoot: 1.4936e-04 - lr: 2.4414e-08 - 36s/epoch - 100ms/step\n",
      "Epoch 123/200\n",
      "360/360 - 37s - loss: 7.7271e-05 - Head: 5.9235e-05 - Beak: 5.8111e-05 - Body_top: 8.7359e-05 - RFlipper_mid: 7.8513e-05 - LFlipper_mid: 8.3138e-05 - Body_bottom: 1.5155e-04 - RFoot: 5.1620e-05 - LFoot: 4.8637e-05 - val_loss: 2.1724e-04 - val_Head: 2.0410e-04 - val_Beak: 1.6117e-04 - val_Body_top: 2.7311e-04 - val_RFlipper_mid: 2.0501e-04 - val_LFlipper_mid: 2.9553e-04 - val_Body_bottom: 3.1146e-04 - val_RFoot: 1.3921e-04 - val_LFoot: 1.4833e-04 - lr: 1.2207e-08 - 37s/epoch - 102ms/step\n",
      "Epoch 124/200\n",
      "360/360 - 39s - loss: 7.6768e-05 - Head: 5.6970e-05 - Beak: 5.5915e-05 - Body_top: 8.8322e-05 - RFlipper_mid: 7.7965e-05 - LFlipper_mid: 8.1968e-05 - Body_bottom: 1.5032e-04 - RFoot: 5.2321e-05 - LFoot: 5.0369e-05 - val_loss: 2.1947e-04 - val_Head: 2.1352e-04 - val_Beak: 1.7211e-04 - val_Body_top: 2.6001e-04 - val_RFlipper_mid: 2.1050e-04 - val_LFlipper_mid: 2.9255e-04 - val_Body_bottom: 3.1489e-04 - val_RFoot: 1.3854e-04 - val_LFoot: 1.5363e-04 - lr: 1.2207e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 125/200\n",
      "360/360 - 37s - loss: 7.7145e-05 - Head: 5.7904e-05 - Beak: 5.6293e-05 - Body_top: 8.7295e-05 - RFlipper_mid: 7.8687e-05 - LFlipper_mid: 8.3473e-05 - Body_bottom: 1.5129e-04 - RFoot: 5.2146e-05 - LFoot: 5.0076e-05 - val_loss: 2.1966e-04 - val_Head: 2.0518e-04 - val_Beak: 1.7070e-04 - val_Body_top: 2.7307e-04 - val_RFlipper_mid: 2.0851e-04 - val_LFlipper_mid: 2.9222e-04 - val_Body_bottom: 3.1453e-04 - val_RFoot: 1.3851e-04 - val_LFoot: 1.5460e-04 - lr: 1.2207e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 126/200\n",
      "360/360 - 39s - loss: 7.7337e-05 - Head: 5.8654e-05 - Beak: 5.4478e-05 - Body_top: 8.9591e-05 - RFlipper_mid: 7.9789e-05 - LFlipper_mid: 8.2181e-05 - Body_bottom: 1.5190e-04 - RFoot: 5.2646e-05 - LFoot: 4.9458e-05 - val_loss: 2.2113e-04 - val_Head: 2.1619e-04 - val_Beak: 1.6601e-04 - val_Body_top: 2.6631e-04 - val_RFlipper_mid: 2.1217e-04 - val_LFlipper_mid: 2.9361e-04 - val_Body_bottom: 3.1546e-04 - val_RFoot: 1.4190e-04 - val_LFoot: 1.5740e-04 - lr: 1.2207e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 127/200\n",
      "360/360 - 36s - loss: 7.6894e-05 - Head: 5.5421e-05 - Beak: 5.6264e-05 - Body_top: 8.7350e-05 - RFlipper_mid: 7.8768e-05 - LFlipper_mid: 8.4230e-05 - Body_bottom: 1.5165e-04 - RFoot: 5.1929e-05 - LFoot: 4.9542e-05 - val_loss: 2.1812e-04 - val_Head: 2.0701e-04 - val_Beak: 1.6829e-04 - val_Body_top: 2.6974e-04 - val_RFlipper_mid: 2.0593e-04 - val_LFlipper_mid: 2.9352e-04 - val_Body_bottom: 3.1197e-04 - val_RFoot: 1.4062e-04 - val_LFoot: 1.4791e-04 - lr: 1.2207e-08 - 36s/epoch - 101ms/step\n",
      "Epoch 128/200\n",
      "360/360 - 39s - loss: 7.6731e-05 - Head: 5.6044e-05 - Beak: 5.6868e-05 - Body_top: 8.7349e-05 - RFlipper_mid: 7.8526e-05 - LFlipper_mid: 8.2268e-05 - Body_bottom: 1.4994e-04 - RFoot: 5.2658e-05 - LFoot: 5.0196e-05 - val_loss: 2.1619e-04 - val_Head: 1.9875e-04 - val_Beak: 1.6095e-04 - val_Body_top: 2.7295e-04 - val_RFlipper_mid: 2.0453e-04 - val_LFlipper_mid: 2.9288e-04 - val_Body_bottom: 3.1253e-04 - val_RFoot: 1.4031e-04 - val_LFoot: 1.4664e-04 - lr: 1.2207e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 129/200\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "360/360 - 37s - loss: 7.7185e-05 - Head: 5.8557e-05 - Beak: 5.8292e-05 - Body_top: 8.8031e-05 - RFlipper_mid: 7.9278e-05 - LFlipper_mid: 8.1790e-05 - Body_bottom: 1.5157e-04 - RFoot: 5.1344e-05 - LFoot: 4.8614e-05 - val_loss: 2.1798e-04 - val_Head: 2.1154e-04 - val_Beak: 1.6884e-04 - val_Body_top: 2.6826e-04 - val_RFlipper_mid: 2.0181e-04 - val_LFlipper_mid: 2.9162e-04 - val_Body_bottom: 3.1473e-04 - val_RFoot: 1.3788e-04 - val_LFoot: 1.4914e-04 - lr: 1.2207e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 130/200\n",
      "360/360 - 37s - loss: 7.6493e-05 - Head: 5.5200e-05 - Beak: 5.6829e-05 - Body_top: 8.6272e-05 - RFlipper_mid: 7.7710e-05 - LFlipper_mid: 8.3683e-05 - Body_bottom: 1.5183e-04 - RFoot: 5.0646e-05 - LFoot: 4.9776e-05 - val_loss: 2.1759e-04 - val_Head: 2.0384e-04 - val_Beak: 1.6888e-04 - val_Body_top: 2.7140e-04 - val_RFlipper_mid: 2.0704e-04 - val_LFlipper_mid: 2.9102e-04 - val_Body_bottom: 3.1433e-04 - val_RFoot: 1.3923e-04 - val_LFoot: 1.4503e-04 - lr: 1.0000e-08 - 37s/epoch - 102ms/step\n",
      "Epoch 131/200\n",
      "360/360 - 37s - loss: 7.7788e-05 - Head: 5.8298e-05 - Beak: 5.9359e-05 - Body_top: 8.6549e-05 - RFlipper_mid: 8.0978e-05 - LFlipper_mid: 8.3082e-05 - Body_bottom: 1.5118e-04 - RFoot: 5.2579e-05 - LFoot: 5.0287e-05 - val_loss: 2.1998e-04 - val_Head: 2.0907e-04 - val_Beak: 1.6973e-04 - val_Body_top: 2.7034e-04 - val_RFlipper_mid: 2.1070e-04 - val_LFlipper_mid: 2.9590e-04 - val_Body_bottom: 3.1263e-04 - val_RFoot: 1.4177e-04 - val_LFoot: 1.4971e-04 - lr: 1.0000e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 132/200\n",
      "360/360 - 37s - loss: 7.7272e-05 - Head: 5.7696e-05 - Beak: 5.8015e-05 - Body_top: 8.6826e-05 - RFlipper_mid: 7.8479e-05 - LFlipper_mid: 8.3695e-05 - Body_bottom: 1.5108e-04 - RFoot: 5.2578e-05 - LFoot: 4.9814e-05 - val_loss: 2.1656e-04 - val_Head: 2.0202e-04 - val_Beak: 1.6440e-04 - val_Body_top: 2.7326e-04 - val_RFlipper_mid: 2.0515e-04 - val_LFlipper_mid: 2.9130e-04 - val_Body_bottom: 3.1099e-04 - val_RFoot: 1.4004e-04 - val_LFoot: 1.4537e-04 - lr: 1.0000e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 133/200\n",
      "360/360 - 39s - loss: 7.5592e-05 - Head: 5.5269e-05 - Beak: 5.2941e-05 - Body_top: 8.6704e-05 - RFlipper_mid: 7.7447e-05 - LFlipper_mid: 8.2261e-05 - Body_bottom: 1.4949e-04 - RFoot: 5.2038e-05 - LFoot: 4.8589e-05 - val_loss: 2.1778e-04 - val_Head: 2.0383e-04 - val_Beak: 1.7244e-04 - val_Body_top: 2.7155e-04 - val_RFlipper_mid: 2.0719e-04 - val_LFlipper_mid: 2.9493e-04 - val_Body_bottom: 3.1142e-04 - val_RFoot: 1.3712e-04 - val_LFoot: 1.4376e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 134/200\n",
      "360/360 - 38s - loss: 7.7224e-05 - Head: 5.7121e-05 - Beak: 5.4833e-05 - Body_top: 8.6911e-05 - RFlipper_mid: 7.9574e-05 - LFlipper_mid: 8.3495e-05 - Body_bottom: 1.5213e-04 - RFoot: 5.2626e-05 - LFoot: 5.1107e-05 - val_loss: 2.1629e-04 - val_Head: 2.0313e-04 - val_Beak: 1.5763e-04 - val_Body_top: 2.6253e-04 - val_RFlipper_mid: 2.1009e-04 - val_LFlipper_mid: 2.9370e-04 - val_Body_bottom: 3.1276e-04 - val_RFoot: 1.4144e-04 - val_LFoot: 1.4901e-04 - lr: 1.0000e-08 - 38s/epoch - 106ms/step\n",
      "Epoch 135/200\n",
      "360/360 - 40s - loss: 7.6792e-05 - Head: 5.6213e-05 - Beak: 5.6069e-05 - Body_top: 8.7239e-05 - RFlipper_mid: 7.9340e-05 - LFlipper_mid: 8.2938e-05 - Body_bottom: 1.4928e-04 - RFoot: 5.3532e-05 - LFoot: 4.9727e-05 - val_loss: 2.1879e-04 - val_Head: 2.0990e-04 - val_Beak: 1.7015e-04 - val_Body_top: 2.6336e-04 - val_RFlipper_mid: 2.0612e-04 - val_LFlipper_mid: 2.9319e-04 - val_Body_bottom: 3.1427e-04 - val_RFoot: 1.4054e-04 - val_LFoot: 1.5278e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 136/200\n",
      "360/360 - 39s - loss: 7.7988e-05 - Head: 5.8668e-05 - Beak: 5.8780e-05 - Body_top: 9.0354e-05 - RFlipper_mid: 7.9664e-05 - LFlipper_mid: 8.3937e-05 - Body_bottom: 1.5173e-04 - RFoot: 5.2132e-05 - LFoot: 4.8639e-05 - val_loss: 2.1803e-04 - val_Head: 2.0450e-04 - val_Beak: 1.6464e-04 - val_Body_top: 2.6825e-04 - val_RFlipper_mid: 2.1084e-04 - val_LFlipper_mid: 2.9460e-04 - val_Body_bottom: 3.1300e-04 - val_RFoot: 1.4135e-04 - val_LFoot: 1.4708e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 137/200\n",
      "360/360 - 39s - loss: 7.7113e-05 - Head: 5.6304e-05 - Beak: 5.6609e-05 - Body_top: 8.7775e-05 - RFlipper_mid: 7.9425e-05 - LFlipper_mid: 8.2218e-05 - Body_bottom: 1.5177e-04 - RFoot: 5.2420e-05 - LFoot: 5.0388e-05 - val_loss: 2.1559e-04 - val_Head: 2.0045e-04 - val_Beak: 1.5992e-04 - val_Body_top: 2.7041e-04 - val_RFlipper_mid: 2.0525e-04 - val_LFlipper_mid: 2.9092e-04 - val_Body_bottom: 3.0942e-04 - val_RFoot: 1.3991e-04 - val_LFoot: 1.4847e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 138/200\n",
      "360/360 - 37s - loss: 7.6752e-05 - Head: 5.6622e-05 - Beak: 5.5828e-05 - Body_top: 8.7019e-05 - RFlipper_mid: 7.8994e-05 - LFlipper_mid: 8.3626e-05 - Body_bottom: 1.5009e-04 - RFoot: 5.2337e-05 - LFoot: 4.9505e-05 - val_loss: 2.1838e-04 - val_Head: 1.9790e-04 - val_Beak: 1.6670e-04 - val_Body_top: 2.7126e-04 - val_RFlipper_mid: 2.0858e-04 - val_LFlipper_mid: 2.9176e-04 - val_Body_bottom: 3.1401e-04 - val_RFoot: 1.4155e-04 - val_LFoot: 1.5526e-04 - lr: 1.0000e-08 - 37s/epoch - 102ms/step\n",
      "Epoch 139/200\n",
      "360/360 - 37s - loss: 7.6433e-05 - Head: 5.6241e-05 - Beak: 5.4780e-05 - Body_top: 8.6080e-05 - RFlipper_mid: 7.8458e-05 - LFlipper_mid: 8.2839e-05 - Body_bottom: 1.5019e-04 - RFoot: 5.4316e-05 - LFoot: 4.8556e-05 - val_loss: 2.1919e-04 - val_Head: 2.1132e-04 - val_Beak: 1.7156e-04 - val_Body_top: 2.7169e-04 - val_RFlipper_mid: 2.1230e-04 - val_LFlipper_mid: 2.9438e-04 - val_Body_bottom: 3.1072e-04 - val_RFoot: 1.3811e-04 - val_LFoot: 1.4345e-04 - lr: 1.0000e-08 - 37s/epoch - 102ms/step\n",
      "Epoch 140/200\n",
      "360/360 - 37s - loss: 7.6900e-05 - Head: 5.5847e-05 - Beak: 5.4694e-05 - Body_top: 8.6594e-05 - RFlipper_mid: 7.9993e-05 - LFlipper_mid: 8.3558e-05 - Body_bottom: 1.5187e-04 - RFoot: 5.2275e-05 - LFoot: 5.0377e-05 - val_loss: 2.2085e-04 - val_Head: 2.0772e-04 - val_Beak: 1.6981e-04 - val_Body_top: 2.7101e-04 - val_RFlipper_mid: 2.1275e-04 - val_LFlipper_mid: 2.9314e-04 - val_Body_bottom: 3.1639e-04 - val_RFoot: 1.4125e-04 - val_LFoot: 1.5471e-04 - lr: 1.0000e-08 - 37s/epoch - 103ms/step\n",
      "Epoch 141/200\n",
      "360/360 - 36s - loss: 7.6375e-05 - Head: 5.6041e-05 - Beak: 5.3950e-05 - Body_top: 8.6511e-05 - RFlipper_mid: 7.8161e-05 - LFlipper_mid: 8.3199e-05 - Body_bottom: 1.5203e-04 - RFoot: 5.2845e-05 - LFoot: 4.8263e-05 - val_loss: 2.1818e-04 - val_Head: 1.9249e-04 - val_Beak: 1.7157e-04 - val_Body_top: 2.6913e-04 - val_RFlipper_mid: 2.0903e-04 - val_LFlipper_mid: 2.9514e-04 - val_Body_bottom: 3.1406e-04 - val_RFoot: 1.3917e-04 - val_LFoot: 1.5485e-04 - lr: 1.0000e-08 - 36s/epoch - 101ms/step\n",
      "Epoch 142/200\n",
      "360/360 - 38s - loss: 7.6519e-05 - Head: 5.8074e-05 - Beak: 5.5804e-05 - Body_top: 8.6911e-05 - RFlipper_mid: 7.8910e-05 - LFlipper_mid: 8.1983e-05 - Body_bottom: 1.5003e-04 - RFoot: 5.1798e-05 - LFoot: 4.8638e-05 - val_loss: 2.1620e-04 - val_Head: 1.9605e-04 - val_Beak: 1.6622e-04 - val_Body_top: 2.6632e-04 - val_RFlipper_mid: 2.0583e-04 - val_LFlipper_mid: 2.9412e-04 - val_Body_bottom: 3.1208e-04 - val_RFoot: 1.3841e-04 - val_LFoot: 1.5055e-04 - lr: 1.0000e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 143/200\n",
      "360/360 - 38s - loss: 7.7663e-05 - Head: 5.7884e-05 - Beak: 5.6596e-05 - Body_top: 8.8455e-05 - RFlipper_mid: 7.9529e-05 - LFlipper_mid: 8.3104e-05 - Body_bottom: 1.5265e-04 - RFoot: 5.3834e-05 - LFoot: 4.9248e-05 - val_loss: 2.1616e-04 - val_Head: 2.0557e-04 - val_Beak: 1.5646e-04 - val_Body_top: 2.6194e-04 - val_RFlipper_mid: 2.0276e-04 - val_LFlipper_mid: 2.9671e-04 - val_Body_bottom: 3.1411e-04 - val_RFoot: 1.3992e-04 - val_LFoot: 1.5178e-04 - lr: 1.0000e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 144/200\n",
      "360/360 - 39s - loss: 7.6728e-05 - Head: 5.6841e-05 - Beak: 5.4668e-05 - Body_top: 8.6144e-05 - RFlipper_mid: 7.8761e-05 - LFlipper_mid: 8.4098e-05 - Body_bottom: 1.5016e-04 - RFoot: 5.1964e-05 - LFoot: 5.1192e-05 - val_loss: 2.1465e-04 - val_Head: 1.8971e-04 - val_Beak: 1.6457e-04 - val_Body_top: 2.6898e-04 - val_RFlipper_mid: 2.0490e-04 - val_LFlipper_mid: 2.9403e-04 - val_Body_bottom: 3.0820e-04 - val_RFoot: 1.4034e-04 - val_LFoot: 1.4650e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 145/200\n",
      "360/360 - 38s - loss: 7.6459e-05 - Head: 5.4949e-05 - Beak: 5.4726e-05 - Body_top: 8.7596e-05 - RFlipper_mid: 7.8863e-05 - LFlipper_mid: 8.2556e-05 - Body_bottom: 1.5055e-04 - RFoot: 5.2248e-05 - LFoot: 5.0182e-05 - val_loss: 2.1760e-04 - val_Head: 2.0853e-04 - val_Beak: 1.6544e-04 - val_Body_top: 2.6997e-04 - val_RFlipper_mid: 2.0295e-04 - val_LFlipper_mid: 2.9298e-04 - val_Body_bottom: 3.1142e-04 - val_RFoot: 1.3934e-04 - val_LFoot: 1.5016e-04 - lr: 1.0000e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 146/200\n",
      "360/360 - 40s - loss: 7.6449e-05 - Head: 5.6637e-05 - Beak: 5.6397e-05 - Body_top: 8.6070e-05 - RFlipper_mid: 7.8207e-05 - LFlipper_mid: 8.1658e-05 - Body_bottom: 1.5212e-04 - RFoot: 5.2320e-05 - LFoot: 4.8187e-05 - val_loss: 2.1928e-04 - val_Head: 2.0740e-04 - val_Beak: 1.6913e-04 - val_Body_top: 2.7547e-04 - val_RFlipper_mid: 2.0902e-04 - val_LFlipper_mid: 2.9475e-04 - val_Body_bottom: 3.1145e-04 - val_RFoot: 1.3805e-04 - val_LFoot: 1.4897e-04 - lr: 1.0000e-08 - 40s/epoch - 112ms/step\n",
      "Epoch 147/200\n",
      "360/360 - 39s - loss: 7.6817e-05 - Head: 5.6744e-05 - Beak: 5.8790e-05 - Body_top: 8.6802e-05 - RFlipper_mid: 7.8234e-05 - LFlipper_mid: 8.3046e-05 - Body_bottom: 1.5093e-04 - RFoot: 5.0666e-05 - LFoot: 4.9320e-05 - val_loss: 2.1801e-04 - val_Head: 2.0842e-04 - val_Beak: 1.6856e-04 - val_Body_top: 2.7007e-04 - val_RFlipper_mid: 2.0463e-04 - val_LFlipper_mid: 2.9467e-04 - val_Body_bottom: 3.1007e-04 - val_RFoot: 1.4126e-04 - val_LFoot: 1.4639e-04 - lr: 1.0000e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 148/200\n",
      "360/360 - 41s - loss: 7.7042e-05 - Head: 5.8199e-05 - Beak: 5.7514e-05 - Body_top: 8.7437e-05 - RFlipper_mid: 7.8853e-05 - LFlipper_mid: 8.2795e-05 - Body_bottom: 1.5092e-04 - RFoot: 5.2068e-05 - LFoot: 4.8553e-05 - val_loss: 2.1855e-04 - val_Head: 2.0027e-04 - val_Beak: 1.6832e-04 - val_Body_top: 2.7171e-04 - val_RFlipper_mid: 2.0794e-04 - val_LFlipper_mid: 2.9304e-04 - val_Body_bottom: 3.1519e-04 - val_RFoot: 1.4045e-04 - val_LFoot: 1.5149e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 149/200\n",
      "360/360 - 41s - loss: 7.7357e-05 - Head: 5.9544e-05 - Beak: 5.7894e-05 - Body_top: 8.8401e-05 - RFlipper_mid: 7.8839e-05 - LFlipper_mid: 8.2895e-05 - Body_bottom: 1.5123e-04 - RFoot: 5.1591e-05 - LFoot: 4.8457e-05 - val_loss: 2.1856e-04 - val_Head: 2.0691e-04 - val_Beak: 1.6199e-04 - val_Body_top: 2.6455e-04 - val_RFlipper_mid: 2.0778e-04 - val_LFlipper_mid: 2.9369e-04 - val_Body_bottom: 3.1645e-04 - val_RFoot: 1.4336e-04 - val_LFoot: 1.5369e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 150/200\n",
      "360/360 - 39s - loss: 7.7446e-05 - Head: 6.0353e-05 - Beak: 5.5887e-05 - Body_top: 8.6615e-05 - RFlipper_mid: 7.9654e-05 - LFlipper_mid: 8.3630e-05 - Body_bottom: 1.5046e-04 - RFoot: 5.2576e-05 - LFoot: 5.0395e-05 - val_loss: 2.1658e-04 - val_Head: 2.0364e-04 - val_Beak: 1.5784e-04 - val_Body_top: 2.6955e-04 - val_RFlipper_mid: 2.0630e-04 - val_LFlipper_mid: 2.9369e-04 - val_Body_bottom: 3.1194e-04 - val_RFoot: 1.4101e-04 - val_LFoot: 1.4867e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 151/200\n",
      "360/360 - 41s - loss: 7.6902e-05 - Head: 5.7956e-05 - Beak: 5.6483e-05 - Body_top: 8.6312e-05 - RFlipper_mid: 8.0604e-05 - LFlipper_mid: 8.3090e-05 - Body_bottom: 1.5092e-04 - RFoot: 5.2303e-05 - LFoot: 4.7545e-05 - val_loss: 2.1758e-04 - val_Head: 2.0748e-04 - val_Beak: 1.6311e-04 - val_Body_top: 2.6803e-04 - val_RFlipper_mid: 2.0734e-04 - val_LFlipper_mid: 2.9491e-04 - val_Body_bottom: 3.1069e-04 - val_RFoot: 1.3866e-04 - val_LFoot: 1.5042e-04 - lr: 1.0000e-08 - 41s/epoch - 113ms/step\n",
      "Epoch 152/200\n",
      "360/360 - 42s - loss: 7.7191e-05 - Head: 5.5922e-05 - Beak: 5.6747e-05 - Body_top: 8.6152e-05 - RFlipper_mid: 7.8652e-05 - LFlipper_mid: 8.3708e-05 - Body_bottom: 1.5213e-04 - RFoot: 5.4382e-05 - LFoot: 4.9836e-05 - val_loss: 2.1661e-04 - val_Head: 2.0222e-04 - val_Beak: 1.6113e-04 - val_Body_top: 2.6789e-04 - val_RFlipper_mid: 2.0320e-04 - val_LFlipper_mid: 2.9355e-04 - val_Body_bottom: 3.1071e-04 - val_RFoot: 1.4087e-04 - val_LFoot: 1.5332e-04 - lr: 1.0000e-08 - 42s/epoch - 115ms/step\n",
      "Epoch 153/200\n",
      "360/360 - 39s - loss: 7.7695e-05 - Head: 6.1465e-05 - Beak: 5.7169e-05 - Body_top: 8.6644e-05 - RFlipper_mid: 7.9950e-05 - LFlipper_mid: 8.2415e-05 - Body_bottom: 1.4957e-04 - RFoot: 5.4085e-05 - LFoot: 5.0263e-05 - val_loss: 2.1838e-04 - val_Head: 2.0713e-04 - val_Beak: 1.6785e-04 - val_Body_top: 2.6837e-04 - val_RFlipper_mid: 2.0943e-04 - val_LFlipper_mid: 2.9591e-04 - val_Body_bottom: 3.1174e-04 - val_RFoot: 1.3968e-04 - val_LFoot: 1.4691e-04 - lr: 1.0000e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 154/200\n",
      "360/360 - 40s - loss: 7.8112e-05 - Head: 5.8920e-05 - Beak: 5.9326e-05 - Body_top: 8.7148e-05 - RFlipper_mid: 8.0167e-05 - LFlipper_mid: 8.3602e-05 - Body_bottom: 1.5087e-04 - RFoot: 5.4328e-05 - LFoot: 5.0532e-05 - val_loss: 2.1640e-04 - val_Head: 2.0555e-04 - val_Beak: 1.6815e-04 - val_Body_top: 2.6226e-04 - val_RFlipper_mid: 2.0825e-04 - val_LFlipper_mid: 2.9201e-04 - val_Body_bottom: 3.1216e-04 - val_RFoot: 1.3571e-04 - val_LFoot: 1.4713e-04 - lr: 1.0000e-08 - 40s/epoch - 112ms/step\n",
      "Epoch 155/200\n",
      "360/360 - 40s - loss: 7.6350e-05 - Head: 5.4580e-05 - Beak: 5.5872e-05 - Body_top: 8.7156e-05 - RFlipper_mid: 7.7894e-05 - LFlipper_mid: 8.3010e-05 - Body_bottom: 1.5116e-04 - RFoot: 5.1436e-05 - LFoot: 4.9688e-05 - val_loss: 2.1710e-04 - val_Head: 2.0535e-04 - val_Beak: 1.6721e-04 - val_Body_top: 2.6388e-04 - val_RFlipper_mid: 2.0224e-04 - val_LFlipper_mid: 2.9371e-04 - val_Body_bottom: 3.1622e-04 - val_RFoot: 1.4218e-04 - val_LFoot: 1.4600e-04 - lr: 1.0000e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 156/200\n",
      "360/360 - 41s - loss: 7.5714e-05 - Head: 5.4183e-05 - Beak: 5.3973e-05 - Body_top: 8.7262e-05 - RFlipper_mid: 7.8238e-05 - LFlipper_mid: 8.2883e-05 - Body_bottom: 1.4884e-04 - RFoot: 5.1757e-05 - LFoot: 4.8576e-05 - val_loss: 2.1851e-04 - val_Head: 2.0207e-04 - val_Beak: 1.7206e-04 - val_Body_top: 2.6620e-04 - val_RFlipper_mid: 2.0606e-04 - val_LFlipper_mid: 2.9593e-04 - val_Body_bottom: 3.1144e-04 - val_RFoot: 1.3827e-04 - val_LFoot: 1.5603e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 157/200\n",
      "360/360 - 40s - loss: 7.7393e-05 - Head: 5.5876e-05 - Beak: 5.7748e-05 - Body_top: 8.8254e-05 - RFlipper_mid: 7.8340e-05 - LFlipper_mid: 8.4452e-05 - Body_bottom: 1.5101e-04 - RFoot: 5.1788e-05 - LFoot: 5.1673e-05 - val_loss: 2.1792e-04 - val_Head: 2.0139e-04 - val_Beak: 1.7061e-04 - val_Body_top: 2.7103e-04 - val_RFlipper_mid: 2.0969e-04 - val_LFlipper_mid: 2.9307e-04 - val_Body_bottom: 3.1218e-04 - val_RFoot: 1.3790e-04 - val_LFoot: 1.4745e-04 - lr: 1.0000e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 158/200\n",
      "360/360 - 40s - loss: 7.6958e-05 - Head: 5.8775e-05 - Beak: 5.5957e-05 - Body_top: 8.5584e-05 - RFlipper_mid: 8.0103e-05 - LFlipper_mid: 8.3013e-05 - Body_bottom: 1.5151e-04 - RFoot: 5.3094e-05 - LFoot: 4.7634e-05 - val_loss: 2.1626e-04 - val_Head: 2.0377e-04 - val_Beak: 1.6172e-04 - val_Body_top: 2.7003e-04 - val_RFlipper_mid: 2.0426e-04 - val_LFlipper_mid: 2.9304e-04 - val_Body_bottom: 3.1089e-04 - val_RFoot: 1.3660e-04 - val_LFoot: 1.4975e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 159/200\n",
      "360/360 - 41s - loss: 7.6383e-05 - Head: 5.6282e-05 - Beak: 5.5356e-05 - Body_top: 8.5868e-05 - RFlipper_mid: 7.8485e-05 - LFlipper_mid: 8.2951e-05 - Body_bottom: 1.5054e-04 - RFoot: 5.1246e-05 - LFoot: 5.0335e-05 - val_loss: 2.1556e-04 - val_Head: 2.0264e-04 - val_Beak: 1.6518e-04 - val_Body_top: 2.6683e-04 - val_RFlipper_mid: 2.0402e-04 - val_LFlipper_mid: 2.9136e-04 - val_Body_bottom: 3.0898e-04 - val_RFoot: 1.3918e-04 - val_LFoot: 1.4628e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 160/200\n",
      "360/360 - 41s - loss: 7.7316e-05 - Head: 5.7215e-05 - Beak: 5.4951e-05 - Body_top: 8.9717e-05 - RFlipper_mid: 7.9427e-05 - LFlipper_mid: 8.2393e-05 - Body_bottom: 1.5092e-04 - RFoot: 5.3894e-05 - LFoot: 5.0015e-05 - val_loss: 2.1884e-04 - val_Head: 2.0950e-04 - val_Beak: 1.6424e-04 - val_Body_top: 2.6515e-04 - val_RFlipper_mid: 2.0654e-04 - val_LFlipper_mid: 2.9605e-04 - val_Body_bottom: 3.1586e-04 - val_RFoot: 1.4044e-04 - val_LFoot: 1.5292e-04 - lr: 1.0000e-08 - 41s/epoch - 113ms/step\n",
      "Epoch 161/200\n",
      "360/360 - 40s - loss: 7.6958e-05 - Head: 5.7155e-05 - Beak: 5.5866e-05 - Body_top: 8.7456e-05 - RFlipper_mid: 7.9840e-05 - LFlipper_mid: 8.3878e-05 - Body_bottom: 1.5017e-04 - RFoot: 5.1506e-05 - LFoot: 4.9794e-05 - val_loss: 2.1874e-04 - val_Head: 2.0516e-04 - val_Beak: 1.6784e-04 - val_Body_top: 2.7273e-04 - val_RFlipper_mid: 2.1094e-04 - val_LFlipper_mid: 2.9301e-04 - val_Body_bottom: 3.1129e-04 - val_RFoot: 1.3929e-04 - val_LFoot: 1.4963e-04 - lr: 1.0000e-08 - 40s/epoch - 112ms/step\n",
      "Epoch 162/200\n",
      "360/360 - 40s - loss: 7.6665e-05 - Head: 5.8524e-05 - Beak: 5.6504e-05 - Body_top: 8.7631e-05 - RFlipper_mid: 7.8365e-05 - LFlipper_mid: 8.1703e-05 - Body_bottom: 1.5098e-04 - RFoot: 5.1018e-05 - LFoot: 4.8596e-05 - val_loss: 2.1477e-04 - val_Head: 1.9645e-04 - val_Beak: 1.6316e-04 - val_Body_top: 2.6567e-04 - val_RFlipper_mid: 2.0483e-04 - val_LFlipper_mid: 2.9252e-04 - val_Body_bottom: 3.1126e-04 - val_RFoot: 1.3912e-04 - val_LFoot: 1.4514e-04 - lr: 1.0000e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 163/200\n",
      "360/360 - 41s - loss: 7.6902e-05 - Head: 5.7011e-05 - Beak: 5.7239e-05 - Body_top: 8.7014e-05 - RFlipper_mid: 7.9698e-05 - LFlipper_mid: 8.2274e-05 - Body_bottom: 1.4891e-04 - RFoot: 5.3191e-05 - LFoot: 4.9880e-05 - val_loss: 2.1754e-04 - val_Head: 2.0078e-04 - val_Beak: 1.6869e-04 - val_Body_top: 2.7202e-04 - val_RFlipper_mid: 2.0927e-04 - val_LFlipper_mid: 2.9393e-04 - val_Body_bottom: 3.0771e-04 - val_RFoot: 1.3891e-04 - val_LFoot: 1.4900e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 164/200\n",
      "360/360 - 39s - loss: 7.6333e-05 - Head: 5.5027e-05 - Beak: 5.1776e-05 - Body_top: 8.6831e-05 - RFlipper_mid: 7.8727e-05 - LFlipper_mid: 8.2446e-05 - Body_bottom: 1.4966e-04 - RFoot: 5.3569e-05 - LFoot: 5.2624e-05 - val_loss: 2.1558e-04 - val_Head: 1.9981e-04 - val_Beak: 1.6670e-04 - val_Body_top: 2.6685e-04 - val_RFlipper_mid: 2.0488e-04 - val_LFlipper_mid: 2.9208e-04 - val_Body_bottom: 3.1045e-04 - val_RFoot: 1.3869e-04 - val_LFoot: 1.4520e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 165/200\n",
      "360/360 - 40s - loss: 7.7336e-05 - Head: 5.8453e-05 - Beak: 5.7506e-05 - Body_top: 8.6863e-05 - RFlipper_mid: 8.0395e-05 - LFlipper_mid: 8.2111e-05 - Body_bottom: 1.5267e-04 - RFoot: 5.1720e-05 - LFoot: 4.8967e-05 - val_loss: 2.1726e-04 - val_Head: 2.0157e-04 - val_Beak: 1.5862e-04 - val_Body_top: 2.7248e-04 - val_RFlipper_mid: 2.0184e-04 - val_LFlipper_mid: 2.9495e-04 - val_Body_bottom: 3.1481e-04 - val_RFoot: 1.4136e-04 - val_LFoot: 1.5248e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 166/200\n",
      "360/360 - 39s - loss: 7.6869e-05 - Head: 5.6283e-05 - Beak: 5.4553e-05 - Body_top: 8.6827e-05 - RFlipper_mid: 7.9485e-05 - LFlipper_mid: 8.2854e-05 - Body_bottom: 1.5048e-04 - RFoot: 5.2433e-05 - LFoot: 5.2039e-05 - val_loss: 2.1695e-04 - val_Head: 1.9515e-04 - val_Beak: 1.6629e-04 - val_Body_top: 2.7142e-04 - val_RFlipper_mid: 2.0630e-04 - val_LFlipper_mid: 2.9320e-04 - val_Body_bottom: 3.1156e-04 - val_RFoot: 1.4057e-04 - val_LFoot: 1.5113e-04 - lr: 1.0000e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 167/200\n",
      "360/360 - 39s - loss: 7.6963e-05 - Head: 5.7998e-05 - Beak: 5.6982e-05 - Body_top: 8.7474e-05 - RFlipper_mid: 7.9105e-05 - LFlipper_mid: 8.3093e-05 - Body_bottom: 1.5064e-04 - RFoot: 5.1984e-05 - LFoot: 4.8429e-05 - val_loss: 2.1481e-04 - val_Head: 1.9990e-04 - val_Beak: 1.5703e-04 - val_Body_top: 2.5976e-04 - val_RFlipper_mid: 2.0119e-04 - val_LFlipper_mid: 2.9143e-04 - val_Body_bottom: 3.1603e-04 - val_RFoot: 1.3945e-04 - val_LFoot: 1.5369e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 168/200\n",
      "360/360 - 40s - loss: 7.6614e-05 - Head: 5.5132e-05 - Beak: 5.4865e-05 - Body_top: 8.7482e-05 - RFlipper_mid: 7.9290e-05 - LFlipper_mid: 8.3119e-05 - Body_bottom: 1.5020e-04 - RFoot: 5.2112e-05 - LFoot: 5.0714e-05 - val_loss: 2.1522e-04 - val_Head: 1.9371e-04 - val_Beak: 1.6506e-04 - val_Body_top: 2.6226e-04 - val_RFlipper_mid: 2.0091e-04 - val_LFlipper_mid: 2.9281e-04 - val_Body_bottom: 3.1573e-04 - val_RFoot: 1.4048e-04 - val_LFoot: 1.5083e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 169/200\n",
      "360/360 - 38s - loss: 7.7315e-05 - Head: 5.6824e-05 - Beak: 5.5936e-05 - Body_top: 8.7744e-05 - RFlipper_mid: 7.8928e-05 - LFlipper_mid: 8.3702e-05 - Body_bottom: 1.5089e-04 - RFoot: 5.3256e-05 - LFoot: 5.1238e-05 - val_loss: 2.1618e-04 - val_Head: 2.0930e-04 - val_Beak: 1.6142e-04 - val_Body_top: 2.6405e-04 - val_RFlipper_mid: 2.0587e-04 - val_LFlipper_mid: 2.9220e-04 - val_Body_bottom: 3.1046e-04 - val_RFoot: 1.3850e-04 - val_LFoot: 1.4762e-04 - lr: 1.0000e-08 - 38s/epoch - 106ms/step\n",
      "Epoch 170/200\n",
      "360/360 - 40s - loss: 7.6621e-05 - Head: 5.7050e-05 - Beak: 5.5270e-05 - Body_top: 8.7118e-05 - RFlipper_mid: 7.9214e-05 - LFlipper_mid: 8.3980e-05 - Body_bottom: 1.5110e-04 - RFoot: 5.1515e-05 - LFoot: 4.7714e-05 - val_loss: 2.1658e-04 - val_Head: 2.0517e-04 - val_Beak: 1.6485e-04 - val_Body_top: 2.6291e-04 - val_RFlipper_mid: 2.0912e-04 - val_LFlipper_mid: 2.9205e-04 - val_Body_bottom: 3.1242e-04 - val_RFoot: 1.3487e-04 - val_LFoot: 1.5125e-04 - lr: 1.0000e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 171/200\n",
      "360/360 - 41s - loss: 7.6970e-05 - Head: 5.8024e-05 - Beak: 5.6391e-05 - Body_top: 8.6264e-05 - RFlipper_mid: 7.9306e-05 - LFlipper_mid: 8.3127e-05 - Body_bottom: 1.5054e-04 - RFoot: 5.2986e-05 - LFoot: 4.9126e-05 - val_loss: 2.1591e-04 - val_Head: 2.0425e-04 - val_Beak: 1.6221e-04 - val_Body_top: 2.6217e-04 - val_RFlipper_mid: 2.0899e-04 - val_LFlipper_mid: 2.9110e-04 - val_Body_bottom: 3.1333e-04 - val_RFoot: 1.4011e-04 - val_LFoot: 1.4515e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 172/200\n",
      "360/360 - 39s - loss: 7.6805e-05 - Head: 5.5676e-05 - Beak: 5.6420e-05 - Body_top: 8.7731e-05 - RFlipper_mid: 7.8341e-05 - LFlipper_mid: 8.3491e-05 - Body_bottom: 1.4998e-04 - RFoot: 5.3978e-05 - LFoot: 4.8824e-05 - val_loss: 2.1843e-04 - val_Head: 2.1012e-04 - val_Beak: 1.6746e-04 - val_Body_top: 2.6463e-04 - val_RFlipper_mid: 2.0684e-04 - val_LFlipper_mid: 2.9184e-04 - val_Body_bottom: 3.1434e-04 - val_RFoot: 1.4116e-04 - val_LFoot: 1.5102e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 173/200\n",
      "360/360 - 41s - loss: 7.7223e-05 - Head: 5.9769e-05 - Beak: 5.7821e-05 - Body_top: 8.8130e-05 - RFlipper_mid: 7.7919e-05 - LFlipper_mid: 8.1944e-05 - Body_bottom: 1.5036e-04 - RFoot: 5.2451e-05 - LFoot: 4.9385e-05 - val_loss: 2.1721e-04 - val_Head: 2.0249e-04 - val_Beak: 1.6385e-04 - val_Body_top: 2.6824e-04 - val_RFlipper_mid: 2.0657e-04 - val_LFlipper_mid: 2.9364e-04 - val_Body_bottom: 3.1358e-04 - val_RFoot: 1.4189e-04 - val_LFoot: 1.4739e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 174/200\n",
      "360/360 - 41s - loss: 7.6797e-05 - Head: 5.5565e-05 - Beak: 5.4541e-05 - Body_top: 8.6860e-05 - RFlipper_mid: 7.9994e-05 - LFlipper_mid: 8.1559e-05 - Body_bottom: 1.5169e-04 - RFoot: 5.3305e-05 - LFoot: 5.0861e-05 - val_loss: 2.1552e-04 - val_Head: 1.9067e-04 - val_Beak: 1.6642e-04 - val_Body_top: 2.6560e-04 - val_RFlipper_mid: 2.0583e-04 - val_LFlipper_mid: 2.9142e-04 - val_Body_bottom: 3.1048e-04 - val_RFoot: 1.4075e-04 - val_LFoot: 1.5301e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 175/200\n",
      "360/360 - 38s - loss: 7.6895e-05 - Head: 5.7751e-05 - Beak: 5.6633e-05 - Body_top: 8.6527e-05 - RFlipper_mid: 7.9635e-05 - LFlipper_mid: 8.3422e-05 - Body_bottom: 1.5073e-04 - RFoot: 5.1904e-05 - LFoot: 4.8567e-05 - val_loss: 2.1634e-04 - val_Head: 1.9550e-04 - val_Beak: 1.6815e-04 - val_Body_top: 2.7254e-04 - val_RFlipper_mid: 2.0234e-04 - val_LFlipper_mid: 2.9516e-04 - val_Body_bottom: 3.1083e-04 - val_RFoot: 1.4047e-04 - val_LFoot: 1.4573e-04 - lr: 1.0000e-08 - 38s/epoch - 105ms/step\n",
      "Epoch 176/200\n",
      "360/360 - 40s - loss: 7.6549e-05 - Head: 5.5144e-05 - Beak: 5.4437e-05 - Body_top: 8.6590e-05 - RFlipper_mid: 7.9890e-05 - LFlipper_mid: 8.2479e-05 - Body_bottom: 1.5173e-04 - RFoot: 5.3372e-05 - LFoot: 4.8743e-05 - val_loss: 2.1699e-04 - val_Head: 1.9691e-04 - val_Beak: 1.7001e-04 - val_Body_top: 2.7080e-04 - val_RFlipper_mid: 2.0420e-04 - val_LFlipper_mid: 2.9262e-04 - val_Body_bottom: 3.1455e-04 - val_RFoot: 1.4001e-04 - val_LFoot: 1.4685e-04 - lr: 1.0000e-08 - 40s/epoch - 111ms/step\n",
      "Epoch 177/200\n",
      "360/360 - 41s - loss: 7.6579e-05 - Head: 5.6963e-05 - Beak: 5.6374e-05 - Body_top: 8.5981e-05 - RFlipper_mid: 7.9020e-05 - LFlipper_mid: 8.2724e-05 - Body_bottom: 1.5183e-04 - RFoot: 5.1662e-05 - LFoot: 4.8073e-05 - val_loss: 2.1687e-04 - val_Head: 2.0055e-04 - val_Beak: 1.6754e-04 - val_Body_top: 2.6897e-04 - val_RFlipper_mid: 2.0701e-04 - val_LFlipper_mid: 2.9032e-04 - val_Body_bottom: 3.1150e-04 - val_RFoot: 1.4146e-04 - val_LFoot: 1.4761e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 178/200\n",
      "360/360 - 40s - loss: 7.7582e-05 - Head: 5.8902e-05 - Beak: 5.8217e-05 - Body_top: 8.8715e-05 - RFlipper_mid: 7.9752e-05 - LFlipper_mid: 8.3273e-05 - Body_bottom: 1.5139e-04 - RFoot: 5.2153e-05 - LFoot: 4.8255e-05 - val_loss: 2.1846e-04 - val_Head: 2.1027e-04 - val_Beak: 1.7042e-04 - val_Body_top: 2.6930e-04 - val_RFlipper_mid: 2.1085e-04 - val_LFlipper_mid: 2.9207e-04 - val_Body_bottom: 3.1110e-04 - val_RFoot: 1.3743e-04 - val_LFoot: 1.4628e-04 - lr: 1.0000e-08 - 40s/epoch - 112ms/step\n",
      "Epoch 179/200\n",
      "360/360 - 42s - loss: 7.7760e-05 - Head: 5.9885e-05 - Beak: 5.8617e-05 - Body_top: 8.7452e-05 - RFlipper_mid: 8.0580e-05 - LFlipper_mid: 8.3230e-05 - Body_bottom: 1.4931e-04 - RFoot: 5.2840e-05 - LFoot: 5.0167e-05 - val_loss: 2.1682e-04 - val_Head: 1.9983e-04 - val_Beak: 1.6014e-04 - val_Body_top: 2.6807e-04 - val_RFlipper_mid: 2.0810e-04 - val_LFlipper_mid: 2.9374e-04 - val_Body_bottom: 3.1368e-04 - val_RFoot: 1.3978e-04 - val_LFoot: 1.5122e-04 - lr: 1.0000e-08 - 42s/epoch - 116ms/step\n",
      "Epoch 180/200\n",
      "360/360 - 41s - loss: 7.7019e-05 - Head: 5.5988e-05 - Beak: 5.7626e-05 - Body_top: 8.7909e-05 - RFlipper_mid: 7.9492e-05 - LFlipper_mid: 8.4396e-05 - Body_bottom: 1.5059e-04 - RFoot: 5.1452e-05 - LFoot: 4.8700e-05 - val_loss: 2.1873e-04 - val_Head: 2.0972e-04 - val_Beak: 1.6832e-04 - val_Body_top: 2.7067e-04 - val_RFlipper_mid: 2.0324e-04 - val_LFlipper_mid: 2.9349e-04 - val_Body_bottom: 3.1351e-04 - val_RFoot: 1.4199e-04 - val_LFoot: 1.4890e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 181/200\n",
      "360/360 - 40s - loss: 7.7104e-05 - Head: 5.9670e-05 - Beak: 5.8345e-05 - Body_top: 8.8039e-05 - RFlipper_mid: 7.8605e-05 - LFlipper_mid: 8.2524e-05 - Body_bottom: 1.4988e-04 - RFoot: 5.0689e-05 - LFoot: 4.9085e-05 - val_loss: 2.1910e-04 - val_Head: 2.1030e-04 - val_Beak: 1.6456e-04 - val_Body_top: 2.6498e-04 - val_RFlipper_mid: 2.1058e-04 - val_LFlipper_mid: 2.9410e-04 - val_Body_bottom: 3.1427e-04 - val_RFoot: 1.4077e-04 - val_LFoot: 1.5320e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 182/200\n",
      "360/360 - 39s - loss: 7.6840e-05 - Head: 5.6139e-05 - Beak: 5.5326e-05 - Body_top: 8.7899e-05 - RFlipper_mid: 7.8120e-05 - LFlipper_mid: 8.3331e-05 - Body_bottom: 1.5011e-04 - RFoot: 5.2878e-05 - LFoot: 5.0914e-05 - val_loss: 2.1777e-04 - val_Head: 2.1136e-04 - val_Beak: 1.6458e-04 - val_Body_top: 2.6782e-04 - val_RFlipper_mid: 2.0742e-04 - val_LFlipper_mid: 2.9524e-04 - val_Body_bottom: 3.1126e-04 - val_RFoot: 1.3742e-04 - val_LFoot: 1.4707e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 183/200\n",
      "360/360 - 41s - loss: 7.7069e-05 - Head: 5.5965e-05 - Beak: 5.6487e-05 - Body_top: 8.5816e-05 - RFlipper_mid: 8.0636e-05 - LFlipper_mid: 8.2395e-05 - Body_bottom: 1.5167e-04 - RFoot: 5.2919e-05 - LFoot: 5.0663e-05 - val_loss: 2.1680e-04 - val_Head: 2.1305e-04 - val_Beak: 1.5670e-04 - val_Body_top: 2.6139e-04 - val_RFlipper_mid: 2.0325e-04 - val_LFlipper_mid: 2.9439e-04 - val_Body_bottom: 3.1266e-04 - val_RFoot: 1.4045e-04 - val_LFoot: 1.5251e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 184/200\n",
      "360/360 - 42s - loss: 7.7425e-05 - Head: 5.6855e-05 - Beak: 5.7600e-05 - Body_top: 8.7751e-05 - RFlipper_mid: 7.9605e-05 - LFlipper_mid: 8.2937e-05 - Body_bottom: 1.5084e-04 - RFoot: 5.2992e-05 - LFoot: 5.0816e-05 - val_loss: 2.1626e-04 - val_Head: 2.0236e-04 - val_Beak: 1.7113e-04 - val_Body_top: 2.6530e-04 - val_RFlipper_mid: 2.0340e-04 - val_LFlipper_mid: 2.9324e-04 - val_Body_bottom: 3.0955e-04 - val_RFoot: 1.3846e-04 - val_LFoot: 1.4662e-04 - lr: 1.0000e-08 - 42s/epoch - 117ms/step\n",
      "Epoch 185/200\n",
      "360/360 - 42s - loss: 7.7548e-05 - Head: 5.8323e-05 - Beak: 5.7094e-05 - Body_top: 8.8071e-05 - RFlipper_mid: 7.8361e-05 - LFlipper_mid: 8.3064e-05 - Body_bottom: 1.5066e-04 - RFoot: 5.3858e-05 - LFoot: 5.0957e-05 - val_loss: 2.1628e-04 - val_Head: 2.0330e-04 - val_Beak: 1.6073e-04 - val_Body_top: 2.7042e-04 - val_RFlipper_mid: 1.9864e-04 - val_LFlipper_mid: 2.9166e-04 - val_Body_bottom: 3.1332e-04 - val_RFoot: 1.4008e-04 - val_LFoot: 1.5212e-04 - lr: 1.0000e-08 - 42s/epoch - 117ms/step\n",
      "Epoch 186/200\n",
      "360/360 - 39s - loss: 7.5735e-05 - Head: 5.5402e-05 - Beak: 5.2892e-05 - Body_top: 8.5133e-05 - RFlipper_mid: 7.8596e-05 - LFlipper_mid: 8.3448e-05 - Body_bottom: 1.4927e-04 - RFoot: 5.2624e-05 - LFoot: 4.8524e-05 - val_loss: 2.1544e-04 - val_Head: 1.9714e-04 - val_Beak: 1.6546e-04 - val_Body_top: 2.6804e-04 - val_RFlipper_mid: 2.0221e-04 - val_LFlipper_mid: 2.9183e-04 - val_Body_bottom: 3.1296e-04 - val_RFoot: 1.3953e-04 - val_LFoot: 1.4637e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 187/200\n",
      "360/360 - 39s - loss: 7.7330e-05 - Head: 5.7697e-05 - Beak: 5.7355e-05 - Body_top: 8.8137e-05 - RFlipper_mid: 7.7479e-05 - LFlipper_mid: 8.2559e-05 - Body_bottom: 1.5251e-04 - RFoot: 5.2359e-05 - LFoot: 5.0539e-05 - val_loss: 2.1793e-04 - val_Head: 2.0958e-04 - val_Beak: 1.6248e-04 - val_Body_top: 2.6700e-04 - val_RFlipper_mid: 2.0659e-04 - val_LFlipper_mid: 2.9346e-04 - val_Body_bottom: 3.1211e-04 - val_RFoot: 1.3772e-04 - val_LFoot: 1.5447e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 188/200\n",
      "360/360 - 40s - loss: 7.7642e-05 - Head: 5.9509e-05 - Beak: 5.7547e-05 - Body_top: 8.8621e-05 - RFlipper_mid: 7.8326e-05 - LFlipper_mid: 8.2597e-05 - Body_bottom: 1.5202e-04 - RFoot: 5.2572e-05 - LFoot: 4.9946e-05 - val_loss: 2.1750e-04 - val_Head: 2.0731e-04 - val_Beak: 1.6501e-04 - val_Body_top: 2.6186e-04 - val_RFlipper_mid: 2.0201e-04 - val_LFlipper_mid: 2.9315e-04 - val_Body_bottom: 3.1646e-04 - val_RFoot: 1.4041e-04 - val_LFoot: 1.5381e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 189/200\n",
      "360/360 - 41s - loss: 7.6838e-05 - Head: 5.4761e-05 - Beak: 5.6373e-05 - Body_top: 8.7312e-05 - RFlipper_mid: 7.8413e-05 - LFlipper_mid: 8.2934e-05 - Body_bottom: 1.5044e-04 - RFoot: 5.4296e-05 - LFoot: 5.0171e-05 - val_loss: 2.1674e-04 - val_Head: 2.0341e-04 - val_Beak: 1.6209e-04 - val_Body_top: 2.6991e-04 - val_RFlipper_mid: 2.0061e-04 - val_LFlipper_mid: 2.9309e-04 - val_Body_bottom: 3.1157e-04 - val_RFoot: 1.3854e-04 - val_LFoot: 1.5467e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 190/200\n",
      "360/360 - 39s - loss: 7.6708e-05 - Head: 5.5759e-05 - Beak: 5.7131e-05 - Body_top: 8.7656e-05 - RFlipper_mid: 7.9108e-05 - LFlipper_mid: 8.2143e-05 - Body_bottom: 1.5073e-04 - RFoot: 5.1535e-05 - LFoot: 4.9596e-05 - val_loss: 2.1621e-04 - val_Head: 2.0058e-04 - val_Beak: 1.6200e-04 - val_Body_top: 2.6642e-04 - val_RFlipper_mid: 1.9814e-04 - val_LFlipper_mid: 2.9296e-04 - val_Body_bottom: 3.1011e-04 - val_RFoot: 1.4630e-04 - val_LFoot: 1.5316e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 191/200\n",
      "360/360 - 42s - loss: 7.6098e-05 - Head: 5.5252e-05 - Beak: 5.4208e-05 - Body_top: 8.6127e-05 - RFlipper_mid: 7.9614e-05 - LFlipper_mid: 8.2699e-05 - Body_bottom: 1.5132e-04 - RFoot: 5.1785e-05 - LFoot: 4.7773e-05 - val_loss: 2.1862e-04 - val_Head: 2.0436e-04 - val_Beak: 1.7040e-04 - val_Body_top: 2.6920e-04 - val_RFlipper_mid: 2.0399e-04 - val_LFlipper_mid: 2.9314e-04 - val_Body_bottom: 3.1454e-04 - val_RFoot: 1.4220e-04 - val_LFoot: 1.5110e-04 - lr: 1.0000e-08 - 42s/epoch - 116ms/step\n",
      "Epoch 192/200\n",
      "360/360 - 39s - loss: 7.7051e-05 - Head: 5.7864e-05 - Beak: 5.5975e-05 - Body_top: 8.6500e-05 - RFlipper_mid: 7.9082e-05 - LFlipper_mid: 8.3713e-05 - Body_bottom: 1.5213e-04 - RFoot: 5.2382e-05 - LFoot: 4.8758e-05 - val_loss: 2.1620e-04 - val_Head: 1.9800e-04 - val_Beak: 1.6134e-04 - val_Body_top: 2.7070e-04 - val_RFlipper_mid: 2.0708e-04 - val_LFlipper_mid: 2.9373e-04 - val_Body_bottom: 3.0876e-04 - val_RFoot: 1.3981e-04 - val_LFoot: 1.5017e-04 - lr: 1.0000e-08 - 39s/epoch - 109ms/step\n",
      "Epoch 193/200\n",
      "360/360 - 41s - loss: 7.6750e-05 - Head: 5.5718e-05 - Beak: 5.6101e-05 - Body_top: 8.7027e-05 - RFlipper_mid: 7.7643e-05 - LFlipper_mid: 8.3064e-05 - Body_bottom: 1.5174e-04 - RFoot: 5.2971e-05 - LFoot: 4.9741e-05 - val_loss: 2.1440e-04 - val_Head: 1.9674e-04 - val_Beak: 1.6632e-04 - val_Body_top: 2.6835e-04 - val_RFlipper_mid: 2.0088e-04 - val_LFlipper_mid: 2.9286e-04 - val_Body_bottom: 3.0698e-04 - val_RFoot: 1.3825e-04 - val_LFoot: 1.4481e-04 - lr: 1.0000e-08 - 41s/epoch - 115ms/step\n",
      "Epoch 194/200\n",
      "360/360 - 40s - loss: 7.7118e-05 - Head: 5.8810e-05 - Beak: 5.7180e-05 - Body_top: 8.7407e-05 - RFlipper_mid: 7.8812e-05 - LFlipper_mid: 8.3846e-05 - Body_bottom: 1.5034e-04 - RFoot: 5.2789e-05 - LFoot: 4.7761e-05 - val_loss: 2.1843e-04 - val_Head: 2.1045e-04 - val_Beak: 1.6310e-04 - val_Body_top: 2.6694e-04 - val_RFlipper_mid: 2.0983e-04 - val_LFlipper_mid: 2.9293e-04 - val_Body_bottom: 3.1354e-04 - val_RFoot: 1.3974e-04 - val_LFoot: 1.5088e-04 - lr: 1.0000e-08 - 40s/epoch - 110ms/step\n",
      "Epoch 195/200\n",
      "360/360 - 39s - loss: 7.6535e-05 - Head: 5.6584e-05 - Beak: 5.5201e-05 - Body_top: 8.6089e-05 - RFlipper_mid: 7.8226e-05 - LFlipper_mid: 8.3453e-05 - Body_bottom: 1.5136e-04 - RFoot: 5.1819e-05 - LFoot: 4.9550e-05 - val_loss: 2.1852e-04 - val_Head: 2.0929e-04 - val_Beak: 1.7329e-04 - val_Body_top: 2.6515e-04 - val_RFlipper_mid: 2.1088e-04 - val_LFlipper_mid: 2.9089e-04 - val_Body_bottom: 3.1353e-04 - val_RFoot: 1.3592e-04 - val_LFoot: 1.4920e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "Epoch 196/200\n",
      "360/360 - 39s - loss: 7.6608e-05 - Head: 5.9322e-05 - Beak: 5.6129e-05 - Body_top: 8.7683e-05 - RFlipper_mid: 7.8079e-05 - LFlipper_mid: 8.2262e-05 - Body_bottom: 1.4994e-04 - RFoot: 5.0616e-05 - LFoot: 4.8827e-05 - val_loss: 2.1633e-04 - val_Head: 2.0258e-04 - val_Beak: 1.6421e-04 - val_Body_top: 2.6536e-04 - val_RFlipper_mid: 2.0736e-04 - val_LFlipper_mid: 2.9253e-04 - val_Body_bottom: 3.1161e-04 - val_RFoot: 1.4061e-04 - val_LFoot: 1.4638e-04 - lr: 1.0000e-08 - 39s/epoch - 110ms/step\n",
      "Epoch 197/200\n",
      "360/360 - 42s - loss: 7.7396e-05 - Head: 5.6521e-05 - Beak: 5.7599e-05 - Body_top: 8.9068e-05 - RFlipper_mid: 7.9378e-05 - LFlipper_mid: 8.3767e-05 - Body_bottom: 1.5073e-04 - RFoot: 5.2244e-05 - LFoot: 4.9854e-05 - val_loss: 2.1845e-04 - val_Head: 2.0996e-04 - val_Beak: 1.6666e-04 - val_Body_top: 2.6269e-04 - val_RFlipper_mid: 2.1112e-04 - val_LFlipper_mid: 2.9377e-04 - val_Body_bottom: 3.1658e-04 - val_RFoot: 1.3936e-04 - val_LFoot: 1.4745e-04 - lr: 1.0000e-08 - 42s/epoch - 115ms/step\n",
      "Epoch 198/200\n",
      "360/360 - 41s - loss: 7.7125e-05 - Head: 5.7679e-05 - Beak: 5.6578e-05 - Body_top: 8.6764e-05 - RFlipper_mid: 8.0101e-05 - LFlipper_mid: 8.4445e-05 - Body_bottom: 1.5054e-04 - RFoot: 5.2592e-05 - LFoot: 4.8293e-05 - val_loss: 2.1554e-04 - val_Head: 1.9837e-04 - val_Beak: 1.6553e-04 - val_Body_top: 2.6516e-04 - val_RFlipper_mid: 2.0392e-04 - val_LFlipper_mid: 2.9324e-04 - val_Body_bottom: 3.1405e-04 - val_RFoot: 1.3919e-04 - val_LFoot: 1.4484e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 199/200\n",
      "360/360 - 41s - loss: 7.7050e-05 - Head: 5.6633e-05 - Beak: 5.3804e-05 - Body_top: 8.7283e-05 - RFlipper_mid: 8.1227e-05 - LFlipper_mid: 8.3542e-05 - Body_bottom: 1.5110e-04 - RFoot: 5.2540e-05 - LFoot: 5.0267e-05 - val_loss: 2.1707e-04 - val_Head: 1.9820e-04 - val_Beak: 1.6525e-04 - val_Body_top: 2.6146e-04 - val_RFlipper_mid: 2.0900e-04 - val_LFlipper_mid: 2.9542e-04 - val_Body_bottom: 3.1343e-04 - val_RFoot: 1.4374e-04 - val_LFoot: 1.5006e-04 - lr: 1.0000e-08 - 41s/epoch - 114ms/step\n",
      "Epoch 200/200\n",
      "360/360 - 39s - loss: 7.6415e-05 - Head: 5.6136e-05 - Beak: 5.5937e-05 - Body_top: 8.5692e-05 - RFlipper_mid: 7.9883e-05 - LFlipper_mid: 8.1510e-05 - Body_bottom: 1.5053e-04 - RFoot: 5.3193e-05 - LFoot: 4.8441e-05 - val_loss: 2.1769e-04 - val_Head: 2.1533e-04 - val_Beak: 1.6618e-04 - val_Body_top: 2.6108e-04 - val_RFlipper_mid: 2.0247e-04 - val_LFlipper_mid: 2.9231e-04 - val_Body_bottom: 3.1489e-04 - val_RFoot: 1.3775e-04 - val_LFoot: 1.5151e-04 - lr: 1.0000e-08 - 39s/epoch - 108ms/step\n",
      "INFO:sleap.nn.training:Finished training loop. [130.4 min]\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6876cdc5bf2b405a961ecd85c4398e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.553600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a64495955d94178a8302f516676f699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.012873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38450028c3934818b75b4b6d57d21c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/labels_pr.test.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch/metrics.test.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.201657\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [35.0s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"find_instance_peaks_2\" (type FindInstancePeaks).\n\nInput 0 of layer \"model_17\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(1, 256, 256, 3)\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(1, 512, 512, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3052/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batches_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         )\n\u001b[1;32m    943\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finished training loop. [{(time() - t0) / 60:.1f} min]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;34m\"\"\"Save figure at the end of each epoch.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# Call plotting function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# Check if output folder exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0mrun_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mviz_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvisualize_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_viz_ds_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             )\n",
      "\u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/training.py\u001b[0m in \u001b[0;36mvisualize_example\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m             \u001b[0;31m# Find peaks by evaluating model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance_image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance_image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mcms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance_confmaps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/sleap/sleap/nn/inference.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         \u001b[0;31m# Network forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0;31m# Sort outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"find_instance_peaks_2\" (type FindInstancePeaks).\n\nInput 0 of layer \"model_17\" is incompatible with the layer: expected shape=(None, 512, 512, 3), found shape=(1, 256, 256, 3)\n\nCall arguments received:\n   inputs=tf.Tensor(shape=(1, 512, 512, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Oct3_test2 error\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4. Continue training from existing model using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "#cfg = sleap.load_config(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json\")\n",
    "cfg = sleap.load_config(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_centroid_200Epoch/training_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n"
     ]
    }
   ],
   "source": [
    "trainer = sleap.nn.training.Trainer.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "INFO:sleap.nn.training:Loaded test example. [1.059s]\n",
      "INFO:sleap.nn.training:  Input shape: (544, 960, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=24, filters_rate=1.5, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=5, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 32\n",
      "INFO:sleap.nn.training:  Parameters: 1,645,179\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CentroidConfmapsHead(anchor_part='Body_top', sigma=2.5, output_stride=4, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 136, 240, 1), dtype=tf.float32, name=None), name='CentroidConfmapsHead/BiasAdd:0', description=\"created by layer 'CentroidConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=150)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_centroid_200Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [5.2s]\n"
     ]
    }
   ],
   "source": [
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 19 layers, found 17 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3052/4261910523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace the randomly initialized weights with the saved weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/best_model.h5\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_centroid_200Epoch/best_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    718\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     raise ValueError(\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0;34mf'Layer count mismatch when loading weights from file. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0;34mf'Model expected {len(filtered_layers)} layers, found '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         f'{len(layer_names)} saved layers.')\n",
      "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 19 layers, found 17 saved layers."
     ]
    }
   ],
   "source": [
    "# Replace the randomly initialized weights with the saved weights.\n",
    "#trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/best_model.h5\")\n",
    "trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_centroid_200Epoch/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [31.5s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n",
      "360/360 - 35s - loss: 1.4365e-04 - val_loss: 1.4932e-04 - lr: 1.0000e-04 - 35s/epoch - 98ms/step\n",
      "Epoch 2/200\n",
      "360/360 - 31s - loss: 1.4057e-04 - val_loss: 1.6928e-04 - lr: 1.0000e-04 - 31s/epoch - 86ms/step\n",
      "Epoch 3/200\n",
      "360/360 - 32s - loss: 1.4540e-04 - val_loss: 1.5009e-04 - lr: 1.0000e-04 - 32s/epoch - 90ms/step\n",
      "Epoch 4/200\n",
      "360/360 - 30s - loss: 1.4074e-04 - val_loss: 1.5041e-04 - lr: 1.0000e-04 - 30s/epoch - 85ms/step\n",
      "Epoch 5/200\n",
      "360/360 - 33s - loss: 1.4278e-04 - val_loss: 1.5035e-04 - lr: 1.0000e-04 - 33s/epoch - 91ms/step\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "360/360 - 32s - loss: 1.3721e-04 - val_loss: 1.5359e-04 - lr: 1.0000e-04 - 32s/epoch - 90ms/step\n",
      "Epoch 7/200\n",
      "360/360 - 33s - loss: 1.3337e-04 - val_loss: 1.7169e-04 - lr: 5.0000e-05 - 33s/epoch - 90ms/step\n",
      "Epoch 8/200\n",
      "360/360 - 32s - loss: 1.2646e-04 - val_loss: 1.5080e-04 - lr: 5.0000e-05 - 32s/epoch - 90ms/step\n",
      "Epoch 9/200\n",
      "360/360 - 32s - loss: 1.2447e-04 - val_loss: 1.7408e-04 - lr: 5.0000e-05 - 32s/epoch - 89ms/step\n",
      "Epoch 10/200\n",
      "360/360 - 33s - loss: 1.2424e-04 - val_loss: 1.5595e-04 - lr: 5.0000e-05 - 33s/epoch - 90ms/step\n",
      "Epoch 11/200\n",
      "360/360 - 32s - loss: 1.2212e-04 - val_loss: 1.5070e-04 - lr: 5.0000e-05 - 32s/epoch - 89ms/step\n",
      "Epoch 12/200\n",
      "360/360 - 32s - loss: 1.1973e-04 - val_loss: 1.5200e-04 - lr: 5.0000e-05 - 32s/epoch - 90ms/step\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "360/360 - 30s - loss: 1.1875e-04 - val_loss: 1.5888e-04 - lr: 5.0000e-05 - 30s/epoch - 84ms/step\n",
      "Epoch 14/200\n",
      "360/360 - 31s - loss: 1.1280e-04 - val_loss: 1.5630e-04 - lr: 2.5000e-05 - 31s/epoch - 85ms/step\n",
      "Epoch 15/200\n",
      "360/360 - 34s - loss: 1.1199e-04 - val_loss: 1.5811e-04 - lr: 2.5000e-05 - 34s/epoch - 94ms/step\n",
      "Epoch 16/200\n",
      "360/360 - 33s - loss: 1.1019e-04 - val_loss: 1.5453e-04 - lr: 2.5000e-05 - 33s/epoch - 91ms/step\n",
      "Epoch 17/200\n",
      "360/360 - 32s - loss: 1.0795e-04 - val_loss: 1.5736e-04 - lr: 2.5000e-05 - 32s/epoch - 90ms/step\n",
      "Epoch 18/200\n",
      "360/360 - 31s - loss: 1.0591e-04 - val_loss: 1.6018e-04 - lr: 2.5000e-05 - 31s/epoch - 85ms/step\n",
      "Epoch 19/200\n",
      "360/360 - 31s - loss: 1.0458e-04 - val_loss: 1.6715e-04 - lr: 2.5000e-05 - 31s/epoch - 85ms/step\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "360/360 - 32s - loss: 1.0505e-04 - val_loss: 1.5195e-04 - lr: 2.5000e-05 - 32s/epoch - 89ms/step\n",
      "Epoch 21/200\n",
      "360/360 - 32s - loss: 9.8528e-05 - val_loss: 1.5754e-04 - lr: 1.2500e-05 - 32s/epoch - 90ms/step\n",
      "Epoch 00021: early stopping\n",
      "INFO:sleap.nn.training:Finished training loop. [11.2 min]\n",
      "INFO:sleap.nn.training:Deleting visualization directory: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/viz\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e05fd9d73a432c86f1a7de0fdf8879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.198020\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22f27f2be854466b4df076cbab66ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.237624\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3437658cf9d4662be59a48f0f081b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/labels_pr.test.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/metrics.test.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.168317\n"
     ]
    }
   ],
   "source": [
    "trainer.config.optimization.epochs = 200\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "cfg = sleap.load_config(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Loading training labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_train.slp\n",
      "INFO:sleap.nn.training:Loading validation labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_val.slp\n",
      "INFO:sleap.nn.training:Loading test labels from: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/labels.SimpleDataset_DLC_test.slp\n"
     ]
    }
   ],
   "source": [
    "# Create and initialize the trainer. prt1\n",
    "trainer = sleap.nn.training.Trainer.from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "INFO:sleap.nn.training:Loaded test example. [1.238s]\n",
      "INFO:sleap.nn.training:  Input shape: (976, 976, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=24, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=4, middle_block=True, up_blocks=2, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 16\n",
      "INFO:sleap.nn.training:  Parameters: 4,311,392\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = CenteredInstanceConfmapsHead(part_names=['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot'], anchor_part=None, sigma=2.5, output_stride=4, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 244, 244, 8), dtype=tf.float32, name=None), name='CenteredInstanceConfmapsHead/BiasAdd:0', description=\"created by layer 'CenteredInstanceConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 360\n",
      "INFO:sleap.nn.training:Validation set: n = 60\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-08, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=10)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "INFO:sleap.nn.training:Finished trainer set up. [3.3s]\n"
     ]
    }
   ],
   "source": [
    "# Create and initialize the trainer. prt2\n",
    "trainer.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the randomly initialized weights with the saved weights.\n",
    "trainer.keras_model.load_weights(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [38.4s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n",
      "360/360 - 63s - loss: 1.4928e-04 - Head: 1.1466e-04 - Beak: 1.2526e-04 - Body_top: 1.7155e-04 - RFlipper_mid: 1.6765e-04 - LFlipper_mid: 1.5744e-04 - Body_bottom: 2.4295e-04 - RFoot: 1.0423e-04 - LFoot: 1.1054e-04 - val_loss: 2.3458e-04 - val_Head: 2.0912e-04 - val_Beak: 1.9808e-04 - val_Body_top: 2.9516e-04 - val_RFlipper_mid: 2.0596e-04 - val_LFlipper_mid: 3.0770e-04 - val_Body_bottom: 3.3015e-04 - val_RFoot: 1.5116e-04 - val_LFoot: 1.7929e-04 - lr: 1.0000e-04 - 63s/epoch - 176ms/step\n",
      "Epoch 2/200\n",
      "360/360 - 56s - loss: 1.4556e-04 - Head: 1.1986e-04 - Beak: 1.1908e-04 - Body_top: 1.6165e-04 - RFlipper_mid: 1.6706e-04 - LFlipper_mid: 1.5632e-04 - Body_bottom: 2.3762e-04 - RFoot: 9.6419e-05 - LFoot: 1.0645e-04 - val_loss: 2.4803e-04 - val_Head: 2.4031e-04 - val_Beak: 2.0338e-04 - val_Body_top: 3.2047e-04 - val_RFlipper_mid: 2.1339e-04 - val_LFlipper_mid: 3.2810e-04 - val_Body_bottom: 3.4888e-04 - val_RFoot: 1.5007e-04 - val_LFoot: 1.7962e-04 - lr: 1.0000e-04 - 56s/epoch - 157ms/step\n",
      "Epoch 3/200\n",
      "360/360 - 55s - loss: 1.4457e-04 - Head: 1.1436e-04 - Beak: 1.1421e-04 - Body_top: 1.6605e-04 - RFlipper_mid: 1.6138e-04 - LFlipper_mid: 1.5415e-04 - Body_bottom: 2.4322e-04 - RFoot: 9.5593e-05 - LFoot: 1.0760e-04 - val_loss: 2.4211e-04 - val_Head: 2.2214e-04 - val_Beak: 2.1282e-04 - val_Body_top: 3.1975e-04 - val_RFlipper_mid: 2.0601e-04 - val_LFlipper_mid: 3.1751e-04 - val_Body_bottom: 3.3169e-04 - val_RFoot: 1.4892e-04 - val_LFoot: 1.7806e-04 - lr: 1.0000e-04 - 55s/epoch - 153ms/step\n",
      "Epoch 4/200\n",
      "360/360 - 55s - loss: 1.3979e-04 - Head: 1.1614e-04 - Beak: 1.0992e-04 - Body_top: 1.5552e-04 - RFlipper_mid: 1.6174e-04 - LFlipper_mid: 1.5018e-04 - Body_bottom: 2.3183e-04 - RFoot: 9.2065e-05 - LFoot: 1.0089e-04 - val_loss: 2.3855e-04 - val_Head: 2.2458e-04 - val_Beak: 1.7325e-04 - val_Body_top: 3.2400e-04 - val_RFlipper_mid: 2.1817e-04 - val_LFlipper_mid: 3.1468e-04 - val_Body_bottom: 3.3315e-04 - val_RFoot: 1.4507e-04 - val_LFoot: 1.7548e-04 - lr: 1.0000e-04 - 55s/epoch - 153ms/step\n",
      "Epoch 5/200\n",
      "360/360 - 57s - loss: 1.3373e-04 - Head: 1.0397e-04 - Beak: 9.8212e-05 - Body_top: 1.5641e-04 - RFlipper_mid: 1.5092e-04 - LFlipper_mid: 1.4699e-04 - Body_bottom: 2.2956e-04 - RFoot: 8.8484e-05 - LFoot: 9.5319e-05 - val_loss: 2.4513e-04 - val_Head: 2.2441e-04 - val_Beak: 2.0493e-04 - val_Body_top: 3.2018e-04 - val_RFlipper_mid: 2.1239e-04 - val_LFlipper_mid: 3.2867e-04 - val_Body_bottom: 3.3227e-04 - val_RFoot: 1.6732e-04 - val_LFoot: 1.7085e-04 - lr: 1.0000e-04 - 57s/epoch - 159ms/step\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "360/360 - 56s - loss: 1.3080e-04 - Head: 1.0424e-04 - Beak: 9.1224e-05 - Body_top: 1.4937e-04 - RFlipper_mid: 1.5653e-04 - LFlipper_mid: 1.4267e-04 - Body_bottom: 2.2568e-04 - RFoot: 8.4041e-05 - LFoot: 9.2638e-05 - val_loss: 2.3594e-04 - val_Head: 2.1654e-04 - val_Beak: 1.9800e-04 - val_Body_top: 2.8590e-04 - val_RFlipper_mid: 2.0818e-04 - val_LFlipper_mid: 3.1173e-04 - val_Body_bottom: 3.3820e-04 - val_RFoot: 1.5556e-04 - val_LFoot: 1.7339e-04 - lr: 1.0000e-04 - 56s/epoch - 155ms/step\n",
      "Epoch 7/200\n",
      "360/360 - 56s - loss: 1.1650e-04 - Head: 8.7824e-05 - Beak: 7.5557e-05 - Body_top: 1.3070e-04 - RFlipper_mid: 1.4383e-04 - LFlipper_mid: 1.3261e-04 - Body_bottom: 2.0553e-04 - RFoot: 7.3807e-05 - LFoot: 8.2147e-05 - val_loss: 2.3753e-04 - val_Head: 2.1792e-04 - val_Beak: 1.6136e-04 - val_Body_top: 3.3763e-04 - val_RFlipper_mid: 2.1325e-04 - val_LFlipper_mid: 3.1909e-04 - val_Body_bottom: 3.3143e-04 - val_RFoot: 1.4995e-04 - val_LFoot: 1.6963e-04 - lr: 5.0000e-05 - 56s/epoch - 154ms/step\n",
      "Epoch 8/200\n",
      "360/360 - 55s - loss: 1.1050e-04 - Head: 8.4131e-05 - Beak: 6.9958e-05 - Body_top: 1.2541e-04 - RFlipper_mid: 1.3142e-04 - LFlipper_mid: 1.2915e-04 - Body_bottom: 1.9942e-04 - RFoot: 6.7697e-05 - LFoot: 7.6804e-05 - val_loss: 2.2833e-04 - val_Head: 2.0383e-04 - val_Beak: 1.5984e-04 - val_Body_top: 3.0512e-04 - val_RFlipper_mid: 2.0555e-04 - val_LFlipper_mid: 3.0185e-04 - val_Body_bottom: 3.3251e-04 - val_RFoot: 1.4607e-04 - val_LFoot: 1.7184e-04 - lr: 5.0000e-05 - 55s/epoch - 154ms/step\n",
      "Epoch 9/200\n",
      "360/360 - 55s - loss: 1.0745e-04 - Head: 8.0057e-05 - Beak: 6.3243e-05 - Body_top: 1.2273e-04 - RFlipper_mid: 1.2878e-04 - LFlipper_mid: 1.2928e-04 - Body_bottom: 1.9577e-04 - RFoot: 6.4902e-05 - LFoot: 7.4806e-05 - val_loss: 2.3545e-04 - val_Head: 2.1379e-04 - val_Beak: 1.6232e-04 - val_Body_top: 3.0264e-04 - val_RFlipper_mid: 2.1827e-04 - val_LFlipper_mid: 3.2273e-04 - val_Body_bottom: 3.3509e-04 - val_RFoot: 1.5845e-04 - val_LFoot: 1.7033e-04 - lr: 5.0000e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 10/200\n",
      "360/360 - 55s - loss: 1.0518e-04 - Head: 7.4758e-05 - Beak: 6.3022e-05 - Body_top: 1.1804e-04 - RFlipper_mid: 1.2636e-04 - LFlipper_mid: 1.2700e-04 - Body_bottom: 1.9183e-04 - RFoot: 6.6572e-05 - LFoot: 7.3889e-05 - val_loss: 2.3267e-04 - val_Head: 2.3039e-04 - val_Beak: 1.6840e-04 - val_Body_top: 2.9762e-04 - val_RFlipper_mid: 2.0776e-04 - val_LFlipper_mid: 3.0415e-04 - val_Body_bottom: 3.2878e-04 - val_RFoot: 1.5210e-04 - val_LFoot: 1.7214e-04 - lr: 5.0000e-05 - 55s/epoch - 154ms/step\n",
      "Epoch 11/200\n",
      "360/360 - 55s - loss: 1.0393e-04 - Head: 7.7726e-05 - Beak: 6.0793e-05 - Body_top: 1.1855e-04 - RFlipper_mid: 1.2604e-04 - LFlipper_mid: 1.2547e-04 - Body_bottom: 1.8680e-04 - RFoot: 6.3441e-05 - LFoot: 7.2583e-05 - val_loss: 2.3774e-04 - val_Head: 2.3810e-04 - val_Beak: 1.6712e-04 - val_Body_top: 3.0563e-04 - val_RFlipper_mid: 2.2476e-04 - val_LFlipper_mid: 3.0305e-04 - val_Body_bottom: 3.3011e-04 - val_RFoot: 1.5679e-04 - val_LFoot: 1.7633e-04 - lr: 5.0000e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 12/200\n",
      "360/360 - 55s - loss: 9.9250e-05 - Head: 7.4247e-05 - Beak: 5.6004e-05 - Body_top: 1.1352e-04 - RFlipper_mid: 1.2042e-04 - LFlipper_mid: 1.2378e-04 - Body_bottom: 1.7889e-04 - RFoot: 6.1810e-05 - LFoot: 6.5340e-05 - val_loss: 2.3436e-04 - val_Head: 2.2637e-04 - val_Beak: 1.7324e-04 - val_Body_top: 2.9564e-04 - val_RFlipper_mid: 2.1091e-04 - val_LFlipper_mid: 3.0789e-04 - val_Body_bottom: 3.2457e-04 - val_RFoot: 1.5945e-04 - val_LFoot: 1.7683e-04 - lr: 5.0000e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "360/360 - 53s - loss: 9.8373e-05 - Head: 7.6075e-05 - Beak: 5.4663e-05 - Body_top: 1.1347e-04 - RFlipper_mid: 1.1685e-04 - LFlipper_mid: 1.2347e-04 - Body_bottom: 1.7432e-04 - RFoot: 6.1188e-05 - LFoot: 6.6953e-05 - val_loss: 2.3060e-04 - val_Head: 2.2033e-04 - val_Beak: 1.6356e-04 - val_Body_top: 2.9025e-04 - val_RFlipper_mid: 2.1187e-04 - val_LFlipper_mid: 3.0370e-04 - val_Body_bottom: 3.2685e-04 - val_RFoot: 1.5635e-04 - val_LFoot: 1.7186e-04 - lr: 5.0000e-05 - 53s/epoch - 147ms/step\n",
      "Epoch 14/200\n",
      "360/360 - 52s - loss: 9.0418e-05 - Head: 6.7133e-05 - Beak: 5.1387e-05 - Body_top: 1.0297e-04 - RFlipper_mid: 1.0787e-04 - LFlipper_mid: 1.1893e-04 - Body_bottom: 1.6171e-04 - RFoot: 5.5020e-05 - LFoot: 5.8326e-05 - val_loss: 2.2690e-04 - val_Head: 2.0796e-04 - val_Beak: 1.3963e-04 - val_Body_top: 2.9273e-04 - val_RFlipper_mid: 2.1706e-04 - val_LFlipper_mid: 3.0896e-04 - val_Body_bottom: 3.2477e-04 - val_RFoot: 1.5415e-04 - val_LFoot: 1.6992e-04 - lr: 2.5000e-05 - 52s/epoch - 145ms/step\n",
      "Epoch 15/200\n",
      "360/360 - 55s - loss: 8.7121e-05 - Head: 6.2260e-05 - Beak: 4.7045e-05 - Body_top: 9.6191e-05 - RFlipper_mid: 1.0599e-04 - LFlipper_mid: 1.1800e-04 - Body_bottom: 1.5680e-04 - RFoot: 5.4029e-05 - LFoot: 5.6656e-05 - val_loss: 2.2822e-04 - val_Head: 2.1053e-04 - val_Beak: 1.5003e-04 - val_Body_top: 2.9199e-04 - val_RFlipper_mid: 2.1616e-04 - val_LFlipper_mid: 3.0629e-04 - val_Body_bottom: 3.2305e-04 - val_RFoot: 1.5669e-04 - val_LFoot: 1.7098e-04 - lr: 2.5000e-05 - 55s/epoch - 154ms/step\n",
      "Epoch 16/200\n",
      "360/360 - 56s - loss: 8.5058e-05 - Head: 6.1543e-05 - Beak: 4.5918e-05 - Body_top: 9.1671e-05 - RFlipper_mid: 1.0605e-04 - LFlipper_mid: 1.1739e-04 - Body_bottom: 1.5507e-04 - RFoot: 4.9915e-05 - LFoot: 5.2906e-05 - val_loss: 2.2888e-04 - val_Head: 2.0773e-04 - val_Beak: 1.5986e-04 - val_Body_top: 2.8529e-04 - val_RFlipper_mid: 2.2493e-04 - val_LFlipper_mid: 3.0636e-04 - val_Body_bottom: 3.2138e-04 - val_RFoot: 1.5308e-04 - val_LFoot: 1.7239e-04 - lr: 2.5000e-05 - 56s/epoch - 155ms/step\n",
      "Epoch 17/200\n",
      "360/360 - 55s - loss: 8.3321e-05 - Head: 5.9714e-05 - Beak: 4.4417e-05 - Body_top: 8.9373e-05 - RFlipper_mid: 1.0252e-04 - LFlipper_mid: 1.1520e-04 - Body_bottom: 1.5165e-04 - RFoot: 5.0984e-05 - LFoot: 5.2708e-05 - val_loss: 2.3083e-04 - val_Head: 2.0909e-04 - val_Beak: 1.6426e-04 - val_Body_top: 2.9416e-04 - val_RFlipper_mid: 2.1584e-04 - val_LFlipper_mid: 3.0509e-04 - val_Body_bottom: 3.2598e-04 - val_RFoot: 1.6396e-04 - val_LFoot: 1.6831e-04 - lr: 2.5000e-05 - 55s/epoch - 154ms/step\n",
      "Epoch 18/200\n",
      "360/360 - 55s - loss: 8.2091e-05 - Head: 5.8626e-05 - Beak: 4.5110e-05 - Body_top: 8.4288e-05 - RFlipper_mid: 1.0223e-04 - LFlipper_mid: 1.1611e-04 - Body_bottom: 1.4520e-04 - RFoot: 5.0692e-05 - LFoot: 5.4478e-05 - val_loss: 2.3373e-04 - val_Head: 2.2495e-04 - val_Beak: 1.6634e-04 - val_Body_top: 3.0246e-04 - val_RFlipper_mid: 2.2156e-04 - val_LFlipper_mid: 3.0398e-04 - val_Body_bottom: 3.2020e-04 - val_RFoot: 1.5850e-04 - val_LFoot: 1.7187e-04 - lr: 2.5000e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 19/200\n",
      "360/360 - 56s - loss: 8.1590e-05 - Head: 6.1418e-05 - Beak: 4.4063e-05 - Body_top: 8.6037e-05 - RFlipper_mid: 1.0175e-04 - LFlipper_mid: 1.1473e-04 - Body_bottom: 1.4055e-04 - RFoot: 4.8913e-05 - LFoot: 5.5257e-05 - val_loss: 2.2661e-04 - val_Head: 2.0625e-04 - val_Beak: 1.5219e-04 - val_Body_top: 2.7476e-04 - val_RFlipper_mid: 2.1955e-04 - val_LFlipper_mid: 3.0968e-04 - val_Body_bottom: 3.1684e-04 - val_RFoot: 1.6372e-04 - val_LFoot: 1.6988e-04 - lr: 2.5000e-05 - 56s/epoch - 154ms/step\n",
      "Epoch 20/200\n",
      "360/360 - 56s - loss: 8.0402e-05 - Head: 6.0529e-05 - Beak: 4.5128e-05 - Body_top: 8.3127e-05 - RFlipper_mid: 1.0315e-04 - LFlipper_mid: 1.1253e-04 - Body_bottom: 1.3439e-04 - RFoot: 5.1233e-05 - LFoot: 5.3125e-05 - val_loss: 2.2739e-04 - val_Head: 2.1853e-04 - val_Beak: 1.5568e-04 - val_Body_top: 2.8961e-04 - val_RFlipper_mid: 2.2804e-04 - val_LFlipper_mid: 3.0476e-04 - val_Body_bottom: 2.9390e-04 - val_RFoot: 1.5569e-04 - val_LFoot: 1.7292e-04 - lr: 2.5000e-05 - 56s/epoch - 155ms/step\n",
      "Epoch 21/200\n",
      "360/360 - 55s - loss: 7.8091e-05 - Head: 5.8748e-05 - Beak: 4.5194e-05 - Body_top: 8.0430e-05 - RFlipper_mid: 9.9809e-05 - LFlipper_mid: 1.1297e-04 - Body_bottom: 1.2474e-04 - RFoot: 4.9322e-05 - LFoot: 5.3514e-05 - val_loss: 2.2581e-04 - val_Head: 2.0734e-04 - val_Beak: 1.4062e-04 - val_Body_top: 2.9437e-04 - val_RFlipper_mid: 2.1994e-04 - val_LFlipper_mid: 3.0133e-04 - val_Body_bottom: 3.0312e-04 - val_RFoot: 1.6671e-04 - val_LFoot: 1.7303e-04 - lr: 2.5000e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 22/200\n",
      "360/360 - 56s - loss: 7.6054e-05 - Head: 5.7465e-05 - Beak: 4.1830e-05 - Body_top: 8.0410e-05 - RFlipper_mid: 9.9838e-05 - LFlipper_mid: 1.1102e-04 - Body_bottom: 1.1946e-04 - RFoot: 4.7401e-05 - LFoot: 5.1006e-05 - val_loss: 2.2920e-04 - val_Head: 2.2465e-04 - val_Beak: 1.6238e-04 - val_Body_top: 2.9002e-04 - val_RFlipper_mid: 2.2076e-04 - val_LFlipper_mid: 3.0475e-04 - val_Body_bottom: 2.9818e-04 - val_RFoot: 1.5952e-04 - val_LFoot: 1.7334e-04 - lr: 2.5000e-05 - 56s/epoch - 157ms/step\n",
      "Epoch 23/200\n",
      "360/360 - 55s - loss: 7.5810e-05 - Head: 5.7234e-05 - Beak: 4.1017e-05 - Body_top: 7.8699e-05 - RFlipper_mid: 9.7977e-05 - LFlipper_mid: 1.0955e-04 - Body_bottom: 1.1944e-04 - RFoot: 4.8227e-05 - LFoot: 5.4338e-05 - val_loss: 2.2969e-04 - val_Head: 2.1584e-04 - val_Beak: 1.5868e-04 - val_Body_top: 2.8042e-04 - val_RFlipper_mid: 2.2477e-04 - val_LFlipper_mid: 3.0444e-04 - val_Body_bottom: 3.1324e-04 - val_RFoot: 1.6666e-04 - val_LFoot: 1.7348e-04 - lr: 2.5000e-05 - 55s/epoch - 152ms/step\n",
      "Epoch 24/200\n",
      "360/360 - 55s - loss: 7.3640e-05 - Head: 5.3613e-05 - Beak: 3.9941e-05 - Body_top: 7.3491e-05 - RFlipper_mid: 9.7044e-05 - LFlipper_mid: 1.0957e-04 - Body_bottom: 1.1897e-04 - RFoot: 4.6109e-05 - LFoot: 5.0387e-05 - val_loss: 2.2813e-04 - val_Head: 2.0927e-04 - val_Beak: 1.6260e-04 - val_Body_top: 2.9272e-04 - val_RFlipper_mid: 2.2581e-04 - val_LFlipper_mid: 3.0591e-04 - val_Body_bottom: 2.9702e-04 - val_RFoot: 1.6396e-04 - val_LFoot: 1.6778e-04 - lr: 2.5000e-05 - 55s/epoch - 152ms/step\n",
      "Epoch 25/200\n",
      "360/360 - 55s - loss: 7.1918e-05 - Head: 5.1935e-05 - Beak: 3.9036e-05 - Body_top: 7.3170e-05 - RFlipper_mid: 9.6690e-05 - LFlipper_mid: 1.0726e-04 - Body_bottom: 1.1334e-04 - RFoot: 4.5135e-05 - LFoot: 4.8784e-05 - val_loss: 2.2846e-04 - val_Head: 2.1188e-04 - val_Beak: 1.6213e-04 - val_Body_top: 2.9563e-04 - val_RFlipper_mid: 2.1862e-04 - val_LFlipper_mid: 3.0139e-04 - val_Body_bottom: 3.0424e-04 - val_RFoot: 1.6339e-04 - val_LFoot: 1.7042e-04 - lr: 2.5000e-05 - 55s/epoch - 152ms/step\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "360/360 - 55s - loss: 7.2025e-05 - Head: 5.4649e-05 - Beak: 3.8528e-05 - Body_top: 7.5427e-05 - RFlipper_mid: 9.7100e-05 - LFlipper_mid: 1.0629e-04 - Body_bottom: 1.1152e-04 - RFoot: 4.3802e-05 - LFoot: 4.8885e-05 - val_loss: 2.2765e-04 - val_Head: 2.2059e-04 - val_Beak: 1.6303e-04 - val_Body_top: 2.8478e-04 - val_RFlipper_mid: 2.1731e-04 - val_LFlipper_mid: 3.1057e-04 - val_Body_bottom: 2.9132e-04 - val_RFoot: 1.6321e-04 - val_LFoot: 1.7037e-04 - lr: 2.5000e-05 - 55s/epoch - 152ms/step\n",
      "Epoch 27/200\n",
      "360/360 - 57s - loss: 6.6705e-05 - Head: 4.6611e-05 - Beak: 3.5673e-05 - Body_top: 6.5328e-05 - RFlipper_mid: 9.1287e-05 - LFlipper_mid: 1.0236e-04 - Body_bottom: 1.0286e-04 - RFoot: 4.3475e-05 - LFoot: 4.6049e-05 - val_loss: 2.2573e-04 - val_Head: 2.1363e-04 - val_Beak: 1.6016e-04 - val_Body_top: 2.7871e-04 - val_RFlipper_mid: 2.2212e-04 - val_LFlipper_mid: 3.0788e-04 - val_Body_bottom: 2.9131e-04 - val_RFoot: 1.6037e-04 - val_LFoot: 1.7162e-04 - lr: 1.2500e-05 - 57s/epoch - 157ms/step\n",
      "Epoch 28/200\n",
      "360/360 - 57s - loss: 6.6763e-05 - Head: 4.9255e-05 - Beak: 3.8559e-05 - Body_top: 6.7961e-05 - RFlipper_mid: 9.1534e-05 - LFlipper_mid: 1.0057e-04 - Body_bottom: 1.0143e-04 - RFoot: 4.0641e-05 - LFoot: 4.4152e-05 - val_loss: 2.2631e-04 - val_Head: 2.1849e-04 - val_Beak: 1.5991e-04 - val_Body_top: 2.7946e-04 - val_RFlipper_mid: 2.2113e-04 - val_LFlipper_mid: 3.0592e-04 - val_Body_bottom: 2.9643e-04 - val_RFoot: 1.6238e-04 - val_LFoot: 1.6674e-04 - lr: 1.2500e-05 - 57s/epoch - 157ms/step\n",
      "Epoch 29/200\n",
      "360/360 - 57s - loss: 6.5928e-05 - Head: 4.7022e-05 - Beak: 3.5438e-05 - Body_top: 6.5815e-05 - RFlipper_mid: 9.1798e-05 - LFlipper_mid: 1.0016e-04 - Body_bottom: 1.0024e-04 - RFoot: 4.0908e-05 - LFoot: 4.6037e-05 - val_loss: 2.2501e-04 - val_Head: 2.1457e-04 - val_Beak: 1.5257e-04 - val_Body_top: 2.8203e-04 - val_RFlipper_mid: 2.1869e-04 - val_LFlipper_mid: 3.0464e-04 - val_Body_bottom: 2.8977e-04 - val_RFoot: 1.6824e-04 - val_LFoot: 1.6955e-04 - lr: 1.2500e-05 - 57s/epoch - 159ms/step\n",
      "Epoch 30/200\n",
      "360/360 - 59s - loss: 6.5523e-05 - Head: 4.7265e-05 - Beak: 3.4705e-05 - Body_top: 6.3639e-05 - RFlipper_mid: 9.1670e-05 - LFlipper_mid: 1.0033e-04 - Body_bottom: 9.9190e-05 - RFoot: 4.1840e-05 - LFoot: 4.5549e-05 - val_loss: 2.2564e-04 - val_Head: 2.0643e-04 - val_Beak: 1.5816e-04 - val_Body_top: 2.8857e-04 - val_RFlipper_mid: 2.2187e-04 - val_LFlipper_mid: 3.0411e-04 - val_Body_bottom: 2.8824e-04 - val_RFoot: 1.6539e-04 - val_LFoot: 1.7232e-04 - lr: 1.2500e-05 - 59s/epoch - 164ms/step\n",
      "Epoch 31/200\n",
      "360/360 - 55s - loss: 6.4886e-05 - Head: 4.5057e-05 - Beak: 3.4481e-05 - Body_top: 6.4372e-05 - RFlipper_mid: 9.0557e-05 - LFlipper_mid: 1.0131e-04 - Body_bottom: 9.8829e-05 - RFoot: 4.0292e-05 - LFoot: 4.4186e-05 - val_loss: 2.2649e-04 - val_Head: 2.2473e-04 - val_Beak: 1.4973e-04 - val_Body_top: 2.8678e-04 - val_RFlipper_mid: 2.2020e-04 - val_LFlipper_mid: 3.0702e-04 - val_Body_bottom: 2.9087e-04 - val_RFoot: 1.6379e-04 - val_LFoot: 1.6875e-04 - lr: 1.2500e-05 - 55s/epoch - 153ms/step\n",
      "Epoch 32/200\n",
      "360/360 - 56s - loss: 6.5324e-05 - Head: 4.8879e-05 - Beak: 3.4281e-05 - Body_top: 6.3735e-05 - RFlipper_mid: 9.0413e-05 - LFlipper_mid: 9.8151e-05 - Body_bottom: 9.6939e-05 - RFoot: 4.2009e-05 - LFoot: 4.8189e-05 - val_loss: 2.2819e-04 - val_Head: 2.1565e-04 - val_Beak: 1.5920e-04 - val_Body_top: 2.8340e-04 - val_RFlipper_mid: 2.2435e-04 - val_LFlipper_mid: 3.0557e-04 - val_Body_bottom: 3.0290e-04 - val_RFoot: 1.6398e-04 - val_LFoot: 1.7050e-04 - lr: 1.2500e-05 - 56s/epoch - 154ms/step\n",
      "Epoch 33/200\n",
      "360/360 - 56s - loss: 6.3784e-05 - Head: 4.3547e-05 - Beak: 3.4760e-05 - Body_top: 6.3844e-05 - RFlipper_mid: 9.0015e-05 - LFlipper_mid: 9.8302e-05 - Body_bottom: 9.5915e-05 - RFoot: 4.0324e-05 - LFoot: 4.3568e-05 - val_loss: 2.2627e-04 - val_Head: 2.1680e-04 - val_Beak: 1.6016e-04 - val_Body_top: 2.7324e-04 - val_RFlipper_mid: 2.2670e-04 - val_LFlipper_mid: 3.0437e-04 - val_Body_bottom: 2.9015e-04 - val_RFoot: 1.6567e-04 - val_LFoot: 1.7305e-04 - lr: 1.2500e-05 - 56s/epoch - 155ms/step\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "360/360 - 56s - loss: 6.3957e-05 - Head: 4.6063e-05 - Beak: 3.3626e-05 - Body_top: 6.2586e-05 - RFlipper_mid: 8.9429e-05 - LFlipper_mid: 9.5880e-05 - Body_bottom: 9.7736e-05 - RFoot: 4.1736e-05 - LFoot: 4.4598e-05 - val_loss: 2.2608e-04 - val_Head: 2.2243e-04 - val_Beak: 1.5635e-04 - val_Body_top: 2.7250e-04 - val_RFlipper_mid: 2.2253e-04 - val_LFlipper_mid: 3.0380e-04 - val_Body_bottom: 2.9839e-04 - val_RFoot: 1.6333e-04 - val_LFoot: 1.6931e-04 - lr: 1.2500e-05 - 56s/epoch - 156ms/step\n",
      "Epoch 35/200\n",
      "360/360 - 54s - loss: 6.1441e-05 - Head: 4.3981e-05 - Beak: 3.2158e-05 - Body_top: 5.9182e-05 - RFlipper_mid: 8.6046e-05 - LFlipper_mid: 9.4724e-05 - Body_bottom: 9.1682e-05 - RFoot: 3.9015e-05 - LFoot: 4.4739e-05 - val_loss: 2.2820e-04 - val_Head: 2.2058e-04 - val_Beak: 1.5837e-04 - val_Body_top: 2.8345e-04 - val_RFlipper_mid: 2.2337e-04 - val_LFlipper_mid: 3.0573e-04 - val_Body_bottom: 2.9751e-04 - val_RFoot: 1.6642e-04 - val_LFoot: 1.7018e-04 - lr: 6.2500e-06 - 54s/epoch - 149ms/step\n",
      "Epoch 36/200\n",
      "360/360 - 56s - loss: 6.0883e-05 - Head: 4.2150e-05 - Beak: 3.4732e-05 - Body_top: 5.7205e-05 - RFlipper_mid: 8.5828e-05 - LFlipper_mid: 9.5183e-05 - Body_bottom: 8.9809e-05 - RFoot: 4.0152e-05 - LFoot: 4.2004e-05 - val_loss: 2.2924e-04 - val_Head: 2.2727e-04 - val_Beak: 1.5702e-04 - val_Body_top: 2.8619e-04 - val_RFlipper_mid: 2.2379e-04 - val_LFlipper_mid: 3.0508e-04 - val_Body_bottom: 2.9980e-04 - val_RFoot: 1.6673e-04 - val_LFoot: 1.6807e-04 - lr: 6.2500e-06 - 56s/epoch - 154ms/step\n",
      "Epoch 37/200\n",
      "360/360 - 56s - loss: 6.0557e-05 - Head: 4.2711e-05 - Beak: 3.6321e-05 - Body_top: 5.7278e-05 - RFlipper_mid: 8.6888e-05 - LFlipper_mid: 9.4516e-05 - Body_bottom: 8.9222e-05 - RFoot: 3.6736e-05 - LFoot: 4.0782e-05 - val_loss: 2.2796e-04 - val_Head: 2.2205e-04 - val_Beak: 1.5632e-04 - val_Body_top: 2.7538e-04 - val_RFlipper_mid: 2.2197e-04 - val_LFlipper_mid: 3.0550e-04 - val_Body_bottom: 3.0650e-04 - val_RFoot: 1.6822e-04 - val_LFoot: 1.6776e-04 - lr: 6.2500e-06 - 56s/epoch - 156ms/step\n",
      "Epoch 38/200\n",
      "360/360 - 55s - loss: 6.0578e-05 - Head: 4.3327e-05 - Beak: 3.3474e-05 - Body_top: 5.9273e-05 - RFlipper_mid: 8.6116e-05 - LFlipper_mid: 9.5040e-05 - Body_bottom: 8.7530e-05 - RFoot: 3.8681e-05 - LFoot: 4.1187e-05 - val_loss: 2.2755e-04 - val_Head: 2.1775e-04 - val_Beak: 1.5341e-04 - val_Body_top: 2.7736e-04 - val_RFlipper_mid: 2.2040e-04 - val_LFlipper_mid: 3.0515e-04 - val_Body_bottom: 3.1099e-04 - val_RFoot: 1.6746e-04 - val_LFoot: 1.6789e-04 - lr: 6.2500e-06 - 55s/epoch - 152ms/step\n",
      "Epoch 39/200\n",
      "360/360 - 55s - loss: 5.9056e-05 - Head: 3.8343e-05 - Beak: 3.1571e-05 - Body_top: 5.6546e-05 - RFlipper_mid: 8.4393e-05 - LFlipper_mid: 9.4318e-05 - Body_bottom: 8.9595e-05 - RFoot: 3.6951e-05 - LFoot: 4.0729e-05 - val_loss: 2.2500e-04 - val_Head: 2.1185e-04 - val_Beak: 1.4557e-04 - val_Body_top: 2.7051e-04 - val_RFlipper_mid: 2.2565e-04 - val_LFlipper_mid: 3.0399e-04 - val_Body_bottom: 3.1165e-04 - val_RFoot: 1.6409e-04 - val_LFoot: 1.6672e-04 - lr: 6.2500e-06 - 55s/epoch - 154ms/step\n",
      "Epoch 00039: early stopping\n",
      "INFO:sleap.nn.training:Finished training loop. [36.2 min]\n",
      "INFO:sleap.nn.training:Deleting visualization directory: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/viz\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d47f1f9baf1447080ee6a086b61772e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 19:58:03.844026: W tensorflow/core/kernels/gpu_utils.cc:49] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.758543\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8429db759e4d43c1b762e0f4fc77f9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.011705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081f9096fe5144b2918042616cdce60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sleap.nn.evals:Saved predictions: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/labels_pr.test.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/metrics.test.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.234757\n"
     ]
    }
   ],
   "source": [
    "trainer.config.optimization.epochs = 200\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Model evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trained SLEAP model will be a folder containing files that specify metadata that is useful for evaluation and analysis. The exact set of files may depend on the configuration, but all models will come with:\n",
    "\n",
    "    metrics.train.npz: Metrics for the training split.\n",
    "\n",
    "    metrics.val.npz: Metrics for the validation split. This is what youll want to use most of the time since it wasnt directly used for optimizing the model.\n",
    "\n",
    "    Note: A test split will also be evaluated if it was provided during training and saved to metrics.test.npz.\n",
    "\n",
    "Additionally, the following files are included and may also be useful:\n",
    "\n",
    "    best_model.h5: The actual saved model and weights. This can be loaded with tf.keras.model.load_model() but it is recommended to use sleap.load_model() instead as it takes care of adding some additional inference-only procedures.\n",
    "\n",
    "    training_config.json: The configuration for the model training job, including metadata inferred during the training procedure. It can be loaded with sleap.load_config().\n",
    "\n",
    "    labels_gt.train.slp and labels_pr.train.slp: These are SLEAP labels files containing the ground truth and predicted points for the training split. They do not contain the images, but can be used to retrieve the poses used.\n",
    "\n",
    "    labels_gt.val.slp and labels_pr.val.slp: These are SLEAP labels files containing the ground truth and predicted points for the validation split. They do not contain the images, but can be used to retrieve the poses used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLEAP metrics can be loaded using the sleap.load_metrics() API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_metrics in module sleap.nn.evals:\n",
      "\n",
      "load_metrics(model_path: str, split: str = 'val') -> typing.Dict[str, typing.Any]\n",
      "    Load metrics for a model.\n",
      "    \n",
      "    Args:\n",
      "        model_path: Path to a model folder or metrics file (.npz).\n",
      "        split: Name of the split to load the metrics for. Must be `\"train\"`, `\"val\"` or\n",
      "            `\"test\"` (default: `\"val\"`). Ignored if a path to a metrics NPZ file is\n",
      "            provided.\n",
      "    \n",
      "    Returns:\n",
      "        The loaded metrics as a dictionary with keys:\n",
      "    \n",
      "        - `\"vis.tp\"`: Visibility - True Positives\n",
      "        - `\"vis.fp\"`: Visibility - False Positives\n",
      "        - `\"vis.tn\"`: Visibility - True Negatives\n",
      "        - `\"vis.fn\"`: Visibility - False Negatives\n",
      "        - `\"vis.precision\"`: Visibility - Precision\n",
      "        - `\"vis.recall\"`: Visibility - Recall\n",
      "        - `\"dist.avg\"`: Average Distance (ground truth vs prediction)\n",
      "        - `\"dist.p50\"`: Distance for 50th percentile\n",
      "        - `\"dist.p75\"`: Distance for 75th percentile\n",
      "        - `\"dist.p90\"`: Distance for 90th percentile\n",
      "        - `\"dist.p95\"`: Distance for 95th percentile\n",
      "        - `\"dist.p99\"`: Distance for 99th percentile\n",
      "        - `\"dist.dists\"`: All distances\n",
      "        - `\"dist.frame_idxs\"`: Frame indices corresponding to `\"dist.dists\"`\n",
      "        - `\"dist.video_paths\"`: Video paths corresponding to `\"dist.dists\"`\n",
      "        - `\"pck.mPCK\"`: Mean Percentage of Correct Keypoints (PCK)\n",
      "        - `\"oks.mOKS\"`: Mean Object Keypoint Similarity (OKS)\n",
      "        - `\"oks_voc.mAP\"`: VOC with OKS scores - mean Average Precision (mAP)\n",
      "        - `\"oks_voc.mAR\"`: VOC with OKS scores - mean Average Recall (mAR)\n",
      "        - `\"pck_voc.mAP\"`: VOC with PCK scores - mean Average Precision (mAP)\n",
      "        - `\"pck_voc.mAR\"`: VOC with PCK scores - mean Average Recall (mAR)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sleap.load_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.0. Inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 60\n",
      "Tracks: 6\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 60\n"
     ]
    }
   ],
   "source": [
    "# inspect the ground truth val dataset\n",
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_gt.val.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 60\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 3\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 2\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 0\n",
      "    max instances in frame: 0\n",
      "Total user labeled frames: 0\n"
     ]
    }
   ],
   "source": [
    "# inspect the predicted val dataset\n",
    "!sleap-inspect /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.val.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Comparing the datasets, max instances varies significantly. It should be a single instance per frame. Seeing 0 and > 1 in the predictions is not good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_gt_c = sleap.load_file('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_gt.val.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_val_gt_c.export_csv('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_gt.val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_gt_c_dict = labels_val_gt_c.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a JSON file with pretty formatting\n",
    "with open(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_gt.val.json\", \"w\") as json_file:\n",
    "    json.dump(labels_val_gt_c_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton: Skeleton(description=None, nodes=[Head, Beak, Body_top, RFlipper_mid, LFlipper_mid, Body_bottom, RFoot, LFoot], edges=[], symmetries=[])\n",
      "Videos: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png']\n",
      "Frames (user/predicted): 60/0\n",
      "Instances (user/predicted): 60/0\n",
      "Tracks: [Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1')]\n",
      "Suggestions: 0\n",
      "Provenance: {}\n"
     ]
    }
   ],
   "source": [
    "labels_val_gt_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_pr_c = sleap.load_file('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.val.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton: Skeleton(description=None, nodes=[Head, Beak, Body_top, RFlipper_mid, LFlipper_mid, Body_bottom, RFoot, LFoot], edges=[], symmetries=[])\n",
      "Videos: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png']\n",
      "Frames (user/predicted): 0/35\n",
      "Instances (user/predicted): 0/49\n",
      "Tracks: []\n",
      "Suggestions: 0\n",
      "Provenance: {}\n"
     ]
    }
   ],
   "source": [
    "labels_val_pr_c.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_pr_c_dict = labels_val_pr_c.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a JSON file with pretty formatting\n",
    "with open(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_pr.val.json\", \"w\") as json_file:\n",
    "    json.dump(labels_val_pr_c_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: so only 35 frames were found to have instances in them. The frames without instances are primarily the penguins lying down. \n",
    "\n",
    "Are these penguins missing the body_top keypoint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.1. Looking at the available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENTROID\n",
      "vis.tp\n",
      "vis.fp\n",
      "vis.tn\n",
      "vis.fn\n",
      "vis.precision\n",
      "vis.recall\n",
      "dist.frame_idxs\n",
      "dist.video_paths\n",
      "dist.dists\n",
      "dist.avg\n",
      "dist.p50\n",
      "dist.p75\n",
      "dist.p90\n",
      "dist.p95\n",
      "dist.p99\n",
      "pck.thresholds\n",
      "pck.pcks\n",
      "pck.mPCK_parts\n",
      "pck.mPCK\n",
      "oks.mOKS\n",
      "oks_voc.match_score_thresholds\n",
      "oks_voc.recall_thresholds\n",
      "oks_voc.match_scores\n",
      "oks_voc.precisions\n",
      "oks_voc.recalls\n",
      "oks_voc.AP\n",
      "oks_voc.AR\n",
      "oks_voc.mAP\n",
      "oks_voc.mAR\n",
      "pck_voc.match_score_thresholds\n",
      "pck_voc.recall_thresholds\n",
      "pck_voc.match_scores\n",
      "pck_voc.precisions\n",
      "pck_voc.recalls\n",
      "pck_voc.AP\n",
      "pck_voc.AR\n",
      "pck_voc.mAP\n",
      "pck_voc.mAR\n"
     ]
    }
   ],
   "source": [
    "#Loading the metrics for the validation split of the model we can see all of the available keys:\n",
    "print('CENTROID')\n",
    "metrics_c = sleap.load_metrics(\"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch\", split=\"val\")\n",
    "print(\"\\n\".join(metrics_c.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.2. Visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation (Visibility):\n",
    "\n",
    "    True Positives (TP): Cases where the model correctly predicted that a keypoint is visible.\n",
    "    False Positives (FP): Cases where the model predicted a keypoint is visible when it is not (false alarm).\n",
    "    True Negatives (TN): Cases where the model correctly predicted that a keypoint is not visible (occluded).\n",
    "    False Negatives (FN): Cases where the model predicted a keypoint is not visible when it actually is (missed detection).\n",
    "    Precision: The proportion of correctly predicted visible keypoints (TP) out of all predicted visible keypoints (TP + FP).\n",
    "    Recall: The proportion of actual visible keypoints that were correctly predicted (TP) out of all actual visible keypoints (TP + FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visibility Metrics:\n",
      "True Positives (TP): 280\n",
      "False Positives (FP): 0\n",
      "True Negatives (TN): 0\n",
      "False Negatives (FN): 0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Display visibility-related metrics\n",
    "print('\\nVisibility Metrics:')\n",
    "print(\"True Positives (TP):\", metrics_c[\"vis.tp\"])\n",
    "print(\"False Positives (FP):\", metrics_c[\"vis.fp\"])\n",
    "print(\"True Negatives (TN):\", metrics_c[\"vis.tn\"])\n",
    "print(\"False Negatives (FN):\", metrics_c[\"vis.fn\"])\n",
    "print(\"Precision:\", metrics_c[\"vis.precision\"])\n",
    "print(\"Recall:\", metrics_c[\"vis.recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS A MISLEADING METRIC FOR THIS... <br>\n",
    "<br>\n",
    "ONLY 35 OF THE FRAMES WERE FOUND TO HAVE INSTANCES OUT OF 60 (35 TP) <br>\n",
    "THERE WERE 49 INSTANCES FOUND. MEANING 14 INSTANCES WERE INCORRECTLY FOUND (14 FP)<br>\n",
    "25 INSTANCES WERE MISSED (25 FN)<br>\n",
    "AND THERE WERE NO TRUE NEGATIVES (0 TN)<br>\n",
    "<br>\n",
    "THEREFORE:<br>\n",
    "<br>\n",
    "<br>\n",
    "Visibility Metrics:<br>\n",
    "True Positives (TP): 35<br>\n",
    "False Positives (FP): 14<br>\n",
    "True Negatives (TN): 0<br>\n",
    "False Negatives (FN): 25<br>\n",
    "Precision: 0.71<br>\n",
    "Recall: 0.58<br>\n",
    "\n",
    "so we are missing over 40% of the penguins... Not good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: this is weird. As I understand it, there should be a single centroid per instance and there should be 60 instances. And from analysis of the datasets we can see the the predictions do not match the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.3. Error distance (means very little for the centroid) - however it is interesting to see that this algorithm seems to work better than the top-down one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist.frame_idxs:\n",
    "\n",
    "    What it is: Indices of the frames in the dataset where the distances are calculated.\n",
    "    How it's calculated: The indices correspond to the frame positions in the video(s) being evaluated.\n",
    "\n",
    "dist.video_paths:\n",
    "\n",
    "    What it is: Paths to the video files associated with the frames being evaluated.\n",
    "    How it's calculated: These are the file paths where the videos used for evaluation are stored.\n",
    "\n",
    "dist.dists:\n",
    "\n",
    "    What it is: The raw distances (in pixels) between predicted and ground truth keypoints for each frame.\n",
    "    How it's calculated: Euclidean distance is computed for each keypoint across the dataset between the predicted and ground truth positions.\n",
    "\n",
    "dist.avg:\n",
    "\n",
    "    What it is: The average distance error across all frames and keypoints.\n",
    "    How it's calculated: The mean of the dist.dists values across all keypoints and frames.\n",
    "\n",
    "dist.p50:\n",
    "\n",
    "    What it is: The 50th percentile (median) of the distance errors.\n",
    "    How it's calculated: The median value of the dist.dists array, meaning 50% of the distances are below this value.\n",
    "\n",
    "dist.p75:\n",
    "\n",
    "    What it is: The 75th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 75% of the dist.dists lie.\n",
    "\n",
    "dist.p90:\n",
    "\n",
    "    What it is: The 90th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 90% of the dist.dists lie.\n",
    "\n",
    "dist.p95:\n",
    "\n",
    "    What it is: The 95th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 95% of the dist.dists lie.\n",
    "\n",
    "dist.p99:\n",
    "\n",
    "    What it is: The 99th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 99% of the dist.dists lie, representing the most extreme errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics_c[\"dist.dists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid Distance Metrics:\n",
      "Error distance (avg): 2.6409071517163838e-05\n",
      "Error distance (50%): 2.5054158188260635e-05\n",
      "Error distance (75%): 3.379028532049095e-05\n",
      "Error distance (90%): 4.965237132973848e-05\n",
      "Error distance (95%): 5.5047631915180444e-05\n",
      "Error distance (99%): 6.1694600633691e-05\n"
     ]
    }
   ],
   "source": [
    "#summary of the localization errors:\n",
    "print('Centroid Distance Metrics:')\n",
    "#print(\"Frame indices:\", metrics_c[\"dist.frame_idxs\"])\n",
    "#print(\"Video paths:\", metrics_c[\"dist.video_paths\"])\n",
    "#print(\"Error distances (all):\", metrics_c[\"dist.dists\"])\n",
    "print(\"Error distance (avg):\", metrics_c[\"dist.avg\"])\n",
    "print(\"Error distance (50%):\", metrics_c[\"dist.p50\"])\n",
    "print(\"Error distance (75%):\", metrics_c[\"dist.p75\"])\n",
    "print(\"Error distance (90%):\", metrics_c[\"dist.p90\"])\n",
    "print(\"Error distance (95%):\", metrics_c[\"dist.p95\"])\n",
    "print(\"Error distance (99%):\", metrics_c[\"dist.p99\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.02772039e-05 2.21802836e-05 4.95011439e-05 5.45935542e-05\n",
      "  3.75801152e-05 5.15746659e-05 4.32580461e-05 3.79066213e-05]\n",
      " [1.06675582e-05 2.08488101e-05 7.79290321e-06 1.41851578e-05\n",
      "  4.49711622e-05 6.39704733e-05 4.56229865e-05 6.15749436e-05]\n",
      " [1.04744050e-05 2.10533227e-05 7.63572953e-06 1.11612053e-05\n",
      "  5.50914356e-05 4.79005774e-05 3.50543418e-05 3.79381501e-05]\n",
      " [4.65225857e-05 2.25803996e-05 4.91001342e-05 2.28582863e-05\n",
      "  3.49606877e-05 2.46715774e-05 2.38324405e-05 2.37567141e-05]\n",
      " [5.89708147e-05 3.00504910e-05 1.10918605e-05 2.78119818e-05\n",
      "  3.09943457e-05 5.59836175e-05 3.86109495e-05 2.25057160e-05]\n",
      " [1.74877907e-05 3.93056775e-05 1.05165553e-05 1.81536925e-05\n",
      "  1.37124807e-05 8.34217017e-06 5.29041197e-05 2.51295563e-05]\n",
      " [5.34782495e-05 3.07676483e-05 1.77991470e-05 1.16177633e-05\n",
      "  6.96698838e-06 2.19494785e-05 6.55645842e-05 4.72454178e-05]\n",
      " [3.06151219e-05 5.18403735e-05 3.27085736e-05 2.90187436e-05\n",
      "  1.89431943e-05 2.94716420e-05 4.70008264e-05 2.56521857e-05]\n",
      " [6.51473994e-06 4.30869810e-05 4.09776286e-05 2.06008333e-05\n",
      "  2.03616404e-05 3.43440648e-05 2.72145923e-05 5.60633168e-05]\n",
      " [4.88466237e-06 2.75557018e-05 2.62759441e-06 3.28339008e-05\n",
      "  1.57581521e-05 3.42114434e-05 6.62178437e-06 3.05898028e-05]\n",
      " [2.55896088e-05 8.31136131e-06 1.73186198e-05 2.96942906e-05\n",
      "  9.87594056e-06 2.33944473e-05 2.36406463e-05 1.89899887e-05]\n",
      " [2.31145707e-05 1.07379858e-05 1.79307645e-05 2.71773433e-05\n",
      "  1.54153758e-05 3.12394746e-05 2.15402860e-06 1.21192500e-05]\n",
      " [8.14863620e-06 1.55723136e-05 1.35629428e-05 1.48148525e-05\n",
      "  5.46197759e-06 2.76007150e-05 1.67916480e-05 2.33990750e-05]\n",
      " [6.75928299e-06 1.72853598e-06 1.54928045e-05 1.41416745e-05\n",
      "  2.72802554e-05 1.23337602e-05 2.08446851e-05 1.00292569e-05]\n",
      " [2.15523801e-06 6.18455322e-06 1.23156056e-05 1.34072701e-05\n",
      "  1.68907897e-05 1.13262764e-05 2.52411663e-05 2.90396000e-05]\n",
      " [4.55807395e-06 2.16598183e-05 2.10883880e-05 2.27774269e-05\n",
      "  5.10849033e-05 4.93866894e-05 1.11538761e-05 1.21155144e-05]\n",
      " [2.86285778e-05 1.01038938e-05 2.35551899e-05 2.51695093e-05\n",
      "  2.48145886e-05 2.83691108e-05 1.20325459e-05 3.37590421e-05]\n",
      " [2.93086191e-05 2.56735295e-05 2.98686052e-05 3.32838331e-05\n",
      "  3.37226210e-05 2.79993917e-05 3.63228415e-06 3.82458330e-05]\n",
      " [3.54905858e-06 7.23062773e-06 2.78887840e-05 5.54994438e-06\n",
      "  3.39264993e-05 5.65737337e-05 2.02148258e-05 2.12637711e-05]\n",
      " [7.72578587e-06 1.57046508e-05 2.97796917e-05 1.55328574e-05\n",
      "  3.34846017e-05 2.34265120e-05 2.33173030e-05 4.37194796e-06]\n",
      " [3.13794876e-05 2.22775266e-05 8.16124127e-06 2.92656397e-05\n",
      "  2.49104894e-05 3.31342720e-05 2.79716144e-05 2.92314005e-05]\n",
      " [9.08535963e-06 2.37185279e-05 1.79336107e-05 2.27230646e-05\n",
      "  3.07558061e-05 4.42655597e-05 3.07303917e-05 4.20103359e-06]\n",
      " [2.86367403e-05 2.77249580e-05 2.02442914e-05 9.69290021e-06\n",
      "  2.76500591e-05 2.97181966e-05 3.31498178e-05 1.74006902e-05]\n",
      " [2.87827325e-05 1.39098368e-05 2.70841519e-05 1.93304672e-05\n",
      "  2.94212387e-05 5.37277148e-05 1.91765288e-05 2.59341813e-05]\n",
      " [2.78671792e-05 2.21265542e-05 1.61837516e-05 2.78847687e-05\n",
      "  2.40151711e-05 2.40954753e-05 2.02955088e-05 1.44662025e-05]\n",
      " [3.46509199e-05 5.27325990e-05 1.77173514e-05 9.67754036e-06\n",
      "  2.50469034e-05 3.12914469e-05 4.49754671e-05 5.18312480e-05]\n",
      " [1.01376614e-05 5.16815712e-05 5.79769435e-05 2.64201468e-05\n",
      "  1.74475176e-05 3.02474602e-05 1.64983083e-05 1.04401669e-05]\n",
      " [1.78930930e-05 4.64631696e-05 1.53183258e-05 2.64201468e-05\n",
      "  3.57448155e-05 3.02474602e-05 3.32147854e-05 6.16846678e-05]\n",
      " [5.10134184e-05 3.75807031e-05 4.59310025e-05 2.80709189e-05\n",
      "  8.52864294e-06 3.69060792e-05 1.83898966e-05 3.38840149e-05]\n",
      " [7.28879682e-06 4.13970897e-05 2.21917457e-05 3.23341477e-05\n",
      "  3.08534139e-05 1.00498785e-05 4.01268532e-05 2.68146162e-06]\n",
      " [3.68013044e-05 3.87348758e-05 5.88929801e-05 2.13012023e-05\n",
      "  4.31693642e-05 2.57668731e-05 2.97199417e-05 2.97692645e-05]\n",
      " [1.15933836e-05 3.96235874e-05 5.92131178e-05 2.06435350e-05\n",
      "  2.64933247e-05 5.29439702e-05 1.82560181e-05 1.08882217e-05]\n",
      " [1.55698832e-05 6.12132329e-05 2.56941861e-05 3.53120039e-05\n",
      "  2.50614130e-05 1.94307975e-05 7.77418714e-06 1.71183827e-05]\n",
      " [2.61209574e-05 1.47109159e-05 4.56644977e-05 1.21111069e-05\n",
      "  6.17319669e-05 4.47654314e-05 1.00425770e-05 5.50453265e-05]\n",
      " [3.93065384e-05 1.84432810e-05 5.25745395e-05 2.60728354e-05\n",
      "  2.13832599e-05 1.17356645e-05 1.13243870e-05 1.49544748e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics_c[\"dist.dists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_dist = metrics_c[\"dist.dists\"].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics_c[\"dist.dists\"].flatten(), \n",
    "             binrange=(0, 0.0001), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 0.0001)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"Localization error (px) Centroid\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.4. PCK (meaningless for centroid I think)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCK (Percentage of Correct Keypoints) Metrics:\n",
    "\n",
    "    pck.thresholds:\n",
    "        What it is: List of distance thresholds used for calculating PCK scores.\n",
    "        How it's calculated: These thresholds define the maximum acceptable distance (in pixels or as a fraction of object size) between predicted and ground truth keypoints for a prediction to be considered correct.\n",
    "\n",
    "    pck.pcks:\n",
    "        What it is: PCK scores for each keypoint at each threshold.\n",
    "        How it's calculated: The fraction of correctly predicted keypoints that fall within the specified thresholds, calculated per keypoint and averaged across all frames.\n",
    "\n",
    "    pck.mPCK_parts:\n",
    "        What it is: Mean PCK score per keypoint across all frames.\n",
    "        How it's calculated: The average PCK for each keypoint across all thresholds, giving a measure of how well each keypoint is predicted on average.\n",
    "\n",
    "    pck.mPCK:\n",
    "        What it is: Overall mean PCK score for all keypoints and thresholds.\n",
    "        How it's calculated: The average of pck.mPCK_parts across all keypoints, providing a summary metric of the models overall performance.\n",
    "\n",
    "PCK-VOC Metrics:\n",
    "\n",
    "    pck_voc.match_score_thresholds:\n",
    "        What it is: Thresholds for match scores between predicted and ground truth keypoints.\n",
    "        How it's calculated: These thresholds define the maximum acceptable distance between predicted and true keypoints for a match to be considered correct, typically based on the PCK method.\n",
    "\n",
    "    pck_voc.recall_thresholds:\n",
    "        What it is: Thresholds for recall values at different levels.\n",
    "        How it's calculated: Predefined thresholds (e.g., evenly spaced from 0 to 1) used to compute recall values at different detection levels.\n",
    "\n",
    "    pck_voc.match_scores:\n",
    "        What it is: Scores representing the match quality between predicted and ground truth keypoints.\n",
    "        How it's calculated: These scores are calculated based on how close the predicted keypoints are to the ground truth, typically using a normalized distance measure (like PCK).\n",
    "\n",
    "    pck_voc.precisions:\n",
    "        What it is: Precision values calculated at different recall thresholds.\n",
    "        How it's calculated: Precision is the fraction of correctly predicted keypoints (true positives) out of all predicted keypoints (true positives + false positives), computed at each recall level.\n",
    "\n",
    "    pck_voc.recalls:\n",
    "        What it is: Recall values calculated across different recall thresholds.\n",
    "        How it's calculated: Recall is the fraction of correctly predicted keypoints out of all ground truth keypoints (true positives + false negatives), calculated at each recall threshold.\n",
    "\n",
    "    pck_voc.AP (Average Precision):\n",
    "        What it is: The average precision score for each keypoint or class.\n",
    "        How it's calculated: The area under the Precision-Recall curve for a single keypoint or class, computed by averaging precision values across all recall thresholds.\n",
    "\n",
    "    pck_voc.AR (Average Recall):\n",
    "        What it is: The average recall score for each keypoint or class.\n",
    "        How it's calculated: The area under the Recall curve, summarizing recall performance across different thresholds for a specific keypoint or class.\n",
    "\n",
    "    pck_voc.mAP (Mean Average Precision):\n",
    "        What it is: The mean of all Average Precision (AP) values across all keypoints or classes.\n",
    "        How it's calculated: The average of AP values across all keypoints or instances, providing an overall measure of the models precision across different thresholds.\n",
    "\n",
    "    pck_voc.mAR (Mean Average Recall):\n",
    "        What it is: The mean of all Average Recall (AR) values across all keypoints or classes.\n",
    "        How it's calculated: The average of AR values across all keypoints or instances, giving an overall measure of recall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCK Metrics:\n",
      "PCK thresholds: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "PCK scores for each keypoint: [[[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]]\n",
      "Mean PCK per keypoint (mPCK_parts): [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Overall mean PCK (mPCK): 1.0\n"
     ]
    }
   ],
   "source": [
    "print('PCK Metrics:')\n",
    "print(\"PCK thresholds:\", metrics[\"pck.thresholds\"])\n",
    "print(\"PCK scores for each keypoint:\", metrics_c[\"pck.pcks\"])\n",
    "print(\"Mean PCK per keypoint (mPCK_parts):\", metrics_c[\"pck.mPCK_parts\"])\n",
    "print(\"Overall mean PCK (mPCK):\", metrics[\"pck.mPCK\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCK-VOC Metrics:\n",
      "Match score thresholds: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]\n",
      "Recall thresholds: [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
      " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
      " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
      " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
      " 0.98 0.99 1.  ]\n",
      "Match scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Precisions at different recall levels: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "Recalls at different recall levels: [0.58333333 0.58333333 0.58333333 0.58333333 0.58333333 0.58333333\n",
      " 0.58333333 0.58333333 0.58333333 0.58333333]\n",
      "Average Precision (AP): [0.58415842 0.58415842 0.58415842 0.58415842 0.58415842 0.58415842\n",
      " 0.58415842 0.58415842 0.58415842 0.58415842]\n",
      "Average Recall (AR): [0.58333333 0.58333333 0.58333333 0.58333333 0.58333333 0.58333333\n",
      " 0.58333333 0.58333333 0.58333333 0.58333333]\n",
      "Mean Average Precision (mAP): 0.5841584158415841\n",
      "Mean Average Recall (mAR): 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "print('PCK-VOC Metrics:')\n",
    "print(\"Match score thresholds:\", metrics[\"pck_voc.match_score_thresholds\"])\n",
    "print(\"Recall thresholds:\", metrics[\"pck_voc.recall_thresholds\"])\n",
    "print(\"Match scores:\", metrics_c[\"pck_voc.match_scores\"])\n",
    "print(\"Precisions at different recall levels:\", metrics_c[\"pck_voc.precisions\"])\n",
    "print(\"Recalls at different recall levels:\", metrics_c[\"pck_voc.recalls\"])\n",
    "print(\"Average Precision (AP):\", metrics_c[\"pck_voc.AP\"])\n",
    "print(\"Average Recall (AR):\", metrics_c[\"pck_voc.AR\"])\n",
    "print(\"Mean Average Precision (mAP):\", metrics_c[\"pck_voc.mAP\"])\n",
    "print(\"Mean Average Recall (mAR):\", metrics_c[\"pck_voc.mAR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((metrics_c[\"pck_voc.match_scores\"]))\n",
    "len(metrics_c[\"pck_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyMAAAG3CAYAAACnu4q5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAABcSAAAXEgFnn9JSAAA6mElEQVR4nO3de1hVZf7//9dGhS2ImHjCA6IkOjlinlI8MKXDqI0mEp6bmPDTYRrMpmlmsnRsLLXrUzo52c+ZRiOnsnHyVJimo6hBno98oiIlFUlJEXEERBHW94+uzW+IjQJ7bRY7no/r4rrivte+7/eae7T1au21bpthGIYAAAAAoI55WV0AAAAAgIaJMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJRpbXUBD0a5dOxUWFio4ONjqUgAAAADTZGVlyc/PTzk5OTX+LHdG6khhYaFKSkqsLgMAAAAwVUlJiQoLC2v1We6M1BHHHZH09HSLKwEAAADM07Nnz1p/ljsjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsITHhpFDhw7ppZdeUkxMjDp06CCbzSa73V7r8fLz8/Xkk0+qc+fO8vHxUefOnTVz5kzl5+ebVzQAAACAch676eELL7ygDz74wJSxLl68qIiICB0/flxdu3ZVdHS00tPT9Ze//EWbNm3S3r17FRgYaMpcAAAAAL7jsXdGIiIi9Mc//lFJSUnKyclxaazf/OY3On78uGJiYpSRkaHVq1frs88+04wZM3TixAk99dRTJlUNAAAAwMFmGIZhdRFmsNls8vHxUXFxcY0+l5OTow4dOqhRo0Y6c+aM2rZtW9537do1derUSXl5efrmm28q9NVUz549JUnp6em1HgMAAACob1y5zvXYOyNm2bx5s8rKyhQZGVkpbPj4+Gjs2LEqLS3V5s2bLaoQAAAA+GHy2GdGzHLs2DFJUt++fZ329+3bV2+++Wb5cZ7IMAwVFRVZXQYAAADcyNfXVzabzeoyaqTBh5GsrCxJUseOHZ32O9odx92K4zbV92VmZio0NLQWFbquqKhIzZo1s2RuAAAA1I2CggL5+flZXUaNNPivaRUUFEj6Lkk641hQx3EAAAAAzNHg74w4nt+v6pZWTZ/vr+rBnarumNS1/++fqfKxN7W6DAAAAJjgWvFVPT55qNVl1FqDDyP+/v6SpMLCQqf9jmctfihfc/KxN5Xd7vwuEAAAAFCXGvzXtIKDgyVJ2dnZTvsd7Y7jAAAAAJijwYeR3r17S5IOHz7stN/RHh4eXmc1AQAAAA1Bgw8jo0aNkpeXl1JSUnT+/PkKfdeuXVNSUpK8vLw0evRoiyoEAAAAfpgaTBhZunSpevTooVmzZlVoDwoK0pQpU3T9+nU9/vjjunHjRnnf73//e124cEFTp05Vu3bt6rpkAAAA4AfNYx9g/+ijj/TCCy9UaLt+/boGDRpU/vucOXP085//XJKUm5urjIwMnTt3rtJYr776qvbu3au1a9eqR48e6t+/v9LT0/XZZ58pNDRUf/7zn917MgAAAEAD5LFh5MKFC9q3b1+FNsMwKrRduHChWmO1atVKBw4c0Ny5c7VhwwatX79ebdu2VUJCgv70pz+pZcuWptYOAAAAQLIZNd1IA7Xi2Gekqn1I3KmwsLD81cQrNhzi1b4AAAA/EMXFRZoe3U+SdTuwu3Kd22CeGQEAAABQvxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAAS3h0GCkuLtbcuXMVFhYmu92u9u3bKz4+XtnZ2TUe6+OPP9bo0aPVqlUrNWnSRG3atNGYMWO0fft2N1QOAAAAwGPDSHFxsUaMGKF58+apoKBA48aNU6dOnZSYmKi+ffsqMzOz2mMtXrxYo0eP1pYtW/SjH/1I999/v0JCQvTRRx/ppz/9qf7617+68UwAAACAhsljw8iCBQu0e/duRURE6KuvvtLq1au1b98+LVq0SBcuXFB8fHy1xrlw4YJmzZolb29vffLJJ0pJSdE///lP7d+/X2vWrJHNZtNvf/tbFRQUuPmMAAAAgIbFI8NISUmJXnvtNUnS66+/rmbNmpX3PfXUUwoPD9cnn3yiQ4cO3XKsffv26fr16xo+fLiGDh1aoe/+++9XeHi4ioqK9Pnnn5t7EgAAAEAD55FhJDU1Vfn5+QoNDVWfPn0q9cfGxkqSkpKSbjmWj49PteZs2bJlzYoEAAAAcFMeGUaOHTsmSerbt6/Tfke747ibGTBggAICApScnKzU1NQKfevWrVNaWpoGDx6s22+/3cWqAQAAAPy3xlYXUBtZWVmSpI4dOzrtd7Q7jruZFi1aaPny5Zo2bZoiIyM1ZMgQdejQQSdPntSBAwc0atQovfXWW9WurWfPnk7bMzMzFRoaWu1xAAAAgB86jwwjjofJfX19nfb7+flVOO5WYmNj1bJlS02aNKnC3ZG2bdtq+PDhCgwMdLFiAAAAAN/nkV/TMgxDkmSz2W7aX12LFi1SVFSUIiMjlZaWpoKCAqWlpSkiIkK/+93vNGnSpGqPlZ6e7vSHuyIAAABARR4ZRvz9/SVJhYWFTvuLiookqcJbtqqya9cuPf3007rzzjv1/vvvq1evXvLz81OvXr20Zs0a9enTR2vXrtXWrVvNOwEAAAAAnhlGgoODJanKndYd7Y7jbuYf//iHJCkmJkZeXhX/52jUqJFiYmIkSTt37qxtuQAAAACc8Mgw0rt3b0nS4cOHnfY72sPDw285liO4NG/e3Gm/oz0vL6/GdQIAAAComkeGkSFDhiggIECZmZk6cuRIpf41a9ZIksaMGXPLsdq1aydJOnjwoNP+AwcOSJJCQkJqWS0AAAAAZzwyjHh7eyshIUGSlJCQUOHZkcWLFystLU1Dhw7VgAEDytuXLl2qHj16aNasWRXGio6OliS9++67lTZJ/OCDD7Rq1Sp5eXlp/PjxbjobAAAAoGHyyFf7StLs2bO1bds27d69W926ddOwYcN0+vRp7du3T4GBgUpMTKxwfG5urjIyMnTu3LkK7dHR0ZowYYLef/993Xffferfv7+6dOmikydPlt8tmT9/vrp3715n5wYAAAA0BB55Z0SS7Ha7duzYoTlz5sjX11cbNmzQqVOnFBcXpyNHjlR7x3SbzabVq1drxYoVioyM1IkTJ7R+/XqdOnVK9957rzZv3qxnn33WzWcDAAAANDw2o6abcqBWHDuzp6en1/nchYWF5a85XrHhkOx255tFAgAAwLMUFxdpenQ/Sd9t+O3Y/LsuuXKd67F3RgAAAAB4NsIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWMD2MLFiwQOfOnTN7WAAAAAA/MKaHkdmzZ6tz584aP368Nm3aJMMwzJ4CAAAAwA+A6WFk7ty56tChgz744AONHTtWwcHBev7555WVlWX2VAAAAAA8mFvCyNdff61NmzZp/PjxOn/+vObNm6euXbvq3nvv1fr161VaWmr2tAAAAAA8jFseYLfZbBo1apTWrFmj7OxsvfTSSwoNDdXHH3+s2NhYdejQQbNmzdKJEyfcMT0AAAAAD+D2t2m1bt1av//975WRkaGdO3dq4sSJOn/+vP73f/9X3bt314gRI7R+/Xp3lwEAAACgnqmzV/uePHlSW7duVUpKiiTJMAwFBQVpx44dio2N1cCBA5WdnV1X5QAAAACwmFvDSElJif71r38pKipK3bp104IFC3T16lXNnDlTn3/+ubKzs5WamqrRo0frwIEDmjFjhjvLAQAAAFCPNHbHoF988YWWL1+ut99+WxcvXpRhGBo0aJAee+wxTZw4UXa7vfzYwYMHa+PGjRo0aJB27NjhjnIAAAAA1EOmh5Fhw4Zp9+7dMgxDzZs312OPPabHHntMvXr1uunnevbsqQMHDphdDgAAAIB6yvQw8umnn6pfv3569NFHNXXqVPn6+lbrc//zP/+jyMhIs8sBAAAAUE+ZHkb279+v/v371/hzERERioiIMLscAAAAAPWU6Q+wb9q0SR9++OEtj0tKStK8efPMnh4AAACAhzA9jDz//PPasGHDLY/78MMP9ac//cns6QEAAAB4iDrbZ+T7SktL5eVl2fQAAAAALGZZGkhPT9dtt91m1fQAAAAALGbKA+zx8fEVfk9NTa3U5nDjxg1lZGTo4MGDio6ONmN6AAAAAB7IlDDy1ltvlf+zzWbTiRMndOLEiZt+Jjw8XC+//LIZ0wMAAADwQKaEEcfO6YZhaPjw4Ro1apT+8Ic/OD3W29tb7du3V+fOnc2YGgAAAICHMiWM/OQnPyn/57i4OA0bNqxCGwAAAAB8n+kPsCcmJlb5vIjZiouLNXfuXIWFhclut6t9+/aKj49XdnZ2rcY7ceKEHn74YYWEhMhut6t169YaPHgwXycDAAAA3MBj361bXFysESNGaN68eSooKNC4cePUqVMnJSYmqm/fvsrMzKzReOvXr1evXr20YsUKBQYGavz48erTp49Onjypv/3tb246CwAAAKDhcvlrWl27dpXNZtO2bdvUpUsXde3atdqftdlsNQ4NDgsWLNDu3bsVERGhrVu3qlmzZpKkxYsX67e//a3i4+O1a9euao117NgxTZ48Wf7+/vr3v/+toUOHlveVlZXp8OHDtaoRAAAAQNVcDiOnTp2SJJWUlFT43Z1KSkr02muvSZJef/318iAiSU899ZRWrlypTz75RIcOHVK/fv1uOd6MGTN0/fp1vfXWWxWCiCR5eXmpf//+5p4AAAAAANe/plVWVqaysjKFhYVV+L26P7WRmpqq/Px8hYaGqk+fPpX6Y2NjJUlJSUm3HOuLL75QSkqKwsLCNGbMmFrVAwAAAKDmTHmbVl07duyYJKlv375O+x3tjuNuZvv27ZKkqKgoFRcXa/Xq1Tp48KBsNpvCw8M1ceJENW/e3KTKAQAAADh4ZBjJysqSJHXs2NFpv6PdcdzNpKenS5KaNm2qO++8UxkZGRX6Z82apbVr1yoyMrJatfXs2dNpe2ZmpkJDQ6s1BgAAANAQeOTbtAoKCiRJvr6+Tvv9/PwqHHczly5dkiS9+uqrysvL07p165Sfn6+MjAxNnTpVubm5io6O1rlz50yqHgAAAIBkwp2RRo0a1fqzNptNN27cqPHnDMMo//zN+qujtLRUknTjxg298847+tnPfiZJCggI0Lvvvqvjx4/rwIEDev311/Xiiy/ecjzHnZbvq+qOCQAAANBQuRxGOnXqVGUocBd/f39JUmFhodP+oqIiSarwlq1bjdWhQ4fyIPLfHnroIR04cEA7d+6sZbUAAAAAnDHt1b51KTg4WJKq3Gnd0e447mZCQkIkSZ07d75p//nz52tYJQAAAICb8chnRnr37i1JVW5G6GgPDw+/5ViOVwPn5eU57b948aKk6t1lAQAAAFB9HhlGhgwZooCAAGVmZurIkSOV+tesWSNJ1do3ZMSIEfLz81NmZqbOnDlTqd/x9ayqXiMMAAAAoHZcDiNZWVnKysoqfxDc8Xt1f2rD29tbCQkJkqSEhIQKz44sXrxYaWlpGjp0qAYMGFDevnTpUvXo0UOzZs2qMJavr69mzJihkpIS/epXv6ow1scff6yVK1fKZrPpkUceqVWtAAAAAJxz+ZmRkJAQeXl56fPPP1dYWJhCQkKq/UB7bd+mJUmzZ8/Wtm3btHv3bnXr1k3Dhg3T6dOntW/fPgUGBioxMbHC8bm5ucrIyHD6it65c+cqJSVFH330kbp166aBAwfq/Pnz2rt3r8rKyjR//nzdddddtaoTAAAAgHMuh5HIyEjZbLbyPT8cv7ub3W7Xjh07tHDhQq1atUobNmzQbbfdpri4OL3wwgvq1KlTjcZKTk7WK6+8onfeeUebN2+W3W7XPffco9/85jf6+c9/7sYzAQAAABomm1GTTTlQa459Rqrah8SdCgsLyx/AX7HhkOx255tFAgAAwLMUFxdpenQ/Sd9t+O3Y/LsuuXKd65EPsAMAAADwfHUSRq5cuaIrV67UxVQAAAAAPITbwsjGjRs1evRoBQQEqEWLFmrRooWaN2+u0aNHKykpyV3TAgAAAPAQpocRwzA0ffp0jRs3Tlu2bNGVK1cUEBCg5s2bq6CgQFu2bFF0dLR++ctfisdVAAAAgIbL9DCyZMkSJSYmKigoSMuWLdPly5eVl5enS5cu6fLly1q2bJmCgoL09ttva8mSJWZPDwAAAMBDmB5G3njjDfn6+iolJUWPPvqo/P39y/v8/f316KOPKiUlRU2bNtUbb7xh9vQAAAAAPITpYeTkyZMaMWKEunTpUuUxXbp00YgRI3Ty5EmzpwcAAADgIUwPI61bt5a3t/ctj/P29larVq3Mnh4AAACAhzA9jIwfP17Jycm6dOlSlcfk5eUpOTlZ0dHRZk8PAAAAwEOYHkZefPFFde3aVcOHD1dycnKl/uTkZEVFRalr165asGCB2dMDAAAA8BCNXR1g+PDhldq8vb116NAhRUVFqWXLlurcubMkKSsrSxcvXpQkDRo0SNHR0dq+fburJQAAAADwQC6HkZ07d1bZZxiGLl68WB5A/tuePXtks9lcnR4AAACAh3I5jPBGLAAAAAC14XIYcXwFCwAAAABqwvQH2AEAAACgOly+M3Ir+fn5unLligzDcNofHBzs7hIAAAAA1ENuCSM5OTmaPXu2PvjgA+Xl5VV5nM1m040bN9xRAgAAAIB6zvQwcu7cOQ0YMEBnz55Vhw4d1Lp1a50/f14RERH6+uuv9e2338pmsykiIkJNmjQxe3oAAAAAHsItmx6ePXtW8+bN05kzZzR69GjZbDZ9+umnOnfunHbu3KkePXrIZrNp8+bNZk8PAAAAwEOYHkY+/vhjdenSRbNnz3baHxkZqa1bt+rIkSN64YUXzJ4eAAAAgIcwPYx88803uvPOO8t/b9SokSTp2rVr5W0dOnTQPffco3/9619mTw8AAADAQ5geRpo3b17hzVktWrSQ9F1I+W92u71SGwAAAICGw/QwEhwcrFOnTpX//uMf/1iStGnTpvK2oqIiffrppwoKCjJ7egAAAAAewvS3aQ0fPlyvvvqqvv32W7Vt21b33Xef/Pz89PTTT+vMmTPq2LGj3nnnHX377bf61a9+Zfb0AAAAADyE6WFk2rRpOnPmjL744gu1bdtWLVu21N/+9jc99NBDevnll2Wz2WQYhnr27Kn58+ebPT0AAAAAD2F6GOndu7fee++9Cm1TpkzRkCFDtGnTJl26dElhYWG677772GcEAAAAaMDcsgO7M8HBwXrsscfqajoAAAAA9ZzpD7A7c+XKFV25cqUupgIAAADgIdwWRjZu3KjRo0crICBALVq0UIsWLdS8eXONHj1aSUlJ7poWAAAAgIcwPYwYhqHp06dr3Lhx2rJli65cuaKAgAA1b95cBQUF2rJli6Kjo/XLX/6ywn4kAAAAABoW08PIkiVLlJiYqKCgIC1btkyXL19WXl6eLl26pMuXL2vZsmUKCgrS22+/rSVLlpg9PQAAAAAPYXoYeeONN+Tr66uUlBQ9+uij8vf3L+/z9/fXo48+qpSUFDVt2lRvvPGG2dMDAAAA8BCmh5GTJ09qxIgR6tKlS5XHdOnSRSNGjNDJkyfNnh4AAACAhzA9jLRu3Vre3t63PM7b21utWrUye3oAAAAAHsL0MDJ+/HglJyfr0qVLVR6Tl5en5ORkRUdHmz09AAAAAA9hehh58cUX1bVrVw0fPlzJycmV+pOTkxUVFaWuXbtqwYIFZk8PAAAAwEO4vAP78OHDK7V5e3vr0KFDioqKUsuWLdW5c2dJUlZWli5evChJGjRokKKjo7V9+3ZXSwAAAADggVwOIzt37qyyzzAMXbx4sTyA/Lc9e/bIZrO5Oj0AAAAAD+VyGOGNWAAAAABqw+Uw4vgKFgAAAADUhOkPsAMAAABAdbh8Z6QqFy5cUGJiolJSUnT27FnZbDYFBQUpMjJScXFxatOmjbumBgAAAOAB3BJG1q5dq+nTp+vKlSsyDKNC36ZNmzR//ny9+eabiomJccf0AAAAADyA6V/TOnjwoKZMmaKCggKNHz9e69ev15EjR3TkyBFt2LBBMTExKigo0JQpU3Tw4EGzpwcAAADgIUy/M7Jw4UKVlpbq/fffr3Tno3fv3rrvvvvKQ8lLL72kNWvWmF0CAAAAAA9g+p2R1NRUDR48+KZfwYqOjtaQIUOUkpJi9vQAAAAAPITpYeTy5csKDg6+5XHBwcG6fPmy2dMDAAAA8BCmh5F27drp6NGjtzzu6NGjateundnTAwAAAPAQpoeRkSNH6ssvv9ScOXMqvUlLkgzD0OzZs/Xll19q1KhRZk8PAAAAwEOYHkbmzJmjli1basGCBQoLC9Nzzz2nv//971q+fLmee+45devWTQsXLlRgYKBmz57t0lzFxcWaO3euwsLCZLfb1b59e8XHxys7O9ulcY8fP66mTZvKZrMRmAAAAAA3Mf1tWh07dlRycrKmTZumzz77TAsXLpTNZpOk8jslvXr10rvvvquOHTvWep7i4mKNGDFCu3fvVlBQkMaNG6dTp04pMTFRGzdu1J49exQaGlqrsR999FFdu3at1rUBAAAAuDW3bHrYq1cvpaWlaefOneU7sEtS+/btNWzYMN19990uz7FgwQLt3r1bERER2rp1q5o1ayZJWrx4sX77298qPj5eu3btqvG4K1as0I4dO/TII4/ojTfecLlOAAAAAM6ZHkZiYmIUFBSk119/XXfffbcpweP7SkpK9Nprr0mSXn/99fIgIklPPfWUVq5cqU8++USHDh1Sv379qj3u+fPn9bvf/U4//elPNWXKFMIIAAAA4EamPzOyadMmXbx40exhK0hNTVV+fr5CQ0PVp0+fSv2xsbGSpKSkpBqN+8QTT+jq1atatmyZKXUCAAAAqJrpYaRLly4qLCw0e9gKjh07Jknq27ev035Hu+O46ti0aZNWr16tZ599VrfffrvrRQIAAAC4KdO/pjVlyhS98sorysnJcds+IllZWZJU5QPwjnbHcbdSWFioxx9/XN27d9cf/vAHl2rr2bOn0/bMzMxaP1APAAAA/BCZfmdk1qxZGjZsmH7yk59o/fr1KikpMXsKFRQUSJJ8fX2d9vv5+VU47lZmz56t06dPa9myZfL29janSAAAAAA3Zfqdke7du6usrExnzpxRbGysbDab2rRpI7vdXulYm82mzMzMGs/heEWw45XBVfVXx8GDB/Xaa6/pwQcf1D333FPjWr4vPT3daXtVd0wAAACAhsr0MHLq1KkKvxuGoZycHFPn8Pf3l6Qqn00pKiqSpApv2XLmxo0bevjhhxUQEKBXXnnF1BoBAAAA3JzpYaSsrMzsISsJDg6WpCp3Wne0O46rSnZ2to4ePap27dppwoQJFfry8/MlSfv379fdd9+tZs2aaePGjS5WDgAAAMDBLZseulvv3r0lSYcPH3ba72gPDw+v1ng5OTlV3r25dOmSdu3apYCAgFpUCgAAAKAqpj3AvmnTJj3yyCMaPXq0oqOj9cc//lEnT540a/gKhgwZooCAAGVmZurIkSOV+tesWSNJGjNmzE3HCQkJkWEYTn927NghSRo5cqQMwyi/UwIAAADAHKaEkWnTpmns2LFasWKFtmzZog8//FDz589Xz5499eGHH5oxRQXe3t5KSEiQJCUkJFR4dmTx4sVKS0vT0KFDNWDAgPL2pUuXqkePHpo1a5bp9QAAAACoOZe/prVixQq99957aty4sX7xi1+oT58+unLlijZu3Kg9e/bowQcf1OnTp03/mtPs2bO1bds27d69W926ddOwYcN0+vRp7du3T4GBgUpMTKxwfG5urjIyMnTu3DlT6wAAAABQOy7fGVm5cqW8vLy0efNmrVixQgkJCZo1a5Y+/fRTxcXF6cqVK1q3bp0ZtVZgt9u1Y8cOzZkzR76+vtqwYYNOnTqluLg4HTlyhF3UAQAAgHrOZtRkUw4nbrvtNvXs2VOpqamV+o4fP67u3bvrySef1OLFi12ZxuM59hmpah8SdyosLCx/zfGKDYdktzvfLBIAAACepbi4SNOj+0n6bsNvx+bfdcmV61yX74z85z//UWhoqNM+R/t//vMfV6cBAAAA8APjchgxDEONGjVyPrjXd8PXxd4jAAAAADyLaa/2BQAAAICaMCWMrFy5Uo0aNXL6Y7PZquxv3Ngj91wEAAAAYAJT0kBtn4F38dl5AAAAAB7M5TDC8yAAAAAAaoNnRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAlvDoMFJcXKy5c+cqLCxMdrtd7du3V3x8vLKzs6s9Rn5+vlatWqWpU6fqjjvukJ+fn/z9/TVw4EAtWbJEJSUlbjwDAAAAoOHy2DBSXFysESNGaN68eSooKNC4cePUqVMnJSYmqm/fvsrMzKzWOK+88oqmTZum1atXy9fXV2PHjtVdd92lY8eO6cknn9Tw4cNVVFTk5rMBAAAAGh6PDSMLFizQ7t27FRERoa+++kqrV6/Wvn37tGjRIl24cEHx8fHVGqdZs2Z69tlnlZWVpYMHD+qf//yntm/frv/7v/9TcHCwUlNT9eKLL7r5bAAAAICGx2YYhmF1ETVVUlKiNm3aKD8/X4cPH1afPn0q9Pfu3VtpaWk6ePCg+vXrV+t53nvvPU2dOlUhISE6efKkSzX37NlTkpSenu7SOLVRWFioZs2aSZJWbDgku923zmsAAACA+YqLizQ9+rvr3YKCAvn5+dV5Da5c53rknZHU1FTl5+crNDS0UhCRpNjYWElSUlKSS/P07t1bknT27FmXxgEAAABQmUeGkWPHjkmS+vbt67Tf0e44rra+/vprSVK7du1cGgcAAABAZY2tLqA2srKyJEkdO3Z02u9odxxXW0uWLJEkjRs3rtqfcdym+r7MzEyFhoa6VA8AAADwQ+KRd0YKCgokSb6+zp99cHxXznFcbfz1r3/Vtm3b1KJFCz3zzDO1HgcAAACAcx55Z8TxzL3NZrtpf23t2rVLM2fOlM1m05tvvqn27dtX+7NVPbhT1R0TAAAAoKHyyDDi7+8v6bu3RDnj2BfE8QapmkhLS1N0dLSuX7+uv/zlLxo/fnztCwUAAABQJY/8mlZwcLAkVbnTuqPdcVx1ZWZmauTIkcrPz9fzzz+vGTNmuFYoAAAAgCp5ZBhxvHL38OHDTvsd7eHh4dUe8+zZs4qKilJOTo5mzpypuXPnul4oAAAAgCp5ZBgZMmSIAgIClJmZqSNHjlTqX7NmjSRpzJgx1Rrv0qVLGjlypE6ePKmHHnpIf/7zn02tFwAAAEBlHhlGvL29lZCQIElKSEio8OzI4sWLlZaWpqFDh2rAgAHl7UuXLlWPHj00a9asCmMVFRXp3nvv1WeffaaJEyfq73//e5UPxgMAAAAwj0c+wC5Js2fP1rZt27R7925169ZNw4YN0+nTp7Vv3z4FBgYqMTGxwvG5ubnKyMjQuXPnKrQ/99xz2rt3rxo1aqTGjRtr+vTpTud766233HUqAAAAQIPksWHEbrdrx44dWrhwoVatWqUNGzbotttuU1xcnF544QV16tSpWuNcunRJklRaWqpVq1ZVeRxhBAAAADCXzXB1Uw5Ui2Ofkar2IXGnwsLC8tccr9hwSHa7880iAQAA4FmKi4s0PbqfpO82/HZs/l2XXLnO9chnRgAAAAB4PsIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCcIIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAAACAJQgjAAAAACxBGAEAAABgCY8OI8XFxZo7d67CwsJkt9vVvn17xcfHKzs7u8Zj5efn68knn1Tnzp3l4+Ojzp07a+bMmcrPzze/cAAAAACeG0aKi4s1YsQIzZs3TwUFBRo3bpw6deqkxMRE9e3bV5mZmdUe6+LFi7rrrru0ZMkSNW7cWNHR0fL399df/vIXDRgwQBcvXnTjmQAAAAANk8eGkQULFmj37t2KiIjQV199pdWrV2vfvn1atGiRLly4oPj4+GqP9Zvf/EbHjx9XTEyMMjIytHr1an322WeaMWOGTpw4oaeeesqNZwIAAAA0TDbDMAyri6ipkpIStWnTRvn5+Tp8+LD69OlTob93795KS0vTwYMH1a9fv5uOlZOTow4dOqhRo0Y6c+aM2rZtW9537do1derUSXl5efrmm28q9NVUz549JUnp6em1HqO2CgsL1axZM0nSig2HZLf71nkNAAAAMF9xcZGmR393vVtQUCA/P786r8GV61yPvDOSmpqq/Px8hYaGVgoikhQbGytJSkpKuuVYmzdvVllZmSIjIyuFDR8fH40dO1alpaXavHmzOcUDAAAAkCQ1trqA2jh27JgkqW/fvk77He2O41wd680336zWWJ7gWvFVq0sAAACASTz92s4jw0hWVpYkqWPHjk77He2O4+pqLOn/v031fV9++aWaNGlSZb87lZWVlf/z45OH1vn8AAAAcL/+/fvLy6vuv/iUmZmpJk2a1OqzHhlGCgoKJEm+vs6ffXB8V85xXF2NdTM2m63Wi+QqLy8v+fj4SJJCQ0MtqQHWcbxZjrVvWFj3hou1b7hY+4bLsfZWBBFJatKkSa2fVfHIMOJ45t5ms920v67Hkqx5QL06rHyAHtZi7Rsm1r3hYu0bLta+4fLktffIB9j9/f0lffeWKGeKiookqfwNUnU1FgAAAIDq88gwEhwcLElV7rTuaHccV1djAQAAAKg+jwwjvXv3liQdPnzYab+jPTw8vE7HAgAAAFB9HhlGhgwZooCAAGVmZurIkSOV+tesWSNJGjNmzC3HGjVqlLy8vJSSkqLz589X6Lt27ZqSkpLk5eWl0aNHm1M8AAAAAEkeGka8vb2VkJAgSUpISKjwvMfixYuVlpamoUOHasCAAeXtS5cuVY8ePTRr1qwKYwUFBWnKlCm6fv26Hn/8cd24caO87/e//70uXLigqVOnql27dm4+KwAAAKBhsRk1fV1UPVFcXKy7775b+/btU1BQkIYNG6bTp09r3759CgwM1N69e3X77beXH//888/rT3/6k+Li4vTWW29VGCs3N1eDBg1SZmamQkND1b9/f6Wnp+uzzz5TaGio9u7dq1atWtXxGQIAAAA/bB55Z0SS7Ha7duzYoTlz5sjX11cbNmzQqVOnFBcXpyNHjlQIIrfSqlUrHThwQDNmzND169e1fv16Xb58WQkJCdq/fz9BBAAAAHADj70zAgAAAMCzeeydEQAAAACejTACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMeqri4WHPnzlVYWJjsdrvat2+v+Ph4ZWdn13is/Px8Pfnkk+rcubN8fHzUuXNnzZw5U/n5+eYXDpeYse75+flatWqVpk6dqjvuuEN+fn7y9/fXwIEDtWTJEpWUlLjxDFBbZv6Z/2/Hjx9X06ZNZbPZNGrUKJOqhZnMXvsTJ07o4YcfVkhIiOx2u1q3bq3Bgwfr5ZdfNrlyuMrMtf/44481evRotWrVSk2aNFGbNm00ZswYbd++3Q2VwxWHDh3SSy+9pJiYGHXo0EE2m012u73W49X76zwDHufq1avG4MGDDUlGUFCQMXHiROOuu+4yJBmtW7c2Tpw4Ue2xcnNzjW7duhmSjK5duxoTJ040evbsaUgybr/9diM3N9eNZ4KaMGvdn3vuOUOS4eXlZfTr18+YNGmSMXz4cMPHx8eQZAwdOtQoLCx089mgJsz8M/9999xzj2Gz2QxJxsiRI02sGmYwe+3XrVtn2O12w2azGX379jUmT55sREVFGe3atTNCQ0PddBaoDTPXftGiRYYkw2azGUOHDjUmTZpkDBgwwJBkSDKWLVvmxjNBTY0bN658bRw/Pj4+tRrLE67zCCMeaM6cOYYkIyIiwrhy5Up5u+Mvm8jIyGqP9Ytf/MKQZMTExBglJSXl7TNmzDAkGQ8++KCptaP2zFr3hQsXGs8++6yRnZ1dof2rr74ygoODDUnGrFmzTK0drjHzz/x/W758uSHJeOSRRwgj9ZSZa3/06FHD29vbCAwMNFJSUir0lZaWGgcOHDCtbrjOrLU/f/684e3tbXh7e1da9zVr1hg2m83w9fWtMAes9dJLLxl//OMfjaSkJCMnJ8elMOIJ13mEEQ9z/fp1o0WLFoYk4/Dhw5X6w8PDDUnGwYMHbznWuXPnDC8vL6NJkyZGTk5Ohb7i4mKjdevWRqNGjSr1oe6Zue43s2rVKkOSERIS4tI4MI+71v7bb781brvtNuOnP/2psWPHDsJIPWT22g8bNsyQZCQlJZldKkxm5tonJSUZkoxRo0Y57e/du7chydi3b5/LdcM9ahtGPOU6j2dGPExqaqry8/MVGhqqPn36VOqPjY2VJCUlJd1yrM2bN6usrEyRkZFq27ZthT4fHx+NHTtWpaWl2rx5sznFo9bMXPeb6d27tyTp7NmzLo0D87hr7Z944gldvXpVy5YtM6VOmM/Mtf/iiy+UkpKisLAwjRkzxvRaYS4z197Hx6dac7Zs2bJmRaLe85TrPMKIhzl27JgkqW/fvk77He2O4+pqLLhXXa3V119/LUlq166dS+PAPO5Y+02bNmn16tV69tlndfvtt7teJNzCzLV3PKQcFRWl4uJirVy5UjNmzNATTzyh5cuX6z//+Y9JVcMMZq79gAEDFBAQoOTkZKWmplboW7dundLS0jR48GD+LvgB8pTrvMaWzo4ay8rKkiR17NjRab+j3XFcXY0F96qrtVqyZIkkady4cS6NA/OYvfaFhYV6/PHH1b17d/3hD38wp0i4hZlrn56eLklq2rSp7rzzTmVkZFTonzVrltauXavIyEhXSoZJzFz7Fi1aaPny5Zo2bZoiIyM1ZMgQdejQQSdPntSBAwc0atQovfXWW6bVjvrDU67zuDPiYQoKCiRJvr6+Tvv9/PwqHFdXY8G96mKt/vrXv2rbtm1q0aKFnnnmmVqPA3OZvfazZ8/W6dOntWzZMnl7e5tTJNzCzLW/dOmSJOnVV19VXl6e1q1bp/z8fGVkZGjq1KnKzc1VdHS0zp07Z1L1cIXZf+5jY2O1efNmBQYGKjU1VatXr9b+/fvVpk0bDR8+XIGBgeYUjnrFU67zCCMexjAMSZLNZrtpf12PBfdy91rt2rVLM2fOlM1m05tvvqn27du7NB7MY+baHzx4UK+99poefPBB3XPPPabUB/cxc+1LS0slSTdu3NA777yj8ePHKyAgQGFhYXr33Xc1YMAAXbp0Sa+//rrrhcNlZv+dv2jRIkVFRSkyMlJpaWkqKChQWlqaIiIi9Lvf/U6TJk1yuWbUP55ynUcY8TD+/v6SvvuqhTNFRUWSpGbNmtXpWHAvd65VWlqaoqOjdf36dS1ZskTjx4+vfaEwnVlrf+PGDT388MMKCAjQK6+8Ym6RcAt3/H3foUMH/exnP6vU/9BDD0mSdu7cWZtSYTIz137Xrl16+umndeedd+r9999Xr1695Ofnp169emnNmjXq06eP1q5dq61bt5p3AqgXPOU6j2dGPExwcLAkVbn7qqPdcVxdjQX3ctdaZWZmauTIkcrPz9fzzz+vGTNmuFYoTGfW2mdnZ+vo0aNq166dJkyYUKHPsQvv/v37dffdd6tZs2bauHGji5XDVWb+uQ8JCZEkde7c+ab958+fr2GVcAcz1/4f//iHJCkmJkZeXhX/G3SjRo0UExOjI0eOaOfOnU6DKjyXp1znEUY8jOPVq4cPH3ba72gPDw+v07HgXu5Yq7NnzyoqKko5OTmaOXOm5s6d63qhMJ3Za5+Tk6OcnBynfZcuXdKuXbsUEBBQi0phNjPX3vF62Ly8PKf9Fy9elGT9fyHFd8xce8cFZ/PmzZ32O9qr+v8GPJfHXOdZsbkJau/atWtGQEDALTdC2r9//y3HOnv2rOHl5WV4e3sb3377bYU+x2Y4Xl5exrlz50yrH7Vj5robhmHk5eUZP/7xjw1JxkMPPWSUlZWZXTJMYvbaO8Omh/WTmWtfWFho+Pn5GU2aNDGysrIq9U+fPt2QZEyfPt2U2uEaM9f+wQcfvOlO2w888IAhyVi4cKHLdcM9VMtNDz3lOo8w4oGee+45Q5IxePBgo6CgoLx90aJFhiRj6NChFY5/7bXXjO7duxvPPPNMpbGmTZtmSDLuv/9+o6SkpLz9iSeeMCQZDzzwgPtOBDVi1roXFhYagwYNMiQZEydONG7cuFEn9aP2zPwz7wxhpP4yc+2feeYZQ5Lx85//vMJYmzdvNho3bmzYbDZ24a5HzFr7devWGZKMRo0aGR9++GGFvg0bNhheXl6Gl5eX8eWXX7rvZOCSW4URT7/OI4x4oKtXrxoDBw40JBlBQUHGxIkTy38PDAw0jh8/XuH4uXPnGpKMuLi4SmNduHDBCA0NNSQZoaGhxqRJk8r/i3loaKhx4cKFOjor3IpZ6/7kk0+W/4tp6tSpRlxcnNMf1B9m/pl3hjBSf5m59levXjWGDBlSPlZ0dLQxePBgw8vLy5BkzJ8/v47OCtVh1tqXlZUZEyZMMCQZkoz+/fsbEyZMMPr371/extrXLxs3bjQGDhxY/iPJsNlsFdo2btxYfrynX+cRRjxUUVGRMWfOHCM0NNTw9vY22rZta8TFxTm9/X6rC5O8vDxjxowZRqdOnQxvb2+jU6dORkJCgnHx4kU3nwVqyox1j4uLK/8X0M1+UL+Y+Wf++wgj9ZuZa3/t2jVj/vz5xo9+9CPDx8fHCAgIMEaMGFHhwgb1h1lrX1ZWZqxYscKIjIw0WrRoYTRu3Nho1aqVce+99xqbN2+ugzNBTSQmJt7y39GJiYnlx3v6dZ7NMOrJS4YBAAAANCjsMwIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWIIwAgAAAMAShBEAAAAAliCMAAAAALAEYQQAUG/YbLYKP15eXmrRooWGDRum5cuXyzCMKj+7b98+PfzwwwoLC5O/v7/sdrtCQkI0ceJErV+/XmVlZU7ncubGjRuKjY2VzWZTWFiYvvnmG1PPEwDwHZtxs7/ZAQCoQ45wEBcXJ0kqLS1VZmam9u7dK8MwNHnyZL333nsVPlNSUqJf//rX+vvf/y5JCgsL0x133CFvb2+dPHlShw4dUllZmYYPH67t27dXmuv7/xosKSnR5MmTtW7dOnXv3l3Jyclq3769284ZABoywggAoN6oKiD8+9//1r333qsbN24oKSlJY8aMKe974IEH9O677yosLEyJiYkaPHhwhc+ePXtW8+bN09atW/X111/fdK6SkhJNmjRJ69evV48ePbRjxw61a9fO9PMEAHyHMAIAqDeqCiOSFB8fr8TERE2fPl3Lly+XJK1du1axsbFq27atjh07prZt21Y59qeffqohQ4ZUOVdJSYkmTJigDz74QHfccYeSk5NvOh4AwHU8MwIA8Ah9+vSRJJ05c6a87eWXX5YkPf/887cMDv8dRL7v+vXrio2N1QcffKAf//jH2rFjB0EEAOpAY6sLAACgOq5cuSJJ8vHxkSTl5uZq//79stlsmjx5cq3HvX79uu6//35t3LhR4eHh2r59u1q1amVKzQCAm+POCACg3jMMQxs3bpQkhYeHS5KOHj0qwzDUtWtXtWjRotZjx8TEaOPGjbrzzjuVnJxMEAGAOkQYAQDUW6WlpTp+/Lji4+O1Z88e+fj46KGHHpIkXbx4UZLUunVrl+b46KOPZLPZ9PbbbyswMNDlmgEA1cfXtAAA9Y6z/T/8/f21cuVKhYaGSnL+kHttDBkyRJ9++qkmT56sXbt2EUgAoA4RRgAA9Y5jnxEvLy81b95cvXr1UkxMjG677bbyYxxfp7pw4YJLc3300UcaPny4Dh8+rJEjRyo5OVnNmzd3aUwAQPXwal8AQL1xs1f7fl9ubq5at24tm82mvLy8Gj838t9z5ebm6ic/+Yk+//xzDRs2TB9//LF8fX1rXD8AoGZ4ZgQA4JFatWqlu+66S4Zh6J///KfLY/373/9W165dlZKSopiYGF2/ft2kSgEAVSGMAAA81tNPPy3pu31Gzp8/f9Njd+/efdP+9u3ba/v27erQoYO2bNmiKVOmqLS01LRaAQCVEUYAAB5rwoQJmjx5sr799ltFRkZqz549lY7JyclRQkKCHnjggVuOFxISom3btql169Zat26d4uPjTXtQHgBQGc+MAADqjZo8M+JQUlKixx57TG+++aYkqUePHrrjjjvUpEkTnTp1SgcPHlRpaamioqK0devWas119OhR3XPPPcrPz9evf/1rLV261JXTAgBUgTACAKg3ahNGHPbs2aPly5frk08+0dmzZ1VaWqp27dpp4MCBmjZtmsaOHVvhlcG3mmvPnj2KiopSYWGhnnnmGS1cuLAWZwQAuBnCCAAAAABL8MwIAAAAAEsQRgAAAABYgjACAAAAwBKEEQAAAACWIIwAAAAAsARhBAAAAIAlCCMAAAAALEEYAQAAAGAJwggAAAAASxBGAAAAAFiCMAIAAADAEoQRAAAAAJYgjAAAAACwBGEEAAAAgCUIIwAAAAAsQRgBAAAAYAnCCAAAAABLEEYAAAAAWOL/AVoPCnGpWpCKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metrics_c = {\n",
    "#     \"pck_voc.match_scores\": np.random.normal(loc=5, scale=2, size=100)  # Sample data with mean 5 and std deviation 2\n",
    "# }\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics_c[\"pck_voc.match_scores\"].flatten(), \n",
    "             binrange=(0, 1), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 1)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"PCK\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(4, 4), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Plot the precision-recall curves for every second threshold and precision\n",
    "for precision, thresh in zip(metrics_c[\"pck_voc.precisions\"], metrics_c[\"pck_voc.match_score_thresholds\"]):\n",
    "    plt.plot(metrics_c[\"pck_voc.recall_thresholds\"], precision, \"-\", label=f\"PCK @ {thresh:.2f}\")\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.5. OKS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OKS (Object Keypoint Similarity) Metrics:\n",
    "\n",
    "    oks.mOKS:\n",
    "        What it is: Mean Object Keypoint Similarity across all keypoints.\n",
    "        How it's calculated: A similarity score between predicted and ground truth keypoints, normalized by object size and considering keypoint visibility. It averages the OKS scores across all keypoints.\n",
    "\n",
    "OKS-VOC Metrics (Adapted from Object Detection Evaluation):\n",
    "\n",
    "    oks_voc.match_score_thresholds:\n",
    "        What it is: Thresholds for match scores between predicted and ground truth keypoints.\n",
    "        How it's calculated: Defined thresholds (e.g., 0.5, 0.75) used to determine whether a keypoint match is considered correct.\n",
    "\n",
    "    oks_voc.recall_thresholds:\n",
    "        What it is: Thresholds for recall values.\n",
    "        How it's calculated: Specific recall thresholds (often fixed intervals) used to evaluate recall at different levels of detection.\n",
    "\n",
    "    oks_voc.match_scores:\n",
    "        What it is: Scores representing the quality of matches between predicted and ground truth keypoints.\n",
    "        How it's calculated: Based on OKS, a score is assigned to each match, determining the closeness of the match between predicted and true keypoints.\n",
    "\n",
    "    oks_voc.precisions:\n",
    "        What it is: Precision values at various recall thresholds.\n",
    "        How it's calculated: The fraction of true positive keypoints (correct matches) out of all predicted keypoints (true positives + false positives), calculated at various recall levels.\n",
    "\n",
    "    oks_voc.recalls:\n",
    "        What it is: Recall values across different recall thresholds.\n",
    "        How it's calculated: The fraction of true positive keypoints out of all ground truth keypoints (true positives + false negatives), calculated at different recall thresholds.\n",
    "\n",
    "    oks_voc.AP (Average Precision):\n",
    "        What it is: The precision averaged across different recall levels for a specific class or keypoint.\n",
    "        How it's calculated: Area under the Precision-Recall curve, summarizing the model's precision performance at different recall levels.\n",
    "\n",
    "    oks_voc.AR (Average Recall):\n",
    "        What it is: The recall averaged across different recall thresholds for a specific class or keypoint.\n",
    "        How it's calculated: Area under the Recall curve, providing an average measure of recall over varying detection thresholds.\n",
    "\n",
    "    oks_voc.mAP (Mean Average Precision):\n",
    "        What it is: The mean of Average Precision (AP) values across all keypoints or classes.\n",
    "        How it's calculated: The mean AP score calculated by averaging the AP values for all classes/keypoints.\n",
    "\n",
    "    oks_voc.mAR (Mean Average Recall):\n",
    "        What it is: The mean of Average Recall (AR) values across all keypoints or classes.\n",
    "        How it's calculated: The mean AR score calculated by averaging the AR values across all classes/keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKS Metrics:\n",
      "Mean OKS (mOKS): 0.9999999999992238\n"
     ]
    }
   ],
   "source": [
    "print('OKS Metrics:')\n",
    "print(\"Mean OKS (mOKS):\", metrics_c[\"oks.mOKS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKS-VOC Metrics:\n",
      "Match score thresholds: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]\n",
      "Recall thresholds: [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
      " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
      " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
      " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
      " 0.98 0.99 1.  ]\n",
      "Match scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Precisions at different recall levels: [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "Recalls at different recall levels: [0.58333333 0.58333333 0.58333333 0.58333333 0.58333333 0.58333333\n",
      " 0.58333333 0.58333333 0.58333333 0.58333333]\n",
      "Average Precision (AP): [0.58415842 0.58415842 0.58415842 0.58415842 0.58415842 0.58415842\n",
      " 0.58415842 0.58415842 0.58415842 0.58415842]\n",
      "Average Recall (AR): [0.58333333 0.58333333 0.58333333 0.58333333 0.58333333 0.58333333\n",
      " 0.58333333 0.58333333 0.58333333 0.58333333]\n",
      "Mean Average Precision (mAP): 0.5841584158415841\n",
      "Mean Average Recall (mAR): 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "print('OKS-VOC Metrics:')\n",
    "print(\"Match score thresholds:\", metrics_c[\"oks_voc.match_score_thresholds\"])\n",
    "print(\"Recall thresholds:\", metrics_c[\"oks_voc.recall_thresholds\"])\n",
    "print(\"Match scores:\", metrics_c[\"oks_voc.match_scores\"])\n",
    "print(\"Precisions at different recall levels:\", metrics_c[\"oks_voc.precisions\"])\n",
    "print(\"Recalls at different recall levels:\", metrics_c[\"oks_voc.recalls\"])\n",
    "print(\"Average Precision (AP):\", metrics_c[\"oks_voc.AP\"])\n",
    "print(\"Average Recall (AR):\", metrics_c[\"oks_voc.AR\"])\n",
    "print(\"Mean Average Precision (mAP):\", metrics_c[\"oks_voc.mAP\"])\n",
    "print(\"Mean Average Recall (mAR):\", metrics_c[\"oks_voc.mAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics_c[\"pck_voc.match_scores\"])\n",
    "len(metrics_c[\"pck_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics_c[\"oks_voc.match_scores\"])\n",
    "len(metrics_c[\"oks_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "oks = metrics_c[\"oks_voc.match_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.7 TiB for an array with shape (3811631691684,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3416/168572296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m              \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m              \u001b[0mkde_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"clip\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m              stat=\"probability\")\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Add labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mhistplot\u001b[0;34m(data, x, y, hue, weights, stat, bins, binwidth, binrange, discrete, cumulative, common_bins, common_norm, multiple, element, fill, shrink, kde, kde_kws, line_kws, thresh, pthresh, pmax, cbar, cbar_ax, cbar_kws, palette, hue_order, hue_norm, color, log_scale, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0mestimate_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimate_kws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0mline_kws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_kws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m         )\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mplot_univariate_histogram\u001b[0;34m(self, multiple, element, fill, common_norm, common_bins, shrink, kde, kde_kws, color, legend, line_kws, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# Do the histogram computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmultiple_histograms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcommon_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mbin_kws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_bin_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mheights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/seaborn/_stats/counting.py\u001b[0m in \u001b[0;36m_define_bin_params\u001b[0;34m(self, data, orient, scale_type)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         bin_edges = self._define_bin_edges(\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/seaborn/_stats/counting.py\u001b[0m in \u001b[0;36m_define_bin_edges\u001b[0;34m(self, vals, weight, bins, binwidth, binrange, discrete)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mbin_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mbin_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# TODO warning or cap on too many bins?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram_bin_edges\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    667\u001b[0m     \"\"\"\n\u001b[1;32m    668\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m     \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    446\u001b[0m         bin_edges = np.linspace(\n\u001b[1;32m    447\u001b[0m             \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_equal_bins\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             endpoint=True, dtype=bin_type)\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_equal_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sleap/lib/python3.7/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;31m# In-place multiplication y *= delta/div is faster, but prevents the multiplicant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 27.7 TiB for an array with shape (3811631691684,) and data type float64"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metrics_c = {\n",
    "#     \"pck_voc.match_scores\": np.random.normal(loc=5, scale=2, size=100)  # Sample data with mean 5 and std deviation 2\n",
    "# }\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics_c[\"oks_voc.match_scores\"].flatten(), \n",
    "             binrange=(0, 1), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 1)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"OKS\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(4, 4), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Plot the precision-recall curves for every second threshold and precision\n",
    "for precision, thresh in zip(metrics_c[\"oks_voc.precisions\"], metrics_c[\"oks_voc.match_score_thresholds\"]):\n",
    "    plt.plot(metrics_c[\"oks_voc.recall_thresholds\"], precision, \"-\", label=f\"OKS @ {thresh:.2f}\")\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Top-down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test3_medium_rf.topdown_200Epoch'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.0. Inspect the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 60\n",
      "Tracks: 6\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 10\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 60\n"
     ]
    }
   ],
   "source": [
    "# inspect the ground truth val dataset\n",
    "!sleap-inspect {model_path}/labels_gt.val.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled frames: 60\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png\n",
      "    labeled frames: 10\n",
      "    labeled frames from 0 to 9\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 0\n"
     ]
    }
   ],
   "source": [
    "# inspect the predicted val dataset\n",
    "!sleap-inspect {model_path}/labels_pr.val.slp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Comparing the datasets, max instances is the same. This is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_gt_td = sleap.load_file(f'{model_path}/labels_gt.val.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_val_gt_c.export_csv('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct3_test1_centroid_200Epoch/labels_gt.val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_gt_td_dict = labels_val_gt_td.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a JSON file with pretty formatting\n",
    "with open(f\"{model_path}/labels_gt.val.json\", \"w\") as json_file:\n",
    "    json.dump(labels_val_gt_td_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton: Skeleton(description=None, nodes=[Head, Beak, Body_top, RFlipper_mid, LFlipper_mid, Body_bottom, RFoot, LFoot], edges=[], symmetries=[])\n",
      "Videos: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png']\n",
      "Frames (user/predicted): 60/0\n",
      "Instances (user/predicted): 60/0\n",
      "Tracks: [Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1'), Track(spawned_on=0, name='ID1')]\n",
      "Suggestions: 0\n",
      "Provenance: {}\n"
     ]
    }
   ],
   "source": [
    "labels_val_gt_td.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_pr_td = sleap.load_file(f'{model_path}/labels_pr.val.slp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skeleton: Skeleton(description=None, nodes=[Head, Beak, Body_top, RFlipper_mid, LFlipper_mid, Body_bottom, RFoot, LFoot], edges=[], symmetries=[])\n",
      "Videos: ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest15/img027.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/stand2/img000.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/walk6/img017.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/preen30/img011.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/rest8/img007.png', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/DLC_data/val/labeled-data/flap1/img010.png']\n",
      "Frames (user/predicted): 0/55\n",
      "Instances (user/predicted): 0/55\n",
      "Tracks: []\n",
      "Suggestions: 0\n",
      "Provenance: {}\n"
     ]
    }
   ],
   "source": [
    "labels_val_pr_td.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_pr_td_dict = labels_val_pr_td.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a JSON file with pretty formatting\n",
    "with open(f\"{model_path}/labels_pr.val.json\", \"w\") as json_file:\n",
    "    json.dump(labels_val_pr_td_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: so only 55 frames were found to have instances in them. what do these frames look like?\n",
    "\n",
    "This is strange that this model picks up the instances better and the other one appears to pick up the keypoints better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.1. Looking at the available metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TOP DOWN\n",
      "vis.tp\n",
      "vis.fp\n",
      "vis.tn\n",
      "vis.fn\n",
      "vis.precision\n",
      "vis.recall\n",
      "dist.frame_idxs\n",
      "dist.video_paths\n",
      "dist.dists\n",
      "dist.avg\n",
      "dist.p50\n",
      "dist.p75\n",
      "dist.p90\n",
      "dist.p95\n",
      "dist.p99\n",
      "pck.thresholds\n",
      "pck.pcks\n",
      "pck.mPCK_parts\n",
      "pck.mPCK\n",
      "oks.mOKS\n",
      "oks_voc.match_score_thresholds\n",
      "oks_voc.recall_thresholds\n",
      "oks_voc.match_scores\n",
      "oks_voc.precisions\n",
      "oks_voc.recalls\n",
      "oks_voc.AP\n",
      "oks_voc.AR\n",
      "oks_voc.mAP\n",
      "oks_voc.mAR\n",
      "pck_voc.match_score_thresholds\n",
      "pck_voc.recall_thresholds\n",
      "pck_voc.match_scores\n",
      "pck_voc.precisions\n",
      "pck_voc.recalls\n",
      "pck_voc.AP\n",
      "pck_voc.AR\n",
      "pck_voc.mAP\n",
      "pck_voc.mAR\n"
     ]
    }
   ],
   "source": [
    "print('\\n TOP DOWN')\n",
    "metrics = sleap.load_metrics(model_path, split=\"val\")\n",
    "print(\"\\n\".join(metrics.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.2. Visibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation (Visibility):\n",
    "\n",
    "    True Positives (TP): Cases where the model correctly predicted that a keypoint is visible.\n",
    "    False Positives (FP): Cases where the model predicted a keypoint is visible when it is not (false alarm).\n",
    "    True Negatives (TN): Cases where the model correctly predicted that a keypoint is not visible (occluded).\n",
    "    False Negatives (FN): Cases where the model predicted a keypoint is not visible when it actually is (missed detection).\n",
    "    Precision: The proportion of correctly predicted visible keypoints (TP) out of all predicted visible keypoints (TP + FP).\n",
    "    Recall: The proportion of actual visible keypoints that were correctly predicted (TP) out of all actual visible keypoints (TP + FN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visibility Metrics:\n",
      "True Positives (TP): 193\n",
      "False Positives (FP): 6\n",
      "True Negatives (TN): 37\n",
      "False Negatives (FN): 180\n",
      "Precision: 0.9698492462311558\n",
      "Recall: 0.517426273458445\n"
     ]
    }
   ],
   "source": [
    "# Display visibility-related metrics\n",
    "print('\\nVisibility Metrics:')\n",
    "print(\"True Positives (TP):\", metrics[\"vis.tp\"])\n",
    "print(\"False Positives (FP):\", metrics[\"vis.fp\"])\n",
    "print(\"True Negatives (TN):\", metrics[\"vis.tn\"])\n",
    "print(\"False Negatives (FN):\", metrics[\"vis.fn\"])\n",
    "print(\"Precision:\", metrics[\"vis.precision\"])\n",
    "print(\"Recall:\", metrics[\"vis.recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We are missing almost half the keypoints. That is not a good sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.3. Error distance (means very little for the centroid) - however it is interesting to see that this algorithm seems to work better than the top-down one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dist.frame_idxs:\n",
    "\n",
    "    What it is: Indices of the frames in the dataset where the distances are calculated.\n",
    "    How it's calculated: The indices correspond to the frame positions in the video(s) being evaluated.\n",
    "\n",
    "dist.video_paths:\n",
    "\n",
    "    What it is: Paths to the video files associated with the frames being evaluated.\n",
    "    How it's calculated: These are the file paths where the videos used for evaluation are stored.\n",
    "\n",
    "dist.dists:\n",
    "\n",
    "    What it is: The raw distances (in pixels) between predicted and ground truth keypoints for each frame.\n",
    "    How it's calculated: Euclidean distance is computed for each keypoint across the dataset between the predicted and ground truth positions.\n",
    "\n",
    "dist.avg:\n",
    "\n",
    "    What it is: The average distance error across all frames and keypoints.\n",
    "    How it's calculated: The mean of the dist.dists values across all keypoints and frames.\n",
    "\n",
    "dist.p50:\n",
    "\n",
    "    What it is: The 50th percentile (median) of the distance errors.\n",
    "    How it's calculated: The median value of the dist.dists array, meaning 50% of the distances are below this value.\n",
    "\n",
    "dist.p75:\n",
    "\n",
    "    What it is: The 75th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 75% of the dist.dists lie.\n",
    "\n",
    "dist.p90:\n",
    "\n",
    "    What it is: The 90th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 90% of the dist.dists lie.\n",
    "\n",
    "dist.p95:\n",
    "\n",
    "    What it is: The 95th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 95% of the dist.dists lie.\n",
    "\n",
    "dist.p99:\n",
    "\n",
    "    What it is: The 99th percentile of the distance errors.\n",
    "    How it's calculated: The value below which 99% of the dist.dists lie, representing the most extreme errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics[\"dist.dists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid Distance Metrics:\n",
      "Error distance (avg): 46.714012124678426\n",
      "Error distance (50%): 10.731174132897111\n",
      "Error distance (75%): 19.35681355090176\n",
      "Error distance (90%): 78.87723090070979\n",
      "Error distance (95%): 239.23818025309083\n",
      "Error distance (99%): 730.6019764445392\n"
     ]
    }
   ],
   "source": [
    "#summary of the localization errors:\n",
    "print('Centroid Distance Metrics:')\n",
    "#print(\"Frame indices:\", metrics[\"dist.frame_idxs\"])\n",
    "#print(\"Video paths:\", metrics[\"dist.video_paths\"])\n",
    "#print(\"Error distances (all):\", metrics[\"dist.dists\"])\n",
    "print(\"Error distance (avg):\", metrics[\"dist.avg\"])\n",
    "print(\"Error distance (50%):\", metrics[\"dist.p50\"])\n",
    "print(\"Error distance (75%):\", metrics[\"dist.p75\"])\n",
    "print(\"Error distance (90%):\", metrics[\"dist.p90\"])\n",
    "print(\"Error distance (95%):\", metrics[\"dist.p95\"])\n",
    "print(\"Error distance (99%):\", metrics[\"dist.p99\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.51291579   5.60229747          nan          nan  60.92507416\n",
      "           nan   8.94494085  15.82000651]\n",
      " [  5.93215665   3.92994917          nan          nan  57.16833175\n",
      "           nan   7.44946336  12.75785832]\n",
      " [  0.88970497   1.90066834          nan          nan          nan\n",
      "           nan   9.90217722   9.96775327]\n",
      " [  4.74290963   1.43703327  15.63868762          nan 187.09151367\n",
      "           nan   7.55550888  13.84795877]\n",
      " [  2.84520469          nan   9.88576029          nan          nan\n",
      "           nan   5.52011798   7.69470222]\n",
      " [  5.08081551          nan  11.02829735          nan 285.77145723\n",
      "           nan   7.48020211  11.0150161 ]\n",
      " [  3.12024395          nan  14.91294069          nan          nan\n",
      "           nan   7.60795166   4.91144186]\n",
      " [         nan          nan   1.61750235          nan          nan\n",
      "           nan   2.70514858   7.52369934]\n",
      " [ 12.28007379   4.68654401   8.77304754          nan          nan\n",
      "   22.07868901   7.06535497   7.02006636]\n",
      " [  3.77468841          nan   2.16013263          nan          nan\n",
      "           nan  11.59180653  10.88919733]\n",
      " [113.18161474          nan          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [         nan          nan 219.22717658          nan          nan\n",
      "           nan          nan          nan]\n",
      " [ 28.47944407   6.39938774  14.38764438  81.81497376          nan\n",
      "           nan  17.49732579          nan]\n",
      " [ 21.26571795   3.57647847  22.83985838  82.42824563          nan\n",
      "           nan  11.36755748          nan]\n",
      " [ 15.23074615   7.95976417   8.8485547   66.07296324          nan\n",
      "           nan  13.75126117          nan]\n",
      " [ 15.35479075          nan  11.37831134          nan          nan\n",
      "           nan  25.07942048          nan]\n",
      " [  9.74785918          nan  19.89061113          nan          nan\n",
      "           nan          nan   9.47060771]\n",
      " [ 22.86378905   2.97591173 495.44276352          nan          nan\n",
      "           nan          nan  34.5147461 ]\n",
      " [ 16.31245857   5.95791279          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  9.2866525           nan  38.50975819          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  6.23346705          nan  15.88294301          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  2.55877105          nan  67.12625945          nan          nan\n",
      "           nan          nan 113.23022421]\n",
      " [  6.65905647   5.11321007          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  5.38298602   9.03218412          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  3.61928992  11.58698671          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  7.39395338   5.65748137          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  2.204928     6.78513311          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [ 12.38790714   1.43340255          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [ 12.30835824   6.8741517           nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [ 16.015937     5.59729455          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [         nan   2.19116872          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [         nan   4.49419419 113.30594944          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  4.77480854   0.86231382 250.43756995  13.94385553          nan\n",
      "           nan          nan          nan]\n",
      " [  9.49466868   2.4711281  239.25566702          nan 170.31635392\n",
      "           nan          nan          nan]\n",
      " [  3.57494994   9.49005505          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  6.82921429   9.87058063          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [  8.53087195   8.76229827          nan          nan          nan\n",
      "           nan          nan          nan]\n",
      " [ 13.52734078   6.42946365 239.22652241          nan          nan\n",
      "           nan          nan          nan]\n",
      " [         nan   4.26522405 237.51454762          nan          nan\n",
      "           nan          nan          nan]\n",
      " [         nan 730.10340732          nan   7.5117945           nan\n",
      "           nan          nan          nan]\n",
      " [         nan 736.33552142 528.61619876  20.08361778          nan\n",
      "           nan          nan          nan]\n",
      " [         nan 809.13659305 518.26223473  28.33038021          nan\n",
      "           nan          nan 641.01082998]\n",
      " [  8.91443912          nan   2.4458983   12.95057234  20.73089754\n",
      "           nan  10.73117413   2.79498861]\n",
      " [  2.69948815          nan  11.03811825  17.20701779   8.92377576\n",
      "           nan   7.86068448   8.97727491]\n",
      " [ 11.77191931          nan   7.97164505  18.22894159  13.67236187\n",
      "           nan   6.25454886  11.90628112]\n",
      " [  7.50831983          nan  11.74574069  17.55514376   3.68154882\n",
      "           nan  10.13766014   5.91953193]\n",
      " [         nan          nan   9.77607399  39.65611522  16.5073888\n",
      "           nan  11.7597436    8.64249602]\n",
      " [ 46.71303165  30.1841053   17.96144217  28.90064073   2.67506084\n",
      "           nan   3.38377312  11.93138668]\n",
      " [ 51.46309607  29.47981206   8.93392255  29.85562706  15.46936196\n",
      "           nan   9.11411008  10.39177092]\n",
      " [ 51.48384659  17.01113352  24.15601916  19.35681355  14.91601135\n",
      "           nan   6.23111503   3.61627987]\n",
      " [ 14.05594878  17.99764505   3.02306418  20.09682803  15.34918659\n",
      "           nan  15.86619372  18.42113061]\n",
      " [ 22.43499874  11.13341362   2.30667325  21.463711    10.48596708\n",
      "           nan   8.59317891   4.16368118]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics[\"dist.dists\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_dist = metrics[\"dist.dists\"].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics[\"dist.dists\"].flatten(), \n",
    "             binrange=(0, 50), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 50)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"Localization error (px) Centroid\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1.4. PCK (meaningless for centroid I think)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCK (Percentage of Correct Keypoints) Metrics:\n",
    "\n",
    "    pck.thresholds:\n",
    "        What it is: List of distance thresholds used for calculating PCK scores.\n",
    "        How it's calculated: These thresholds define the maximum acceptable distance (in pixels or as a fraction of object size) between predicted and ground truth keypoints for a prediction to be considered correct.\n",
    "\n",
    "    pck.pcks:\n",
    "        What it is: PCK scores for each keypoint at each threshold.\n",
    "        How it's calculated: The fraction of correctly predicted keypoints that fall within the specified thresholds, calculated per keypoint and averaged across all frames.\n",
    "\n",
    "    pck.mPCK_parts:\n",
    "        What it is: Mean PCK score per keypoint across all frames.\n",
    "        How it's calculated: The average PCK for each keypoint across all thresholds, giving a measure of how well each keypoint is predicted on average.\n",
    "\n",
    "    pck.mPCK:\n",
    "        What it is: Overall mean PCK score for all keypoints and thresholds.\n",
    "        How it's calculated: The average of pck.mPCK_parts across all keypoints, providing a summary metric of the models overall performance.\n",
    "\n",
    "PCK-VOC Metrics:\n",
    "\n",
    "    pck_voc.match_score_thresholds:\n",
    "        What it is: Thresholds for match scores between predicted and ground truth keypoints.\n",
    "        How it's calculated: These thresholds define the maximum acceptable distance between predicted and true keypoints for a match to be considered correct, typically based on the PCK method.\n",
    "\n",
    "    pck_voc.recall_thresholds:\n",
    "        What it is: Thresholds for recall values at different levels.\n",
    "        How it's calculated: Predefined thresholds (e.g., evenly spaced from 0 to 1) used to compute recall values at different detection levels.\n",
    "\n",
    "    pck_voc.match_scores:\n",
    "        What it is: Scores representing the match quality between predicted and ground truth keypoints.\n",
    "        How it's calculated: These scores are calculated based on how close the predicted keypoints are to the ground truth, typically using a normalized distance measure (like PCK).\n",
    "\n",
    "    pck_voc.precisions:\n",
    "        What it is: Precision values calculated at different recall thresholds.\n",
    "        How it's calculated: Precision is the fraction of correctly predicted keypoints (true positives) out of all predicted keypoints (true positives + false positives), computed at each recall level.\n",
    "\n",
    "    pck_voc.recalls:\n",
    "        What it is: Recall values calculated across different recall thresholds.\n",
    "        How it's calculated: Recall is the fraction of correctly predicted keypoints out of all ground truth keypoints (true positives + false negatives), calculated at each recall threshold.\n",
    "\n",
    "    pck_voc.AP (Average Precision):\n",
    "        What it is: The average precision score for each keypoint or class.\n",
    "        How it's calculated: The area under the Precision-Recall curve for a single keypoint or class, computed by averaging precision values across all recall thresholds.\n",
    "\n",
    "    pck_voc.AR (Average Recall):\n",
    "        What it is: The average recall score for each keypoint or class.\n",
    "        How it's calculated: The area under the Recall curve, summarizing recall performance across different thresholds for a specific keypoint or class.\n",
    "\n",
    "    pck_voc.mAP (Mean Average Precision):\n",
    "        What it is: The mean of all Average Precision (AP) values across all keypoints or classes.\n",
    "        How it's calculated: The average of AP values across all keypoints or instances, providing an overall measure of the models precision across different thresholds.\n",
    "\n",
    "    pck_voc.mAR (Mean Average Recall):\n",
    "        What it is: The mean of all Average Recall (AR) values across all keypoints or classes.\n",
    "        How it's calculated: The average of AR values across all keypoints or instances, giving an overall measure of recall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCK Metrics:\n",
      "PCK thresholds: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "PCK scores for each keypoint: [[[False False False ...  True  True  True]\n",
      "  [False False False ...  True  True  True]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False  True  True]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ...  True  True  True]\n",
      "  [False False False ...  True  True  True]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ...  True  True  True]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [False  True  True ...  True  True  True]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False  True]\n",
      "  [False False False ... False False  True]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ...  True  True  True]\n",
      "  [False False False ...  True  True  True]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ...  True  True  True]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False  True ...  True  True  True]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False  True  True]\n",
      "  [False False False ...  True  True  True]]]\n",
      "Mean PCK per keypoint (mPCK_parts): [0.24423077 0.27307692 0.09807692 0.00576923 0.03269231 0.\n",
      " 0.1        0.09038462]\n",
      "Overall mean PCK (mPCK): 0.10552884615384617\n"
     ]
    }
   ],
   "source": [
    "print('PCK Metrics:')\n",
    "print(\"PCK thresholds:\", metrics[\"pck.thresholds\"])\n",
    "print(\"PCK scores for each keypoint:\", metrics[\"pck.pcks\"])\n",
    "print(\"Mean PCK per keypoint (mPCK_parts):\", metrics[\"pck.mPCK_parts\"])\n",
    "print(\"Overall mean PCK (mPCK):\", metrics[\"pck.mPCK\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCK-VOC Metrics:\n",
      "Match score thresholds: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]\n",
      "Recall thresholds: [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
      " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
      " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
      " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
      " 0.98 0.99 1.  ]\n",
      "Match scores: [0.15   0.1875 0.2625 0.225  0.2125 0.1    0.2    0.25   0.175  0.1875\n",
      " 0.     0.     0.05   0.0875 0.0625 0.     0.025  0.1    0.0625 0.0125\n",
      " 0.05   0.1    0.1125 0.075  0.0875 0.1    0.15   0.1125 0.05   0.0625\n",
      " 0.1    0.075  0.2    0.1125 0.1    0.0625 0.05   0.05   0.075  0.0375\n",
      " 0.     0.     0.225  0.1875 0.0875 0.1875 0.0375 0.1875 0.0375 0.1375\n",
      " 0.0875 0.2   ]\n",
      "Precisions at different recall levels: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Recalls at different recall levels: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Average Precision (AP): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Average Recall (AR): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Mean Average Precision (mAP): 0.0\n",
      "Mean Average Recall (mAR): 0.0\n"
     ]
    }
   ],
   "source": [
    "print('PCK-VOC Metrics:')\n",
    "print(\"Match score thresholds:\", metrics[\"pck_voc.match_score_thresholds\"])\n",
    "print(\"Recall thresholds:\", metrics[\"pck_voc.recall_thresholds\"])\n",
    "print(\"Match scores:\", metrics[\"pck_voc.match_scores\"])\n",
    "print(\"Precisions at different recall levels:\", metrics[\"pck_voc.precisions\"])\n",
    "print(\"Recalls at different recall levels:\", metrics[\"pck_voc.recalls\"])\n",
    "print(\"Average Precision (AP):\", metrics[\"pck_voc.AP\"])\n",
    "print(\"Average Recall (AR):\", metrics[\"pck_voc.AR\"])\n",
    "print(\"Mean Average Precision (mAP):\", metrics[\"pck_voc.mAP\"])\n",
    "print(\"Mean Average Recall (mAR):\", metrics[\"pck_voc.mAR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15   0.1875 0.2625 0.225  0.2125 0.1    0.2    0.25   0.175  0.1875\n",
      " 0.     0.     0.05   0.0875 0.0625 0.     0.025  0.1    0.0625 0.0125\n",
      " 0.05   0.1    0.1125 0.075  0.0875 0.1    0.15   0.1125 0.05   0.0625\n",
      " 0.1    0.075  0.2    0.1125 0.1    0.0625 0.05   0.05   0.075  0.0375\n",
      " 0.     0.     0.225  0.1875 0.0875 0.1875 0.0375 0.1875 0.0375 0.1375\n",
      " 0.0875 0.2   ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((metrics[\"pck_voc.match_scores\"]))\n",
    "len(metrics[\"pck_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metrics = {\n",
    "#     \"pck_voc.match_scores\": np.random.normal(loc=5, scale=2, size=100)  # Sample data with mean 5 and std deviation 2\n",
    "# }\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics[\"pck_voc.match_scores\"].flatten(), \n",
    "             binrange=(0, 1), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 1)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"PCK\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the figure\n",
    "plt.figure(figsize=(4, 4), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Plot the precision-recall curves for every second threshold and precision\n",
    "for precision, thresh in zip(metrics[\"pck_voc.precisions\"], metrics[\"pck_voc.match_score_thresholds\"]):\n",
    "    plt.plot(metrics[\"pck_voc.recall_thresholds\"], precision, \"-\", label=f\"PCK @ {thresh:.2f}\")\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2.5. OKS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OKS (Object Keypoint Similarity) Metrics:\n",
    "\n",
    "    oks.mOKS:\n",
    "        What it is: Mean Object Keypoint Similarity across all keypoints.\n",
    "        How it's calculated: A similarity score between predicted and ground truth keypoints, normalized by object size and considering keypoint visibility. It averages the OKS scores across all keypoints.\n",
    "\n",
    "OKS-VOC Metrics (Adapted from Object Detection Evaluation):\n",
    "\n",
    "    oks_voc.match_score_thresholds:\n",
    "        What it is: Thresholds for match scores between predicted and ground truth keypoints.\n",
    "        How it's calculated: Defined thresholds (e.g., 0.5, 0.75) used to determine whether a keypoint match is considered correct.\n",
    "\n",
    "    oks_voc.recall_thresholds:\n",
    "        What it is: Thresholds for recall values.\n",
    "        How it's calculated: Specific recall thresholds (often fixed intervals) used to evaluate recall at different levels of detection.\n",
    "\n",
    "    oks_voc.match_scores:\n",
    "        What it is: Scores representing the quality of matches between predicted and ground truth keypoints.\n",
    "        How it's calculated: Based on OKS, a score is assigned to each match, determining the closeness of the match between predicted and true keypoints.\n",
    "\n",
    "    oks_voc.precisions:\n",
    "        What it is: Precision values at various recall thresholds.\n",
    "        How it's calculated: The fraction of true positive keypoints (correct matches) out of all predicted keypoints (true positives + false positives), calculated at various recall levels.\n",
    "\n",
    "    oks_voc.recalls:\n",
    "        What it is: Recall values across different recall thresholds.\n",
    "        How it's calculated: The fraction of true positive keypoints out of all ground truth keypoints (true positives + false negatives), calculated at different recall thresholds.\n",
    "\n",
    "    oks_voc.AP (Average Precision):\n",
    "        What it is: The precision averaged across different recall levels for a specific class or keypoint.\n",
    "        How it's calculated: Area under the Precision-Recall curve, summarizing the model's precision performance at different recall levels.\n",
    "\n",
    "    oks_voc.AR (Average Recall):\n",
    "        What it is: The recall averaged across different recall thresholds for a specific class or keypoint.\n",
    "        How it's calculated: Area under the Recall curve, providing an average measure of recall over varying detection thresholds.\n",
    "\n",
    "    oks_voc.mAP (Mean Average Precision):\n",
    "        What it is: The mean of Average Precision (AP) values across all keypoints or classes.\n",
    "        How it's calculated: The mean AP score calculated by averaging the AP values for all classes/keypoints.\n",
    "\n",
    "    oks_voc.mAR (Mean Average Recall):\n",
    "        What it is: The mean of Average Recall (AR) values across all keypoints or classes.\n",
    "        How it's calculated: The mean AR score calculated by averaging the AR values across all classes/keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKS Metrics:\n",
      "Mean OKS (mOKS): 0.37586655730354923\n"
     ]
    }
   ],
   "source": [
    "print('OKS Metrics:')\n",
    "print(\"Mean OKS (mOKS):\", metrics[\"oks.mOKS\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKS-VOC Metrics:\n",
      "Match score thresholds: [0.5  0.55 0.6  0.65 0.7  0.75 0.8  0.85 0.9  0.95]\n",
      "Recall thresholds: [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
      " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
      " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
      " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
      " 0.98 0.99 1.  ]\n",
      "Match scores: [4.55174193e-01 4.71719695e-01 4.80171559e-01 5.29411016e-01\n",
      " 4.80217780e-01 4.55881854e-01 4.54141291e-01 4.14736645e-01\n",
      " 6.85215458e-01 4.73548918e-01 6.01098529e-04 1.92195408e-11\n",
      " 3.05675245e-01 3.30263884e-01 3.94256020e-01 2.93725541e-01\n",
      " 3.63497339e-01 1.76547285e-01 1.93180258e-01 1.28162998e-01\n",
      " 2.21176506e-01 1.23669861e-01 3.88416810e-01 3.84426376e-01\n",
      " 3.79124227e-01 3.88144006e-01 3.92992802e-01 3.79049858e-01\n",
      " 3.73208785e-01 3.63207675e-01 1.99345504e-01 1.97300907e-01\n",
      " 3.64891985e-01 2.45031694e-01 2.42820580e-01 2.39715801e-01\n",
      " 2.39054552e-01 2.35466854e-01 1.23778026e-01 1.21199140e-01\n",
      " 1.00281449e-01 8.43892395e-02 6.89811996e-01 6.98692601e-01\n",
      " 6.77838445e-01 6.99181474e-01 4.96972809e-01 6.29646135e-01\n",
      " 6.17401724e-01 6.53454511e-01 7.37559846e-01 7.71680722e-01]\n",
      "Precisions at different recall levels: [[0.25       0.25       0.22222222 ... 0.         0.         0.        ]\n",
      " [0.19230769 0.19230769 0.19230769 ... 0.         0.         0.        ]\n",
      " [0.19230769 0.19230769 0.19230769 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "Recalls at different recall levels: [0.18333333 0.16666667 0.16666667 0.13333333 0.03333333 0.01666667\n",
      " 0.         0.         0.         0.        ]\n",
      "Average Precision (AP): [0.04076754 0.03236862 0.03236862 0.02132521 0.00152323 0.00038081\n",
      " 0.         0.         0.         0.        ]\n",
      "Average Recall (AR): [0.18333333 0.16666667 0.16666667 0.13333333 0.03333333 0.01666667\n",
      " 0.         0.         0.         0.        ]\n",
      "Mean Average Precision (mAP): 0.012873402724887874\n",
      "Mean Average Recall (mAR): 0.06999999999999999\n"
     ]
    }
   ],
   "source": [
    "print('OKS-VOC Metrics:')\n",
    "print(\"Match score thresholds:\", metrics[\"oks_voc.match_score_thresholds\"])\n",
    "print(\"Recall thresholds:\", metrics[\"oks_voc.recall_thresholds\"])\n",
    "print(\"Match scores:\", metrics[\"oks_voc.match_scores\"])\n",
    "print(\"Precisions at different recall levels:\", metrics[\"oks_voc.precisions\"])\n",
    "print(\"Recalls at different recall levels:\", metrics[\"oks_voc.recalls\"])\n",
    "print(\"Average Precision (AP):\", metrics[\"oks_voc.AP\"])\n",
    "print(\"Average Recall (AR):\", metrics[\"oks_voc.AR\"])\n",
    "print(\"Mean Average Precision (mAP):\", metrics[\"oks_voc.mAP\"])\n",
    "print(\"Mean Average Recall (mAR):\", metrics[\"oks_voc.mAR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(metrics[\"pck_voc.match_scores\"])\n",
    "len(metrics[\"pck_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.55174193e-01 4.71719695e-01 4.80171559e-01 5.29411016e-01\n",
      " 4.80217780e-01 4.55881854e-01 4.54141291e-01 4.14736645e-01\n",
      " 6.85215458e-01 4.73548918e-01 6.01098529e-04 1.92195408e-11\n",
      " 3.05675245e-01 3.30263884e-01 3.94256020e-01 2.93725541e-01\n",
      " 3.63497339e-01 1.76547285e-01 1.93180258e-01 1.28162998e-01\n",
      " 2.21176506e-01 1.23669861e-01 3.88416810e-01 3.84426376e-01\n",
      " 3.79124227e-01 3.88144006e-01 3.92992802e-01 3.79049858e-01\n",
      " 3.73208785e-01 3.63207675e-01 1.99345504e-01 1.97300907e-01\n",
      " 3.64891985e-01 2.45031694e-01 2.42820580e-01 2.39715801e-01\n",
      " 2.39054552e-01 2.35466854e-01 1.23778026e-01 1.21199140e-01\n",
      " 1.00281449e-01 8.43892395e-02 6.89811996e-01 6.98692601e-01\n",
      " 6.77838445e-01 6.99181474e-01 4.96972809e-01 6.29646135e-01\n",
      " 6.17401724e-01 6.53454511e-01 7.37559846e-01 7.71680722e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics[\"oks_voc.match_scores\"])\n",
    "len(metrics[\"oks_voc.match_scores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "oks = metrics_c[\"oks_voc.match_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metrics_c = {\n",
    "#     \"pck_voc.match_scores\": np.random.normal(loc=5, scale=2, size=100)  # Sample data with mean 5 and std deviation 2\n",
    "# }\n",
    "\n",
    "# Set up the figure with a larger size and higher resolution\n",
    "plt.figure(figsize=(6, 3), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Create the histogram with KDE\n",
    "sns.histplot(metrics[\"oks_voc.match_scores\"].flatten(), \n",
    "             binrange=(0, 1), \n",
    "             kde=True, \n",
    "             kde_kws={\"clip\": (0, 1)}, \n",
    "             stat=\"probability\")\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel(\"OKS\")\n",
    "plt.ylabel(\"Probability\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAIqCAYAAADfIrX+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAABcSAAAXEgFnn9JSAADaRklEQVR4nOzdeVyU1f7A8c8Mu4iCC65loxIoJZiouQEuVwUXREHNJUy9WlmaaOFaXaXEckmzuraIS2S/QCQVUDRwV1TSXHAhM7eQREHFQHA4vz+4MzHOIMMmEOf9evG6zfOc5zznmeswX875nnMUQgiBJEmSJEmSpKWs7AZIkiRJkiRVNTJAkiRJkiRJeoQMkCRJkiRJkh4hAyRJkiRJkqRHyABJkiRJkiTpETJAkiRJkiRJeoQMkCRJkiRJkh4hAyRJkiRJkqRHyABJkiRJkiTpETJAkiRJkiRJeoQMkCRJkiRJkh4hAyRJkiRJkqRHmFZ2A6SiNW7cmPv37/P0009XdlMkSZIkqVq5cuUK1tbW3Lhxo1TXyx6kKuz+/fvk5eVVdjMkSZIkqdrJy8vj/v37pb5e9iBVYZqeozNnzlRySyRJkiSpenF2di7T9bIHSZIkSZIk6REyQJIkSZIkSXqEDJAkSZIkSZIeIQMkSZIkSZKkR8gASZIkSZIk6REyQJIkSZIkSXqEnOYvSZJUTQghEEJUdjMk6YlTKBQoFIonek8ZIEmSJFVh2dnZ3Llzh3v37vHw4cPKbo4kVRoLCwvs7OyoW7cuSmXFD4DJAEmSJKmKunv3LtevX6/sZkhSlfDgwQNu3LhBTk4OjRs3rvAeJRkgSZIkVUHZ2dna4Kh27drY2dlhaWn5RP5ylqSqRq1Wc/fuXf78808yMzOxtramTp06FXpPGSBJkiRVQXfu3AEKgqPmzZs/8fwLSapKlEol9evX5+HDh9y+fZt79+5VeIAk/xSRJEmqgu7duweAnZ2dDI4k6X9sbGwAyrQJrbGqdYCUk5PDe++9x7PPPoulpSVNmzZl/PjxXLt2zeg6MjMz+e677xg1ahRt27bF2toaGxsbOnfuzIoVK8jLyzN43bhx47RZ9YZ+/vvf/5bXY0qSVMMIIbQJ2ZaWlpXcGkmqOiwsLICCIbeKntFZbYfYcnJy6N27NwcPHqRJkyb4+Pjw+++/ExoayrZt2zh06BCtWrUqtp4lS5bwwQcfoFQqad++PYMGDeLmzZscOHCAI0eOEBERwY4dO6hVq5bB6/v160fjxo31jjs6Opb5GSVJqpkK/+KXOUeS9LfCvalCiArtXa22AdKHH37IwYMH6dKlC3FxcdSuXRuAZcuWMWPGDMaPH8+ePXuKrad27drMmTOH119/nWbNmmmPp6Sk0KdPH/bv309wcDAffvihwetnzZqFp6dnuTyTJEmSJElVQ7X80yQvL49PP/0UgM8++0wbHAEEBgbSrl079u7dS1JSUrF1zZo1iw8++EAnOAJwcHAgJCQEgI0bN5Zj6yVJkiRJquqqZYC0f/9+MjMzadWqFe3bt9c77+fnB8DWrVvLdB8XFxcA/vjjjzLVI0mSJElS9VIth9h++eUXAF544QWD5zXHNeVK67fffgMwmGOkERkZyaZNm1Cr1ahUKgYNGoSTk1OZ7ltRsv7KJfrgJb3jpkolnZ9rTHN7m0polSRJkiRVPdWyB+nKlSsANG/e3OB5zXFNudJasWIFAD4+PkWW+fTTT1m1ahVffPEF77zzDm3btmXKlCkl2hLA2dnZ4M/FixfL1P5HZWXn8W3sOb2ftdHJzFy5j/vZhmfsSZIkVTXp6enMnz+f9u3bY2trS61atWjdujWTJk3i9OnTRV7n6emJQqFg9+7dBs8vX74chUKBtbU1CQkJOufCw8Pp168fDRo0wMzMDHt7e9q1a8eECRMICwsrz8crd/n5+XzyySc8//zzWFlZ0bBhQ/z9/UlOTi5xXZr3sKif7du3F3nt+vXr6dSpE7Vr16ZevXp4e3tz8ODBsjxahamWPUhZWVkARc4ss7a21ilXGv/973/ZtWsXtra2zJo1S+98+/bt6dKlC7169aJ58+bcuHGD2NhY5s2bx+eff465uTnLly8v9f2ftPvZefx6NROXZxtWdlMkSZIea9euXfj7+5OZmUnDhg3x8PDAwsKCU6dO8dVXX7FmzRqCg4MN/u5+HM0kH2tra2JiYnB3d9eeGzduHOvWrQPAzc0NlUqFWq3mzJkzrFmzhrCwMEaPHl3qZzpz5gxhYWHExcVx5coV7t69S9OmTXFycmLkyJEMGzZM+91WUkIIRowYQUREBLa2tgwYMID09HQ2bdpEdHQ0CQkJdO7cucT1Dhs2TCcHWOPRnF6NwMBAli9fjpWVFX379iUnJ4edO3cSFxdHeHg4vr6+JW5DhRLV0MSJEwUg5s2bZ/D8hQsXBCCeffbZUtW/e/duYW5uLhQKhYiMjCzRtadOnRLm5ubCxMREXLlypVT312jbtq1o27ZtmeooLONujvh4wzGdn9HvxoiBgVFiYGCUSEi6Wm73kiSp9NRqtUhOThbJyclCrVZXdnOqlCNHjmh/Py9atEjk5eXpnI+OjhZ2dnYCECtWrNC73sPDQwAiISFB5/jHH38sAFG7dm2xb98+nXMRERECEHZ2duLo0aN6dV64cEEEBQWV6nlu3bolxo4dK5RKpVAoFMLJyUn4+vqKkSNHCnd3d1GnTh0BiGbNmonY2NhS3eObb74RgHBwcBA3btzQe65WrVrpvY+Po3kPL126ZPQ1P/30kwBE/fr1xYULF7THDx48KMzNzUXdunXF7du3i62nJJ+Nsn6HVssAafr06QIQ06dPN3j+xIkTAhAvvPBCiev+5ZdfhK2trQDEypUrS9U+Pz8/AYg1a9aU6nqN8g6QDPnP14e0AdLm3b9W6L0kSTKODJAMy8/PF23atBGAWLhwYZHl9uzZIxQKhbC0tBS///67zjlDAdLixYsFIGxsbMSBAwf06hs1atRj/ygvrZSUFNG6dWthamoq3nzzTfHbb7/plcnOzhZhYWHiqaeeEoBYtWpVie/Ttm1bAYjNmzfrnRs8eLAAREREhNH1lSZA8vb2FoBYvny53rmpU6cKQCxZsqTYep5kgFQtc5CefvppgCJXzNYc15Qz1sWLF+nXrx+ZmZm8//77vPnmm6Vqn4ODAwCpqamluv5Jsq1tof3vzHs5ldgSSZKkx4uNjeXs2bM0a9aMoKCgIsu5u7vj7+9PTk4On3322WPrDAkJISgoiLp16xIXF0fXrl31yty8eROAhg3LLwXhzp07DBgwgNu3b7Nr1y5WrlyJSqXSK2dpacmoUaM4c+YMffr0YerUqfz4449G3+fSpUskJydjZWXFgAED9M6X16zvx8nJyeGnn37Sud+TbkNpVMsASTP9/ueffzZ4XnO8Xbt2Rtf5xx9/8K9//YsbN24wbdo03nvvvVK3LyMjA8Dg2GxVY2vzd4CUce9BJbZEkiTp8WJiYgDw9/fHzMzssWVHjRoFFARVRVm0aBGzZ8/G1taWuLg4XnzxRYPlNBN/NmzYUG57gAUGBnL58mUSEhLw8PAotryNjQ1RUVG4uLgwefJk7t69a9R9NLO5n3vuOYPvWVlmfX/zzTe8/vrrvPHGG6xcubLIiVHnzp3jwYMHNGzY0ODkKk0bTp48WeI2VKRqGSB169aNunXrcvHiRY4fP653PiIiAoCBAwcaVV9GRgb9+vXj0qVLvPLKK2VKrn7w4AHR0dEAdOjQodT1PCl2Nn/v85SZJQMkSaouhBBkZedVqx9Rxr2zTpw4ARj3u1VTJjk52eCemkuWLGHOnDnY2dmxc+dOOnXqVGRd48ePR6FQcOzYMVQqFZMnT2bDhg2lnmmckpLCunXrCA4O1vlDfufOnXTs2BFLS0uaN2/O22+/zW+//YZCoWDt2rVYW1uzevVq0tLS2LBhg1H3qshZ38HBwXzxxRd89tlnTJs2jdatW7Nw4cISt8Ha2hpbW1syMjK0mzRXBdVyFpu5uTlvvPEGH3zwAW+88QZxcXHa7P5ly5Zx8uRJunfvTseOHbXXrFq1ilWrVuHr68uiRYu0x//66y+8vb05ffo0w4cP56uvvip2b5fz589z7tw5Bg4ciImJifb4zZs3mTRpElevXsXFxcVgV21VU7gHKVP2IElStXE/5yEvzYup7GaUyMZgb2pbPb7n53Fu3boFgL29fbFlNcNh+fn53L59m0aNGumc1/whGxwcjJub22Pr6t69O+vXr2fq1KncvHmTL7/8ki+//BKAFi1aMGnSJAIDA43eWPjbb7/FysqK119/XXssPj4eb29vlEolPXr0wNzcnC+++EJvOYKOHTvi6upKVFQUU6ZMKfZeFTHr293dnYkTJ9K1a1eaNGnC1atXiYiIIDg4mHfffZc6deowbdo0o9ugaUdmZiZZWVnY2FSNNfmqZYAEMG/ePHbt2sXBgwdxcHCgR48eXL58mcTEROrXr09oaKhO+fT0dM6fP6+XFzR37lwOHz6MiYkJpqamTJgwweD91q5dq/3v1NRUhgwZQv369XFycqJZs2b8+eefJCUlce/ePZo3b84PP/xQoZvolRcZIEmSVF1oeqCM6YkqXMbQ7+Ju3bpx4MABZs2ahZub22N7kADGjBmDj48PkZGR/PTTTxw9epRz585x+fJl5s6dy5YtW0hISMDKyqrYtsXFxeHj46MTMEyfPh0TExP27dun/eM+JSXF4B/aXbp0ITw8vNj7wN/vQ3l+Hy1YsEDn9bPPPsucOXNwc3OjX79+vPfee0yaNEn7XhjThrL2LlaEajnEBgWJawkJCcyfP59atWoRFRXF77//TkBAAMePH6d169ZG1aPJF1Kr1Xz33XesW7fO4E9hzz77LG+99RYODg5cvHiRzZs3c+zYMRwcHHjvvfc4efIkzz77bLk/c0UonKR9J+sB+flV7x+pJEkSQIMGDQD4888/iy2rSaxWKBTY2dnpnQ8ODmbixIncu3cPLy8vTp06VWydNjY2BAQEsH79es6ePcvVq1eZPXs2JiYmJCYmsmzZMqOe49KlSzg6OmpfX7t2jZMnTxIQEKAz8uHg4KDTE6Nha2tLZmamUffS9MYUlTulOV4eObN9+/bFzc2NO3fucPjwYaPbAAWjOeXVjvJSbXuQAKysrFiwYIFeNGvI+++/z/vvv693fO3atTq9Q8Zo2rRptVoE8nHsCvUgqfMF9/7KpW6hoEmSpKrJ2tKUjcHeld2MErG2LNtXjouLCwcOHCApKYmxY8c+tqxms3JnZ+ciE7pXr15NVlYW33//PX379mXfvn1G/3ENBTk1H374Ibm5uSxdupTo6Gjmzp1b7HWPDvlpcnQMTSxydXXVO5aamoqtra1RbayoWd9FcXBw4NixYzqjNcW14f79+2RmZmJra1tlhtegGvcgSeXD2soMU5O//xnIRG1Jqh4UCgW1rcyq1U9Zh3m8vLyAgok4hhKvC/vuu+8A6N+/f5FllEolGzZsYNCgQdy4cYPevXtz9erVErfL09MTKEjlMMajPUDm5uaA4TygR48JIUhMTDS4Ubshmlnfp0+fNvielWbW9+MYmsXt6OiIhYUFN2/eNBgklXcbyosMkGo4hUIh85AkSaoWvL29cXR05Pr16yxevLjIcnv37iUiIgJzc/NiE5lNTU0JDw+nV69eXLlyhT59+pCWlqZTprj8GM1stqZNmxr1HC1atNDZL87JyQlTU1ODe5jt2LFD53VERARnz54ttgdNQ6VS0aZNG7Kzs7WJ6Y/WB8bP+n6cmzdvsm/fPkB3M3krKyt69eqlc7+KakN5kgGSJAMkSZKqBaVSydq1azEzM+Pdd99l8eLFqNVqnTKxsbEMGTIEIQQhISE888wzxdZrYWHBli1b6NKlCxcuXKBv377anhCAiRMn8sEHH3Djxg29a48ePaqd2j506FCjnqNXr15s376d3NxcoKC3Zfjw4ezevZuZM2dy/fp10tPTWbp0qXY6f0ZGBqtWrWLs2LH07NlTu86TMQIDAwF45513dPK3IiMj2bJlCyqViiFDhuhcs3nzZpycnHj55Zd1jh8+fJiEhAS9oPH333/H19eX+/fvM3jwYL0p/Zo2BAcHk5KSoj1+6NAhVq9eTZ06dYqcJFVpSr0Gt1ThnsRWI0II8f5Xf283ErVHbjciSZVNbjXyeLGxsaJu3boCEPb29sLHx0cMHz5cuw2JUqksciuSovZiE0KIjIwM4erqKgDRuXNnce/ePSGEED4+Ptp6XVxchJ+fn/Dz8xPt27cXgACEl5eXyM3NNar9x48f19vOKi0tTTg6OmrrA4SJiYlYuHChzrERI0aIu3fvluj9UqvVwtfXV7ufnJ+fn/D09NRux2Joe5XQ0FABCA8PD4PHmzRpIjw8PMSIESNEt27dhKWlpQCEs7OzSEtLM9iOadOmCUDUqlVL+Pj4CC8vL2FqaiqUSqXRW508ya1GqnWStlQ+7GQPkiRJ1Uj//v1JSUlhxYoVbNu2jfj4ePLy8mjSpAkTJ07kzTffLFU+i2ZFbXd3dxITExk8eDAxMTGsWrUKb29v4uLiSE5OJi4ujuzsbOrXr0///v0ZPXo0o0ePNjrHytXVlaFDhzJ37lx69eqFs7Mz9vb2JCUlERoayunTp6lXrx7Dhw+nZcuWpKamolKp8PLywtnZucTPpVQqCQ8PZ8WKFaxZs4Zt27ZhbW2Nr68vCxYsKFGdnTt35rXXXiMxMZHk5GQOHDiAtbU1rq6u+Pv789prrxW51MEnn3yCq6srq1atYufOnZiZmdG7d2/mzZtH9+7dS/xcFU0hRBVcfEAC0P6jPXPmTIXeZ31MMuE/FXR59u74FG+NfKGYKyRJqkj5+fmcP38eKEhwVSplNsQ/TVpaGh06dEChULB161aDs9UKy8/PR61WF7vFyj9dST4bZf0OlZ86SeYgSZIkPWGNGjUiOjqa/Px8unbtyuzZs/WSwwEePnxIZGQkbm5ujB8/vhJaWnPJITYJu9pyPzZJkqQnzcXFhSNHjjB58mRCQkJYvHgxLi4uqFQqLC0tSU1N1e7Q4OzszNSpUyu7yTWKDJAk2YMkSZJUSZo1a8a2bds4ePAgGzduJCEhgfj4eHJycmjcuDEDBw7E39+fIUOGVIvtq/5JZIAk6QRImu1GlEr5QZQkSXpSunbtWi02OK9JZA6SpDOL7aFakJX9+BVqJUmSJOmfTgZIkv52I/dyKrE1kiRJklT5ZIAkFWw3Uttc+1omakuSJEk1nQyQJEAmakuSJElSYTJAkgCwtSk01V8GSJIkSVINJwMkCXhkuxE5xCZJkiTVcDJAkgDdIbaMuzJAkiRJkmo2GSBJANjWlj1IkiRJkqQhAyQJeDRJW07zlyRJkmo2GSBJANjJJG1JkqqR9PR05s+fT/v27bG1taVWrVq0bt2aSZMmcfr06SKv8/T0RKFQsHv3boPnly9fjkKhwNramoSEBJ1z4eHh9OvXjwYNGmBmZoa9vT3t2rVjwoQJhIWFlefjlbv8/Hw++eQTnn/+eaysrGjYsCH+/v4kJyeXuC7Ne1jUz/bt2/Wuef/99x97zaxZs8rjMcuV3GpEAh7pQcp6gBBC7vsjSVKVtGvXLvz9/cnMzKRhw4Z4eHhgYWHBqVOn+Oqrr1izZg3BwcEl/tJdtmwZM2bMwNrampiYGNzd3bXnxo0bx7p16wBwc3NDpVKhVqs5c+YMa9asISwsjNGjR5f6mc6cOUNYWBhxcXFcuXKFu3fv0rRpU5ycnBg5ciTDhg3D2tq6VHULIRgxYgQRERHY2toyYMAA0tPT2bRpE9HR0SQkJNC5c+cS1zts2DBq166td7xZs2ZFXtOtWzdat26td7xDhw4lvn9FkwGSBOgGSJrtRmxqmT/mCkmSpCfv6NGjDBgwgLy8PBYtWsTMmTMxNf37qywmJoYxY8Ywe/ZsatWqxdSpU42qd8mSJbz99tvUrl2b2NhYunfvrj23adMm1q1bh52dHXFxcbi5uelcm5KSwjfffFOq57l9+zZvvfUWYWFhCCFwdHSke/fuWFhY8Mcff3DgwAFiY2OZM2cOX3/9Nf379y/xPUJDQ4mIiMDBwYF9+/bRqFEj7XP5+fkxevRozp07p/M+GmPJkiU888wzJbpm4sSJjBs3rkTXVBY5xCYBUNvKDFOTv3uM5DCbJElVjRCCgIAAcnNzWbBgAbNmzdL7Uvf29iYqKgqFQkFQUBCXL18utt6PPvqIt99+GxsbG3bs2KETHAFERkYCMGXKFL3gCMDBwYGQkJASP8+vv/5K586d2bhxI1OmTOHixYucPXuWyMhINm7cyJ49e0hLSyMsLAylUomXlxefffZZie+zdOlS7XNqgiMo6AEaPHgwFy9e5Mcffyxxvf90MkCSgILtRurWlqtpS5JUdcXGxnL27FmaNWtGUFBQkeXc3d3x9/cnJyen2IAiJCSEoKAg6tatS1xcHF27dtUrc/PmTQAaNmxYtgco5M6dOwwYMIDbt2+za9cuVq5ciUql0itnaWnJqFGjOHPmDH369GHq1KklCmYuXbpEcnIyVlZWDBgwQO+8n58fAFu3bi39w/xDyQBJ0rKT241IklSFxcTEAODv74+Zmdljy44aNQooCKqKsmjRImbPno2trS1xcXG8+OKLBss1b94cgA0bNnD//v3SNF1PYGAgly9fJiEhAQ8Pj2LL29jYEBUVhYuLC5MnT+bu3btG3eeXX34B4LnnnjP4nr3wwgs65Urim2++4fXXX+eNN95g5cqVXLlypdhr4uPjeeutt3j11VcJDg4mKSmpxPd9UmQOkqRVsN3IHQAysuRUf0mqyoQQ/JWXXdnNKJFaZlZlmvxx4sQJwLiEXk2Z5ORk8vLy9IKDJUuWEB0dXWReUWHjx49n7dq1HDt2DJVKha+vL927d6dr1660atWqxM+RkpLCunXrCAkJoV27dtrjO3fuZM6cOZw6dYoGDRrw0ksv8dprr9GqVStCQ0MZN24cq1evplOnTmzYsIEpU6YUey9N0KIJ8h6lOW5McPOo4OBgndczZ85k/vz5zJ8/v8hrNmzYoPN6/vz5DBs2jLVr1xpM+K5MMkCStGzlEJskVRt/5WXzyuYZld2MEgn1XYq1ea1SX3/r1i0A7O3tiy2rGQ7Lz8/n9u3bOrk3ANHR0UDBl/zjgiOA7t27s379eqZOncrNmzf58ssv+fLLLwFo0aIFkyZNIjAwEEtLy8fWo/Htt99iZWXF66+/rj0WHx+Pt7c3SqWSHj16YG5uzhdffKG3HEHHjh1xdXUlKirKqAApKysLgFq1DL/vmplxmnLGcHd3Z+LEiXTt2pUmTZpw9epVIiIiCA4O5t1336VOnTpMmzZN55rWrVuzZMkSvLy8aNGiBRkZGezdu5d33nmHTZs2oVar2bx5s9FteBLkEJukZSuH2CRJqsKEEDr/a0xZwGCvVbdu3QCYNWsWR44cKba+MWPGcPnyZdauXcvYsWNxcnIC4PLly8ydOxdPT0+ys43r0YuLi8PHx0cnaJk+fTomJibs37+fXbt2ERMTw/Hjx/n999/1ru/SpYu2N604mvehPJdtWbBgAWPGjKFly5ZYWVnx7LPPMmfOHKKiogB477339N6LMWPGMGPGDNq2bYu1tTXNmzdn1KhRHD16lPr16xMVFcXBgwfLrY3lQQZIkpbOfmwyQJIkqYpp0KABAH/++WexZTWJ1QqFAjs7O73zwcHBTJw4kXv37uHl5cWpU6eKrdPGxoaAgADWr1/P2bNnuXr1KrNnz8bExITExESWLVtm1HNcunQJR0dH7etr165x8uRJAgIC6Nixo/a4g4ODXk8MgK2tLZmZmUbdy8bGBqDI3CnN8fIY3urbty9ubm7cuXOHw4cPG3VNkyZNeOWVVwDYsWNHmdtQnuQQm6RlZyP3Y5Ok6qKWmRWhvksruxklUsvMqkzXu7i4cODAAZKSkhg7duxjy2qSf52dnYtM6F69ejVZWVl8//339O3bl3379hlcxLAozZs358MPPyQ3N5elS5cSHR3N3Llzi73u0SE/Tf5P4XwkDVdXV71jqamp2NraGtXGp59+GigIwgzRHNeUKysHBweOHTtGampqia4BSnTNkyB7kCQtOcQmSdWHQqHA2rxWtfop6zCPl5cXABEREeTl5T227HfffQfw2IUVlUolGzZsYNCgQdy4cYPevXtz9erVErfL09MTKNj+xBiP9gCZmxcsymsoD+jRY0IIEhMTad++vVH3cnFxAeD06dMG37Off/4ZMByclUZGRgZQsh6p0lzzJMgASdJ6NEnbmHF+SZKkJ8Xb2xtHR0euX7/O4sWLiyy3d+9eIiIiMDc3LzaR2dTUlPDwcHr16sWVK1fo06cPaWlpOmWK+1148eJFAJo2bWrUc7Ro0UJnvzgnJydMTU0N7mH26LBTREQEZ8+eLbYHTUOlUtGmTRuys7O1iemP1gcwcOBAo+p7nJs3b7Jv3z7g7+UDiiOE0CZnV7XtRmSAJGnZFtqw9qE6n/vZj/8LTZIk6UlSKpWsXbsWMzMz3n33XRYvXoxardYpExsby5AhQxBCEBISYtRWGBYWFmzZsoUuXbpw4cIF+vbtq+3VgILtMT744ANu3Lihd+3Ro0dZuHAhAEOHDjXqOXr16sX27dvJzc0FCnpOhg8fzu7du5k5cybXr18nPT2dpUuXaqfFZ2RksGrVKsaOHUvPnj216zwZIzAwEIB33nlHJ38rMjKSLVu2oFKpGDJkiM41mzdvxsnJiZdfflnn+OHDh0lISNALGn///Xd8fX25f/8+gwcP1llWID09nfXr1/Pgge7IRFZWFq+99hqJiYk0btwYX19fo5/piRBSldW2bVvRtm3bJ3Y/tTpf+Mz8UQwMjBIDA6PElRt3n9i9JUn6m1qtFsnJySI5OVmo1erKbk6VExsbK+rWrSsAYW9vL3x8fMTw4cNFmzZtBCCUSqVYuHChwWs9PDwEIBISEvTOZWRkCFdXVwGIzp07i3v37gkhhPDx8dHW6+LiIvz8/ISfn59o3769AAQgvLy8RG5urlHtP378uADEypUrtcfS0tKEo6Ojtj5AmJiYiIULF+ocGzFihLh7t2S/m9VqtfD19RWAsLOzE35+fsLT01MoFAphaWkpDhw4oHdNaGioAISHh4fB402aNBEeHh5ixIgRolu3bsLS0lIAwtnZWaSlpelcc+nSJQGIOnXqiM6dOwt/f3/xr3/9S9SvX18AwtbWVuzfv9/oZzH2s1HW71CZpC1pKZUKbG0suHWnYJHIzKwHPNXIppJbJUmSpKt///6kpKSwYsUKtm3bRnx8PHl5eTRp0oSJEyfy5ptvliqnRrOitru7O4mJiQwePJiYmBhWrVqFt7c3cXFxJCcnExcXR3Z2NvXr16d///6MHj2a0aNHG51j5erqytChQ5k7dy69evXC2dkZe3t7kpKSCA0N5fTp09SrV4/hw4fTsmVLUlNTUalUeHl54ezsXOLnUiqVhIeHs2LFCtasWcO2bduwtrbG19eXBQsWlKjOzp07a3t9kpOTOXDgANbW1ri6uuLv789rr72GlZVuMn79+vUJCgri8OHD/Prrr5w4cQITExNUKhXjxo1j+vTpNGvWrMTPVdEUQshEk6pK84/2zJkzT+yeby3fzcVrBatp29erhbVlQQzduL41//Z5noZ2ZZuFIklS8fLz8zl//jwAjo6OKJUyG+KfJi0tjQ4dOqBQKNi6davB2WqF5efno1ari91i5Z+uJJ+Nsn6Hyk+dpMOuUB7Sn7f/4tIfd7n0x10OnUrl2+1nK7FlkiRJ/xyNGjUiOjqa/Px8unbtyuzZs/WSwwEePnxIZGQkbm5ujB8/vhJaWnPJITZJRw/Xphw7q/8hBfgl5SZCiHJdkVWSJKmmcnFx4ciRI0yePJmQkBAWL16Mi4sLKpUKS0tLUlNTSUpK4t69ezg7OzN16tTKbnKNIgMkSUcvt6dp3dyW6zcLVld9kKdmaVjBgmu37uTwZ0Y2jeqVfi8lSZIk6W/NmjVj27ZtHDx4kI0bN5KQkEB8fDw5OTk0btyYgQMH4u/vz5AhQ+Qfp0+YDJAkPU83rsPTjetoX2/ccY4/0gsCpuRLt2SAJEmSVM66du1K165dK7sZUiEyB0kqVltVfe1/n/ntViW2RJIkSZKeDBkgScVybllP+9/Jl25XYkskSZIk6cmQAZJUrMI9SFfT7nH3fm4ltkaSJEmSKp4MkKRiNWlgrbNP27nfZS+SJEmS9M8mAySpWAqFgraFhtlkHpIkSZL0TycDJMkohYfZki/JAEmSJEn6Z5MBkmSUtqq/e5B+vZbJgzz1Y0pLkiRJUvUmAyTJKC2b1sXS3ASAh2rBhSsZldwiSZIkSao4MkCSjGJiosSpReHp/nKYTZIkSfrnkgGSZLTCw2xyPSRJkiTpn0wGSJLRCidqn/v9Nup8UYmtkSSpJktPT2f+/Pm0b98eW1tbatWqRevWrZk0aRKnT58u8jpPT08UCgW7d+82eH758uUoFAqsra1JSEjQORceHk6/fv1o0KABZmZm2Nvb065dOyZMmEBYWFh5Pl65y8/P55NPPuH555/HysqKhg0b4u/vT3JycqnrvHHjBtOnT+fZZ5/FysqKevXq0aFDB955550ir1m/fj2dOnWidu3a1KtXD29vbw4ePFjqNlQkGSBJRnNsYYdSWbBZ4l85D7mcereSWyRJUk20a9cuHBwcCA4O5vr163h4eDBw4EDMzMz46quvcHV1JSQkpMT1Llu2jMDAQKytrYmNjaVnz57ac+PGjWP48OHExcWhUqnw9fWlR48e5ObmsmbNGiZMmFCmZzpz5gxz5szBzc0Ne3t7LC0tadmyJd7e3qxfv5779++Xum4hBCNGjGD69Olcu3aNAQMG4OzszKZNm3BzcyMxMbHEdR46dIg2bdrwySefYGZmxuDBg3nxxRe5desWy5YtM3hNYGAgAQEBnD59mj59+tCpUyd27tyJu7s7mzdvLvXzVRghVVlt27YVbdu2rexm6Ji+fLcYGBglBgZGia37LlZ2cyTpH0mtVovk5GSRnJws1Gp1ZTenSjly5IgwNzcXCoVCLFq0SOTl5emcj46OFnZ2dgIQK1as0Lvew8NDACIhIUHn+McffywAUbt2bbFv3z6dcxEREQIQdnZ24ujRo3p1XrhwQQQFBZXqeW7duiXGjh0rlEqlUCgUwsnJSfj6+oqRI0cKd3d3UadOHQGIZs2aidjY2FLd45tvvhGAcHBwEDdu3NB7rlatWum9j49z/fp1YWtrK6ysrERkZKTe+cTERL1jP/30kwBE/fr1xYULF7THDx48KMzNzUXdunXF7du3i713ST4bZf0ONa280Eyqjtqq6pNyNROADbFn+XHvxcpt0BNgZqrEu6uKgd1bVnZTJKlGE0IQEBBAbm4uCxcuZNasWXplvL29iYqKwtPTk6CgIHx8fGjRosVj6/3oo48ICgrCxsaG7du307VrV53zkZGRAEyZMgU3Nze96x0cHErVY/Xrr7/i5eXF77//zpQpU5g+fToqlUqnTE5ODpGRkcyaNQsvLy9WrVrFlClTSnSfpUuXAgXP2ahRI+3xYcOGMXjwYLZs2cKPP/7IsGHDjKpv1qxZZGZm8umnn+Lr66t3vlOnTkW2Yd68eTg4OGiPd+nShVdffZWVK1eyZs0aZsyYUaJnq0gyQJJKxLllPW1Q9FfOQ/7KeVjJLXoyvv7xNH06PY2lufzISFJliY2N5ezZszRr1oygoKAiy7m7u+Pv788PP/zAZ599xkcffVRk2ZCQEGbPnk3dunXZvn07L774ol6ZmzdvAtCwYcOyP8T/3LlzhwEDBnD79m127dqFh4eHwXKWlpaMGjWKQYMGMXToUKZOnUrz5s3x8fEx6j6XLl0iOTkZKysrBgwYoHfez8+PLVu2sHXrVqMCpIyMDH744Qfq1q3LxIkTjWpDTk4OP/30k/Z+htqwcuVKtm7dKgMkqfpq72hPk/rWpN4q/Xh4daTOF2Q/eCgDJKnKEEKgvv9XZTejREysa6FQKEp9fUxMDAD+/v6YmZk9tuyoUaP44YcfiI2NLTJAWrRoEXPmzMHW1pYdO3YY7PkAaN68OQAbNmxgwoQJWFtbl/oZNAIDA7l8+TJHjhyhXbt2xZa3sbEhKiqKHj16MHnyZHr27EmdOnWKve6XX34B4LnnnjP4nr3wwgs65Ypz4MABHjx4QJ8+fTAzMyMiIoL9+/eTl5eHk5MTw4cP1+mlAjh37hwPHjygYcOG2vfSUBtOnjxpVBueFPnbXioRS3NTVr3dkwtXMlCr/9mz2NT5gve+OqR9nS9n7UlViPr+XySOfrmym1EincPWY1q79MHFiRMnAOjQoUOxZTVlkpOTycvL0wsOlixZQnR0NHZ2dsTFxRkcOtMYP348a9eu5dixY9oE7e7du9O1a1datWpV4udISUlh3bp1hISE6ARHO3fuZM6cOZw6dYoGDRrw0ksv8dprr9GqVStCQ0MZN24cq1evplOnTmzYsMGoobYrV64AGAxMCh/XlCvOmTNnAGjUqBE9evTg0KFDOudnz55NaGgo/v7+RrfB2toaW1tbMjIyuHfvHjY2Nka1paLJAEkqMXMzE55r1aCym1HhHl3GQC5rIEmV69atggVq7e3tiy2rGQ7Lz8/n9u3ber0a0dHRAAQHBz82OALo3r0769evZ+rUqdy8eZMvv/ySL7/8EoAWLVowadIkAgMDsbS0NOo5vv32W6ysrHj99de1x+Lj4/H29kapVNKjRw/Mzc354osv9JYj6NixI66urkRFRRkVIGVlZQFQq1Ytg+c1vWGacsXJyCjYRWH9+vVYWFjwzTffMHjwYLKysvj0009ZtmwZY8aMwdHRURv8FdcGTTsyMzPJysqqMgGSnOYvSUVQPjISIHuQJKlyCSF0/teYsoDBYb1u3boBBQnHR44cKba+MWPGcPnyZdauXcvYsWNxcnIC4PLly8ydOxdPT0+ys7ONeo64uDh8fHx0Aobp06djYmLC/v372bVrFzExMRw/fpzff/9d7/ouXbpoe9OKo3kfyjK0WZhaXbAP58OHD1m2bBnjx4+nQYMGPPPMMyxduhQ/Pz9yc3N1hjWNaYMx/58+abIHSZKKoFAoUCpAExflV8EPsFRzmVjXonPY+spuRomYWBfdg2CMBg0acP78ef78889iy2oSqxUKBXZ2dnrng4ODCQsL4+uvv8bLy4vdu3fz/PPPP7ZOGxsbAgICCAgIAODatWt8/vnnfPTRRyQmJrJs2TLmzp1bbNsuXbqEt7e39vW1a9c4efIkkyZNomPHjtrjDg4OTJs2jfnz5+tcb2trS2ZmZrH30bQZKHIdJc3x2rVrl6g+pVKpfR8KGz9+PBERETo9X8W1AeCvv/4qUTueBBkgSdJjKJUK8v+XayV7kKSqRKFQlCmfpzpycXHhwIEDJCUlMXbs2MeWTUpKAsDZ2bnIhO7Vq1eTlZXF999/T9++fdm3bx+tW7c2uj3Nmzfnww8/JDc3l6VLlxIdHW1UgPTokJ8mR8dQsrarq6vesdTUVGxtbY1q49NPPw0UBGGGaI5ryhXnmWeeAaBx48ZYWFgUeb5wEFtcG+7fv09mZia2trZVZngN5BCbJD2WslCXsAyQJKlyeXl5ARAREUFeXt5jy3733XcA9O/fv8gySqWSDRs2MGjQIG7cuEHv3r25evVqidvl6ekJFGx/YoxHe4DMzc0Bw3lAjx4TQpCYmEj79u2NupeLiwsAp0+fNvie/fzzz4Dh4MwQzX0zMjIMDotp8sQK9wQ5OjpiYWHBzZs3DQZJJW3DkyIDJEl6DGWhRCQZH0lS5fL29sbR0ZHr16+zePHiIsvt3buXiIgIzM3Ni01kNjU1JTw8nF69enHlyhX69OlDWlqaTpni8mMuXixYG65p06ZGPUeLFi109otzcnLC1NSU7du365XdsWOHzuuIiAjOnj1bbA+ahkqlok2bNmRnZ2sT0x+tD2DgwIFG1ff888+jUqnIzs42uEWJZmhNM3UfwMrKil69euncryxteFJkgCRJj6ETIMkISZIqlVKpZO3atZiZmfHuu++yePFibdKwRmxsLEOGDEEIQUhIiHbI53EsLCzYsmULXbp04cKFC/Tt21c7Wwtg4sSJfPDBB9y4cUPv2qNHj7Jw4UIAhg4datRz9OrVi+3bt5ObmwsU9LYMHz6c3bt3M3PmTK5fv056ejpLly5lw4YNQEGPzapVqxg7diw9e/Zk1KhRRt0LCtZcAnjnnXd0hr4iIyPZsmULKpWKIUOG6FyzefNmnJycePll/aUkNIt0Tp06VafXLCkpSbti9quvvmqwDcHBwaSkpGiPHzp0iNWrV1OnTp0y72dX7kq9SYlU4ariXmw1zci50dq951KuZFR2c6QaQu7F9nixsbGibt26AhD29vbCx8dHDB8+XLRp00YAQqlUioULFxq8tqi92IQQIiMjQ7i6ugpAdO7cWdy7d08IIYSPj4+2XhcXF+Hn5yf8/PxE+/btBSAA4eXlJXJzc41q//HjxwUgVq5cqT2WlpYmHB0dtfUBwsTERCxcuFDn2IgRI8Tdu3dL9H6p1Wrh6+ur3U/Oz89PeHp6CoVCISwtLcWBAwf0rgkNDRWA8PDwMFifv7+/AES9evXEwIEDhaenpzA3NxeA+Pe//22wHdOmTROAqFWrlvDx8RFeXl7C1NRUKJVKERERYfSzyL3YJKkK0B1ikz1IklQV9O/fn5SUFFasWMG2bduIj48nLy+PJk2aMHHiRN58881S5bPY2toSFxeHu7s7iYmJDB48mJiYGFatWoW3tzdxcXEkJycTFxdHdnY29evXp3///owePZrRo0cbPZXe1dWVoUOHMnfuXHr16oWzszP29vYkJSURGhrK6dOnqVevHsOHD6dly5akpqaiUqnw8vLC2dm5xM+lVCoJDw9nxYoVrFmzhm3btmFtbY2vry8LFiwocZ1KpZLvv/8eT09Pvv76a+Lj41EoFLi5ufHqq68WOfz3ySef4OrqyqpVq9i5cydmZmb07t2befPm0b179xI/V0VTCCF/61dVmn+0mpVLpSdv7Pvbybz3AICP3+yB0zP1KrlFUk2Qn5/P+fPngYIEV6VSZkP806SlpdGhQwcUCgVbt241OFutsPz8fNRqdbFbrPzTleSzUdbv0Gr9qcvJyeG9997j2WefxdLSkqZNmzJ+/PgipxIakpmZyXfffceoUaNo27Yt1tbW2NjY0LlzZ1asWPHYmRL5+fl88sknPP/881hZWdGwYUP8/f1JTk4uj8eTqoDCs9jkStqSJJWXRo0aER0dTX5+Pl27dmX27Nl6yeFQsCBjZGQkbm5ujB8/vhJaWnNV2wApJyeH3r17s2DBArKysvDx8eGpp54iNDSUF154QTuroDhLlixh9OjR/N///R+1atVi0KBBdOrUiV9++YW33nqLXr16aRewKkwIwYgRI5g+fTrXrl1jwIABODs7s2nTJtzc3Axm90vVjxxikySpori4uHDkyBF69epFSEgITZo0oX379gwdOpRRo0bRs2dP6tWrx7Bhw8jNzWXq1KmV3eQapdoGSB9++CEHDx7Uzjr4v//7PxITE1m6dCk3b940OtKuXbs2c+bM4cqVKxw7dozvv/+en376iVOnTvH000+zf/9+goOD9a4LDQ0lIiICBwcHzp07p105NDw8nOzsbEaPHs3Dhw/L+7GlJ0zOYpMkqSI1a9aMbdu2ceDAAaZMmUJeXh7x8fFERkZy6dIlBg4cSGRkJKdOndJZZVuqeNUyBykvLw97e3syMzP5+eef9RbMcnFx4eTJkxw7dsyoXZ+LsnHjRkaNGsUzzzzDpUuXdM45OzuTnJzM5s2b9aZH+vj4sGXLFiIiIhg2bFip7y9zkCrfpA93kXqrYHn8BZO60N6x+E0yJamsZA6SJBkmc5CKsX//fjIzM2nVqpXB1UT9/PwA2Lp1a5nuo1mB9I8//tA5funSJZKTk7GysmLAgAEVdn+p8hX+7MkhNkmSpJqjWgZIv/zyC6C7UmdhmuOacqX122+/AQV7zhi6/3PPPWdwRkF53V+qfHKITZIkqWaqlusgaTb2a968ucHzmuOacqW1YsUKoGDIrCLvX9QaFBcvXqRVq1ZG1SFVDLkXmyRJUs1ULXuQNJv31apVy+B5a2trnXKl8d///pddu3Zha2vLrFmznvj9parBpNAYmxxikyRJqjmqZQ+SJq+8qFVLy5p3vmfPHqZNm4ZCoWDNmjV6GxAWd/+SKiqBrDQrpkrlSycHKb/y2iFJkiQ9WdUyQLKxsQHg/v37Bs9r1i2qXbt2ies+efIkQ4YMITc3l5UrV+Lr61vi+2uOl+b+UtUic5AkSZJqpmo5xPb0008DFLlitua4ppyxLl68SL9+/cjMzOT999/nzTfffKL3l6oenZW05RCbJElSjVEtAyTN9Puff/7Z4HnN8ZJsVvjHH3/wr3/9ixs3bjBt2jTee++9Yu9/+vRpg1uRlOb+UtUke5AkSZJqpmoZIHXr1o26dety8eJFjh8/rnc+IiICgIEDBxpVX0ZGBv369ePSpUu88sorLF++/LHlVSoVbdq0ITs7m+jo6DLfX6q6dAMkmYQkSZJUU1TLAMnc3Jw33ngDgDfeeEMnF2jZsmWcPHmS7t276yzLvmrVKpycnJg9e7ZOXX/99Rfe3t6cPn2a4cOH89VXXxmVfB0YGAjAO++8w59//qk9HhkZyZYtW1CpVHorbEvVj+5mtZXYEEmSdKSnpzN//nzat2+Pra0ttWrVonXr1kyaNInTp08XeZ2npycKhYLdu3cbPL98+XIUCgXW1tYkJCTonAsPD6dfv340aNAAMzMz7O3tadeuHRMmTCAsLKw8H6/cVcTm6jdu3GD69Ok8++yzWFlZUa9ePTp06MA777yjV/b9999HoVAU+fPobPGqoFomaQPMmzePXbt2cfDgQRwcHOjRoweXL18mMTGR+vXrExoaqlM+PT2d8+fPk5qaqnN87ty5HD58GBMTE0xNTZkwYYLB+61du1bn9fjx44mJiWHz5s04OTnRu3dv0tPT2bNnD5aWlnz77bcGF5GUqhe5Wa0kVT27du3C39+fzMxMGjZsiIeHBxYWFpw6dYqvvvqKNWvWEBwcXOIv3WXLljFjxgysra2JiYnB3d1de27cuHGsW7cOADc3N1QqFWq1mjNnzrBmzRrCwsIYPXp0qZ/pzJkzhIWFERcXx5UrV7h79y5NmzbFycmJkSNHMmzYMO0SMiWl2Vw9IiICW1tbBgwYQHp6Ops2bSI6OpqEhAQ6d+5cojoPHTqEt7c3mZmZtG3blsGDB3Pv3j2Sk5NZtmwZH330kcHrunXrRuvWrfWOl2VbsAojqrG//vpLzJ8/X7Rq1UqYm5uLRo0aiYCAAHHlyhW9su+9954AREBAgM7xgIAAART7Y8jDhw/F0qVLhbOzs7C0tBT169cXQ4cOFadPny6X52vbtq1o27ZtudQllc67Xx4UAwOjxMDAKLFt/2+V3RyphlCr1SI5OVkkJycLtVpd2c2pUo4cOSLMzc2FQqEQixYtEnl5eTrno6OjhZ2dnQDEihUr9K738PAQgEhISNA5/vHHHwtA1K5dW+zbt0/nXEREhACEnZ2dOHr0qF6dFy5cEEFBQaV6nlu3bomxY8cKpVIpFAqFcHJyEr6+vmLkyJHC3d1d1KlTRwCiWbNmIjY2tlT3+OabbwQgHBwcxI0bN/Seq1WrVnrv4+Ncv35d2NraCisrKxEZGal3PjExUe+Y5js4NDS0VM+gUZLPRlm/Q6t1gPRPJwOkyvf+V4e0AdKWvRcruzlSDSEDJMPy8/NFmzZtBCAWLlxYZLk9e/YIhUIhLC0txe+//65zzlCAtHjxYgEIGxsbceDAAb36Ro0aJQAxb968cnsWIYRISUkRrVu3FqampuLNN98Uv/2m/0dYdna2CAsLE0899ZQAxKpVq0p8n7Zt2wpAbN68We/c4MGDBSAiIiKMrm/s2LECEJ9++qnR11THAKla5iBJ0pNiIofYJKnKiI2N5ezZszRr1oygoKAiy7m7u+Pv709OTg6fffbZY+sMCQkhKCiIunXrEhcXR9euXfXK3Lx5E4CGDRuW7QEKuXPnDgMGDOD27dvs2rWLlStXolKp9MpZWloyatQozpw5Q58+fZg6dSo//vij0fcp783VMzIy+OGHH6hbty4TJ040uh3VUbXNQZJKLiP9Bge/WlnZzahyLOwb4j72dczNLfTOyWn+klR1xMTEAODv719sjueoUaP44YcfiI2NLTIfZtGiRcyZMwdbW1t27NhBp06dDJbT7K+5YcMGJkyYUOpcoMICAwO5fPkyR44cMWpJGBsbG6KioujRoweTJ0+mZ8+e1KlTp9jryntz9QMHDvDgwQP69OmDmZkZERER7N+/n7y8PJycnBg+fDiNGjUq8vr4+HhOnDhBTk4OzZs3x8vLq2rmHyEDpBrl/t3b2B4+X9nNqILOE5+TQ/8ps/XOyM1qpapKCMGDnIeV3YwSsbA0LdMWTSdOnACMS+jVlElOTiYvL08vOFiyZAnR0dHY2dkRFxeHm5tbkXWNHz+etWvXcuzYMVQqFb6+vnTv3p2uXbuWakPxlJQU1q1bR0hIiE5wtHPnTubMmcOpU6do0KABL730Eq+99hqtWrUiNDSUcePGsXr1ajp16sSGDRuYMmVKsfcq783VNVtjNWrUiB49enDo0CGd87NnzyY0NBR/f3+D12/YsEHn9fz58xk2bBhr166tcrtPyABJkoC8P24YPC5nsUlV1YOch3w0b3tlN6NE3gnuj6VV6Wf33rp1CwB7e/tiy2qGw/Lz87l9+7Zer4ZmDbvg4ODHBkcA3bt3Z/369UydOpWbN2/y5Zdf8uWXXwLQokULJk2aRGBgIJaWlkY9x7fffouVlRWvv/669lh8fDze3t4olUp69OiBubk5X3zxhd5yBB07dsTV1ZWoqCijAqTy3lw9IyMDgPXr12NhYcE333zD4MGDycrK4tNPP2XZsmWMGTMGR0dHneCvdevWLFmyBC8vL1q0aEFGRgZ79+7lnXfeYdOmTajVajZv3mxUG54UGSDVILVs7MjopD+9ssa6cgO7GwW/FEQRi0DKHiRJqjrE//5IEUb8sVK4jKFeq27dunHgwAFmzZqFm5tbkcNrGmPGjMHHx4fIyEh++uknjh49yrlz57h8+TJz585ly5YtJCQkYGVlVWzb4uLi8PHx0Qlapk+fjomJCfv27dOu4ZeSkmIwJ6pLly6Eh4cXex8o/83V1Wo1AA8fPuSzzz5j/PjxADRo0IClS5dy5coVIiIi+Oijj/j222+1140ZM0anHmtra0aNGkXPnj15/vnniYqK4uDBgwaft7LIAKkGqdewCQPnLq7sZlQZO75YDNuPFLwoIvhRFprGIAMkSapcDRo04Pz58zqL8xZFk1itUCiws7PTOx8cHExYWBhff/01Xl5e7N69m+eff/6xddrY2BAQEEBAQABQsO/m559/zkcffURiYiLLli1j7ty5xbbt0qVLeHt7a19fu3aNkydPMmnSJJ0Fjh0cHJg2bRrz58/Xud7W1pbMzMxi76NpM5Tf5uqa+pRKpfZ9KGz8+PFEREQUuRDno5o0acIrr7zCkiVL2LFjhwyQJKkqUOhGPwbLFB5ik5vVSlWJhaUp7wT3r+xmlIiFZdm+clxcXDhw4ABJSUmMHTv2sWWTkpIAcHZ2LjKhe/Xq1WRlZfH999/Tt29f9u3bZ3ARw6I0b96cDz/8kNzcXJYuXUp0dLRRAdKjQ36a/B9Dydqurq56x1JTU7G1tTWqjeW9ufozzzwDQOPGjbGw0J/YojlvTBCr4eDgAKC3kHNlk9P8pRpLoTT5+4UcYpOqGYVCgaWVWbX6Keswj5eXF1Cw36WhjcIL++677wDo37/oIFKpVLJhwwYGDRrEjRs36N27N1evXi1xuzw9PYGCHRuM8WgPkLm5OWA4D+jRY0IIEhMTad++vVH3Ku/N1TX3zcjIMDjUqckTK0nCtSavqaolacsASaqxFCaFflkX0Tskp/lLUtXh7e2No6Mj169fZ/HiotMF9u7dS0REBObm5sUmMpuamhIeHk6vXr24cuUKffr0IS0tTadMcTlPFy9eBKBp06ZGPUeLFi109otzcnLC1NSU7dv1k+537Nih8zoiIoKzZ88W24OmUd6bqz///POoVCqys7NJTEzUO68ZWtMsH1AcIYQ2ObuqTfeXAZJUYymUf3f3K4wYYpPxkSRVLqVSydq1azEzM+Pdd99l8eLF2qRhjdjYWIYMGYIQgpCQEO2Qz+NYWFiwZcsWunTpwoULF+jbt6+2VwNg4sSJfPDBB9y4oT/b9ejRoyxcuBCAoUOHGvUcvXr1Yvv27eTm5gIFPSfDhw9n9+7dzJw5k+vXr5Oens7SpUu10+IzMjJYtWoVY8eOpWfPnowaNcqoe0HpNlfX7DP68ssv69WnWaRz6tSpOr1mSUlJLF26FIBXX31Vezw9PZ3169fz4MEDnXqysrJ47bXXSExMpHHjxvj6+hr9TE9Eqdfgliqc3GqkYsWvXyX2Dx4q9g8eKra8OcFgmf9u+kW71chXUaeecAulmkpuNfJ4sbGxom7dugIQ9vb2wsfHRwwfPly7DYlSqSxyK5Ki9mITQoiMjAzh6uoqANG5c2dx7949IYQQPj4+2npdXFyEn5+f8PPzE+3bt9fu1+nl5SVyc3ONav/x48cFIFauXKk9lpaWJhwdHXX2ADUxMRELFy7UOTZixAhx9+7dEr1farVa+Pr6aveT8/PzE56entrtWAxtrxIaGioA4eHhYbA+f39/AYh69eqJgQMHCk9PT2Fubi4A8e9//1un/KVLlwQg6tSpIzp37iz8/f3Fv/71L1G/fn0BCFtbW7F//36jn+VJbTUik7SlGks3SduIITaZpC1JVUL//v1JSUlhxYoVbNu2jfj4ePLy8mjSpAkTJ07kzTffNDqnpjBbW1vi4uJwd3cnMTGRwYMHExMTw6pVq/D29iYuLo7k5GTi4uLIzs6mfv369O/fn9GjRzN69Gijc6xcXV0ZOnQoc+fOpVevXjg7O2Nvb09SUhKhoaGcPn2aevXqMXz4cFq2bElqaioqlQovLy+cnZ1L/FxKpZLw8HBWrFjBmjVr2LZtG9bW1vj6+rJgwYIS16lUKvn+++/x9PTk66+/Jj4+HoVCgZubG6+++qre8F/9+vUJCgri8OHD/Prrr5w4cQITExNUKhXjxo1j+vTpNGvWrMTPVdEUQsjf+lWV5h+tZuVSqXzt+f4rTDcWjPnfblaHQZ+H6pX5ZstpovYU5BcM6Kbi1aEl/6UrSSWVn5/P+fMFq947OjqiVMpsiH+atLQ0OnTogEKhYOvWrQZnqxWWn5+PWq0udouVf7qSfDbK+h0qP3VSjaU0+XsWm6KIvxNMZJK2JEkVoFGjRkRHR5Ofn0/Xrl2ZPXu2XnI4FCzIGBkZiZubm3ZRRunJkENsUo0lh9gkSapMLi4uHDlyhMmTJxMSEsLixYtxcXFBpVJhaWlJamoqSUlJ3Lt3D2dnZ6ZOnVrZTa5RZIAk1ViKwj1IRQVIch0kSZIqULNmzdi2bRsHDx5k48aNJCQkEB8fT05ODo0bN2bgwIH4+/szZMiQctsuRDKODJCkGkupNEE7ud+IdZDUMkCSJKmCdO3atUptsyHJHCSpBlOY/P3Pv8geJDnEJkmSVCPJAEmqsZSmhTpQjRliU8sASZIkqaaQAZJUYymVxc9ik5vVSpIk1UwyQJJqLKVJoa1GigqQZJK2JElSjSQDJKnGUpY0B0kGSJIkSTWGDJCkGkth1BDb3/8tk7QlSZJqDhkgSTWW0uTvJfuL6kEykUNskiRJNZIMkKQaS2eIrYjYRw6xSZIk1UwyQJJqrMJ7scmtRiRJkqTCZIAk1Vgmpn8PsSmL6kHSGWKr6BZJkmSs9PR05s+fT/v27bG1taVWrVq0bt2aSZMmcfr06SKv8/T0RKFQsHv3boPnly9fjkKhwNramoSEBJ1z4eHh9OvXjwYNGmBmZoa9vT3t2rVjwoQJhIWFlefjlbv8/Hw++eQTnn/+eaysrGjYsCH+/v4kJyeXqJ7du3ejUCiK/VmwYIHB69evX0+nTp2oXbs29erVw9vbm4MHD5bHI5Y7udWIVGMV3qzWmHWQZA+SJFUNu3btwt/fn8zMTBo2bIiHhwcWFhacOnWKr776ijVr1hAcHMysWbNKVO+yZcuYMWMG1tbWxMTE4O7urj03btw41q1bB4CbmxsqlQq1Ws2ZM2dYs2YNYWFhjB49utTPdObMGcLCwoiLi+PKlSvcvXuXpk2b4uTkxMiRIxk2bBjW1talqlsIwYgRI4iIiMDW1pYBAwaQnp7Opk2biI6OJiEhgc6dOxtVV+PGjQkICDB4Tq1W8+233wLQo0cPvfOBgYEsX74cKysr+vbtS05ODjt37iQuLo7w8HB8fX1L9XwVRkhVVtu2bUXbtm0ruxn/WL+ePib2Dx4q9g8eKhJ8hxksE3/sihgYGCUGBkaJt1fufcItlGoqtVotkpOTRXJyslCr1ZXdnCrlyJEjwtzcXCgUCrFo0SKRl5encz46OlrY2dkJQKxYsULveg8PDwGIhIQEneMff/yxAETt2rXFvn37dM5FREQIQNjZ2YmjR4/q1XnhwgURFBRUque5deuWGDt2rFAqlUKhUAgnJyfh6+srRo4cKdzd3UWdOnUEIJo1ayZiY2NLdY9vvvlGAMLBwUHcuHFD77latWql9z6WRkxMjADEU089pffv9qeffhKAqF+/vrhw4YL2+MGDB4W5ubmoW7euuH37drH3KMlno6zfoXKITaqxTAptNaKUC0VKUpUnhCAgIIDc3FwWLFjArFmzMDXVHQjx9vYmKioKhUJBUFAQly9fLrbejz76iLfffhsbGxt27NhB9+7ddc5HRkYCMGXKFNzc3PSud3BwICQkpMTP8+uvv9K5c2c2btzIlClTuHjxImfPniUyMpKNGzeyZ88e0tLSCAsLQ6lU4uXlxWeffVbi+yxdulT7nI0aNdIeHzZsGIMHD+bixYv8+OOPJa73UZreo9GjR6NU6oYXmjbMmzcPBwcH7fEuXbrw6quvcufOHdasWVPmNpQnGSBJNZaJzjpIhsvIrUYkqeqIjY3l7NmzNGvWjKCgoCLLubu74+/vT05OTrEBRUhICEFBQdStW5e4uDi6du2qV+bmzZsANGzYsGwPUMidO3cYMGAAt2/fZteuXaxcuRKVSqVXztLSklGjRnHmzBn69OnD1KlTSxTMXLp0ieTkZKysrBgwYIDeeT8/PwC2bt1a+ocB7t+/r23XmDFjdM7l5OTw008/6dyvItpQ3mSAJNVYhbcaUYqCJEa9MnKavyRVGTExMQD4+/tjZmb22LKjRo0CCoKqoixatIjZs2dja2tLXFwcL774osFyzZs3B2DDhg3cv3+/NE3XExgYyOXLl0lISMDDw6PY8jY2NkRFReHi4sLkyZO5e/euUff55ZdfAHjuuecMvmcvvPCCTrnSioyM5P79+7Rv3x5nZ2edc+fOnePBgwc0bNhQ+14aasPJkyfL1IbyJgMkqcZSmul2zQu1Wr+MHGKTqighBA/zsqvVjyhjL+yJEycA6NChQ7FlNWWSk5PJy8vTO79kyRLmzJmDnZ0dO3fupFOnTkXWNX78eBQKBceOHUOlUjF58mQ2bNjAxYsXS/UcKSkprFu3juDgYNq1a6c9vnPnTjp27IilpSXNmzfn7bff5rfffkOhULB27Vqsra1ZvXo1aWlpbNiwwah7XblyBcBgYFL4uKZcaWmG18aOHVviNlhbW2Nra0tGRgb37t0rUzvKk5zFJtVYykJDbFAwA8Pkkb+wTOQsNqmKUj/M4ZeEdyu7GSXi0nMBpmZWpb7+1q1bANjb2xdbVjMclp+fz+3bt3VybwCio6MBCA4ONphXVFj37t1Zv349U6dO5ebNm3z55Zd8+eWXALRo0YJJkyYRGBiIpaWlUc/x7bffYmVlxeuvv649Fh8fj7e3N0qlkh49emBubs4XX3yhtxxBx44dcXV1JSoqiilTphR7r6ysLABq1apl8LxmZpymXGncuHGDn376CRMTE1566aUSt0HTjszMTLKysrCxsSl1W8qT7EGSaiwTE92/D/LVD/XKyCE2Sao6ND1QxvREFS6jKNQTrNGtWzcAZs2axZEjR4qtb8yYMVy+fJm1a9cyduxYnJycALh8+TJz587F09OT7Oxso54jLi4OHx8fnYBh+vTpmJiYsH//fnbt2kVMTAzHjx/n999/17u+S5cu2t604mjeB0PvQXn57rvvUKvV/Otf/6Jx48alakNZexcrggyQpBqr8EKRAA/V+t3wMkCSpKqjQYMGAPz555/FltUkVisUCuzs7PTOBwcHM3HiRO7du4eXlxenTp0qtk4bGxsCAgJYv349Z8+e5erVq8yePRsTExMSExNZtmyZUc9x6dIlHB0dta+vXbvGyZMnCQgIoGPHjtrjDg4OTJs2Te96W1tbMjMzjbqXpjemqNwpzfHatWsbVZ8hjxteM6YNAH/99VeZ21He5BCbVGPpbDUCqA30IOlsVlsF/8KRai4TU0tcehperbiqMjE1bgiqKC4uLhw4cICkpKQiv4w1kpKSAHB2di4yoXv16tVkZWXx/fff07dvX/bt20fr1q2Nbk/z5s358MMPyc3NZenSpURHRzN37txir3t0yE+To1M4H0nD1dVV71hqaiq2trZGtfHpp58GCoIwQzTHNeVK6uzZsxw/fpzatWszZMiQUrXh/v37ZGZmYmtrW2WG10D2IEk1mP4Qm4EkbdmDJFVRCoUCUzOravVT1mEeLy8vACIiIgwmXhf23XffAdC/f/8iyyiVSjZs2MCgQYO4ceMGvXv35urVqyVul6enJ1Cw/YkxHu0BMjc3BwznAT16TAhBYmIi7du3N+peLi4uAJw+fdrge/bzzz8DhoMzY2iSxYcOHVpkjpGjoyMWFhbcvHnTYJBU1jZUFBkgSTWWqYnuX5Xqh3KITZKqMm9vbxwdHbl+/TqLFy8ustzevXuJiIjA3Ny82ERmU1NTwsPD6dWrF1euXKFPnz6kpaXplCkuP0Yzm61p06ZGPUeLFi109otzcnLC1NSU7du365XdsWOHzuuIiAjOnj1bbA+ahkqlok2bNmRnZ2sT0x+tD2DgwIFG1VeYEEIbiD6uPVZWVvTq1UvnfuXVhookAySpxlI+0oNkaIhNKYfYJKnKUCqVrF27FjMzM959910WL16M+pGe39jYWIYMGYIQgpCQEJ555pli67WwsGDLli106dKFCxcu0LdvXzIyMrTnJ06cyAcffMCNGzf0rj169CgLFy4ECnpRjNGrVy+2b99Obm4uUJB3M3z4cHbv3s3MmTO5fv066enpLF26VNtDk5GRwapVqxg7diw9e/bUrvNkjMDAQADeeecdnfytyMhItmzZgkql0hse27x5M05OTrz88stF1rtv3z4uX75M06ZNtQFQcW0IDg4mJSVFe/zQoUOsXr2aOnXqMGHCBKOf6Yko9SYlUoWTe7FVrIcP87R7se0fPFT8cSVFr8y5329p92Ib827p9kGSpJKSe7E9XmxsrKhbt64AhL29vfDx8RHDhw8Xbdq0EYBQKpVi4cKFBq8tai82IYTIyMgQrq6uAhCdO3cW9+7dE0II4ePjo63XxcVF+Pn5CT8/P9G+fXsBCEB4eXmJ3Nxco9p//PhxAYiVK1dqj6WlpQlHR0dtfYAwMTERCxcu1Dk2YsQIcffu3RK9X2q1Wvj6+mr3k/Pz8xOenp5CoVAIS0tLceDAAb1rQkNDBSA8PDyKrPff//63AMTbb79tVDumTZsmAFGrVi3h4+MjvLy8hKmpqVAqlSIiIsLoZ3lSe7HJJG2pxtLLQcp7/DR/tYGVtiVJevL69+9PSkoKK1asYNu2bcTHx5OXl0eTJk2YOHEib775ZqnyWTQraru7u5OYmMjgwYOJiYlh1apVeHt7ExcXR3JyMnFxcWRnZ1O/fn369+/P6NGjGT16tNE5Vq6urgwdOpS5c+fSq1cvnJ2dsbe3JykpidDQUE6fPk29evUYPnw4LVu2JDU1FZVKhZeXl94q1cZQKpWEh4ezYsUK1qxZw7Zt27C2tsbX15cFCxaUqs4HDx5oh8Ye3VqkKJ988gmurq6sWrWKnTt3YmZmRu/evZk3b57e/ndVgUIIOW5QVWn+0Z45c6aSW/LPtW/IMJT/+wQ8veQ/POXwnM75i9cyeWv5HgCsLU35/gP9vYwkqbzl5+dz/vx5oCDB9dGNP6XqLy0tjQ4dOqBQKNi6davB2WqF5efno1ari91i5Z+uJJ+Nsn6Hyk+dVKPlF/qD72FxC0XKvyUkSSonjRo1Ijo6mvz8fLp27crs2bP1ksMBHj58SGRkJG5ubowfP74SWlpzySE2qUYTCgUFQ/vFT/NXyxE2SZLKkYuLC0eOHGHy5MmEhISwePFiXFxcUKlUWFpakpqaSlJSEvfu3cPZ2ZmpU6dWdpNrFBkgSTWaUAL/i4sMbjUiN6uVJKkCNWvWjG3btnHw4EE2btxIQkIC8fHx5OTk0LhxYwYOHIi/vz9Dhgyp0O1CJH0yQJJqtPzCPUgPDaykLYfYJEl6Arp27UrXrl0ruxlSITIHSarRRKE/yPLz5UrakiRJUgEZIEk1W+EAyFAO0iNd2jJIkiRJqhlkgCTVaPmFc4yKmcUGcphNkiSpppABklSzFfoEFDeLDWQPkiRJUk0hAySpRhOFepCEoRwkOcQmSZJUI8kASarRROF1jozpQZJDbJIkSTWCDJCkGk2nB0kOsUmSJEn/IwMkqUYTOgtBGhpi032tlgGSJElSjSADJKlmKzzN38BCkXKITZIkqWaSAZJUoxXOQRIGNlszkUNskiRJNZIMkKSardghtkcDpApvkSRJRkhPT2f+/Pm0b98eW1tbatWqRevWrZk0aRKnT58u8jpPT08UCgW7d+82eH758uUoFAqsra1JSEjQORceHk6/fv1o0KABZmZm2Nvb065dOyZMmEBYWFh5Pl65y8/P55NPPuH555/HysqKhg0b4u/vT3Jyconq2b17NwqFotifBQsW6Fz3/vvvP7b8rFmzyvNxy4Xci02q0XR7kOQsNkmqDnbt2oW/vz+ZmZk0bNgQDw8PLCwsOHXqFF999RVr1qwhODi4xF+6y5YtY8aMGVhbWxMTE4O7u7v23Lhx41i3bh0Abm5uqFQq1Go1Z86cYc2aNYSFhTF69OhSP9OZM2cICwsjLi6OK1eucPfuXZo2bYqTkxMjR45k2LBhWFtbl6puIQQjRowgIiICW1tbBgwYQHp6Ops2bSI6OpqEhAQ6d+5sVF2NGzcmICDA4Dm1Ws23334LQI8ePQyW6datG61bt9Y73qFDByOf5smRAZJUsxUOkAx0DykUCpQK0IysySE2SapcR48eZcCAAeTl5bFo0SJmzpyJqenfX2UxMTGMGTOG2bNnU6tWLaZOnWpUvUuWLOHtt9+mdu3axMbG0r17d+25TZs2sW7dOuzs7IiLi8PNzU3n2pSUFL755ptSPc/t27d56623CAsLQwiBo6Mj3bt3x8LCgj/++IMDBw4QGxvLnDlz+Prrr+nfv3+J7xEaGkpERAQODg7s27ePRo0aaZ/Lz8+P0aNHc+7cOZ33sShOTk6sXbvW4LnY2Fi+/fZbnnrqKTw8PAyWmThxIuPGjSvxM1QGOcQm1WhC+fdHwNBK2vDIhrWyB0mSKo0QgoCAAHJzc1mwYAGzZs3S+1L39vYmKioKhUJBUFAQly9fLrbejz76iLfffhsbGxt27NihExwBREZGAjBlyhS94AjAwcGBkJCQEj/Pr7/+SufOndm4cSNTpkzh4sWLnD17lsjISDZu3MiePXtIS0sjLCwMpVKJl5cXn332WYnvs3TpUu1zaoIjgGHDhjF48GAuXrzIjz/+WOJ6H6XpPRo9ejRKZfUPL6r/E0hSWeisg6Q/iw1085BkD5IkVZ7Y2FjOnj1Ls2bNCAoKKrKcu7s7/v7+5OTkFBtQhISEEBQURN26dYmLi6Nr1656ZW7evAlAw4YNy/YAhdy5c4cBAwZw+/Ztdu3axcqVK1GpVHrlLC0tGTVqFGfOnKFPnz5MnTq1RMHMpUuXSE5OxsrKigEDBuid9/PzA2Dr1q2lfxjg/v372naNGTOmTHVVFTJAkmq2YobY4JEeJBkgSVKliYmJAcDf3x8zM7PHlh01ahRQEFQVZdGiRcyePRtbW1vi4uJ48cUXDZZr3rw5ABs2bOD+/fulabqewMBALl++TEJCQpHDUYXZ2NgQFRWFi4sLkydP5u7du0bd55dffgHgueeeM/ievfDCCzrlSisyMpL79+/Tvn17nJ2diywXHx/PW2+9xauvvkpwcDBJSUllum9FkgGSVKPJITapuhJC8Ffew2r1I8r4+Tlx4gRgXEKvpkxycjJ5eXl655csWcKcOXOws7Nj586ddOrUqci6xo8fj0Kh4NixY6hUKiZPnsyGDRu4ePFiqZ4jJSWFdevWERwcTLt27bTHd+7cSceOHbG0tKR58+a8/fbb/PbbbygUCtauXYu1tTWrV68mLS2NDRs2GHWvK1euAH8HeY/SHNeUKy3N8NrYsWMfW27Dhg2sWLGC1atXM3/+fNzc3PDz8yMrK6tM968IMklbqtl0epCKCJAUhfdrkwGSVDVkP1QzbefJym5Giaz4VztqmZX+a+fWrVsA2NvbF1tWMxyWn5/P7du3dXJvAKKjowEIDg42mFdUWPfu3Vm/fj1Tp07l5s2bfPnll3z55ZcAtGjRgkmTJhEYGIilpaVRz/Htt99iZWXF66+/rj0WHx+Pt7c3SqWSHj16YG5uzhdffKG3HEHHjh1xdXUlKiqKKVOmFHsvTeBRq1Ytg+c1M+PKEqDcuHGDn376CRMTE1566SWDZVq3bs2SJUvw8vKiRYsWZGRksHfvXt555x02bdqEWq1m8+bNpW5DRZA9SFLNppODZDj4kT1IklQ1aHqgjOmJKlxG8ch6ZlAw3Rxg1qxZHDlypNj6xowZw+XLl1m7di1jx47FyckJgMuXLzN37lw8PT3Jzs426jni4uLw8fHRCVqmT5+OiYkJ+/fvZ9euXcTExHD8+HF+//13veu7dOmi7U0rjuZ9MPQelJfvvvsOtVrNv/71Lxo3bmywzJgxY5gxYwZt27bF2tqa5s2bM2rUKI4ePUr9+vWJiori4MGDFdbG0pA9SDVIxq2/+HLZnspuRoUyNzfFs78j7Ts/bdwFJn//jSDyi0jSljlIklQlNGjQgPPnz/Pnn38WW1aTWK1QKLCzs9M7HxwcTFhYGF9//TVeXl7s3r2b559//rF12tjYEBAQoF0H6Nq1a3z++ed89NFHJCYmsmzZMubOnVts2y5duoS3t7f29bVr1zh58iSTJk2iY8eO2uMODg5MmzaN+fPn61xva2tLZmZmsffRtBkoMndKc7x27dpG1WeIscNrhjRp0oRXXnmFJUuWsGPHDoNJ8pWlWgdIOTk5LFq0iI0bN3LlyhXq1atH//79WbBgQZHjrYbs2bOH3bt3c+TIEY4cOUJ6ejqOjo6cO3euyGsKLxpmyBdffMGrr75aouepeIIHOYaDgH+KBzkPSdh+zvgASVE4QCqiB6nwEJsMkKQqwsrUhBX/ald8wSrEytSkTNe7uLhw4MABkpKSiv0y1iT/Ojs7F5nQvXr1arKysvj+++/p27cv+/btM7iIYVGaN2/Ohx9+SG5uLkuXLiU6OtqoAOnRIT9N/k/hfCQNV1dXvWOpqanY2toa1canny74XXjt2jWD5zXHNeVK6uzZsxw/fpzatWszZMiQUtXh4OAAFDxXVVJtA6ScnBx69+7NwYMHadKkCT4+Pvz++++Ehoaybds2Dh06RKtWrYyqa9q0aaXO4O/Xr5/BLkVHR8dS1SeVXYmCwMIrZReVgySH2KQqSKFQlCmfpzry8vLi888/JyIigo8//vixM9m+++47gMcurKhUKrUz07Zu3Urv3r3Zv38/Tz31VIna5enpydKlS0lPTzeq/KM9QObm5oDhPKBHjwkhSExMpH379kbdy8XFBYDTp0+Tl5en9579/PPPgOHgzBiaZPGhQ4cWmedUnIyMDKBsvVgVodp+uj788EMOHjxIly5diIuL076xmqXix48fz549xg0n9e3bl+HDh9OxY0caNGignfZojFmzZuHp6VmaR3jibOpaMmmGe/EFq6E7t7P5v9CjAKgNbDpbpEJDbPkPjQiQZA+SJFUab29vHB0dOX/+PIsXL2bevHkGy+3du5eIiAjMzc2LTWQ2NTUlPDwcb29v4uPj6dOnD3v37tXp4RFCPDaHRzObrWnTpkY9R4sWLXT2i3NycsLU1JTt27frre+0Y8cOndcRERGcPXuW2bNnG3UvlUpFmzZtOHv2LNHR0Xq9PBEREQAMHDjQqPoKE0JoA9HSDK9p6tAkZ1e57UZENZSbmytsbW0FIH7++We98+3atROAOHbsWInrvnTpkgCEo6PjY8sFBAQIQCQkJJT4HsZq27ataNu2bYXV/09y62aW+E/gloKfGVuMvm7LvLfE/sFDxf7BQ0XMsv8YLPPvD3aKgYFRYmBglPj5XFp5NVmSiqRWq0VycrJITk4WarW6sptTpRw6dEiYmZkJhUIhQkJCxMOHD3XOx8TECDs7OwGIZcuW6V3v4eFh8Hd3VlaW6NKliwBEu3btxO3bt7Xnxo8fL4KDg0VqaqpefUeOHBH169cXgFixYoVRz/DOO++Ihg0bigcPHmiPjRo1SgBixowZ4tq1a+LmzZtiyZIlwsTERPssn376qbCwsBA9e/bUe+7H+eqrrwQgHBwcRFra37/DNm3aJAChUqlEbm6uzjWRkZHC0dFRjB07tsh69+zZIwDRtGnTx/47vXnzpli3bp3IycnROX7v3j0xefJkAYjGjRuL+/fvF/ssJflslPU7tFrOYtu/fz+ZmZm0atXKYDdjea0MKlUfOpvKiqLzifQvNGahyL//Ww6xSVLlevHFF9myZQt16tRh1qxZNG3alCFDhjBixAjatm2Lt7c3d+7cYeHChUyfPt3oejUb1Lq6unLy5Em8vLy0w1u3bt1i3rx5NGvWDFdXV/z9/fH39+eFF16gU6dO3Lp1Cy8vL1577TWj7vXSSy9x8+ZNVq9erT22fPlyHB0dWbp0Kc2bN6dhw4YEBQXx/vvvAwULS7755psMGTKEH3/8ERMT4/O5xo8fj6+vLykpKTg5OeHv70/Pnj3x8/PD0tKSb7/9Vm/o7c6dO5w/f/6x6yMZu7VIVlYWAQEB2Nvb8+KLLzJ8+HD69u3LM888w+rVq7G1tSUiIqLUQ3QVpVoOsWnyhYoaCiuvlUGNERkZqV3DQaVSMWjQIO30T+nJUZrodn/n5wtMlEZMa9WZxSaH2CSpOujfvz8pKSmsWLGCbdu2ER8fT15eHk2aNGHixIm8+eabpcqp0ayo7e7uTmJiIoMHDyYmJoZVq1bh7e1NXFwcycnJxMXFkZ2dTf369enfvz+jR49m9OjRRk+ld3V1ZejQocydO5devXrh7OyMvb09SUlJhIaGcvr0aerVq8fw4cNp2bIlqampqFQqvLy8HrtKdVGUSiXh4eGsWLGCNWvWsG3bNqytrfH19WXBggWlqvPBgwfa4bnithapX78+QUFBHD58mF9//ZUTJ05gYmKCSqVi3LhxTJ8+nWbNmpW4DRWtWgZIT2plUGN8+umnOq+DgoJ47bXXWLFihVE7IwNF/uO8ePGi0YnmNd2jf73k5+djYsQyXwqd7qEiepDkXmySVOU0bNiQ4OBggoODS3TdowsvGqr37NmzOseaN2/OpEmTmDRpUkmbWaTPP/+cDh060L9/f7Zu3YqrqyvW1ta88cYbemU/++wz8vPzURex2r8xTExMCAwMJDAw0Kjy48aNY9y4cUWet7Cw4Pbt20bVZWNjU6rNfCtbhQ6xPXz4kLS0NK5cuVLkT2k8iZVBi9O+fXv++9//cuHCBf766y9+++03PvvsM2xtbfn88895++23K+zekj6TR3qQjF7xWmeavxF7sckhNkmSykGjRo2Ijo4mPz+frl27Mnv2bNLS0vTKPXz4kMjISNzc3Bg/fnwltLTmqpAepF27dhEcHMzhw4cN7oGjoVAoePiw5OvyiGJWBhVP4Ets2rRpOq9VKhWvv/467u7udOjQgU8//ZTAwECjpoueOXPG4PHSdHvWVEql/hCbMRSFhtgoYvab7hBbydsmSZJkiIuLC0eOHGHy5MmEhISwePFiXFxcUKlUWFpakpqaSlJSEvfu3cPZ2ZmpU6dWdpNrlHIPkLZt24avry9qtRo7OztatmxZ7msbFLcy6F9//QVUzpoKzz33HIMHDyYiIoJdu3bxyiuvPPE21ESlDZCQQ2ySJFWiZs2asW3bNg4ePMjGjRtJSEggPj6enJwcGjduzMCBA/H392fIkCEVul2IpK/cA6T//Oc/5Ofn88knnzBlypQSZdobq6JXBi2rqroq6D+ZoRwkYxTOQTJmiE0th9gkSaoAXbt2rVLbbEgVECCdOXOGLl26VGhXoGZlUM0KoI8q68qgZVVVVwX9J9PrQTI2B6lwAC97kCRJkqT/Kfck7dq1a+usQFoRunXrRt26dbl48SLHjx/XO1+WlUHL6sGDB0RHRwNVcFXQfzCFUkHh3mejc5B0FzkyWEZO85ckSap5yj1A6tOnDz///LPRQxylYW5urp0K+cYbb+jkIi1btoyTJ0/SvXt3nV2RV61ahZOTk9HLsz/O+fPn+fHHH/WmXN68eZORI0dy9epVXFxcZHfpE1Z4mC3fyO1GjBliM5Gz2CRJkmqcch9iW7x4MR07dmTGjBksWbKkQnKQAObNm8euXbs4ePAgDg4O9OjRg8uXL5OYmEj9+vUJDQ3VKZ+ens758+cN5gV9/fXXfP3110BBDxDA5cuXefHFF7VlPv/8c+0ClKmpqQwZMoT69evj5OREs2bN+PPPP7WzDZo3b84PP/wgE+qeMKWJAk3MavwsNiOG2GQPkiRJUo1T7gFSaGgoXl5erFy5km3btuHp6Unz5s0NBgsKhYL58+eX6j6WlpYkJCSwaNEivvvuO6KiorCzsyMgIICFCxeWaDfma9eukZiYqHMsJydH59jdu3e1//3ss8/y1ltvcfjwYS5evMiRI0ewsLDg2WefZdCgQUybNg07O7tSPZdUeqUJZEo8xCZ7kCRJkmoEhSjnRYOUSiUKhcKotYgUCkWZVgb9p9Osg1TUOkmSro/nbyf7r4J1tya+1YOmT9kWe83Or5ZSa9tBAG452DN4yRd6Zf7z9WGOnS1YwG2y7/MM7N6y/BotSQbk5+dz/vx5ABwdHR+7z5Uk1SQl+WyU9Tu0QnqQJKkyKAst+li6HiQjcpDkEJskSVKNUO4BUkBAQHlXKUlG0VmvqBRJ2hTR6ymH2CRJkmoe2W8r/WOUKgepUJK2oqitRhSFAy8ZIEmSJNUEFRogHTlyhKVLlzJjxgxmzpzJ0qVLOXLkSEXeUqrBdAIkIwMZhbLQLDbZgyRJ1UZ6ejrz58+nffv22NraUqtWLVq3bs2kSZM4ffp0kdd5enqiUCjYvXu3wfPLly9HoVBgbW1NQkKCzrnw8HD69etHgwYNMDMzw97ennbt2jFhwgTCwsLK8/HKnWaHi+effx4rKysaNmyIv78/ycnJparv8OHDDBs2jMaNG2NmZka9evXo3bu3dh3Coqxfv55OnTpRu3Zt6tWrh7e3NwcPHixVGypahWxWe+HCBV5++WWOHj0K6G8u26lTJ9avX6/dkkOSyoNuD5KRQ2wmRsxikytpS1KVsmvXLvz9/cnMzKRhw4Z4eHhgYWHBqVOn+Oqrr1izZg3BwcHMmjWrRPUuW7aMGTNmYG1tTUxMDO7u7tpz48aNY926dQC4ubmhUqlQq9WcOXOGNWvWEBYWxujRo0v9TGfOnCEsLIy4uDiuXLnC3bt3adq0KU5OTowcOZJhw4ZhbW1dqrqFEIwYMYKIiAhsbW0ZMGAA6enpbNq0iejoaBISEujcubPR9YWHhzNy5Ejy8/Nxc3PD09OTP/74g927dxMfH09QUBAhISF61wUGBrJ8+XKsrKzo27cvOTk57Ny5k7i4OMLDw/H19S3V81WUcg+QUlNT8fDwIC0tjaZNm+Lv788zzzwDFKwtFB4eTmJiIp6enhw7dowmTZqUdxOkGqo0SdrKQj1IiiKn+f/93zJAkqTKdfToUQYMGEBeXh6LFi1i5syZmJr+/VUWExPDmDFjmD17NrVq1TJ626slS5bw9ttvU7t2bWJjY+nevbv23KZNm1i3bh12dnbExcXh5uamc21KSgrffPNNqZ7n9u3bvPXWW4SFhSGEwNHRke7du2NhYcEff/zBgQMHiI2NZc6cOXz99df079+/xPcIDQ0lIiICBwcH9u3bp93tYtOmTfj5+TF69GjOnTun8z4W5eHDh0yZMoX8/Hy+//57RowYoT136NAhevXqxUcffcS///1vWrVqpT0XHx/P8uXLqV+/PocOHdJ2kBw6dAhPT09eeeUVPD09q9YSOaKcvf7660KhUIjAwEDx4MEDvfO5ublixowZQqFQiDfeeKO8b/+P0rZtW9G2bdvKbka1sXrJbvGfwC3iP4FbRPIvfxh1zd7wNWL/4KFi/+ChYuvklw2WWb4xSQwMjBIDA6PEhtjk8myyJBmkVqtFcnKySE5OFmq1urKbU2Xk5+eLNm3aCEAsXLiwyHJ79uwRCoVCWFpait9//13nnIeHhwBEQkKC9tjixYsFIGxsbMSBAwf06hs1apQAxLx588rtWYQQIiUlRbRu3VqYmpqKN998U/z22296ZbKzs0VYWJh46qmnBCBWrVpV4vu0bdtWAGLz5s165wYPHiwAERERYVRdp06dEoBwcnIyeN7Hx0cA4v/+7/90jnt7ewtALF++XO+aqVOnCkAsWbKk2PuX5LNR1u/Qcs9BiomJwdHRkaVLl2Jubq533szMjI8//hhHR0e2bdtW3reXajClScmHwpRyiE2Sqo3Y2FjOnj1Ls2bNCAoKKrKcu7s7/v7+5OTk8Nlnnz22zpCQEIKCgqhbty5xcXEGt4i6efMmAA0bNizbAxRy584dBgwYwO3bt9m1axcrV65EpVLplbO0tGTUqFGcOXOGPn36MHXqVH788Uej73Pp0iWSk5OxsrJiwIABeuf9/PwA2Lp1q1H1WVhYGFWuXr162v/Oycnhp59+0rlfWdrwpJR7gJSamqrdkqMoCoWCF154weC2H5JUWoWn7Bubg6Q0+btLueghNhkgSVJVEBMTA4C/vz9mZmaPLTtq1CigIKgqyqJFi5g9eza2trbExcXpbC9VWPPmzQHYsGGDzt6fZREYGMjly5dJSEjAw8Oj2PI2NjZERUXh4uLC5MmTdXZ3eJxffvkFgOeee87ge6b5vtaUK07Lli1p2bIl586d44cfftA5d+jQIXbs2IFKpdLJ3zp37hwPHjygYcOG2vfSUBtOnjxpVBuelHIPkOrUqcPVq1eLLXf16lXq1KlT3reXarDSbTVS0llspWubJJU3IQRZ2XnV6keUcRboiRMnAOjQoUOxZTVlkpOTycvL0zu/ZMkS5syZg52dHTt37qRTp05F1jV+/HgUCgXHjh1DpVIxefJkNmzYwMWLF0v1HCkpKaxbt47g4GDatWunPb5z5046duyIpaUlzZs35+233+a3335DoVCwdu1arK2tWb16NWlpaWzYsMGoe125cgXAYGBS+LimXHFMTExYu3YtdevWZcSIEXTs2JGRI0fi4eFB9+7dcXV1JS4uTmcEqbg2WFtbY2trS0ZGBvfu3TOqHU9CuSdpd+nShejoaGJjY/Hy8jJYJiYmhgMHDjBo0KDyvr1Ug5Vqmn+hIbaiepBM5BCbVAXdz3nIS/NiKrsZJbIx2JvaVo/v+XmcW7duAWBvb19sWc1wWH5+Prdv39YmJmtER0cDEBwcrJd0/aju3buzfv16pk6dys2bN/nyyy/58ssvAWjRogWTJk0iMDAQS0tLo57j22+/xcrKitdff117LD4+Hm9vb5RKJT169MDc3JwvvvhCbzmCjh074urqSlRUFFOmTCn2XllZWQDUqlXL4HnNzDhNOWP06NGDPXv24Ovry7Fjxzh27BhQ0MvVp08fmjZtWqI2aNqRmZlJVlYWNjY2RrelIpV7D9KsWbNQKBQMGTKEV155hZ07d5KSksKvv/7Kzp07GTduHL6+vpiYmJR4CqYkPY5JqXKQCg2xyXWQJKlK0/RAGdMTVbiMoc3Su3XrBhR8ZxmzPt+YMWO4fPkya9euZezYsTg5OQEFs7Pnzp2Lp6cn2dnZRj1HXFwcPj4+OgHD9OnTMTExYf/+/ezatYuYmBiOHz/O77//rnd9ly5dtL1pxRGPLLNTHjZu3Ejnzp15+umnSUxMJCsriwsXLvDSSy8RHBxMnz59dHrtjGlDWXsXK0K5B0hdunQhNDQUU1NT1q1bR//+/XFycsLR0ZH+/fuzfv16TE1NCQ0NLXK8V5JKo/CmhflGbzVSaIhN5iBJUpXWoEEDAP78889iy2oSqxUKhcGp48HBwUycOJF79+7h5eXFqVOniq3TxsaGgIAA1q9fz9mzZ7l69SqzZ8/GxMSExMREli1bZtRzXLp0CUdHR+3ra9eucfLkSQICAujYsaP2uIODA9OmTdO73tbWlszMTKPupemNKSp3SnO8du3aRtWXkpJCQEAADRs2JDo6mk6dOmFtbY2DgwOrV69m0KBBHDp0SGdf1uLaAPDXX3+VqB1PQoUsFDlmzBg8PT356quv2L9/P3/88QcATZs2pUePHkyYMIGnnnqqIm4t1WClCWQKz2JTFHGJnMUmVUXWlqZsDPau7GaUiLVl2b5yXFxcOHDgAElJSYwdO/axZZOSkoCCHd2LSuhevXo1WVlZfP/99/Tt25d9+/bRunVro9vTvHlzPvzwQ3Jzc1m6dCnR0dHMnTu32OseHfLT5OgUzkfScHV11TuWmpqKra2tUW18+umngYIgzBDNcU254nz//ffk5eXRv39/gwtXDh8+nK1bt7J7924mTZpkVBvu379PZmYmtra2VWZ4DSooQIKCfzj/+c9/Kqp6SdJTqmn+pn//4lQUMfNNDrFJVZFCoShTPk915OXlxeeff05ERAQff/zxY2eyfffddwCPXVhRqVRqZ6Zt3bqV3r17s3///hL/Ae/p6cnSpUtJT083qvyjPUCahGZDeUCPHhNCkJiYSPv27Y26l4uLCwCnT58mLy9P7z37+eefAcPBmSGaIKeoSVaa47dv39Yec3R0xMLCgps3b3Lt2jW9ZO2StuFJkZvVSv8YpepBUhrRgySH2CSpSvD29sbR0ZHr16+zePHiIsvt3buXiIgIzM3Ni01kNjU1JTw8nF69enHlyhX69OlDWlqaTpni8mM0s9keTU4uSosWLXT2i3NycsLU1JTt27frld2xY4fO64iICM6ePVtsD5qGSqWiTZs2ZGdnaxPTH60PYODAgUbV17hxYwBtYvajNFuMaXbQALCysqJXr1469ytLG54UGSBJ/xjKUq2DZMRWI4WG2NQyQJKkSqNUKlm7di1mZma8++67LF68GLVarVMmNjaWIUOGIIQgJCRE54u6KBYWFmzZsoUuXbpw4cIF+vbtS0ZGhvb8xIkT+eCDD7hx44betUePHmXhwoUADB061Kjn6NWrF9u3byc3NxcoyLsZPnw4u3fvZubMmVy/fp309HSWLl2qnc6fkZHBqlWrGDt2LD179tSu82SMwMBAAN555x2d/K3IyEi2bNmCSqViyJAhOtds3rwZJycnXn75ZZ3jPj4+QEEQ+sUXX+icO3z4MMuXLwf0F4TUtCE4OJiUlBTt8UOHDrF69Wrq1KnDhAkTjH6mJ6LUa3D/j0KhECYmJuL8+fMFS3MrlUb/mJiYlPX2/2hyq5GS2fzdz9qtRhK2nzPqmuQje7Rbjewc7mewzHc7zmm3GlkSdqw8myxJBsmtRh4vNjZW1K1bVwDC3t5e+Pj4iOHDh2u3IVEqlUVuRWJoqxGNjIwM4erqKgDRuXNnce/ePSHE39tnKJVK4eLiIvz8/ISfn59o3769AAQgvLy8RG5urlHtP378uADEypUrtcfS0tKEo6Ojtj5AmJiYiIULF+ocGzFihLh7926J3i+1Wi18fX0FIOzs7ISfn5/w9PTUbsdiaHuV0NBQAQgPDw+9czNnztS2x9nZWfj7+4tu3boJpVIpADFp0iSD7Zg2bZoARK1atYSPj4/w8vISpqamQqlUGr3VyZPcaqTMOUhPP/00CoVCO6751FNPlet0QkkyVoUlacvNaiWpSunfvz8pKSmsWLGCbdu2ER8fT15eHk2aNGHixIm8+eabpcpn0ayo7e7uTmJiIoMHDyYmJoZVq1bh7e1NXFwcycnJxMXFkZ2dTf369enfvz+jR49m9OjRRn/3ubq6MnToUObOnUuvXr1wdnbG3t6epKQkQkNDOX36NPXq1WP48OG0bNmS1NRUVCoVXl5eODs7l/i5lEol4eHhrFixgjVr1rBt2zasra3x9fVlwYIFJa7z448/pmvXrvz3v/8lKSmJ8+fPY2Njg4eHBxMnTiyyd+uTTz7B1dWVVatWsXPnTszMzOjduzfz5s3T2Ry4qlAIIbNOqyrNP9ozZ85Uckuqh23hv/Dz4YLZIF17tqbPwDbFXpPySyJ/vvsRALlmCnoaGB8P/+kC62POAtDdpSlBL3fUKyNJ5Sk/P5/z588DBQmuhYePpX+GtLQ0OnTogEKhYOvWrQZnqxWWn5+PWq0udouVf7qSfDbK+h0qP3XSP0ZpcpAURvQgmRSuV/49IUlSOWjUqBHR0dHk5+fTtWtXZs+erZccDvDw4UMiIyNxc3Nj/PjxldDSmqvCpvkXJT09HTs7O0wKJcdKUnkoPM1fGDkUZlLSlbTlEJskSeXExcWFI0eOMHnyZEJCQli8eDEuLi6oVCosLS1JTU0lKSmJe/fu4ezszNSpUyu7yTVKufcgHTt2jAULFpCcnKxzfMuWLTRp0oRGjRrRoEEDVq1aVd63lmq4woGM2si92Ex01kEqqt6//9vIjilJkiSjNGvWjG3btnHgwAGmTJlCXl4e8fHxREZGcunSJQYOHEhkZCSnTp3SWWVbqnjl3oP06aef8v333+tswnf58mWGDx9Obm4uTZo0IS0tjWnTpuHi4kKPHj3KuwlSDVW6af5/X6MsaohNIReKlCSpYnXt2pWuXbtWdjOkQsq9B+nw4cO4urpq98wB+Oabb7RLsV+/fp2jR49iYmKiXS9BkspDqVbSVhYaYgPU6ocGysghNkmSpJqm3AOktLQ0vT1d4uLiqF27tnZF0/bt29O9e3ejdyOWJGOUJpApPMQG6C0692i9ajnGJkmSVCOUe4D06BfMgwcPOHHiBN26ddPuNwMFS7IbWpVUkkpLJ0AyMgdJ+chkgXxDPUg6m9WWsnGSJElStVLuAVKLFi04deqU9vWuXbvIzc2ld+/eOuXu3r1L3bp1y/v2Ug1mYlI4B8nYWWy6AVKxQ2wyB0mSJKlGKPcAafDgwaSkpDB9+nS2bNnCO++8g1Kp1O7fonH8+HFatGhR3reXajDdITYjk7QfGWLLz5M5SJIkSVIFBEgzZ86kZcuWrFixAl9fX86ePctbb72Fg4ODtkxiYiLXr1/H3d29vG8v1WClGWLT60HKL26ITQZIkiRJNUG5T/OvV68eJ06cICIigj///JMOHTrQq1cvnTI3btxg2rRpjBkzprxvL9VgpduLTfcjYDAHqXCSthxikyRJqhEqZCVta2trAgICijzv4+OjN+QmSWWlO83fuCE200eG2B4+lENskiRJktyLTfoH0V0osuRbjYAxs9hkgCRJklQTlLkHae/evQB06tQJS0tL7WtjyTwkqbwU7kEydqsR/SE2/XWQTOQsNkmSpBqnzD1Inp6e9OzZkytXrui8NvZHkspLqXKQlEry/75MrqQtSdVEeno68+fPp3379tja2lKrVi1at27NpEmTOH36dJHXeXp6olAo2L17t8Hzy5cvR6FQYG1tTUJCgs658PBw+vXrR4MGDTAzM8Pe3p527doxYcIEwsLCyvPxyl1+fj6ffPIJzz//PFZWVjRs2BB/f3+9fVONdfjwYYYNG0bjxo0xMzOjXr169O7dm4iICIPl33//fRQKRZE/s2bNKsvjVYgy9yC9/PLLKBQK7ZpGmteS9KQVHmITJVjRUSiA/8U9cohNkqq+Xbt24e/vT2ZmJg0bNsTDwwMLCwtOnTrFV199xZo1awgODi7xl+6yZcuYMWMG1tbWxMTE6IxwjBs3jnXr1gHg5uaGSqVCrVZz5swZ1qxZQ1hYGKNHjy71M505c4awsDDi4uK4cuUKd+/epWnTpjg5OTFy5EiGDRuGtbV1qeoWQjBixAgiIiKwtbVlwIABpKens2nTJqKjo0lISKBz585G1xceHs7IkSPJz8/Hzc0NT09P/vjjD3bv3k18fDxBQUGEhIQYvLZbt260bt1a73iHDh1K9WwVqcwB0tq1ax/7WpKelNJM84f/BUja6wxtNVLovBxik6RKdfToUQYMGEBeXh6LFi1i5syZmJr+/VUWExPDmDFjmD17NrVq1WLq1KlG1btkyRLefvttateuTWxsLN27d9ee27RpE+vWrcPOzo64uDjc3Nx0rk1JSeGbb74p1fPcvn2bt956i7CwMIQQODo60r17dywsLPjjjz84cOAAsbGxzJkzh6+//pr+/fuX+B6hoaFERETg4ODAvn37aNSokfa5/Pz8GD16NOfOndN5H4vy8OFDpkyZQn5+Pt9//z0jRozQnjt06BC9evXio48+4t///jetWrXSu37ixImMGzeuxM9QGWSStvSPUZrNagHyC/UQqeUsNkmqsoQQBAQEkJuby4IFC5g1a5bel7q3tzdRUVEoFAqCgoK4fPlysfV+9NFHvP3229jY2LBjxw6d4AggMjISgClTpugFRwAODg5F9pg8zq+//krnzp3ZuHEjU6ZM4eLFi5w9e5bIyEg2btzInj17SEtLIywsDKVSiZeXF5999lmJ77N06VLtc2qCI4Bhw4YxePBgLl68yI8//mhUXefOnePmzZs4OTnpBEcAXbp0oV+/fgghSEpKKnE7q5pyD5AePHjAlStXuHfvXpFl7t27x5UrV8jNzS3v20s1mM56ReoSDrH9jxxik6SqKzY2lrNnz9KsWTOCgoKKLOfu7o6/vz85OTnFBhQhISEEBQVRt25d4uLi6Nq1q16ZmzdvAtCwYcOyPUAhd+7cYcCAAdy+fZtdu3axcuVKVCqVXjlLS0tGjRrFmTNn6NOnD1OnTjU6mAG4dOkSycnJWFlZMWDAAL3zfn5+AGzdutWo+iwsLIwqV69ePaPbWFWVe4C0bNkyVCoVv/zyS5FlfvnlF1QqFStWrCjv20s1WGmm+QOIQoGVyDc0xCZnsUlVjxCC+7l/VasfUcbPT0xMDAD+/v6YmZk9tuyoUaOAgqCqKIsWLWL27NnY2toSFxfHiy++aLBc8+bNAdiwYQP3798vTdP1BAYGcvnyZRISEvDw8Ci2vI2NDVFRUbi4uDB58mTu3r1r1H0038XPPfecwffshRde0ClXnJYtW9KyZUvOnTvHDz/8oHPu0KFD7NixA5VKVeQM9fj4eN566y1effVVgoODq3RPU7kvFBkVFYVKpdLroiyse/fuPPPMM2zevJm33367vJsg1VClHWITJRpiK2XjJKmc/ZWXzSubZ1R2M0ok1Hcp1ua1Sn39iRMnAOMSejVlkpOTycvL0wsOlixZQnR0dJF5RYWNHz+etWvXcuzYMVQqFb6+vnTv3p2uXbsazLMpTkpKCuvWrSMkJIR27dppj+/cuZM5c+Zw6tQpGjRowEsvvcRrr71Gq1atCA0NZdy4caxevZpOnTqxYcMGpkyZUuy9NDPMNUHeozTHNeWKY2Jiwtq1axk0aBAjRozg448/plWrVqSmprJ//35t28zNzQ1ev2HDBp3X8+fPZ9iwYaxdu5batWsb1YYnpdx7kC5evEjbtm2LLefs7MzFixfL+/ZSDVbaXCGdITZDPUiFAyg5xCZJlebWrVsA2NvbF1tWMxyWn5/P7du39c5HR0cDEBwc/NjgCAr+qF+/fj12dnbcvHmTL7/8kpdffpnWrVvzzDPP8OGHH5KTk2P0c3z77bdYWVnx+uuva4/Fx8fj7e3NyZMn6d69O+3ateOLL77Qy/Pp2LEjrq6uREVFGXWvrKwsAGrVMhyYambGacoZo0ePHuzZsweVSsWxY8f4v//7P/bu3Yu1tTV9+vShadOmete0bt2aJUuWcObMGbKysrh69SphYWE0a9aMTZs2MXbsWKPv/6SUe4B0//59o6Yi1qpVy+guQkkyRqkDJGUJepDkEJskVRrNEJ0xQ3WFyxhaeqZbt24AzJo1iyNHjhRb35gxY7h8+TJr165l7NixODk5AXD58mXmzp2Lp6cn2dnZRj1HXFwcPj4+OkHL9OnTMTExYf/+/ezatYuYmBiOHz/O77//rnd9ly5dtL1pxdG8D+W5/M7GjRvp3LkzTz/9NImJiWRlZXHhwgVeeuklgoOD6dOnD3l5eTrXjBkzhhkzZtC2bVusra1p3rw5o0aN4ujRo9SvX5+oqCgOHjxYbm0sD+U+xPbUU09x7NixYsslJSXRpEmT8r69VIOZmBTKQSpRknahHKTiVtKWPUhSFVHLzIpQ36WV3YwSqWVmVabrGzRowPnz5/nzzz+LLatJrFYoFNjZ2emdDw4OJiwsjK+//hovLy92797N888//9g6bWxsCAgI0O41eu3aNT7//HM++ugjEhMTWbZsGXPnzi22bZcuXcLb21v7+tq1a5w8eZJJkybRsWNH7XEHBwemTZvG/Pnzda63tbUlMzOz2Pto2gwUmTulOW7s8FZKSgoBAQE0atSI6OhobYeIg4MDq1evJjU1la1btxIaGsqkSZOKra9Jkya88sorLFmyhB07dhhMkq8s5d6D1LdvX3777Tc+/fTTIst89tlnXLx4kX79+pX37aUarDx6kAwOsckeJKkKUigUWJvXqlY/Ze3FcHFxATAqsVdTxtnZuciE7tWrVzNy5Ehu375N3759+fXXX0vUnubNm/Phhx/y1ltvAX8P2xXn9u3bOtPtNfk/hfORNFxdXfWOpaamYmtra9S9nn76aaAgCDNEc1xTrjjff/89eXl59O/f3+Bo0fDhwwGKXKncEAcHB6DguaqScg+QgoKCsLGx4a233mLIkCHExMRw/vx5Lly4QExMDEOGDGHq1KnUqVPnsdM0JamkyiVAMrRQpJzmL0lVgpeXFwARERF6QziP+u677wAeu7CiUqlkw4YNDBo0iBs3btC7d2+uXr1a4nZ5enoCBdufGOPRHiBNQrOhPKBHjwkhSExMpH379kbdSxNUnj592uB79vPPPwOGgzNDNAFVnTp1DJ7XHDeU91WUjIwMwPherCel3AOkp556ii1btlC/fn22bNnCoEGDaNu2LW3atGHQoEHac1FRUTzzzDPlfXupBivtStoU+qNWDrFJUtXl7e2No6Mj169fZ/HixUWW27t3LxEREZibmxc708vU1JTw8HB69erFlStX6NOnD2lpaTplist50kw4MpScbEiLFi109otzcnLC1NSU7du365XdsWOHzuuIiAjOnj1rdFKzSqWiTZs2ZGdnG+zh0uydNnDgQKPqa9y4MUCRqTRHjx4FMPr7XQjB5s2bgaq33UiFrKTt7u7OhQsXCAkJoU+fPjg6OuLo6EifPn1YvHgx58+f10bcklRelIVzkEq0F5scYpOk6kCpVLJ27VrMzMx49913Wbx4MepH/qiJjY1lyJAhCCEICQkx6ovawsKCLVu20KVLFy5cuEDfvn21vRpQsD3GBx98wI0bN/SuPXr0KAsXLgRg6NChRj1Hr1692L59u3ax5Nq1azN8+HB2797NzJkzuX79Ounp6SxdulQ7LT4jI4NVq1YxduxYevbsqV3nyRiBgYEAvPPOOzr5W5GRkWzZsgWVSsWQIUN0rtm8eTNOTk68/PLLOsd9fHyAgiD0iy++0Dl3+PBhli9fDvy9ACUU9KytX7+eBw8e6JTPysritddeIzExkcaNG+Pr62v0Mz0RQqqy2rZtK9q2bVvZzag2Mm7dF/8J3KL9yVfnG3XdtvGjxf7BQ8X+wUPFwa3f6Z1Pu3VfDAyM0v6ojaxXkkpLrVaL5ORkkZycLNRqdWU3p8qJjY0VdevWFYCwt7cXPj4+Yvjw4aJNmzYCEEqlUixcuNDgtR4eHgIQCQkJeucyMjKEq6urAETnzp3FvXv3hBBC+Pj4aOt1cXERfn5+ws/PT7Rv315QsNW18PLyErm5uUa1//jx4wIQK1eu1B5LS0sTjo6O2voAYWJiIhYuXKhzbMSIEeLu3bsler/UarXw9fUVgLCzsxN+fn7C09NTKBQKYWlpKQ4cOKB3TWhoqACEh4eH3rmZM2dq2+Ps7Cz8/f1Ft27dhFKpFICYNGmSTvlLly4JQNSpU0d07txZ+Pv7i3/961+ifv36AhC2trZi//79Rj+LsZ+Nsn6HlvssNkmqLIUXioSC4bDCw2NFX/j4WWzKR+rIFwIl5TdlVpKkkunfvz8pKSmsWLGCbdu2ER8fT15eHk2aNGHixIm8+eabRufUFKZZUdvd3Z3ExEQGDx5MTEwMq1atwtvbm7i4OJKTk4mLiyM7O5v69evTv39/Ro8ezejRo41OQnd1dWXo0KHMnTuXXr164ezsjL29PUlJSYSGhnL69Gnq1avH8OHDadmyJampqahUKry8vHB2di7xcymVSsLDw1mxYgVr1qxh27ZtWFtb4+vry4IFC0pc58cff0zXrl3573//S1JSEufPn8fGxgYPDw8mTpyo17tVv359goKCOHz4ML/++isnTpzAxMQElUrFuHHjmD59Os2aNSvxc1U0hRAVM2Zw+vRpvv76a44ePUp6ejo+Pj589NFHABw4cICkpCTGjBnzj9ivpaJo/tGeOXOmkltSPWTde8Cy9+O0r2cv8sLMvPi/AbZNehm7tP9NgR03mG6+ATrnb9/NIeA/f+cBbAoZiLmZSfk0WpIMyM/P5/z58wA4OjrqbKMj/TOk/X979x0W1bW1Afw9MzRFFAXsJQQREgv2ggZ7Qb2KBbtijDe5id3EGk28RmOJJUaNMbErGj8QjSgYJJZYInaNNUosIbGAigVBYOZ8f3hnnAZzGA7CzLy/5/G5esqefc6VzHKvtfe+dw8NGjSAIAiIjo42OVtNl1qthkqlMrvFiq3Ly89Gfr9DC+Snbv78+ahfvz6++eYb/Pbbb7h+/bpedf/z588xbtw4REREFMTHk50yGumRWlCtu4dbdu6z2PLULhFRDjTrCKnVagQGBmLKlClGxeEAkJ2djaioKDRs2BDDhg0rhJ7aL9kDpJ9++gmTJ09GtWrVsGPHDiQnJxvNAGjXrh08PT0lL5VOJIWlAVJe1kECWKhNRPIICAjA8ePH0aZNG8ydOxcVKlRAvXr10LNnTwwYMACtW7dGmTJl0KtXL2RmZmL06NGF3WW7InsN0uLFi1GiRAns3bs3x9kDgiDAz88Pf/zxh9wfT3ZMaViDJHWqv+5K2iZmv1k8MkVEZEalSpWwa9cuHD16FFu2bMH+/fuxb98+ZGRkoHz58ujatStCQ0MREhIi63YhZJ7sAdKZM2fQrFkzs1MrK1WqJGlLEiKpDHPRKqlT/XXuM1mkbfDfJG5YS0RyCwwMLFLbbFABpNiys7Nz3DVYV3Jysnb1UCI5GI30SB1B0p3FxhQbERGhAAIkHx8fnDp1ymjxLl1paWk4e/Ys3n77bbk/nuyYoBD0VsW2pAZJNLHJreFSAUyxERHZPtkDpN69eyMpKclo92Fd06dPx6NHj9C3b1+5P57snEX7sZlNsRkGSJb1jYiIrIfsNUgff/wxtm7dinnz5uHw4cPo1q0bAODPP//EsmXLsGPHDuzbtw8BAQH4z3/+I/fHk51TKARtak16gJTHIm2m2IiIbJ7sAZKrqyv279+PoUOHYs+ePThy5AiAl/u2HDp0CKIoom3btggPD4ezs7PcH092TqlUIDvrZZAjeT823REkE/cIggBBADRxEVNsRES2r0C2GilbtixiYmJw7tw57N27Fzdv3oRKpULlypXRrl07NGnSpCA+lkg/xWZBkbY6h9o5hSBA9b8IiSNIRES2T/YAqWfPnqhQoQKWL1+OgIAABAQEyP0RRDmyqAZJ0CnFy2HUSaEQtNP7OYJERGT7ZC/SjomJwYMHD+RulkgS3bWQ1CZmpJkiKHMv0n7ZrgWBFxERWS3ZAyRvb2+kpaXJ3SyRJApl/kaQTNUgAfoz2ZhiIyKyfbIHSP3798fBgwdx9+5duZsmMsuyaf56iyeZbZcraRMVvpSUFEyfPh316tWDu7s7ihcvjurVq+P999/HhQsXcryvVatWEAQBBw4cMHl+8eLFEARBO+FIV0REBDp27AhPT084OjqibNmyqFOnDt577z2Eh4fL+XiyU6vV+Prrr1G7dm0UK1YMXl5eCA0NxaVLlyxq79ixY+jevTs8PT3h4uKCGjVqYNq0aXj+/Hmu923YsAGNGzdGiRIlUKZMGXTu3BlHjx61qA8FTfYAacqUKXjnnXfQsmVLbN++HVlZWXJ/BFGO9AIZiSk2KJXa35paKBIwGEFigERUqOLj4+Hr64tZs2bh77//RsuWLdG1a1c4Ojrihx9+QN26dTF37tw8t7to0SKMHz8erq6uiI2NRevWrbXnhg4dij59+iAuLg7e3t7o0aMH3nnnHWRmZmLNmjV477338vVMFy9exNSpU9GwYUOULVsWLi4uePPNN9G5c2ds2LAhX5kZURTRt29fjBs3DklJSejSpQtq1qyJbdu2oWHDhkhISMhTe+Hh4WjRogV27tyJN954A507d0ZGRgZmz56NwMBAPH361OR948ePR1hYGC5cuIB27dqhcePG2Lt3L4KCgrB9+3aLn6+gyF6k7efnB7Vajb/++gu9e/eGIAja/7MNCYKAxMREubtAdkyhU08kNZARJIwg6W6EyxQbUeE5ceIEunTpgqysLMyZMweffPIJHBxefZXFxMRg0KBBmDJlCooXL47Ro0dLanfBggWYMGECSpQogdjYWLRo0UJ7btu2bVi/fj1Kly6NuLg4NGzYUO/ea9euYfXq1RY9z8OHDzF27FiEh4dDFEX4+fmhRYsWcHZ2xj///IMjR44gNjYWU6dOxapVq9CpU6c8f8batWsRGRkJX19fHDp0COXKldM+V+/evTFw4EBcuXJF7z3mJCkpCcOHD4dKpcKaNWvw7rvvAgBevHiBwYMHIyIiAhMnTsSKFSv07tu3bx8WL14MDw8P/Pbbb/D19QUA/Pbbb2jVqhXeffddtGrVCqVLl87z8xUU2UeQbt68idu3b0MURYiiCLVajbt37+LmzZtGv27cuJGvz8rIyMDnn3+OGjVqwMXFBRUrVsSwYcOQlJSUp3YOHjyI//73v+jSpQu8vLwgCAL8/f3N3if3kCXln0Jv0UcLVtKWUoPEESSiQiGKIsLCwpCZmYmZM2di8uTJRl/qnTt3xo4dOyAIAiZNmoRbt26ZbXf+/PmYMGEC3Nzc8PPPP+sFRwAQFRUFABgxYoRRcAQAvr6+Fo1YXb9+HU2aNMGWLVswYsQIJCYm4vLly4iKisKWLVtw8OBB3Lt3D+Hh4VAoFAgODsby5cvz/DkLFy7UPqcmOAKAXr16oVu3bkhMTMRPP/0kqa1169YhIyMD7du31wZHAODs7Izly5ejePHiWL16tdFkLU0fpk2bpg2OAKBZs2b4z3/+g8ePH2PNmjV5fraCJHuApFar8/TLUhkZGWjbti1mzpyJZ8+eoXv37qhSpQrWrl2L+vXr52lkasyYMZgxYwZiYmKQkpIi6R65hyxJHpbUIAkKnRSbhBokBkhEhSM2NhaXL19GpUqVMGnSpByvCwoKQmhoKDIyMswGFHPnzsWkSZNQqlQpxMXFITAw0Oia5ORkAICXl1f+HkDH48eP0aVLFzx8+BDx8fH45ptv4O3tbXSdi4sLBgwYgIsXL6Jdu3YYPXq05GAGAG7cuIFLly6hWLFi6NKli9H53r17AwCio6MltXfq1CkAL2u5DHl5eeHtt99GVlYWYmJitMczMjLwyy+/6H1efvrwusgeIL0uX375JY4ePYpmzZrhjz/+wNatW5GQkICFCxciOTkZw4YNk9xWhw4dMHv2bMTFxeH06dOS7tEdsrxy5QoiIyNx4MABREREID09HQMHDkR2dralj0cW0kuxSVwoUlBIWwdJewlTbESFQvOlGxoaCkdHx1yvHTBgAICXQVVO5syZgylTpsDd3R1xcXFo2rSpyesqV64MANi4caNss7THjx+PW7duYf/+/WjZsqXZ693c3LBjxw4EBATggw8+wJMnTyR9zrlz5wAAtWrVMvnO6tevr3edOZrnzykVVqZMGaP2rly5ghcvXsDLy0v7Lk314fz585L68LrIFiDFxMTg/fffR3BwMEJCQvDZZ5/lO4WWk6ysLCxduhQAsHz5cpQoUUJ7bvz48ahTpw5+/fVXbaRrzvz58zF16lS0b99ecv5TziFLko/+bLO8bzWSYw0SU2xUxIiiiOxnaVb1S8znPy7Onj0LAGjQoIHZazXXXLp0yeRkoQULFmDq1KkoXbo09u7di8aNG+fY1rBhwyAIAk6ePAlvb2988MEH2Lhxo8U1tNeuXcP69esxa9Ys1KlTR3t87969aNSoEVxcXFC5cmVMmDABf/75JwRBwLp16+Dq6oqVK1fi3r172Lhxo6TPun37NgCYDEx0j2uuM0czipZT6lJz/ObNm5L74OrqCnd3dzx69CjHAu/CIEuR9sCBA/Hjjz8CgPYHIDo6GgsWLMCPP/6o3bBWLocPH0Zqaip8fHxQr149o/O9e/fG+fPnER0dLekHKa+kDFnu3LkT0dHR6NWrl+yfTzmzZKsR3YUicx5BevV7TvOnokCV9hwJA4cUdjfypEn4BjiUcLX4fk1dS9myZc1eq/kiV6vVePjwod4/ZAFg9+7dAIBZs2aZrCvS1aJFC2zYsAGjR49GcnIyvv/+e3z//fcAgGrVquH999/H+PHjTU5GMmXTpk0oVqwYPvroI+2xffv2oXPnzlAoFHjnnXfg5OSEFStWGC1H0KhRI9StWxc7duzAiBEjzH7Ws2fPAADFixc3ed7V1VXvOnNatmyJzZs3Y8uWLZg5cyacnJy0544dO4arV68CgF6gY64Pmn6kpqbi2bNncHNzk9SXgpbvEaTVq1djy5YtUCqVGDp0KL755hvMnj0bTZs2RUZGBoYMGYLHjx/L0VctzdCdZljOUF6HDC39fLmGLEk+ltUg6QZIpu9hDRJR4dP8A1zKSJTuNYLOCLBG8+bNAQCTJ0/G8ePHzbY3aNAg3Lp1C+vWrcPgwYO1E3lu3bqFTz/9FK1atUJ6erqk54iLi0P37t31AoZx48ZBqVTi8OHDiI+PR0xMDM6cOaM3EqPRrFkz7WiaOZr3YOodWGLgwIGoWrUqbt++je7du+PixYt4+vQp9uzZg9DQUG3RvO6uBlL6kN/RxYKQ7wBp/fr1UCgUiI2NxerVqzFy5EhMmTIFR44cQVhYGJ4+faqdASAXuYcMC/vza9asafIXl0DIO0tW0tbbaoSz2IiKLE9PTwDA/fv3zV6rKawWBMFk6cSsWbMwfPhwPH36FMHBwfj999/Ntunm5oawsDBs2LABly9fxl9//YUpU6ZAqVQiISEBixYtkvQcN27cgJ+fn/bPSUlJOH/+PMLCwtCoUSPtcV9fX4wZM8bofnd3d6Smpkr6LM1oTE61U5rjuqUquXF1dcWuXbtQtWpV7NmzB7Vq1ULJkiURHBwMhUKB8ePHA9CvUTLXBwDaBSal9uN1yHeK7ffff0fTpk3Rtm1bo3NTp07F+vXrJf3Fywu5hwyt7fMpZ3p7sUmuQXo1i41F2mQtlK7F0SR8Q2F3I0+UrjmnWKQICAjAkSNHcOrUKQwePDjXazU1qDVr1syxoHvlypV49uwZfvzxR3To0AGHDh1C9erVJfencuXK+PLLL5GZmYmFCxdi9+7d+PTTT83eZ5jy0/xjWrceSaNu3bpGx+7cuQN3d3dJfaxatSoA5Lj8jea45jopateujStXriAiIgInT55EdnY2AgICMGDAAMyaNQvAy/cutQ9paWlITU2Fu7t7kUmvATIESE+ePIGPj4/Jc5rjUqvtpTI3XFfQQ3VyD1levHjR5HHdv2AkjdKSEaQ8p9gs6xuRnARByFc9jzUKDg7Gt99+i8jISHz11Ve5zmTbvHkzAOS6sKJCodDOTIuOjkbbtm1x+PBhVKlSJU/9atWqFRYuXCh5mRjDESBNHY+pf1QbHhNFEQkJCSbrb00JCAgAAFy4cAFZWVlG70wzc9tUcJabYsWKYciQIRgyRL8OLj4+HoD+MgB+fn5wdnZGcnIykpKSjLIvlvahoOU7xSaKIpQ6WzXoNf6/L578rHdkirnhuoIeqpN7yJLkY1GRtpQRJKbYiApd586d4efnh7///hvz5s3L8bpff/0VkZGRcHJyMlvI7ODggIiICLRp0wa3b99Gu3btcO/ePb1rzP2jW1MOUbFiRUnPUa1aNb394vz9/eHg4IA9e/YYXfvzzz/r/TkyMhKXL182O4Km4e3tjbfeegvp6enawnTD9gCga9euktrLzcGDB3H69GnUrFlTW+MFvAym2rRpo/d5BdUHOVnlOkgFMWRoTZ9PObMkxaY/i838CJKKKTaiQqFQKLBu3To4Ojris88+w7x586BSqfSuiY2NRUhICERRxNy5c/HGG2+YbdfZ2Rk7d+7UrqvXoUMHPHr0SHt++PDhmD17tslN2E+cOIEvvvgCANCzZ09Jz9GmTRvs2bMHmZmZAF7+Y7pPnz44cOAAPvnkE/z9999ISUnBwoULtdP5Hz16hGXLlmHw4MFo3bq1dp0nKTR1QRMnTtSr34qKisLOnTvh7e2NkJAQvXu2b98Of39/oxEi4OVyC4br/J0+fRoDBgyAIAjaZXhM9WHWrFm4du2a9vhvv/2GlStXomTJkvnez05usgRI69evh1KpNPlLEIQcz0vZ98UUzZBhTos6FvRwneGQ5ev+fMpZfkeQBJEjSERFWdOmTbFz506ULFkSkydPRsWKFRESEoK+ffvi7bffRufOnfH48WN88cUXGDdunOR2XV1dERMTg7p16+L8+fMIDg7WprcePHiAadOmoVKlSqhbty5CQ0MRGhqK+vXro3Hjxnjw4AGCg4Px4YcfSvqs/v37Izk5GStXrtQeW7x4Mfz8/LBw4UJUrlwZXl5emDRpEmbMmAHgZYAxatQohISE4Keffsoxc2PKsGHD0KNHD1y7dg3+/v4IDQ1F69at0bt3b7i4uGDTpk1GqbfHjx/j6tWrJicbjR07FhUrVkSHDh0wYMAABAYGolGjRrh//z5Wrlypt8mvRrt27TBmzBg8ePAAdevWRUhICDp37oygoCBkZWVhzZo12kUmiwpZ1kGytObH0vuaN2+OUqVKITExEWfOnDHKxRb0cJ1myPLy5cvYvXu3UeRdVIcL7YEl0/EVDropNk7zJyrqOnXqhGvXrmHJkiXYtWsX9u3bh6ysLFSoUAHDhw/HqFGjLPoHqmZF7aCgICQkJKBbt26IiYnBsmXL0LlzZ8TFxeHSpUuIi4tDeno6PDw80KlTJwwcOBADBw6UXJdat25d9OzZE59++inatGmDmjVromzZsjh16hTWrl2LCxcuoEyZMujTpw/efPNN3LlzB97e3ggODraoNlWhUCAiIgJLlizBmjVrsGvXLri6uqJHjx6YOXNmntscNGgQNm3ahLNnzyI1NRVeXl7o168fJkyYYLKoXOPrr79G3bp1sWzZMuzduxeOjo5o27Ytpk2bZrT/XVEgiEVx8QEJpk2bhtmzZyMwMBBxcXHamWOLFi3Cxx9/jBYtWuDQoUPa65ctW4Zly5ahR48emDNnTo7t3rx5E97e3vDz88OVK1dyvG7VqlX497//DV9fXxw+fFi7cFlUVBR69eoFb29vXL161exy+LnR/KXNqYibjO2KOIfTx17+i6d5m+po2+Uts/cc2PwdHLfuBQA8rFIK/1pmvGHipyuO4Pz1lwWYo/rURYcm1WTsNZE+tVqtXXDPz89PL3VMtuHevXto0KABBEFAdHR0roEF8PLvhEqlytd3ii3Iy89Gfr9Drfanbtq0aWjSpAmOHj0KX19f9O3bF02bNsXHH38MDw8PrF27Vu/6lJQUXL16FXfu3DFqa9WqVWjatCmaNm2KHj16AHi5+JfmWNOmTY3SeZYMWVLB0/1hUakk1iApJIwgMcVGRDIqV64cdu/eDbVajcDAQEyZMsWoOBwAsrOzERUVhYYNG+Zpj1HKP1lSbIXBxcUF+/fvx5w5c7B582bs2LEDpUuXRlhYGL744os8TdNMSkpCQkKC3rGMjAy9Y4ZLFcg9ZEny0F0oUpSaYtPJ5QtSUmzWOehKREVMQEAAjh8/jg8++ABz587FvHnzEBAQAG9vb7i4uODOnTs4deoUnj59ipo1a2L06NGF3WW7YrUpNnvAFFvexe28iGMH/wQANGr+BoJ71jZ7z+Go9RDW7wQAPCpfAl1Xrje65r+rjuHk5Zf/uvugR210bfGmjL0m0scUm/05evQotmzZgv379yMpKQkZGRkoX748AgMDERoaipCQENnW3rNmrzPFZrUjSESm5HcvthxHkJhiI6ICFBgYiMDAwMLuBungP0vIpih01jSSOs1fobvcRI5bjehcwkFXIiKbxwCJbIrego4SF4pU6K2DxGn+RETEAIlsjEULReqtpJ1Du4Ju4MUAiYjI1jFAIpti0UKRylcpNkkjSEyxERHZPAZIZFMs2YtNL8WWQ1Cl1Au8LOwcERFZDQZIZFN010GSPoKkM4uNNUhERAQGSGRjlJZM89dNsUmZ5s8UGxGRzWOARDZFbwRJ4lYjCkUea5A4gkREZPMYIJFN0a9BsiTFllO7DJCIiOwJAySyKZYEMkqHV5sK51ikzWn+REVKSkoKpk+fjnr16sHd3R3FixdH9erV8f777+PChQs53teqVSsIgoADBw6YPL948WIIggBXV1fs379f71xERAQ6duwIT09PODo6omzZsqhTpw7ee+89hIeHy/l4slOr1fj6669Ru3ZtFCtWDF5eXggNDcWlS5csau/YsWPo3r07PD094eLigho1amDatGl4/vy5yetnzJgBQRBy/DV58uT8PF6B4FYjZFMsWQdJb7NaKSNIrEEiKlTx8fEIDQ1FamoqvLy80LJlSzg7O+P333/HDz/8gDVr1mDWrFl5/tJdtGgRPv74Y7i6uiImJgZBQUHac0OHDsX69S/3aWzYsCG8vb2hUqlw8eJFrFmzBuHh4Rg4cKDFz3Tx4kWEh4cjLi4Ot2/fxpMnT1CxYkX4+/ujX79+6NWrF1xdXS1qWxRF9O3bF5GRkXB3d0eXLl2QkpKCbdu2Yffu3di/fz+aNGkiub3w8HCEhYVBpVKhQYMGqFq1Kk6ePInZs2dj165dOHToENzc3Eze27x5c1SvXt3oeIMGDSx6toLEAIlsit5WI5bsxcYaJKIi7cSJE+jSpQuysrIwZ84cfPLJJ3DQ2S4oJiYGgwYNwpQpU1C8eHGMHj1aUrsLFizAhAkTUKJECcTGxqJFixbac9u2bcP69etRunRpxMXFoWHDhnr3Xrt2DatXr7boeR4+fIixY8ciPDwcoijCz88PLVq0gLOzM/755x8cOXIEsbGxmDp1KlatWoVOnTrl+TPWrl2LyMhI+Pr64tChQyhXrpz2uXr37o2BAwfiypUreu8xJ0lJSRg+fDhUKhXWrFmDd999FwDw4sULDB48GBEREZg4cSJWrFhh8v7hw4dj6NCheX6GwsAUG9kU/REkaUXa+im2HNrlZrVEhU4URYSFhSEzMxMzZ87E5MmTjb7UO3fujB07dkAQBEyaNAm3bt0y2+78+fMxYcIEuLm54eeff9YLjgAgKioKADBixAij4AgAfH19MXfu3Dw/z/Xr19GkSRNs2bIFI0aMQGJiIi5fvoyoqChs2bIFBw8exL179xAeHg6FQoHg4GAsX748z5+zcOFC7XNqgiMA6NWrF7p164bExET89NNPktpat24dMjIy0L59e21wBADOzs5Yvnw5ihcvjtWrV+PBgwd57mdRwwCJbIplK2m/SrEpuJI2UZEVGxuLy5cvo1KlSpg0aVKO1wUFBSE0NBQZGRlmA4q5c+di0qRJKFWqFOLi4hAYGGh0TXJyMgDAy8srfw+g4/Hjx+jSpQsePnyI+Ph4fPPNN/D29ja6zsXFBQMGDMDFixfRrl07jB49WnIwAwA3btzApUuXUKxYMXTp0sXofO/evQEA0dHRkto7deoUgJe1XIa8vLzw9ttvIysrCzExMZL7WFQxQCKbYslCkXojSJzFRlRkab50Q0ND4ejomOu1AwYMAPAyqMrJnDlzMGXKFLi7uyMuLg5NmzY1eV3lypUBABs3bkRaWpolXTcyfvx43Lp1C/v370fLli3NXu/m5oYdO3YgICAAH3zwAZ48eSLpc86dOwcAqFWrlsl3Vr9+fb3rzNE8f+nSpU2eL1OmTK7t7du3D2PHjsV//vMfzJo1SxtwFUWsQSKbkv8RpJezPXSXCwC4WS0VPaIo4kVGdmF3I0+cXRwg6Pws5dXZs2cBSCvo1Vxz6dIlZGVlGQUHCxYswO7du3OsK9I1bNgwrFu3DidPnoS3tzd69OiBFi1aIDAwED4+Pnl+jmvXrmH9+vWYO3cu6tSpoz2+d+9eTJ06Fb///js8PT3Rv39/fPjhh/Dx8cHatWsxdOhQrFy5Eo0bN8bGjRsxYsQIs591+/ZtAK+CPEOa45rrzNGMouWUutQcv3nzpsnzGzdu1Pvz9OnT0atXL6xbtw4lSpSQ1IfXhQES2RT9Im2JC0XqBEgAIKpUgGGAxBQbFTEvMrIxf9qewu5Gnkyc1QkuxXIf+cmNpq6lbNmyZq/VfJGr1Wo8fPhQr/YGAHbv3g0AmDVrVq7BEQC0aNECGzZswOjRo5GcnIzvv/8e33//PQCgWrVqeP/99zF+/Hi4uLhIeo5NmzahWLFi+Oijj7TH9u3bh86dO0OhUOCdd96Bk5MTVqxYYbQcQaNGjVC3bl3s2LFDUoD07NkzAEDx4sVNntfMjNNcZ07Lli2xefNmbNmyBTNnzoSTk5P23LFjx3D16lUAwNOnT/Xuq169OhYsWIDg4GBUq1YNjx49wq+//oqJEydi27ZtUKlU2L59u6Q+vC5MsZFN0Q1kVBKn+SuV+v/BzlZlmWj31e+ZYiMqHOL//nEiSvhHiu41pkatmjdvDgCYPHkyjh8/bra9QYMG4datW1i3bh0GDx4Mf39/AC9HTD799FO0atUK6enpkp4jLi4O3bt31wtaxo0bB6VSicOHDyM+Ph4xMTE4c+aMyZGYZs2aaUfTzNG8h/yM3OkaOHAgqlatitu3b6N79+64ePEinj59ij179iA0NFRbNG84Cj9o0CB8/PHHePvtt+Hq6orKlStjwIABOHHiBDw8PLBjxw4cPXpUlj7KhQES2RSLFoo0GEFSqVTG7XIWG1Gh8/T0BADcv3/f7LWawmpBEEzWy8yaNQvDhw/H06dPERwcjN9//91sm25ubggLC8OGDRtw+fJl/PXXX5gyZQqUSiUSEhKwaNEiSc9x48YN+Pn5af+clJSE8+fPIywsDI0aNdIe9/X1xZgxY4zud3d3R2pqqqTP0qxHlFPtlOa41PSWq6srdu3ahapVq2LPnj2oVasWSpYsieDgYCgUCowfPx5AzjVKhipUqKCdDffzzz9Luud1YYqNbIreViNS92JT6v8YqFXGdR1KptioiHF2ccDEWXlfE6cwObvk7ysnICAAR44cwalTpzB48OBcr9UU/9asWTPHgu6VK1fi2bNn+PHHH9GhQwccOnTI5CKGOalcuTK+/PJLZGZmYuHChdi9ezc+/fRTs/cZpvw09T+69UgadevWNTp2584duLu7S+pj1apVAbwMwkzRHNdcJ0Xt2rVx5coVRERE4OTJk8jOzkZAQAAGDBiAWbNmAXj53qXy9fUF8PK5ihIGSGRTLBlBcjBMsWWbSrFxBImKFkEQ8lXPY42Cg4Px7bffIjIyEl999VWuM9k2b94MALkurKhQKLQz06Kjo9G2bVscPnwYVapUyVO/WrVqhYULFyIlJUXS9YYjQJo6HlN1QIbHRFFEQkIC6tWrJ+mzAgICAAAXLlwwWax++vRpAKaDs9wUK1YMQ4YMwZAhQ/SOx8fHAzC9DEBOHj16BED6KNbrwhQb2RRLpvkbFmmrzabYLOwcEeVL586d4efnh7///hvz5s3L8bpff/0VkZGRcHJyMlvI7ODggIiICLRp0wa3b99Gu3btcO/ePb1rzNU8JSYmAgAqVqwo6TmqVaumt1+cv78/HBwcsGePcdG9YdopMjISly9fNjuCpuHt7Y233noL6enp2sJ0w/YAoGvXrpLay83Bgwdx+vRp1KxZU1vjZY4oitri7KK23QgDJLIpSgv2YlNKSLFxFhtR4VMoFFi3bh0cHR3x2WefYd68eUY1g7GxsQgJCYEoipg7dy7eeOMNs+06Oztj586daNasGf744w906NBBO6oBvNweY/bs2bh7967RvSdOnMAXX3wBAOjZs6ek52jTpg327NmDzMxMAC9HTvr06YMDBw7gk08+wd9//42UlBQsXLhQOy3+0aNHWLZsGQYPHozWrVtr13mSQlMXNHHiRL36raioKOzcuRPe3t4ICQnRu2f79u3w9/c3GiECXi63kJ2t/9/J06dPY8CAARAEAUuXLtU7l5KSgg0bNuDFixd6x589e4YPP/wQCQkJKF++PHr06CH5mV4HptjIplg0zd9gyFmVbSZAYoqNqNA0bdoUO3fuRL9+/TB58mQsWrQIzZo1025We/nyZSgUCnzxxRcYN26c5HY1G9S2bt0aZ8+eRXBwMOLj41GiRAk8ePAAa9aswWeffYbatWtra2YSExNx5swZAC/Tfx9++KGkz+rfvz/mz5+PlStXYtSoUQCAxYsX49SpU1i4cKF2axClUokZM2Zg+vTp2iCnb9+++OGHH4wml+Rm2LBhiImJ0QY9bdu2RUpKCg4ePAgXFxds2rTJKPX2+PFjXL16FeXLlzdqb+zYsbh06RLq1q0LT09P3Lx5EwkJCVAoFFi5ciVat26td/2zZ88QFhaGUaNG4a233kLVqlWRmpqK06dP48GDB3B3d0dkZGSOSxEUFgZIZFN0AxlRBES1CEGR+/RWw//QmBxB4iw2oiKjU6dOuHbtGpYsWYJdu3Zh3759yMrKQoUKFTB8+HCMGjUqzzU1ALQragcFBSEhIQHdunVDTEwMli1bhs6dOyMuLg6XLl1CXFwc0tPT4eHhgU6dOmHgwIEYOHCg5Kn0devWRc+ePfHpp5+iTZs2qFmzJsqWLYtTp05h7dq1uHDhAsqUKYM+ffrgzTffxJ07d+Dt7Y3g4OA8FT9rKBQKREREYMmSJVizZg127doFV1dX9OjRAzNnzsxzm4MGDcKmTZtw9uxZpKamwsvLC/369cOECRNMFpV7eHhg0qRJOHbsGK5fv46zZ89CqVTC29sbQ4cOxbhx41CpUqU8P1dBE0QpC0pQodD8pb148WIh98R6PElNx9dfxGv//On8LlAqzWeSj3Tvpf39G4tno9Kb/nrn4xJuYen/nQUA1KnuidkfSsuvE1lCrVZrF9zz8/MzWlOGrN+9e/fQoEEDCIKA6Ohok4GFLrVaDZVKZXaLFVuXl5+N/H6H8qeObIrCYLRI6miPSuc2lZlp/txqhIjyq1y5cti9ezfUajUCAwMxZcoUo+JwAMjOzkZUVBQaNmyIYcOGFUJP7RdTbGRTFAajRWqVCEj4B5coAPhf3GMqQGINEhHJLSAgAMePH8cHH3yAuXPnYt68eQgICIC3tzdcXFxw584dnDp1Ck+fPkXNmjUxevTowu6yXWGARDbFeARJWqG2KLyKkMxO82dWmohkUqlSJezatQtHjx7Fli1bsH//fuzbtw8ZGRkoX748unbtitDQUISEhMi2XQhJwwCJbIpRgCRxqr+oAPC/uEjNWWxE9JoFBgYiMDCwsLtBOliDRDZFd6FIQHowo9YdIeI6SEREdo8BEtkUwxkN0lNsuvdws1oiInvHAIlsikIhAHrBjtQUm04AZCLFxllsRET2hQES2RzddJhKag2S3giRiREk1iDRa6RbjGu4lQaRPdPNChR00ToDJLI5lgQzos5PgvnNahkgUcESBAHOzs4AgCdPnhRyb4iKjrS0NACAk5NTgQdInMVGNudlHdLLf2VIrUGCXpG2qRGkV79nkTa9DqVLl8bdu3dx//59ZGdnw83NDc7OzpzqTXZJrVYjLS1Nu5imm5tbgX8mAySyOXojSJKn+TPFRkVLqVKlkJGRgdTUVDx8+BAPHz4s7C4RFQkuLi7w8PAo8M9hgEQ2R3eqv1xF2kyx0eumUChQvnx5uLq64unTp0hLS2M9Etk1JycnuLm5wcPDw2iT8YLAAIlsjlInH6ZW5WUlbc09ZkaQmGKj10QQBJQsWRIlS5YEAIiiCO4vTvZIEITXnl5mgEQ2x5IRJN0aJNFsis3yvhHlR2F8SRDZK85iI5tj2Sw2nQDJzCw2roNERGT7GCCRzclvgMQUGxERMUAim2PRjDO9FJtxDk3JWWxERHaFARLZHIUy70XaugsdmZ3FxhEkIiKbxwCJbE6+a5BMjCBxHSQiIvvCAIlsjiULReZtFhsDJCIiW8cAiWyOfjAjNcVmpkibKTYiIrvCAIlsjl4NkuQU26t7zKXYRBFcrI+IyMYxQCKbY1E6TGEmxWawOB/TbEREto0BEtkc3ZW0VVJrkHRHkEzMfFMqDQIkjiAREdk0BkhkcxS6U/YtqEGSMoLE1bSJiGwbAySyOZYtFKlbg2R8j26beWqXiIisEgMksjkWTfPXKewWTS0UaRggMT4iIrJpDJDI5uS/SNvELDaDDdQ5gkREZNsYIJHNUVqw1Yigk2IzNTzEFBsRkX1hgEQ2x6IRJN0Um4kibaXCsEhbYvE3ERFZJQZIZHN0p/nLl2IzHEGyrG9ERGQdGCCRzbFkBElQKF/9wdRWI0ZF2kyxERHZMgZIZHPyvw6S8T2CIOjuZ8saJCIiG8cAiWyOXopN4jR/QZF7kTbADWuJiOwJAySyOZYVab9KsZkq0ra4XSIiskoMkMjmWLJQpKQRJAZIRER2gwES2RzLapB0AyTT9zDFRkRkPxggkc2xZJq/7giSqSJtQH8EiZvVEhHZNgZIZHMsm+afxyJtBkhERDaNARLZHN0Um0rqViM6Rdo5pdh0V9Nmio2IyLZZdYCUkZGBzz//HDVq1ICLiwsqVqyIYcOGISkpKc9tpaamYuzYsahWrRqcnZ1RrVo1jBkzBqmpqSavHzp06P/WxjH967vvvsvn05GlLEqxKSXUIOldwgCJiMiWORR2ByyVkZGBtm3b4ujRo6hQoQK6d++OmzdvYu3atdi1axd+++03+Pj4SGrrwYMHaNasGa5du4Y333wTISEhuHjxIr755hvExMTg2LFj8PDwMHlvx44dUb58eaPjfn5++Xo+sly+V9Jmio2IyO5ZbYD05Zdf4ujRo2jWrBni4uJQokQJAMCiRYvw8ccfY9iwYTh48KCktsaNG4dr166hZ8+e2Lp1KxwcXr6W0aNHY+nSpRg/fjzWr19v8t7JkyejVatWsjwTySP/0/zNF2kzxUZEZNusMsWWlZWFpUuXAgCWL1+uDY4AYPz48ahTpw5+/fVXnDp1ymxbd+/eRXh4OBwdHfHtt99qgyMA+Oqrr+Dl5YXw8HDcu3dP/gehAmHRCJJSwggS10EiIrIbVhkgHT58GKmpqfDx8UG9evWMzvfu3RsAEB0dbbat2NhYqNVqBAUFoVy5cnrnnJ2d8a9//QsqlQqxsbHydJ4KnFKZ93WQdEeQBCnrIElcXomIiKyTVabYzp07BwCoX7++yfOa45rr8tvWmjVrcmwrKioK27Ztg0qlgre3N/71r3/B39/f7OdSwbEsxaYzgpRD+owpNiIi+2GVAdLt27cBAJUrVzZ5XnNcc11BtqVJ9WlMmjQJH374IZYsWaKXrstNzZo1TR5PTEyUXGhOr1iSClNISLEpmWIjIrIbVplie/bsGQCgePHiJs+7urrqXVcQbdWrVw/fffcd/vjjDzx//hx//vknli9fDnd3d3z77beYMGGCtIch2elP87ckxWZ+BIkraRMR2TarHEES/5feEHRqQkydL8i2xowZo/dnb29vfPTRRwgKCkKDBg20s9+qVKlitg8XL140eTynkSXKnf5ebBYUaYucxUZEZO+scgTJzc0NAJCWlmby/PPnzwFAb3bb62gLAGrVqoVu3bpBpVIhPj5e0j0kL0sWipSSYuM6SERE9sMqA6SqVasCQI4rZmuOa657XW1p+Pr6AgDu3Lkj+R6SjyVF2roBkpQUGwMkIiLbZpUBUkBAAADg9OnTJs9rjtepU+e1tqXx6NEjANJHnUhe+ik2C/Ziy2kWm8AaJCIie2GVAVLz5s1RqlQpJCYm4syZM0bnIyMjAQBdu3Y121anTp2gUChw6NAh3L9/X+/cixcvEB0dDYVCgeDgYEl9e/HiBXbv3g0AaNCggaR7SF75nebPESQiIrLKAMnJyQkjR44EAIwcOVKvfmjRokU4f/48WrRogUaNGmmPL1u2DP7+/pgyZYpeWxUqVED//v2RmZmJjz76CNnZ2dpzEydORHJyMgYMGKC339rVq1fx008/QaVS6bWVnJyMfv364a+//kJAQAACAwNlfW6SJr/T/IUcRpCULNImIrIbVjmLDQCmTZuG+Ph4HD16FL6+vnjnnXdw69YtJCQkwMPDA2vXrtW7PiUlBVevXjVZF/T111/j2LFj2LZtG/z9/dGwYUNcvHgRFy5cgI+PDxYvXqx3/Z07dxASEgIPDw/4+/ujUqVKuH//Pk6dOoWnT5+icuXK+L//+78cZ8ZRwVIo8z6LTaGzZlWOI0gs0iYishtWOYIEAC4uLti/fz+mT5+O4sWLY8eOHbh58ybCwsJw5swZVK9eXXJbnp6eOHHiBEaNGoXMzExs374djx8/xsiRI3H8+HF4enrqXV+jRg2MHTsWvr6+SExMxPbt23Hy5En4+vri888/x/nz51GjRg25H5kk0luvSCWtBkmR1xQbR5CIiGyaIOZl0SB6rTTrIOW0ThKZdu/OE6xccBAA4OikxJQ5nc3ec/bQHqQt+AEA8KyEAzqGbzW65r+rjuHk5ZebFn/Qoza6tnhTxl4TEZGc8vsdarUjSEQ5saQGSak3zT+HdpliIyKyGwyQyOZYVKStMF+krbN6AFNsREQ2jgES2RylTpG2qBYlbT2jUOoUaecYIHEEiYjIXjBAIpujG8gA0oIZRR5TbFwokojItjFAIptjWYD0agRJIWUEiSk2IiKbxgCJbI5RgCRhNW1BJy0n5HC5forNsr4REZF1YIBENkd3oUhA2n5sSgdH7e+5UCQREVntStqUd6JaheysNPMXmqB0LA6Fwjr+uliSYlPqFWnncA1TbEREdsM6vvFIFpkZqbhweK5F9zo4usKnbhhKlPaWuVfyUygtqUF6NeqkkJRiY4BERGTLmGIjSbKz0nD/r6OF3Q1JFAqDFJuE7UaUSp0UGwCVKtvoGqbYiIjsBwMkkiz7xdPC7oIkhnsE53UWGwCoVCrja5hiIyKyG0yx2RGnYqVRr+2Xebon9f4F3Ph9MwAgOzu9ILolO0EQoFAI2sAor+sgAYBalQ3AWf8aptiIiOwGAyQ7IggKvensUjg4ldD+XpVlHQESAP0AScI0f91ZbACgysoCihlcwwCJiMhuMMVGuVI6vooSVFYyggToF11bNoJkIsWmu5I2U2xERDaNARLlysFBN0DKgChaxwqJuukwlYQibQfDESS1iSJtjiAREdkNBkiUK90RJOBlkGQNdKf6W1SknZ1lfA0DJCIiu8EAiXKldHDBy4nvL1lLHVJegxmlQYrN5Cw2gbPYiIjsBQMkypUgKKB0eDWby1pmsukHSBJSbEqDFJsq9xEkFUeQiIhsGgMkMkupW4eU9bwQeyKdUrdIW9JmtRKKtHV+WphiIyKybQyQyCylY3Ht7201xaZQKKDWWWDS3Cw2BkhERLaNARKZ5aBTqJ1tLUXaFhRUizoBkqkibW5WS0RkPxggkVnWmGLT3Y9Nyl5sAKDWHSEyt9UIR5CIiGwaAyQyyxoXi8zrNH9AfwTJfIrN8r4REVHRxwCJzNJdLDLbSmqQBEtSbLr3qMwsFMkUGxGRTWOARGZZ4wiSJfummR1BYoqNiMhuMEAis3SLtK1mFpsy7zVIomBmBImz2IiI7AYDJDJLaYUpNotmsen8NKiyzYwgMcVGRGTTGCCRWdaYYrNsmr/uPbmPIHElbSIi28YAicxycLDyhSIlrKQN6AdIImuQiIjsGgMkMkupt1BkOkQrSC/p1SBJnJOvP4uNKTYiInvGAInM0q1BgqiGWvWi8Dojkd7GslJHkPRGiIwDJCWLtImI7AYDJDJLdxYbYB1pNovSYTrT/M2m2DiCRERk0xggkVmCQgmF0kn752wrKNS2aCVtsym2V7/nCBIRkW1jgESS6O/HZgUBksKCGiQh9xQb10EiIrIfDJBIEmub6q+0YARJd4iIKTYiIvvGAIkksbb92Cya5m8mxabUG5VigEREZMsYIJEk1jaCZEmKDWbXQXr1e6lNEhGRdWKARJJY235sQgGMIOktHcAUGxGRTWOARJJY235sFk3z17lHZJE2EZFdY4BEkuin2J4XYk+ksWSaPwSdIm0TOTRuNUJEZD8cCrsD9Po8ysjEilN/Gh1XKgQ0qVgGrap55Xiv/n5sGQXSPzlZVFCtG1Rlcy82IiJ7xgDJjmSrRdx4bHr0J/FRGt72dENZVxeT5/X3Y7OyESSV1HWQdEeQck+xqRggERHZNKbYCAAgAvjrSc61Rda3UGT+apBMTVPjOkhERPaDI0h2xM3JAe/XfUPv2N4b97WjSinpmTneqzuLzXaLtHXScibXQWKKjYjIXjBAsiMuDko0qlhG71hiatqrAOn5ixzvtb51kPKeYtOfxWZiBEngCBIRkb1gis3OeRZz1v4+txEk3RSbqM6GWpVVoP3KL4XSgiJtcwESR5CIiOwGAyQ751ncSfv75FxGkHRTbEDRH0XSW9RR4kKRgkL56g/m9mJjgEREZNMYINk5r+KvRpAepGfmmDoSFI4QhFcBRFGvQ8r/QpFMsRER2TMGSHbOo9irEaRstYjUDNOpM0EQrKoOybK92KQvFCmKgMggiYjIZjFAsnMuDkq4Ob2q1c99JpvuYpFFPECyZCVtnbolmCjs1h1BylO7RERkdRggkV4dUq4z2RxeLSKZnVW0F4u0aEq+wtwIkv6fmWYjIrJdDJBIfyZbrlP9dUaQinqKzYKVtIU8LBQJcDVtIiJbxgCJ4KU7ky23FJsVraatsGAvNt1ZbOa2GslLu0REZH0YIBE8i0sdQdLdj61oB0hCvlNsxvcoDUaQGB8REdkuBkhkkGKTtlhk0R9B0k2xSRxB0i3SlpBi4wgSEZHtYoBEekXaqS+ykJVDzY417ceW373YOIuNiMi+MUAilHFx0tvIPqep/ta0DpJSd6sRyUXaOj8OooQRJM5iIyKyWQyQCEqFgDIu5qf6W22KTWqRtlKnSNvUCBJTbEREdoMBEgHQ33IkpzokBysq0rZooUhzI0hMsRER2Q0GSATAYLHIdDsdQdINkEzco1AI0I2RmGIjIrJdDJAIgP5MtuScUmw6C0WqVS9MrhVUVFiyF5tCJ8VmahYbYLBhLUeQiIhsFgMkAmA4gmQ+xQYAquyMAu1TfuivpC3PCBKgPzLFlbSJiGwXAyQCYFiD9MLkTvUKpROAVwFCUd6PzaJAJo8BElNsRES2iwESAQA8i70aQUrPVuN5lnH6TBAUVjPVX2GwKrapgM/oHodXKTaBKTYiIrvGAIkAACWcHOCss3ZQTnVIuvuxFeXFIg2n5JvaOsSQ7l5sTLEREdk3BkgEABAEQa8OKadNa61mBEmZ9yn55haKBDiCRERkLxggkZZhHZIp1jLV32hjWSkBktL8CJKSNUhERHbBqgOkjIwMfP7556hRowZcXFxQsWJFDBs2DElJSXluKzU1FWPHjkW1atXg7OyMatWqYcyYMUhNTc3xHrVaja+//hq1a9dGsWLF4OXlhdDQUFy6dCkfT1V4pGxaay37sSmU+n+1VRK2G1EodGuQckqxvfo9R5CIiGyX1QZIGRkZaNu2LWbOnIlnz56he/fuqFKlCtauXYv69esjMTFRclsPHjxA48aNsWTJEjg4OCAkJARubm745ptv0KhRIzx48MDoHlEU0bdvX4wbNw5JSUno0qULatasiW3btqFhw4ZISEiQ83FfC0mLReql2KxjFhtgwQhSDqNDTLEREdkHqw2QvvzySxw9ehTNmjXDH3/8ga1btyIhIQELFy5EcnIyhg0bJrmtcePG4dq1a+jZsyeuXr2KrVu34sKFCxg1ahSuX7+O8ePHG92zdu1aREZGwtfXF1euXEFkZCQOHDiAiIgIpKenY+DAgcjOzpbzkQuc/mKROdQgObxaLFKVVYTXQbIgQNJdKDLHWWxMsRER2QWrDJCysrKwdOlSAMDy5ctRokQJ7bnx48ejTp06+PXXX3Hq1Cmzbd29exfh4eFwdHTEt99+CwcHB+25r776Cl5eXggPD8e9e/f07lu4cCEAYP78+ShXrpz2eK9evdCtWzckJibip59+ytdzvm5eOiNID9NfmAwAHBxdtL8vyvuxGQVIEhaLlFKDZMkWJkREZH2sMkA6fPgwUlNT4ePjg3r16hmd7927NwAgOjrabFuxsbFQq9UICgrSC3QAwNnZGf/617+gUqkQGxurPX7jxg1cunQJxYoVQ5cuXfL1+UWJh06RtkoEHmUYjyLpF2kX3RSbYMkIkm4NkqQUm4WdIyKiIs/B/CVFz7lz5wAA9evXN3lec1xzXX7bWrNmjV5bmt/XqlULjo6O+fr81yk7OxtJf93J9ZqSaY/xPPPlIpERR86jpLP+8714/hxPH/oAAIRURxy6t7tgOisDwfeJtpRobWwMdJc5MuVFRibE9h3/dzNwbtVao2uquIuoXOrl72MP7EbsQRk7TERk55zVaoz9d5heNqewFH4PLHD79m0AQOXKlU2e1xzXXCd3W3J+PgDUrFnT5PHExET4+PhIakOKpL/uYMOys7leU+p/vwDgPtJx3+RVlbS/e4SiPIxSUvu7Z5Kud8arpzev6G7VS0RknZ7j5XfVG95VCrsr1plie/bs5ddd8eLFTZ53dXXVu07utuT8fCIiIip6rHIESbOvliAIuZ4vqLbM3ZNXFy9eNHk8p5ElIiIiKlhWGSC5ubkBANLS0kyef/78ZfGw7uw2Odsyd4/muJTPf50qV6mAISMLuxdEREQ5q1ylQmF3AYCVBkhVq1YFgBxXzNYc11wnd1tyfv7r5ODgUCTyukREREWdVdYgBQQEAABOnz5t8rzmeJ06dQqkLc09Fy5cQFZWVr4+n4iIiIoeqwyQmjdvjlKlSiExMRFnzpwxOh8ZGQkA6Nq1q9m2OnXqBIVCgUOHDuH+ff05Wy9evEB0dDQUCgWCg4O1x729vfHWW28hPT0du3cbT3PPy+cTERFR0WOVAZKTkxNGjnxZTDNy5Ei9WqBFixbh/PnzaNGiBRo1aqQ9vmzZMvj7+2PKlCl6bVWoUAH9+/dHZmYmPvroI73tQSZOnIjk5GQMGDAA5cuX17tPs/3IxIkT9QKrqKgo7Ny5E97e3ggJCZHtmYmIiOj1scoaJACYNm0a4uPjcfToUfj6+uKdd97BrVu3kJCQAA8PD6xdq7/IX0pKCq5evYo7d4wXSvz6669x7NgxbNu2Df7+/mjYsCEuXryICxcuwMfHB4sXLza6Z9iwYYiJicH27dvh7++Ptm3bIiUlBQcPHoSLiws2bdpkchFJIiIiKvqscgQJAFxcXLB//35Mnz4dxYsXx44dO3Dz5k2EhYXhzJkzqF69uuS2PD09ceLECYwaNQqZmZnYvn07Hj9+jJEjR+L48ePw9PQ0ukehUCAiIgILFy5ExYoVsWvXLvz+++/o0aMHTp48icDAQDkfl4iIiF4jQczLokH0WmnWQcppnSQiIiIyLb/foVY7gkRERERUUBggERERERlggERERERkgAESERERkQEGSEREREQGGCARERERGWCARERERGSAARIRERGRAQZIRERERAYYIBEREREZ4FYjRZibmxuysrLg4+NT2F0hIiKyKomJiXB0dMTTp08tup8jSEWYq6srHB0dZW0zMTERiYmJsrZp7/hO5cd3Ki++T/nxncqrIN6no6MjXF1dLb6fI0h2hhvgyo/vVH58p/Li+5Qf36m8iuL75AgSERERkQEGSEREREQGGCARERERGWCARERERGSAARIRERGRAc5iIyIiIjLAESQiIiIiAwyQiIiIiAwwQCIiIiIywACJiIiIyAADJCIiIiIDDJCIiIiIDDBAIiIiIjLAAImIiIjIAAMkK5eRkYHPP/8cNWrUgIuLCypWrIhhw4YhKSkpz22lpqZi7NixqFatGpydnVGtWjWMGTMGqamp8ne8CJPjnaampmLz5s0YMGAA3n77bbi6usLNzQ1NmjTBkiVLkJWVVYBPULTI+XdU17Vr11CsWDEIgoBOnTrJ1FvrIPc7vX79Ov7973/jjTfegIuLC7y8vBAYGIivvvpK5p4XTXK+zz179iA4OBienp5wdHRE2bJl0bVrV/zyyy8F0POi6dSpU5g7dy569uyJSpUqQRAEuLi4WNxeoX03iWS10tPTxcDAQBGAWKFCBbFPnz5i48aNRQCil5eXeP36dcltpaSkiL6+viIA8c033xT79Okj1qxZUwQgVq9eXUxJSSnAJyk65Hqnn376qQhAVCgUYoMGDcS+ffuKbdq0EZ2dnUUAYosWLcS0tLQCfprCJ+ffUUOtW7cWBUEQAYgdO3aUsddFm9zvNCoqSnRxcREFQRDr168v9uvXT2zfvr1Yvnx50cfHp4CeouiQ830uXLhQBCAKgiC2aNFC7Nu3r9ioUSMRgAhAXLFiRQE+SdHRvXt37TNrfjk7O1vUVmF+NzFAsmLTp08XAYjNmjUTnz59qj2u+SENCgqS3NbgwYNFAGLPnj3FrKws7fFRo0aJAMQhQ4bI2veiSq53OmfOHHHq1KliUlKS3vE//vhDrFq1qghAnDJliqx9L4rk/Duqa9WqVSIA8f3337e7AEnOd3r27FnRyclJ9PDwEA8dOqR3TqVSiSdOnJCt30WVXO/z/v37opOTk+jk5GT0LiMjI0VBEMTixYvrfYatmjt3rvjZZ5+J0dHR4t27d/MVIBXmdxMDJCuVmZkpuru7iwDE06dPG52vU6eOCEA8efKk2bbu3LkjKhQK0dHRUbx7967euYyMDNHLy0tUKpVG52yNnO80N5s3bxYBiG+88Ua+2inqCup93rt3TyxdurTYrl07cf/+/XYVIMn9Tt955x0RgBgdHS13V62CnO8zOjpaBCB26tTJ5PmAgAARgJiQkJDvflsbSwOkwv5uYg2SlTp8+DBSU1Ph4+ODevXqGZ3v3bs3ACA6OtpsW7GxsVCr1QgKCkK5cuX0zjk7O+Nf//oXVCoVYmNj5el8ESXnO81NQEAAAOCff/7JVztFXUG9z9GjRyM9PR0rVqyQpZ/WRM53evnyZRw6dAg1atRA165dZe+rNZDzfTo7O0v6zDJlyuStk3assL+bGCBZqXPnzgEA6tevb/K85rjmutfVljV7Xe/hzz//BACUL18+X+0UdQXxPmNiYrB161ZMnToV1atXz38nrYyc71RTNNy+fXtkZGRg/fr1GDVqFEaPHo1Vq1bhyZMnMvW66JLzfTZq1AilSpXCvn37cPjwYb1zUVFROH/+PAIDA+3y762lCvu7yaFAWqUCd/v2bQBA5cqVTZ7XHNdc97rasmav6z0sWbIEANC9e/d8tVPUyf0+09LS8NFHH8HPzw+TJk2Sp5NWRs53evHiRQBAsWLFULduXVy9elXv/JQpU7Bt2zYEBQXlp8tFmpzv093dHatWrcLAgQMRFBSE5s2bo1KlSrhx4wZOnDiBTp06Yd26dbL13R4U9ncTR5Cs1LNnzwAAxYsXN3ne1dVV77rX1ZY1ex3v4bvvvkN8fDzc3d0xefJki9uxBnK/z2nTpuHWrVtYsWIFnJyc5OmklZHznT569AgA8PXXX+Phw4eIiopCamoqrl69igEDBiAlJQUhISG4c+eOTL0veuT+O9q7d2/ExsbCw8MDhw8fxtatW3H8+HGULVsWbdq0gYeHhzwdtxOF/d3EAMlKiaIIABAEIdfzr7sta1bQ7+HgwYMYM2YMBEHAmjVrULFixXy1V9TJ+T5PnjyJpUuXYsiQIWjdurUs/bNGcr5TlUoFAMjOzsamTZvQo0cPlCpVCjVq1EB4eDgaNWqER48eYfny5fnveBEl98/8woUL0b59ewQFBeH8+fN49uwZzp8/j2bNmmHChAno27dvvvtsTwr7u4kBkpVyc3MD8DLtYMrz588BACVKlHitbVmzgnwP58+fR0hICDIzM7FkyRL06NHD8o5aCbneZ3Z2Nv7973+jVKlSWLBggbydtDIF8XNfqVIldOjQwej8u+++CwA4cOCAJV21CnK+z4MHD+KTTz5B3bp1ERERgdq1a8PV1RW1a9dGZGQk6tWrh23btiEuLk6+B7Bxhf3dxBokK1W1alUAyHGlV81xzXWvqy1rVlDvITExER07dkRqaipmzJiBUaNG5a+jVkKu95mUlISzZ8+ifPnyCA0N1TunWUn3+PHjaNWqFUqUKIFdu3bls+dFl5x/R9944w0AQLVq1XI9f//+/Tz20nrI+T43bNgAAOjZsycUCv2xB6VSiZ49e+LMmTM4cOCAyYCUjBX2dxMDJCulmSp++vRpk+c1x+vUqfNa27JmBfEe/vnnH7Rv3x53797FmDFj8Pnnn+e/o1ZC7vd59+5d3L171+S5R48e4eDBgyhVqpQFPbUecr5TzbT2hw8fmjz/4MEDALY9cizn+9R8WZcsWdLkec3xnN43GSv076YCWV2JCtyLFy/EUqVKmV3g7Pjx42bb+ueff0SFQiE6OTmJ9+7d0zunWYxLoVCId+7cka3/RZGc71QURfHhw4dirVq1RADiu+++K6rVarm7XKTJ/T5NsbeFIuV8p2lpaaKrq6vo6Ogo3r592+j8e++9JwIQ33vvPVn6XhTJ+T6HDBmS68rOgwYNEgGIc+bMyXe/rQ0sXCiysL+bGCBZMc1+X4GBgeKzZ8+0xzVL5Ldo0ULv+qVLl4p+fn7i5MmTjdoaOHCgCEDs1auX3nLuo0ePFgGIgwYNKrgHKULkeqdpaWli06ZNRQBinz59xOzs7NfS/6JGzr+jpthbgCSK8r7TyZMniwDELl266LUVGxsrOjg4iIIg2PzKz3K9z6ioKBGAqFQqxZ07d+qd27Fjh6hQKESFQiFeuXKl4B6miDIXIBXV7yYGSFYsPT1dbNKkid4mi5o/e3h4iNeuXdO7/vPPPxcBiGFhYUZtJScniz4+PiIA0cfHR+zbt6929MPHx0dMTk5+TU9VuOR6p2PHjtX+x3LAgAFiWFiYyV+2Ts6/o6bYY4Ak5ztNT08Xmzdvrm0rJCREDAwMFBUKhQhAnD179mt6qsIj1/tUq9ViaGiodnPWhg0biqGhoWLDhg21x+zhfYqiKO7atUts0qSJ9hf+t4Gv7rFdu3Zpry+q300MkKzc8+fPxenTp4s+Pj6ik5OTWK5cOTEsLMzkkLm5L5+HDx+Ko0aNEqtUqSI6OTmJVapUEUeOHCk+ePCggJ+iaJHjnYaFhWn/o5jbL3sg599RQ/YYIImivO/0xYsX4uzZs8W33npLdHZ2FkuVKiW2bdtW7wvM1sn1PtVqtbh69WoxKChIdHd3Fx0cHERPT0+xc+fOYmxs7Gt4kqJh7dq1Zv/bt3btWu31RfW7SRBFO1nkhoiIiEgiroNEREREZIABEhEREZEBBkhEREREBhggERERERlggERERERkgAESERERkQEGSEREREQGGCARERERGWCARERERGSAARIRERGRAQZIRERERAYYIBGRzRAEQe+XQqFAqVKl0LRpUyxevBhZWVmF3UVJhg4dCkEQcODAAb3jrVq1giAIuHnzZqH0i8ieOBR2B4iI5BYWFgYAUKlUuHnzJo4ePYqEhATs3r0be/bsgYMD/9NHRLnjfyWIyOasW7dO788JCQlo1aoVfvnlF/z4448YNGhQ4XSMiKwGU2xEZPOaNGmCoUOHAgB+/vnnwu0MEVkFBkhEZBdq1qwJALh//77ROVEUsX79egQFBcHd3R3FihVDnTp1sGDBghzrltLS0jBnzhzUr18fbm5uKFGiBN5++22MHTsWt27d0l6XmpqKpUuXomPHjqhWrRqcnZ3h4eGBTp06Ye/evQXzsESUbwyQiMguPH36FABQtmxZveNqtRp9+/bF0KFDce7cOTRs2BAdO3ZEcnIyJkyYgJCQEKjVar177ty5g8aNG2Pq1Km4desW2rRpg06dOsHJyQnffPMN9u/fr7322LFjGD16NC5fvgxfX1/06NEDfn5+iIuLQ8eOHbFmzZqCf3giyjPWIBGRXdizZw8AoFOnTnrHFyxYgIiICLRv3x7h4eHw8vIC8HKEqH///oiOjsaKFSswYsQI7T2DBw/GpUuX0L9/f/zwww9wdXXVnrt27RpUKpX2z35+fjhy5AgCAwP1PvfMmTNo06YNxo0bhz59+qBEiRKyPzMRWY4jSERks9RqNRITE/Hhhx/i119/Rbdu3dC3b1/t+ezsbHz11Vdwc3PD5s2btcERALi6uuKHH36As7MzVq5cqT1+/Phx/PLLLyhfvrxRcAQAvr6+8Pf31/7Z29vbKDgCgHr16mHEiBF48uSJ3ogTERUNHEEiIpsjCILRsffeew/ff/89FIpX/y48c+YMUlJSEBwcDE9PT6N7ypUrB19fX1y4cAHp6ekoVqwY4uPjAQADBw40Co5yolKp8Msvv+Do0aO4e/cuMjIyALwcbdL9XyIqOhggEZHN0ayDlJGRgbNnz+Lq1atYvXo1mjVrhvfee097nWbBxdjYWJNBla6HDx+iUqVK+OuvvwAAPj4+kvqSlJSErl274ty5czleo6mPIqKigwESEdkcw3WQ5s+fj0mTJmHUqFFo164dqlWrBgDaWiFfX1+TaTBdzs7Oen82F1BpDB8+HOfOnUPPnj0xadIk+Pn5wc3NDQqFAt9//z0++OADiKIo8cmI6HVhgERENm/ixIn45ZdfEBcXh//+97/amWOVK1cGANSqVcsoqMpJlSpVAADXr183e21aWhr27t2LcuXK4f/+7/+gVCr1zv/55595eAoiep1YpE1EdmHevHkQBAEbN27UrlPUqFEjlCpVCvv378eTJ08ktdOuXTsAQHh4OJ4/f57rtY8fP4ZarUaFChWMgqPs7Gxs377dgichoteBARIR2YW6deuie/fuyM7Oxvz58wG8TJt98sknSE1NRa9evfQWeNQ4f/48tm7dqv1z48aN0bp1a9y9excffPCBUZB0/fp1XLlyBcDLNZdKlSqFCxcu4MiRI9prVCoVJk6ciD/++KMgHpWIZMAAiYjsxowZMyAIAtasWYO7d+8CAKZOnYr+/fsjPj4efn5+CAwMRL9+/dCuXTu8+eabCAgIwJYtW/Ta2bhxI2rUqIFNmzahatWqCAkJQWhoKOrVq4caNWrg2LFjAAAHBwdMnDgR2dnZaNmyJTp06IB+/fqhevXq+O677/TWViKiooUBEhHZjYCAAPTo0QMZGRlYtGgRAEChUGDz5s2IjIxE69atce3aNURFReHSpUsoV64cZsyYgXnz5um1U6lSJZw4cQIzZsxAhQoVEBcXh59//hmZmZkYO3Ys2rRpo7126tSpWL9+PerUqYMjR44gPj4eAQEBOHbsGBo2bPhan5+IpBNETp8gIiIi0sMRJCIiIiIDDJCIiIiIDDBAIiIiIjLAAImIiIjIAAMkIiIiIgMMkIiIiIgMMEAiIiIiMsAAiYiIiMgAAyQiIiIiAwyQiIiIiAwwQCIiIiIywACJiIiIyAADJCIiIiIDDJCIiIiIDDBAIiIiIjLAAImIiIjIAAMkIiIiIgP/DzuitUVcJyaXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(4, 4), dpi=150, facecolor=\"w\")\n",
    "\n",
    "# Plot the precision-recall curves for every second threshold and precision\n",
    "for precision, thresh in zip(metrics[\"oks_voc.precisions\"], metrics[\"oks_voc.match_score_thresholds\"]):\n",
    "    plt.plot(metrics[\"oks_voc.recall_thresholds\"], precision, \"-\", label=f\"OKS @ {thresh:.2f}\")\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "# Display the plot inline\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1. using CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see: \n",
    "usage: sleap-track [-h] [-m MODELS] [--frames FRAMES] [--only-labeled-frames] [--only-suggested-frames] [-o OUTPUT] [--no-empty-frames]\n",
    "                   [--verbosity {none,rich,json}] [--video.dataset VIDEO.DATASET] [--video.input_format VIDEO.INPUT_FORMAT]\n",
    "                   [--video.index VIDEO.INDEX] [--cpu | --first-gpu | --last-gpu | --gpu GPU] [--max_edge_length_ratio MAX_EDGE_LENGTH_RATIO]\n",
    "                   [--dist_penalty_weight DIST_PENALTY_WEIGHT] [--batch_size BATCH_SIZE] [--open-in-gui] [--peak_threshold PEAK_THRESHOLD]\n",
    "                   [-n MAX_INSTANCES] [--tracking.tracker TRACKING.TRACKER] [--tracking.max_tracking TRACKING.MAX_TRACKING]\n",
    "                   [--tracking.max_tracks TRACKING.MAX_TRACKS] [--tracking.target_instance_count TRACKING.TARGET_INSTANCE_COUNT]\n",
    "                   [--tracking.pre_cull_to_target TRACKING.PRE_CULL_TO_TARGET] [--tracking.pre_cull_iou_threshold TRACKING.PRE_CULL_IOU_THRESHOLD]\n",
    "                   [--tracking.post_connect_single_breaks TRACKING.POST_CONNECT_SINGLE_BREAKS]\n",
    "                   [--tracking.clean_instance_count TRACKING.CLEAN_INSTANCE_COUNT] [--tracking.clean_iou_threshold TRACKING.CLEAN_IOU_THRESHOLD]\n",
    "                   [--tracking.similarity TRACKING.SIMILARITY] [--tracking.match TRACKING.MATCH] [--tracking.robust TRACKING.ROBUST]\n",
    "                   [--tracking.track_window TRACKING.TRACK_WINDOW] [--tracking.min_new_track_points TRACKING.MIN_NEW_TRACK_POINTS]\n",
    "                   [--tracking.min_match_points TRACKING.MIN_MATCH_POINTS] [--tracking.img_scale TRACKING.IMG_SCALE]\n",
    "                   [--tracking.of_window_size TRACKING.OF_WINDOW_SIZE] [--tracking.of_max_levels TRACKING.OF_MAX_LEVELS]\n",
    "                   [--tracking.save_shifted_instances TRACKING.SAVE_SHIFTED_INSTANCES] [--tracking.kf_node_indices TRACKING.KF_NODE_INDICES]\n",
    "                   [--tracking.kf_init_frame_count TRACKING.KF_INIT_FRAME_COUNT]\n",
    "                   [data_path]\n",
    "\n",
    "positional arguments:\n",
    "  data_path             Path to data to predict on. This can be a labels (.slp) file or any supported video format.\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -m MODELS, --model MODELS\n",
    "                        Path to trained model directory (with training_config.json). Multiple models can be specified, each preceded by --model.\n",
    "  --frames FRAMES       List of frames to predict when running on a video. Can be specified as a comma separated list (e.g. 1,2,3) or a range\n",
    "                        separated by hyphen (e.g., 1-3, for 1,2,3). If not provided, defaults to predicting on the entire video.\n",
    "  --only-labeled-frames\n",
    "                        Only run inference on user labeled frames when running on labels dataset. This is useful for generating predictions to compare\n",
    "                        against ground truth.\n",
    "  --only-suggested-frames\n",
    "                        Only run inference on unlabeled suggested frames when running on labels dataset. This is useful for generating predictions for\n",
    "                        initialization during labeling.\n",
    "  -o OUTPUT, --output OUTPUT\n",
    "                        The output filename to use for the predicted data. If not provided, defaults to '[data_path].predictions.slp'.\n",
    "  --no-empty-frames     Clear any empty frames that did not have any detected instances before saving to output.\n",
    "  --verbosity {none,rich,json}\n",
    "                        Verbosity of inference progress reporting. 'none' does not output anything during inference, 'rich' displays an updating\n",
    "                        progress bar, and 'json' outputs the progress as a JSON encoded response to the console.\n",
    "  --video.dataset VIDEO.DATASET\n",
    "                        The dataset for HDF5 videos.\n",
    "  --video.input_format VIDEO.INPUT_FORMAT\n",
    "                        The input_format for HDF5 videos.\n",
    "  --video.index VIDEO.INDEX\n",
    "                        Integer index of video in .slp file to predict on. To be used with an .slp path as an alternative to specifying the video\n",
    "                        path.\n",
    "  --cpu                 Run inference only on CPU. If not specified, will use available GPU.\n",
    "  --first-gpu           Run inference on the first GPU, if available.\n",
    "  --last-gpu            Run inference on the last GPU, if available.\n",
    "  --gpu GPU             Run training on the i-th GPU on the system. If 'auto', run on the GPU with the highest percentage of available memory.\n",
    "  --max_edge_length_ratio MAX_EDGE_LENGTH_RATIO\n",
    "                        The maximum expected length of a connected pair of points as a fraction of the image size. Candidate connections longer than\n",
    "                        this length will be penalized during matching. Only applies to bottom-up (PAF) models.\n",
    "  --dist_penalty_weight DIST_PENALTY_WEIGHT\n",
    "                        A coefficient to scale weight of the distance penalty. Set to values greater than 1.0 to enforce the distance penalty more\n",
    "                        strictly. Only applies to bottom-up (PAF) models.\n",
    "  --batch_size BATCH_SIZE\n",
    "                        Number of frames to predict at a time. Larger values result in faster inference speeds, but require more memory.\n",
    "  --open-in-gui         Open the resulting predictions in the GUI when finished.\n",
    "  --peak_threshold PEAK_THRESHOLD\n",
    "                        Minimum confidence map value to consider a peak as valid.\n",
    "  -n MAX_INSTANCES, --max_instances MAX_INSTANCES\n",
    "                        Limit maximum number of instances in multi-instance models. Not available for ID models. Defaults to None.\n",
    "  --tracking.tracker TRACKING.TRACKER\n",
    "                        Options: simple, flow, simplemaxtracks, flowmaxtracks, None (default: None)\n",
    "  --tracking.max_tracking TRACKING.MAX_TRACKING\n",
    "                        If true then the tracker will cap the max number of tracks. (default: False)\n",
    "  --tracking.max_tracks TRACKING.MAX_TRACKS\n",
    "                        Maximum number of tracks to be tracked by the tracker. (default: None)\n",
    "  --tracking.target_instance_count TRACKING.TARGET_INSTANCE_COUNT\n",
    "                        Target number of instances to track per frame. (default: 0)\n",
    "  --tracking.pre_cull_to_target TRACKING.PRE_CULL_TO_TARGET\n",
    "                        If non-zero and target_instance_count is also non-zero, then cull instances over target count per frame *before* tracking.\n",
    "                        (default: 0)\n",
    "  --tracking.pre_cull_iou_threshold TRACKING.PRE_CULL_IOU_THRESHOLD\n",
    "                        If non-zero and pre_cull_to_target also set, then use IOU threshold to remove overlapping instances over count *before*\n",
    "                        tracking. (default: 0)\n",
    "  --tracking.post_connect_single_breaks TRACKING.POST_CONNECT_SINGLE_BREAKS\n",
    "                        If non-zero and target_instance_count is also non-zero, then connect track breaks when exactly one track is lost and exactly\n",
    "                        one track is spawned in frame. (default: 0)\n",
    "  --tracking.clean_instance_count TRACKING.CLEAN_INSTANCE_COUNT\n",
    "                        Target number of instances to clean *after* tracking. (default: 0)\n",
    "  --tracking.clean_iou_threshold TRACKING.CLEAN_IOU_THRESHOLD\n",
    "                        IOU to use when culling instances *after* tracking. (default: 0)\n",
    "  --tracking.similarity TRACKING.SIMILARITY\n",
    "                        Options: instance, centroid, iou (default: instance)\n",
    "  --tracking.match TRACKING.MATCH\n",
    "                        Options: hungarian, greedy (default: greedy)\n",
    "  --tracking.robust TRACKING.ROBUST\n",
    "                        Robust quantile of similarity score for instance matching. If equal to 1, keep the max similarity score (non-robust).\n",
    "                        (default: 1)\n",
    "  --tracking.track_window TRACKING.TRACK_WINDOW\n",
    "                        How many frames back to look for matches (default: 5)\n",
    "  --tracking.min_new_track_points TRACKING.MIN_NEW_TRACK_POINTS\n",
    "                        Minimum number of instance points for spawning new track (default: 0)\n",
    "  --tracking.min_match_points TRACKING.MIN_MATCH_POINTS\n",
    "                        Minimum points for match candidates (default: 0)\n",
    "  --tracking.img_scale TRACKING.IMG_SCALE\n",
    "                        For optical-flow: Image scale (default: 1.0)\n",
    "  --tracking.of_window_size TRACKING.OF_WINDOW_SIZE\n",
    "                        For optical-flow: Optical flow window size to consider at each pyramid (default: 21)\n",
    "  --tracking.of_max_levels TRACKING.OF_MAX_LEVELS\n",
    "                        For optical-flow: Number of pyramid scale levels to consider (default: 3)\n",
    "  --tracking.save_shifted_instances TRACKING.SAVE_SHIFTED_INSTANCES\n",
    "                        If non-zero and tracking.tracker is set to flow, save the shifted instances between elapsed frames (default: 0)\n",
    "  --tracking.kf_node_indices TRACKING.KF_NODE_INDICES\n",
    "                        For Kalman filter: Indices of nodes to track. (default: )\n",
    "  --tracking.kf_init_frame_count TRACKING.KF_INIT_FRAME_COUNT\n",
    "                        For Kalman filter: Number of frames to track with other tracker. 0 means no Kalman filters will be used. (default: 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  -o OUTPUT, --output OUTPUT\n",
    "                        The output filename to use for the predicted data. If not provided, defaults to '[data_path].predictions.slp'.\n",
    "\n",
    "  --verbosity {none,rich,json}\n",
    "                        Verbosity of inference progress reporting. 'none' does not output anything during inference, 'rich' displays an updating\n",
    "                        progress bar, and 'json' outputs the progress as a JSON encoded response to the console.\n",
    "\n",
    "  --cpu                 Run inference only on CPU. If not specified, will use available GPU.\n",
    "\n",
    "    --batch_size BATCH_SIZE\n",
    "                        Number of frames to predict at a time. Larger values result in faster inference speeds, but require more memory.\n",
    "\n",
    "  --open-in-gui         Open the resulting predictions in the GUI when finished.\n",
    "\n",
    "  --peak_threshold PEAK_THRESHOLD\n",
    "                        Minimum confidence map value to consider a peak as valid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 17:38:38.786980\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 17:38:38.823485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.844646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.857289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 2984 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\n",
      "2024-10-02 17:38:38.941508: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 17:38:38.942767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.956094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:38.960123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.587590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.588900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.590020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 17:38:39.591594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1202 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 17:38:44.285992: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 17:38:45.373395: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:45.373460: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.166344: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.166405: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.227468: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.227531: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.319752: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.319815: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.338854: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 17:38:46.475251: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 17:38:46.475324: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m16.7 FPS\u001b[0m6 FPS\u001b[0m8 FPS\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 17:38:54.060876\n",
      "Total runtime: 15.273920774459839 secs\n",
      "Predicted frames: 147/147\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4 -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m15.273920774459839\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 17:38:38.786980'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 17:38:54.060876'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "# without tracking on a video\n",
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/flap1.mp4\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 18:10:06.164381\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 18:10:06.199842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:06.209992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:06.213740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 3010 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "2024-10-02 18:10:07.002319: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 18:10:07.004256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.009966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.013208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.400909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.402140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.404059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:10:07.405052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1240 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 18:10:12.291944: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 18:10:13.060962: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.061037: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.560261: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.560317: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.622518: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.622576: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.712253: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.712307: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 876.70MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.731610: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 18:10:13.869447: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:10:13.869510: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m30.1 FPS\u001b[0m \u001b[31m31.1 FPS\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:10:17.849119\n",
      "Total runtime: 11.684762954711914 secs\n",
      "Predicted frames: 80/80\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m11.684762954711914\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:10:06.164381'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:10:17.849119'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "# without tracking on a .slp dataset\n",
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/labels_gt.test.slp\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started inference at: 2024-10-02 18:13:19.469232\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_errors'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_score_weighting'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'tracking.oks_normalization'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "2024-10-02 18:13:19.505449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.514820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.519676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 3014 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.4.1a2\n",
      "TensorFlow: 2.7.0\n",
      "Numpy: 1.21.5\n",
      "Python: 3.7.12\n",
      "OS: Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "       Initialized: False\n",
      "     Memory growth: True\n",
      "\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.jpg\n",
      "Video: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.jpg\n",
      "2024-10-02 18:13:19.594895: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-02 18:13:19.596475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.600353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.606516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.992065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.993300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.994395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-02 18:13:19.995436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1227 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2024-10-02 18:13:24.120600: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2024-10-02 18:13:24.856016: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:24.856096: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.35GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.388804: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.388850: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.430346: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "2024-10-02 18:13:25.536140: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.536191: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.558197: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.558248: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.622059: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.622109: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-02 18:13:25.678448: W tensorflow/core/common_runtime/bfc_allocator.cc:343] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:26.449140\n",
      "Total runtime: 6.979929685592651 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m6.979929685592651\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:26.449140'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_3.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:28.637856\n",
      "Total runtime: 9.168640375137329 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m9.168640375137329\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:28.637856'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_5.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:30.034574\n",
      "Total runtime: 10.5653555393219 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m10.5653555393219\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:30.034574'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_7.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:31.712635\n",
      "Total runtime: 12.243422269821167 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m12.243422269821167\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:31.712635'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_2.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0mWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2efc373ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:33.151504\n",
      "Total runtime: 13.682286977767944 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m13.682286977767944\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:33.151504'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_6.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0mWARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2efc1eedd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:34.562574\n",
      "Total runtime: 15.093356370925903 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m15.093356370925903\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:34.562574'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_0.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:36.409931\n",
      "Total runtime: 16.94071340560913 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m16.94071340560913\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:36.409931'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_9.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:37.829495\n",
      "Total runtime: 18.36027765274048 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m18.36027765274048\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:37.829495'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_4.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:39.336149\n",
      "Total runtime: 19.86693286895752 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m19.86693286895752\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:39.336149'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_8.predictions.slp\n",
      "\u001b[2KPredicting... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2024-10-02 18:13:40.814249\n",
      "Total runtime: 21.345032215118408 secs\n",
      "Predicted frames: 1/1\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch/training_config.json'\u001b[0m,\n",
      "\u001b[2;32m      \u001b[0m\u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch/training_config.json'\u001b[0m\n",
      "\u001b[2;32m   \u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'TopDownPredictor'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.4.1a2'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-6.1.0-0.deb11.17-amd64-x86_64-with-debian-11.0'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/home/matthew/anaconda3/envs/sleap/bin/sleap-track /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch -m /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.jpg'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m21.345032215118408\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:19.469232'\u001b[0m,\n",
      "\u001b[2;32m   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2024-10-02 18:13:40.814249'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images/frame_flap1.mp4_1.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "# without tracking on a folder of images\n",
    "!sleap-track \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_prediction/test_inference_on_folder_images\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_centroid_50Epoch\" -m \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/SLEAP_model/baseline_models/Oct2_test1_medium_rf.topdown_50Epoch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2. Using predictions to create a new labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can download the generated colab.predicted_suggestions.slp file and merge it into your labeling project (File -> Merge into Project from the GUI) to get new predictions for your suggested frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a DLC model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. create project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/videos\"\n",
      "Created \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/labeled-data\"\n",
      "Created \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/training-datasets\"\n",
      "Created \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models\"\n",
      "Attempting to create a symbolic link of the video ...\n",
      "Created the symlink of /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos/flap1.mp4 to /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/videos/flap1.mp4\n",
      "Created the symlink of /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos/flap2.mp4 to /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/videos/flap2.mp4\n",
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/videos/flap1.mp4\n",
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/videos/flap2.mp4\n",
      "Generated \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/config.yaml\"\n",
      "\n",
      "A new project with name DLC_simple_dataset-model1-2024-09-18 is created at /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "# create new project\n",
    "config_path = deeplabcut.create_new_project('DLC_simple_dataset','model1', ['/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos/flap1.mp4', '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos/flap2.mp4'],\n",
    "              copy_videos=False, multianimal=True, working_directory = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. load the annotations previously annotated to the labelled data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/config.yaml'\n",
    "#config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/CollectedData_model1.h5')\n",
    "#df2 = pd.read_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/labeled-data/flap2/CollectedData_model1.h5')\n",
    "\n",
    "#df2 = pd.read_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep15/CollectedData_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/Filtered_CollectedData_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_all_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisplay_all_cols\u001b[49m(df2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_all_cols' is not defined"
     ]
    }
   ],
   "source": [
    "display_all_cols(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scorer                              model1                           \\\n",
      "individuals                            ID1                            \n",
      "bodyparts                             Head                     Beak   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1232.965220   84.758200  1326.238992   \n",
      "                   img014.png  1232.965220   78.325526  1331.063497   \n",
      "                   img024.png  1232.965220   75.109190  1331.063497   \n",
      "                   img048.png  1226.532546   84.758200  1326.238992   \n",
      "                   img071.png  1183.111997  116.921570  1200.801851   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                     Body_top               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap1 img010.png  144.260434  1184.720166  287.387428   \n",
      "                   img014.png  134.611423  1189.544671  282.562923   \n",
      "                   img024.png  133.003255  1189.544671  269.697575   \n",
      "                   img048.png  147.476771  1184.720166  269.697575   \n",
      "                   img071.png  197.329994  1163.813976  272.913912   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                     RFlipper_mid             LFlipper_mid   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1031.944161  461.069623  1374.484046   \n",
      "                   img014.png  1036.768666  443.379770  1379.308551   \n",
      "                   img024.png   988.523612  401.567390  1419.512763   \n",
      "                   img048.png  1123.609764  166.774793  1332.671666   \n",
      "                   img071.png   966.009253  319.550798  1429.161774   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                  Body_bottom               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap1 img010.png  465.894129  1226.532546  583.290428   \n",
      "                   img014.png  457.853287  1224.924378  578.465922   \n",
      "                   img024.png  427.298086  1223.316209  581.682259   \n",
      "                   img048.png  190.897320  1220.099872  572.033248   \n",
      "                   img071.png  324.375303  1223.316209  570.425080   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                            RFoot                    LFoot   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1144.515954  626.710976  1305.332802   \n",
      "                   img014.png  1144.515954  633.143650  1308.549138   \n",
      "                   img024.png  1146.124123  633.143650  1305.332802   \n",
      "                   img048.png  1147.732291  626.710976  1303.724633   \n",
      "                   img071.png  1158.989470  626.710976  1298.900128   \n",
      "\n",
      "scorer                                     \n",
      "individuals                                \n",
      "bodyparts                                  \n",
      "coords                                  y  \n",
      "labeled-data flap1 img010.png  636.359987  \n",
      "                   img014.png  646.008998  \n",
      "                   img024.png  642.792661  \n",
      "                   img048.png  636.359987  \n",
      "                   img071.png  634.751819  \n"
     ]
    }
   ],
   "source": [
    "display_all_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_updated = add_missing_ids(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scorer                              model1                          \\\n",
      "individuals                            ID1                           \n",
      "bodyparts                             Head                    Beak   \n",
      "coords                                   x          y            x   \n",
      "labeled-data flap2 img001.png  1273.169432  -0.474729  1413.080089   \n",
      "                   img024.png  1414.688258  65.460179  1541.733567   \n",
      "                   img034.png  1528.868220  86.366369  1646.264518   \n",
      "                   img054.png  1580.329611  92.799043  1713.807594   \n",
      "                   img074.png  1638.223676  67.068347  1776.526165   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                     Body_top               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap2 img001.png   30.080472  1266.736758  198.938162   \n",
      "                   img024.png  161.950287  1347.145182  245.575048   \n",
      "                   img034.png  173.207466  1316.589981  195.721825   \n",
      "                   img054.png  160.342119  1384.133057  184.464646   \n",
      "                   img074.png  126.570581  1413.080089  153.909445   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                     RFlipper_mid             LFlipper_mid   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap2 img001.png  1094.662731  399.959221  1430.769943   \n",
      "                   img024.png  1067.323867  324.375303  1474.190491   \n",
      "                   img034.png  1139.691449  309.901787          NaN   \n",
      "                   img054.png  1252.263242  356.538673  1318.198149   \n",
      "                   img074.png  1400.214742  367.795852          NaN   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                  Body_bottom               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap2 img001.png  380.661200  1237.789726  541.478047   \n",
      "                   img024.png  408.000064  1226.532546  567.208743   \n",
      "                   img034.png         NaN  1142.907786  488.408488   \n",
      "                   img054.png  182.856477  1113.960753  530.220868   \n",
      "                   img074.png         NaN  1155.773133  490.016656   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                            RFoot                    LFoot   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap2 img001.png  1187.936503  612.237460  1287.642948   \n",
      "                   img024.png  1186.328334  629.927313  1277.993937   \n",
      "                   img034.png  1245.830568  629.927313  1300.508296   \n",
      "                   img054.png  1257.087747  647.617167  1274.777601   \n",
      "                   img074.png  1236.181557  604.196618  1303.724633   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                ID2                             \n",
      "bodyparts                                 Head     Beak     Body_top       \n",
      "coords                                  y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png  618.670134  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png  605.804786  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png  620.278302  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png  610.629292  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png  633.143650  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                            ID3                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                        ID4       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                              ID5                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                            ID6                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                        ID7       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                              ID8                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                            ID9                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                       ID10       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                             ID11                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                           ID12                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                       ID13       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                             ID14                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                           ID15                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                       ID16       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                             ID17                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                                   \\\n",
      "individuals                                           ID18                \n",
      "bodyparts                         RFoot     LFoot     Head     Beak       \n",
      "coords                          y     x   y     x   y    x   y    x   y   \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                        \\\n",
      "individuals                                                                    \n",
      "bodyparts                     Body_top     RFlipper_mid     LFlipper_mid       \n",
      "coords                               x   y            x   y            x   y   \n",
      "labeled-data flap2 img001.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img024.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img034.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img054.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "                   img074.png      NaN NaN          NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                      \\\n",
      "individuals                                                       ID19       \n",
      "bodyparts                     Body_bottom     RFoot     LFoot     Head       \n",
      "coords                                  x   y     x   y     x   y    x   y   \n",
      "labeled-data flap2 img001.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img024.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img034.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img054.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "                   img074.png         NaN NaN   NaN NaN   NaN NaN  NaN NaN   \n",
      "\n",
      "scorer                                                                \\\n",
      "individuals                                                            \n",
      "bodyparts                     Beak     Body_top     RFlipper_mid       \n",
      "coords                           x   y        x   y            x   y   \n",
      "labeled-data flap2 img001.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img024.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img034.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img054.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "                   img074.png  NaN NaN      NaN NaN          NaN NaN   \n",
      "\n",
      "scorer                                                                    \\\n",
      "individuals                                                                \n",
      "bodyparts                     LFlipper_mid     Body_bottom     RFoot       \n",
      "coords                                   x   y           x   y     x   y   \n",
      "labeled-data flap2 img001.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img024.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img034.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img054.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "                   img074.png          NaN NaN         NaN NaN   NaN NaN   \n",
      "\n",
      "scorer                                                                  \\\n",
      "individuals                             ID20                             \n",
      "bodyparts                     LFoot     Head     Beak     Body_top       \n",
      "coords                            x   y    x   y    x   y        x   y   \n",
      "labeled-data flap2 img001.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img024.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img034.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img054.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "                   img074.png   NaN NaN  NaN NaN  NaN NaN      NaN NaN   \n",
      "\n",
      "scorer                                                                       \\\n",
      "individuals                                                                   \n",
      "bodyparts                     RFlipper_mid     LFlipper_mid     Body_bottom   \n",
      "coords                                   x   y            x   y           x   \n",
      "labeled-data flap2 img001.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img024.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img034.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img054.png          NaN NaN          NaN NaN         NaN   \n",
      "                   img074.png          NaN NaN          NaN NaN         NaN   \n",
      "\n",
      "scorer                                                 \n",
      "individuals                                            \n",
      "bodyparts                         RFoot     LFoot      \n",
      "coords                          y     x   y     x   y  \n",
      "labeled-data flap2 img001.png NaN   NaN NaN   NaN NaN  \n",
      "                   img024.png NaN   NaN NaN   NaN NaN  \n",
      "                   img034.png NaN   NaN NaN   NaN NaN  \n",
      "                   img054.png NaN   NaN NaN   NaN NaN  \n",
      "                   img074.png NaN   NaN NaN   NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "#display_all_cols(df_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"16\" halign=\"left\">model1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th colspan=\"16\" halign=\"left\">ID1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Head</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Beak</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_top</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_bottom</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFoot</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFoot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">labeled-data</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">flap1</th>\n",
       "      <th>img010.png</th>\n",
       "      <td>1232.965220</td>\n",
       "      <td>84.758200</td>\n",
       "      <td>1326.238992</td>\n",
       "      <td>144.260434</td>\n",
       "      <td>1184.720166</td>\n",
       "      <td>287.387428</td>\n",
       "      <td>1031.944161</td>\n",
       "      <td>461.069623</td>\n",
       "      <td>1374.484046</td>\n",
       "      <td>465.894129</td>\n",
       "      <td>1226.532546</td>\n",
       "      <td>583.290428</td>\n",
       "      <td>1144.515954</td>\n",
       "      <td>626.710976</td>\n",
       "      <td>1305.332802</td>\n",
       "      <td>636.359987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img014.png</th>\n",
       "      <td>1232.965220</td>\n",
       "      <td>78.325526</td>\n",
       "      <td>1331.063497</td>\n",
       "      <td>134.611423</td>\n",
       "      <td>1189.544671</td>\n",
       "      <td>282.562923</td>\n",
       "      <td>1036.768666</td>\n",
       "      <td>443.379770</td>\n",
       "      <td>1379.308551</td>\n",
       "      <td>457.853287</td>\n",
       "      <td>1224.924378</td>\n",
       "      <td>578.465922</td>\n",
       "      <td>1144.515954</td>\n",
       "      <td>633.143650</td>\n",
       "      <td>1308.549138</td>\n",
       "      <td>646.008998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img024.png</th>\n",
       "      <td>1232.965220</td>\n",
       "      <td>75.109190</td>\n",
       "      <td>1331.063497</td>\n",
       "      <td>133.003255</td>\n",
       "      <td>1189.544671</td>\n",
       "      <td>269.697575</td>\n",
       "      <td>988.523612</td>\n",
       "      <td>401.567390</td>\n",
       "      <td>1419.512763</td>\n",
       "      <td>427.298086</td>\n",
       "      <td>1223.316209</td>\n",
       "      <td>581.682259</td>\n",
       "      <td>1146.124123</td>\n",
       "      <td>633.143650</td>\n",
       "      <td>1305.332802</td>\n",
       "      <td>642.792661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img048.png</th>\n",
       "      <td>1226.532546</td>\n",
       "      <td>84.758200</td>\n",
       "      <td>1326.238992</td>\n",
       "      <td>147.476771</td>\n",
       "      <td>1184.720166</td>\n",
       "      <td>269.697575</td>\n",
       "      <td>1123.609764</td>\n",
       "      <td>166.774793</td>\n",
       "      <td>1332.671666</td>\n",
       "      <td>190.897320</td>\n",
       "      <td>1220.099872</td>\n",
       "      <td>572.033248</td>\n",
       "      <td>1147.732291</td>\n",
       "      <td>626.710976</td>\n",
       "      <td>1303.724633</td>\n",
       "      <td>636.359987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img071.png</th>\n",
       "      <td>1183.111997</td>\n",
       "      <td>116.921570</td>\n",
       "      <td>1200.801851</td>\n",
       "      <td>197.329994</td>\n",
       "      <td>1163.813976</td>\n",
       "      <td>272.913912</td>\n",
       "      <td>966.009253</td>\n",
       "      <td>319.550798</td>\n",
       "      <td>1429.161774</td>\n",
       "      <td>324.375303</td>\n",
       "      <td>1223.316209</td>\n",
       "      <td>570.425080</td>\n",
       "      <td>1158.989470</td>\n",
       "      <td>626.710976</td>\n",
       "      <td>1298.900128</td>\n",
       "      <td>634.751819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img082.png</th>\n",
       "      <td>1160.597639</td>\n",
       "      <td>96.015380</td>\n",
       "      <td>1167.030313</td>\n",
       "      <td>165.166624</td>\n",
       "      <td>1162.205807</td>\n",
       "      <td>268.089407</td>\n",
       "      <td>1036.768666</td>\n",
       "      <td>412.824569</td>\n",
       "      <td>1355.186024</td>\n",
       "      <td>422.473580</td>\n",
       "      <td>1218.491704</td>\n",
       "      <td>560.776069</td>\n",
       "      <td>1157.381302</td>\n",
       "      <td>633.143650</td>\n",
       "      <td>1298.900128</td>\n",
       "      <td>641.184493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img086.png</th>\n",
       "      <td>1168.638481</td>\n",
       "      <td>79.933695</td>\n",
       "      <td>1179.895660</td>\n",
       "      <td>144.260434</td>\n",
       "      <td>1160.597639</td>\n",
       "      <td>258.440396</td>\n",
       "      <td>1052.850351</td>\n",
       "      <td>401.567390</td>\n",
       "      <td>1329.455329</td>\n",
       "      <td>408.000064</td>\n",
       "      <td>1218.491704</td>\n",
       "      <td>557.559732</td>\n",
       "      <td>1155.773133</td>\n",
       "      <td>633.143650</td>\n",
       "      <td>1295.683791</td>\n",
       "      <td>636.359987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img097.png</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1247.438736</td>\n",
       "      <td>7.566114</td>\n",
       "      <td>1178.287492</td>\n",
       "      <td>206.979004</td>\n",
       "      <td>1093.054563</td>\n",
       "      <td>428.906254</td>\n",
       "      <td>1303.724633</td>\n",
       "      <td>409.608232</td>\n",
       "      <td>1220.099872</td>\n",
       "      <td>576.857754</td>\n",
       "      <td>1160.597639</td>\n",
       "      <td>631.535482</td>\n",
       "      <td>1294.075622</td>\n",
       "      <td>636.359987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img120.png</th>\n",
       "      <td>1339.104340</td>\n",
       "      <td>4.349777</td>\n",
       "      <td>1461.325144</td>\n",
       "      <td>76.717358</td>\n",
       "      <td>1290.859285</td>\n",
       "      <td>192.505488</td>\n",
       "      <td>1014.254308</td>\n",
       "      <td>301.860944</td>\n",
       "      <td>1479.014997</td>\n",
       "      <td>330.807977</td>\n",
       "      <td>1220.099872</td>\n",
       "      <td>536.653542</td>\n",
       "      <td>1157.381302</td>\n",
       "      <td>623.494639</td>\n",
       "      <td>1284.426611</td>\n",
       "      <td>628.319145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img136.png</th>\n",
       "      <td>1329.455329</td>\n",
       "      <td>73.501021</td>\n",
       "      <td>1388.957562</td>\n",
       "      <td>176.423803</td>\n",
       "      <td>1277.993937</td>\n",
       "      <td>231.101532</td>\n",
       "      <td>1019.078813</td>\n",
       "      <td>271.305743</td>\n",
       "      <td>1451.676133</td>\n",
       "      <td>319.550798</td>\n",
       "      <td>1228.140715</td>\n",
       "      <td>565.600574</td>\n",
       "      <td>1187.936503</td>\n",
       "      <td>620.278302</td>\n",
       "      <td>1295.683791</td>\n",
       "      <td>639.576324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer                              model1                           \\\n",
       "individuals                            ID1                            \n",
       "bodyparts                             Head                     Beak   \n",
       "coords                                   x           y            x   \n",
       "labeled-data flap1 img010.png  1232.965220   84.758200  1326.238992   \n",
       "                   img014.png  1232.965220   78.325526  1331.063497   \n",
       "                   img024.png  1232.965220   75.109190  1331.063497   \n",
       "                   img048.png  1226.532546   84.758200  1326.238992   \n",
       "                   img071.png  1183.111997  116.921570  1200.801851   \n",
       "                   img082.png  1160.597639   96.015380  1167.030313   \n",
       "                   img086.png  1168.638481   79.933695  1179.895660   \n",
       "                   img097.png          NaN         NaN  1247.438736   \n",
       "                   img120.png  1339.104340    4.349777  1461.325144   \n",
       "                   img136.png  1329.455329   73.501021  1388.957562   \n",
       "\n",
       "scorer                                                              \\\n",
       "individuals                                                          \n",
       "bodyparts                                     Body_top               \n",
       "coords                                  y            x           y   \n",
       "labeled-data flap1 img010.png  144.260434  1184.720166  287.387428   \n",
       "                   img014.png  134.611423  1189.544671  282.562923   \n",
       "                   img024.png  133.003255  1189.544671  269.697575   \n",
       "                   img048.png  147.476771  1184.720166  269.697575   \n",
       "                   img071.png  197.329994  1163.813976  272.913912   \n",
       "                   img082.png  165.166624  1162.205807  268.089407   \n",
       "                   img086.png  144.260434  1160.597639  258.440396   \n",
       "                   img097.png    7.566114  1178.287492  206.979004   \n",
       "                   img120.png   76.717358  1290.859285  192.505488   \n",
       "                   img136.png  176.423803  1277.993937  231.101532   \n",
       "\n",
       "scorer                                                               \\\n",
       "individuals                                                           \n",
       "bodyparts                     RFlipper_mid             LFlipper_mid   \n",
       "coords                                   x           y            x   \n",
       "labeled-data flap1 img010.png  1031.944161  461.069623  1374.484046   \n",
       "                   img014.png  1036.768666  443.379770  1379.308551   \n",
       "                   img024.png   988.523612  401.567390  1419.512763   \n",
       "                   img048.png  1123.609764  166.774793  1332.671666   \n",
       "                   img071.png   966.009253  319.550798  1429.161774   \n",
       "                   img082.png  1036.768666  412.824569  1355.186024   \n",
       "                   img086.png  1052.850351  401.567390  1329.455329   \n",
       "                   img097.png  1093.054563  428.906254  1303.724633   \n",
       "                   img120.png  1014.254308  301.860944  1479.014997   \n",
       "                   img136.png  1019.078813  271.305743  1451.676133   \n",
       "\n",
       "scorer                                                              \\\n",
       "individuals                                                          \n",
       "bodyparts                                  Body_bottom               \n",
       "coords                                  y            x           y   \n",
       "labeled-data flap1 img010.png  465.894129  1226.532546  583.290428   \n",
       "                   img014.png  457.853287  1224.924378  578.465922   \n",
       "                   img024.png  427.298086  1223.316209  581.682259   \n",
       "                   img048.png  190.897320  1220.099872  572.033248   \n",
       "                   img071.png  324.375303  1223.316209  570.425080   \n",
       "                   img082.png  422.473580  1218.491704  560.776069   \n",
       "                   img086.png  408.000064  1218.491704  557.559732   \n",
       "                   img097.png  409.608232  1220.099872  576.857754   \n",
       "                   img120.png  330.807977  1220.099872  536.653542   \n",
       "                   img136.png  319.550798  1228.140715  565.600574   \n",
       "\n",
       "scorer                                                               \\\n",
       "individuals                                                           \n",
       "bodyparts                            RFoot                    LFoot   \n",
       "coords                                   x           y            x   \n",
       "labeled-data flap1 img010.png  1144.515954  626.710976  1305.332802   \n",
       "                   img014.png  1144.515954  633.143650  1308.549138   \n",
       "                   img024.png  1146.124123  633.143650  1305.332802   \n",
       "                   img048.png  1147.732291  626.710976  1303.724633   \n",
       "                   img071.png  1158.989470  626.710976  1298.900128   \n",
       "                   img082.png  1157.381302  633.143650  1298.900128   \n",
       "                   img086.png  1155.773133  633.143650  1295.683791   \n",
       "                   img097.png  1160.597639  631.535482  1294.075622   \n",
       "                   img120.png  1157.381302  623.494639  1284.426611   \n",
       "                   img136.png  1187.936503  620.278302  1295.683791   \n",
       "\n",
       "scorer                                     \n",
       "individuals                                \n",
       "bodyparts                                  \n",
       "coords                                  y  \n",
       "labeled-data flap1 img010.png  636.359987  \n",
       "                   img014.png  646.008998  \n",
       "                   img024.png  642.792661  \n",
       "                   img048.png  636.359987  \n",
       "                   img071.png  634.751819  \n",
       "                   img082.png  641.184493  \n",
       "                   img086.png  636.359987  \n",
       "                   img097.png  636.359987  \n",
       "                   img120.png  628.319145  \n",
       "                   img136.png  639.576324  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"21\" halign=\"left\">model1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ID1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ID20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Head</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Beak</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_top</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFlipper_mid</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_bottom</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFoot</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFoot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">labeled-data</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">flap2</th>\n",
       "      <th>img001.png</th>\n",
       "      <td>1273.169432</td>\n",
       "      <td>-0.474729</td>\n",
       "      <td>1413.080089</td>\n",
       "      <td>30.080472</td>\n",
       "      <td>1266.736758</td>\n",
       "      <td>198.938162</td>\n",
       "      <td>1094.662731</td>\n",
       "      <td>399.959221</td>\n",
       "      <td>1430.769943</td>\n",
       "      <td>380.661200</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img024.png</th>\n",
       "      <td>1414.688258</td>\n",
       "      <td>65.460179</td>\n",
       "      <td>1541.733567</td>\n",
       "      <td>161.950287</td>\n",
       "      <td>1347.145182</td>\n",
       "      <td>245.575048</td>\n",
       "      <td>1067.323867</td>\n",
       "      <td>324.375303</td>\n",
       "      <td>1474.190491</td>\n",
       "      <td>408.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img034.png</th>\n",
       "      <td>1528.868220</td>\n",
       "      <td>86.366369</td>\n",
       "      <td>1646.264518</td>\n",
       "      <td>173.207466</td>\n",
       "      <td>1316.589981</td>\n",
       "      <td>195.721825</td>\n",
       "      <td>1139.691449</td>\n",
       "      <td>309.901787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img054.png</th>\n",
       "      <td>1580.329611</td>\n",
       "      <td>92.799043</td>\n",
       "      <td>1713.807594</td>\n",
       "      <td>160.342119</td>\n",
       "      <td>1384.133057</td>\n",
       "      <td>184.464646</td>\n",
       "      <td>1252.263242</td>\n",
       "      <td>356.538673</td>\n",
       "      <td>1318.198149</td>\n",
       "      <td>182.856477</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img074.png</th>\n",
       "      <td>1638.223676</td>\n",
       "      <td>67.068347</td>\n",
       "      <td>1776.526165</td>\n",
       "      <td>126.570581</td>\n",
       "      <td>1413.080089</td>\n",
       "      <td>153.909445</td>\n",
       "      <td>1400.214742</td>\n",
       "      <td>367.795852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img097.png</th>\n",
       "      <td>1670.387045</td>\n",
       "      <td>86.366369</td>\n",
       "      <td>1805.473197</td>\n",
       "      <td>147.476771</td>\n",
       "      <td>1438.810785</td>\n",
       "      <td>171.599298</td>\n",
       "      <td>1327.847160</td>\n",
       "      <td>232.709700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img105.png</th>\n",
       "      <td>1676.819719</td>\n",
       "      <td>87.974537</td>\n",
       "      <td>1810.297703</td>\n",
       "      <td>145.868602</td>\n",
       "      <td>1469.365986</td>\n",
       "      <td>169.991130</td>\n",
       "      <td>1380.916720</td>\n",
       "      <td>269.697575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img121.png</th>\n",
       "      <td>1675.211551</td>\n",
       "      <td>70.284684</td>\n",
       "      <td>1789.391512</td>\n",
       "      <td>105.664391</td>\n",
       "      <td>1499.921187</td>\n",
       "      <td>161.950287</td>\n",
       "      <td>1462.933312</td>\n",
       "      <td>263.264901</td>\n",
       "      <td>1329.455329</td>\n",
       "      <td>178.031972</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img135.png</th>\n",
       "      <td>1720.240268</td>\n",
       "      <td>62.243842</td>\n",
       "      <td>1810.297703</td>\n",
       "      <td>89.582706</td>\n",
       "      <td>1535.300893</td>\n",
       "      <td>134.611423</td>\n",
       "      <td>1610.884812</td>\n",
       "      <td>408.000064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img149.png</th>\n",
       "      <td>1737.930121</td>\n",
       "      <td>52.594831</td>\n",
       "      <td>1811.905871</td>\n",
       "      <td>86.366369</td>\n",
       "      <td>1559.423421</td>\n",
       "      <td>157.125782</td>\n",
       "      <td>1517.611040</td>\n",
       "      <td>263.264901</td>\n",
       "      <td>1388.957562</td>\n",
       "      <td>250.399553</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer                              model1                          \\\n",
       "individuals                            ID1                           \n",
       "bodyparts                             Head                    Beak   \n",
       "coords                                   x          y            x   \n",
       "labeled-data flap2 img001.png  1273.169432  -0.474729  1413.080089   \n",
       "                   img024.png  1414.688258  65.460179  1541.733567   \n",
       "                   img034.png  1528.868220  86.366369  1646.264518   \n",
       "                   img054.png  1580.329611  92.799043  1713.807594   \n",
       "                   img074.png  1638.223676  67.068347  1776.526165   \n",
       "                   img097.png  1670.387045  86.366369  1805.473197   \n",
       "                   img105.png  1676.819719  87.974537  1810.297703   \n",
       "                   img121.png  1675.211551  70.284684  1789.391512   \n",
       "                   img135.png  1720.240268  62.243842  1810.297703   \n",
       "                   img149.png  1737.930121  52.594831  1811.905871   \n",
       "\n",
       "scorer                                                              \\\n",
       "individuals                                                          \n",
       "bodyparts                                     Body_top               \n",
       "coords                                  y            x           y   \n",
       "labeled-data flap2 img001.png   30.080472  1266.736758  198.938162   \n",
       "                   img024.png  161.950287  1347.145182  245.575048   \n",
       "                   img034.png  173.207466  1316.589981  195.721825   \n",
       "                   img054.png  160.342119  1384.133057  184.464646   \n",
       "                   img074.png  126.570581  1413.080089  153.909445   \n",
       "                   img097.png  147.476771  1438.810785  171.599298   \n",
       "                   img105.png  145.868602  1469.365986  169.991130   \n",
       "                   img121.png  105.664391  1499.921187  161.950287   \n",
       "                   img135.png   89.582706  1535.300893  134.611423   \n",
       "                   img149.png   86.366369  1559.423421  157.125782   \n",
       "\n",
       "scorer                                                               \\\n",
       "individuals                                                           \n",
       "bodyparts                     RFlipper_mid             LFlipper_mid   \n",
       "coords                                   x           y            x   \n",
       "labeled-data flap2 img001.png  1094.662731  399.959221  1430.769943   \n",
       "                   img024.png  1067.323867  324.375303  1474.190491   \n",
       "                   img034.png  1139.691449  309.901787          NaN   \n",
       "                   img054.png  1252.263242  356.538673  1318.198149   \n",
       "                   img074.png  1400.214742  367.795852          NaN   \n",
       "                   img097.png  1327.847160  232.709700          NaN   \n",
       "                   img105.png  1380.916720  269.697575          NaN   \n",
       "                   img121.png  1462.933312  263.264901  1329.455329   \n",
       "                   img135.png  1610.884812  408.000064          NaN   \n",
       "                   img149.png  1517.611040  263.264901  1388.957562   \n",
       "\n",
       "scorer                                     ...                                \\\n",
       "individuals                                ...         ID20                    \n",
       "bodyparts                                  ... RFlipper_mid     LFlipper_mid   \n",
       "coords                                  y  ...            x   y            x   \n",
       "labeled-data flap2 img001.png  380.661200  ...          NaN NaN          NaN   \n",
       "                   img024.png  408.000064  ...          NaN NaN          NaN   \n",
       "                   img034.png         NaN  ...          NaN NaN          NaN   \n",
       "                   img054.png  182.856477  ...          NaN NaN          NaN   \n",
       "                   img074.png         NaN  ...          NaN NaN          NaN   \n",
       "                   img097.png         NaN  ...          NaN NaN          NaN   \n",
       "                   img105.png         NaN  ...          NaN NaN          NaN   \n",
       "                   img121.png  178.031972  ...          NaN NaN          NaN   \n",
       "                   img135.png         NaN  ...          NaN NaN          NaN   \n",
       "                   img149.png  250.399553  ...          NaN NaN          NaN   \n",
       "\n",
       "scorer                                                                 \n",
       "individuals                                                            \n",
       "bodyparts                         Body_bottom     RFoot     LFoot      \n",
       "coords                          y           x   y     x   y     x   y  \n",
       "labeled-data flap2 img001.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img024.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img034.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img054.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img074.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img097.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img105.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img121.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img135.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "                   img149.png NaN         NaN NaN   NaN NaN   NaN NaN  \n",
       "\n",
       "[10 rows x 320 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_updated.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scorer                                  Ro                           \\\n",
      "individuals                            ID1                            \n",
      "bodyparts                             Head                     Beak   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1232.965220   84.758200  1326.238992   \n",
      "                   img014.png  1232.965220   78.325526  1331.063497   \n",
      "                   img024.png  1232.965220   75.109190  1331.063497   \n",
      "                   img048.png  1226.532546   84.758200  1326.238992   \n",
      "                   img071.png  1183.111997  116.921570  1200.801851   \n",
      "                   img082.png  1160.597639   96.015380  1167.030313   \n",
      "                   img086.png  1168.638481   79.933695  1179.895660   \n",
      "                   img097.png          NaN         NaN  1247.438736   \n",
      "                   img120.png  1339.104340    4.349777  1461.325144   \n",
      "                   img136.png  1329.455329   73.501021  1388.957562   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                     Body_top               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap1 img010.png  144.260434  1184.720166  287.387428   \n",
      "                   img014.png  134.611423  1189.544671  282.562923   \n",
      "                   img024.png  133.003255  1189.544671  269.697575   \n",
      "                   img048.png  147.476771  1184.720166  269.697575   \n",
      "                   img071.png  197.329994  1163.813976  272.913912   \n",
      "                   img082.png  165.166624  1162.205807  268.089407   \n",
      "                   img086.png  144.260434  1160.597639  258.440396   \n",
      "                   img097.png    7.566114  1178.287492  206.979004   \n",
      "                   img120.png   76.717358  1290.859285  192.505488   \n",
      "                   img136.png  176.423803  1277.993937  231.101532   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                     RFlipper_mid             LFlipper_mid   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1031.944161  461.069623  1374.484046   \n",
      "                   img014.png  1036.768666  443.379770  1379.308551   \n",
      "                   img024.png   988.523612  401.567390  1419.512763   \n",
      "                   img048.png  1123.609764  166.774793  1332.671666   \n",
      "                   img071.png   966.009253  319.550798  1429.161774   \n",
      "                   img082.png  1036.768666  412.824569  1355.186024   \n",
      "                   img086.png  1052.850351  401.567390  1329.455329   \n",
      "                   img097.png  1093.054563  428.906254  1303.724633   \n",
      "                   img120.png  1014.254308  301.860944  1479.014997   \n",
      "                   img136.png  1019.078813  271.305743  1451.676133   \n",
      "\n",
      "scorer                                                              \\\n",
      "individuals                                                          \n",
      "bodyparts                                  Body_bottom               \n",
      "coords                                  y            x           y   \n",
      "labeled-data flap1 img010.png  465.894129  1226.532546  583.290428   \n",
      "                   img014.png  457.853287  1224.924378  578.465922   \n",
      "                   img024.png  427.298086  1223.316209  581.682259   \n",
      "                   img048.png  190.897320  1220.099872  572.033248   \n",
      "                   img071.png  324.375303  1223.316209  570.425080   \n",
      "                   img082.png  422.473580  1218.491704  560.776069   \n",
      "                   img086.png  408.000064  1218.491704  557.559732   \n",
      "                   img097.png  409.608232  1220.099872  576.857754   \n",
      "                   img120.png  330.807977  1220.099872  536.653542   \n",
      "                   img136.png  319.550798  1228.140715  565.600574   \n",
      "\n",
      "scorer                                                               \\\n",
      "individuals                                                           \n",
      "bodyparts                            RFoot                    LFoot   \n",
      "coords                                   x           y            x   \n",
      "labeled-data flap1 img010.png  1144.515954  626.710976  1305.332802   \n",
      "                   img014.png  1144.515954  633.143650  1308.549138   \n",
      "                   img024.png  1146.124123  633.143650  1305.332802   \n",
      "                   img048.png  1147.732291  626.710976  1303.724633   \n",
      "                   img071.png  1158.989470  626.710976  1298.900128   \n",
      "                   img082.png  1157.381302  633.143650  1298.900128   \n",
      "                   img086.png  1155.773133  633.143650  1295.683791   \n",
      "                   img097.png  1160.597639  631.535482  1294.075622   \n",
      "                   img120.png  1157.381302  623.494639  1284.426611   \n",
      "                   img136.png  1187.936503  620.278302  1295.683791   \n",
      "\n",
      "scorer                                     \n",
      "individuals                                \n",
      "bodyparts                                  \n",
      "coords                                  y  \n",
      "labeled-data flap1 img010.png  636.359987  \n",
      "                   img014.png  646.008998  \n",
      "                   img024.png  642.792661  \n",
      "                   img048.png  636.359987  \n",
      "                   img071.png  634.751819  \n",
      "                   img082.png  641.184493  \n",
      "                   img086.png  636.359987  \n",
      "                   img097.png  636.359987  \n",
      "                   img120.png  628.319145  \n",
      "                   img136.png  639.576324  \n"
     ]
    }
   ],
   "source": [
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the body parts to retain\n",
    "# body_parts_to_keep = ['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot']\n",
    "\n",
    "# # Filter the dataframe by selecting only the relevant body parts\n",
    "# filtered_df = df.loc[:, (slice(None), slice(None), body_parts_to_keep)]\n",
    "\n",
    "# # Save the filtered dataframe back to an HDF5 file\n",
    "# filtered_file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/CollectedData_model1_edit.h5'\n",
    "# filtered_df.to_hdf(filtered_file_path, key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_hdf('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/CollectedData_model1_edit.h5',key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/CollectedData_model1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"21\" halign=\"left\">Matt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ID1</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">ID20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Head</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Beak</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_top</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFlipper_mid</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFlipper_mid</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Body_bottom</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RFoot</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LFoot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>...</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">frames_to_label</th>\n",
       "      <th rowspan=\"20\" valign=\"top\">PenguinPi1_video_2024-02-26_15-15</th>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg</th>\n",
       "      <td>59.451922</td>\n",
       "      <td>294.394441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.938570</td>\n",
       "      <td>291.127378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg</th>\n",
       "      <td>56.044090</td>\n",
       "      <td>289.686473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.629254</td>\n",
       "      <td>285.765999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg</th>\n",
       "      <td>58.547084</td>\n",
       "      <td>289.329461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.343945</td>\n",
       "      <td>287.181432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg</th>\n",
       "      <td>60.695114</td>\n",
       "      <td>290.940483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.538434</td>\n",
       "      <td>287.986943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg</th>\n",
       "      <td>56.667559</td>\n",
       "      <td>286.912928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.343945</td>\n",
       "      <td>287.181432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg</th>\n",
       "      <td>59.621099</td>\n",
       "      <td>290.671980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.417959</td>\n",
       "      <td>288.255446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg</th>\n",
       "      <td>552.335913</td>\n",
       "      <td>90.637598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535.711135</td>\n",
       "      <td>80.175453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.577476</td>\n",
       "      <td>95.510378</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg</th>\n",
       "      <td>57.271329</td>\n",
       "      <td>292.683434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.341359</td>\n",
       "      <td>287.238330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg</th>\n",
       "      <td>551.046060</td>\n",
       "      <td>89.777695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.704696</td>\n",
       "      <td>78.885599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.434159</td>\n",
       "      <td>94.507158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg</th>\n",
       "      <td>550.329474</td>\n",
       "      <td>90.494281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.427720</td>\n",
       "      <td>79.745502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540.297280</td>\n",
       "      <td>95.653695</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg</th>\n",
       "      <td>551.476011</td>\n",
       "      <td>91.210866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.141086</td>\n",
       "      <td>80.462087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539.294061</td>\n",
       "      <td>95.367060</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg</th>\n",
       "      <td>551.332694</td>\n",
       "      <td>92.070768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536.714354</td>\n",
       "      <td>80.892038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539.580695</td>\n",
       "      <td>95.367060</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg</th>\n",
       "      <td>55.862048</td>\n",
       "      <td>289.866468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.584893</td>\n",
       "      <td>286.912928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg</th>\n",
       "      <td>58.278581</td>\n",
       "      <td>291.477491</td>\n",
       "      <td>47.001426</td>\n",
       "      <td>286.107417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg</th>\n",
       "      <td>57.473070</td>\n",
       "      <td>292.551505</td>\n",
       "      <td>46.464419</td>\n",
       "      <td>286.375921</td>\n",
       "      <td>37.066790</td>\n",
       "      <td>316.985340</td>\n",
       "      <td>256.006585</td>\n",
       "      <td>250.868795</td>\n",
       "      <td>278.356609</td>\n",
       "      <td>241.627013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg</th>\n",
       "      <td>57.204566</td>\n",
       "      <td>288.523950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.121900</td>\n",
       "      <td>286.912928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg</th>\n",
       "      <td>57.741573</td>\n",
       "      <td>288.523950</td>\n",
       "      <td>231.481029</td>\n",
       "      <td>221.247339</td>\n",
       "      <td>46.732922</td>\n",
       "      <td>286.912928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg</th>\n",
       "      <td>58.547084</td>\n",
       "      <td>289.329461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.269930</td>\n",
       "      <td>287.986943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg</th>\n",
       "      <td>58.278581</td>\n",
       "      <td>292.820009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.075441</td>\n",
       "      <td>287.181432</td>\n",
       "      <td>38.946316</td>\n",
       "      <td>315.642822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg</th>\n",
       "      <td>58.278581</td>\n",
       "      <td>289.329461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.612448</td>\n",
       "      <td>286.912928</td>\n",
       "      <td>41.362849</td>\n",
       "      <td>315.642822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer                                                                                                      Matt  \\\n",
       "individuals                                                                                                  ID1   \n",
       "bodyparts                                                                                                   Head   \n",
       "coords                                                                                                         x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg    59.451922   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg    56.044090   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg   58.547084   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg   60.695114   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg   56.667559   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg   59.621099   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg  552.335913   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg   57.271329   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg  551.046060   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg  550.329474   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg  551.476011   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg  551.332694   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg    55.862048   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg    58.278581   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    57.473070   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg    57.204566   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg    57.741573   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg    58.547084   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg    58.278581   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg    58.278581   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                          \n",
       "coords                                                                                                         y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg   294.394441   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg   289.686473   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg  289.329461   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg  290.940483   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg  286.912928   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg  290.671980   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   90.637598   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg  292.683434   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   89.777695   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   90.494281   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   91.210866   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   92.070768   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg   289.866468   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg   291.477491   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   292.551505   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg   288.523950   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg   288.523950   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg   289.329461   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg   292.820009   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg   289.329461   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                   Beak   \n",
       "coords                                                                                                         x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg    47.001426   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    46.464419   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg   231.481029   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg          NaN   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                          \n",
       "coords                                                                                                         y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg   286.107417   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   286.375921   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg   221.247339   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg          NaN   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                               Body_top   \n",
       "coords                                                                                                         x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg    40.938570   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg    43.629254   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg   48.343945   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg   47.538434   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg   48.343945   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg   49.417959   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg  535.711135   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg   48.341359   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg  533.704696   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg  536.427720   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg  536.141086   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg  536.714354   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg    44.584893   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    37.066790   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg    45.121900   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg    46.732922   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg    47.269930   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg    48.075441   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg    48.612448   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                          \n",
       "coords                                                                                                         y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg   291.127378   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg   285.765999   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg  287.181432   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg  287.986943   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg  287.181432   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg  288.255446   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   80.175453   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg  287.238330   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   78.885599   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   79.745502   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   80.462087   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   80.892038   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg   286.912928   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   316.985340   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg   286.912928   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg   286.912928   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg   287.986943   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg   287.181432   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg   286.912928   \n",
       "\n",
       "scorer                                                                                                             \\\n",
       "individuals                                                                                                         \n",
       "bodyparts                                                                                            RFlipper_mid   \n",
       "coords                                                                                                          x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    256.006585   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg     38.946316   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg     41.362849   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                          \n",
       "coords                                                                                                         y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   250.868795   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg   315.642822   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg   315.642822   \n",
       "\n",
       "scorer                                                                                                             \\\n",
       "individuals                                                                                                         \n",
       "bodyparts                                                                                            LFlipper_mid   \n",
       "coords                                                                                                          x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   538.577476   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   538.434159   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   540.297280   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   539.294061   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   539.580695   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    278.356609   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg           NaN   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                                          \n",
       "coords                                                                                                         y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   95.510378   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   94.507158   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   95.653695   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   95.367060   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   95.367060   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   241.627013   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg          NaN   \n",
       "\n",
       "scorer                                                                                                ...  \\\n",
       "individuals                                                                                           ...   \n",
       "bodyparts                                                                                             ...   \n",
       "coords                                                                                                ...   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg  ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg   ...   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg   ...   \n",
       "\n",
       "scorer                                                                                                             \\\n",
       "individuals                                                                                                  ID20   \n",
       "bodyparts                                                                                            RFlipper_mid   \n",
       "coords                                                                                                          x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg           NaN   \n",
       "\n",
       "scorer                                                                                                    \\\n",
       "individuals                                                                                                \n",
       "bodyparts                                                                                                  \n",
       "coords                                                                                                 y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg  NaN   \n",
       "\n",
       "scorer                                                                                                             \\\n",
       "individuals                                                                                                         \n",
       "bodyparts                                                                                            LFlipper_mid   \n",
       "coords                                                                                                          x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg           NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg           NaN   \n",
       "\n",
       "scorer                                                                                                    \\\n",
       "individuals                                                                                                \n",
       "bodyparts                                                                                                  \n",
       "coords                                                                                                 y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg  NaN   \n",
       "\n",
       "scorer                                                                                                            \\\n",
       "individuals                                                                                                        \n",
       "bodyparts                                                                                            Body_bottom   \n",
       "coords                                                                                                         x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg         NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg          NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg          NaN   \n",
       "\n",
       "scorer                                                                                                    \\\n",
       "individuals                                                                                                \n",
       "bodyparts                                                                                                  \n",
       "coords                                                                                                 y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg  NaN   \n",
       "\n",
       "scorer                                                                                                      \\\n",
       "individuals                                                                                                  \n",
       "bodyparts                                                                                            RFoot   \n",
       "coords                                                                                                   x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg    NaN   \n",
       "\n",
       "scorer                                                                                                    \\\n",
       "individuals                                                                                                \n",
       "bodyparts                                                                                                  \n",
       "coords                                                                                                 y   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg  NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg  NaN   \n",
       "\n",
       "scorer                                                                                                      \\\n",
       "individuals                                                                                                  \n",
       "bodyparts                                                                                            LFoot   \n",
       "coords                                                                                                   x   \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg   NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg    NaN   \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg    NaN   \n",
       "\n",
       "scorer                                                                                                    \n",
       "individuals                                                                                               \n",
       "bodyparts                                                                                                 \n",
       "coords                                                                                                 y  \n",
       "frames_to_label PenguinPi1_video_2024-02-26_15-15 frame_PenguinPi1_video_2024-02-26_15-15.mp4_0.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_1.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_10.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_11.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_12.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_13.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_14.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_15.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_16.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_17.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_18.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_19.jpg NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_2.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_3.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_4.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_5.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_6.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_7.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_8.jpg  NaN  \n",
       "                                                  frame_PenguinPi1_video_2024-02-26_15-15.mp4_9.jpg  NaN  \n",
       "\n",
       "[20 rows x 320 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_csv_filename = f\"CollectedData_{model_name}.csv\"\n",
    "#new_csv_path = os.path.join(root, new_csv_filename)\n",
    "\n",
    "# # add ids until there are 20 ids \n",
    "# filtered_df = add_missing_ids(df)\n",
    "# new_csv_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data/flap1/test.csv'\n",
    "# filtered_df.to_csv(new_csv_path, index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_ids(df, total_ids=20):\n",
    "    \"\"\"\n",
    "    Adds missing individual IDs to the DataFrame until it reaches a specified number of total IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame with the labeled data and existing IDs.\n",
    "    - total_ids (int): The total number of IDs that should be in the DataFrame. Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A new DataFrame with missing IDs added as NaNs.\n",
    "    \"\"\"\n",
    "    # Get the existing IDs\n",
    "    existing_ids = df.columns.get_level_values('individuals').unique()\n",
    "\n",
    "    # Check how many IDs need to be added\n",
    "    missing_ids_count = total_ids - len(existing_ids)\n",
    "    \n",
    "    if missing_ids_count <= 0:\n",
    "        # No missing IDs to add\n",
    "        return df\n",
    "    \n",
    "    # Create missing IDs\n",
    "    new_ids = [f'ID{i}' for i in range(len(existing_ids) + 1, total_ids + 1)]\n",
    "    \n",
    "    # Create empty DataFrame with NaNs for new IDs\n",
    "    new_columns = pd.MultiIndex.from_product([df.columns.get_level_values('scorer').unique(),\n",
    "                                              new_ids, \n",
    "                                              df.columns.get_level_values('bodyparts').unique(),\n",
    "                                              df.columns.get_level_values('coords').unique()],\n",
    "                                             names=df.columns.names)\n",
    "    \n",
    "    # Create DataFrame with NaNs for new IDs\n",
    "    new_df = pd.DataFrame(np.nan, index=df.index, columns=new_columns)\n",
    "    \n",
    "    # Concatenate the old DataFrame with the new one\n",
    "    result_df = pd.concat([df, new_df], axis=1)\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_scorer(df, old_scorer, new_scorer):\n",
    "    \"\"\"\n",
    "    Replaces the scorer in the MultiIndex of the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame with a MultiIndex.\n",
    "    - old_scorer: The scorer value to be replaced.\n",
    "    - new_scorer: The new scorer value.\n",
    "\n",
    "    Returns:\n",
    "    - df: The DataFrame with the scorer replaced.\n",
    "    \"\"\"\n",
    "\n",
    "    # Rename the 'scorer' level of the index\n",
    "    df.columns = df.columns.set_levels(\n",
    "        [new_scorer if scorer == old_scorer else scorer for scorer in df.columns.levels[0]], level=0\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labelled_images(parent_dir, model_name, base_dir, kp_to_keep):\n",
    "    \"\"\"\n",
    "    adjust data have correct naming convention and to have only relevant keypoints, load the first .h5 file from each, and save as new .h5 and .csv.\n",
    "    Also, generate a list of video paths with crop information and save it to a .txt file in base_dir. (to be put in the config file later).\n",
    "    \n",
    "    NOTES: Adjusted csvs are not it the same format... But that's not really an issue, just something to note \n",
    "    \n",
    "    Parameters:\n",
    "    - parent_dir (str): Path to the parent directory containing nested directories.\n",
    "    - model_name (str): The model name to use for renaming the saved files.\n",
    "    - base_dir (str): Path to the base directory where the video_paths.txt will be saved.\n",
    "    - kp_to_keep (list): list of kp names that need to be kept (filter others out)\n",
    "    \"\"\"\n",
    "    # Create a list to store video paths and crop information\n",
    "    video_paths_list = []\n",
    "    \n",
    "    # Walk through the parent directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(parent_dir):\n",
    "        # If there are any .h5 files in the current directory\n",
    "        h5_files = [f for f in files if f.endswith('.h5')]\n",
    "        if h5_files:\n",
    "            # Load the first .h5 file\n",
    "            h5_file_path = os.path.join(root, h5_files[0])\n",
    "            \n",
    "            # Load .h5 into DataFrame\n",
    "            df = pd.read_hdf(h5_file_path)\n",
    "\n",
    "            # Filter the dataframe by selecting only the relevant body parts\n",
    "            #filtered_df = df.loc[:, (slice(None), slice(None), kp_to_keep)]\n",
    "\n",
    "            # replace scorer with new scorer\n",
    "            #filtered_df = replace_scorer(filtered_df, old_scorer='Ro', new_scorer='model1')\n",
    "            #filtered_df = replace_scorer(df, old_scorer='Ro', new_scorer='model1')\n",
    "\n",
    "            # add ids until there are 20 ids \n",
    "            filtered_df = add_missing_ids(df)\n",
    "            \n",
    "            # Save to new .h5 file\n",
    "            new_h5_filename = f\"CollectedData_{model_name}.h5\"\n",
    "            new_h5_path = os.path.join(root, new_h5_filename)\n",
    "            filtered_df.to_hdf(new_h5_path, key='df', mode='w')\n",
    "\n",
    "            # Save to .csv file\n",
    "            new_csv_filename = f\"CollectedData_{model_name}.csv\"\n",
    "            new_csv_path = os.path.join(root, new_csv_filename)\n",
    "            filtered_df.to_csv(new_csv_path, index=True, header=True)\n",
    "\n",
    "            # Delete the old .h5 file\n",
    "            #if os.path.exists(h5_file_path):\n",
    "                #os.remove(h5_file_path)\n",
    "                #print(f\"Deleted old file: {h5_file_path}\")\n",
    "\n",
    "            # Delete the old .csv file with the same name, if it exists\n",
    "            \n",
    "            #old_csv_file = h5_file_path.replace('.h5', '.csv')\n",
    "            #if os.path.exists(old_csv_file):\n",
    "                #os.remove(old_csv_file)\n",
    "                #print(f\"Deleted old file: {old_csv_file}\")\n",
    "            \n",
    "            # Get the directory name \n",
    "            dir_name = os.path.basename(root)\n",
    "            \n",
    "            # Create video path string\n",
    "            video_path = f\"  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos/{dir_name}.mp4\"\n",
    "            crop_info = \"    crop: 0, 1920, 0, 1080\"\n",
    "            video_paths_list.append(f\"{video_path}:\\n{crop_info}\")\n",
    "\n",
    "    # Save video paths to a .txt file in the base directory\n",
    "    txt_file_path = os.path.join(base_dir, \"video_paths.txt\")\n",
    "    with open(txt_file_path, 'w') as txt_file:\n",
    "        txt_file.write(\"\\n\".join(video_paths_list))\n",
    "\n",
    "    print(\"Processing complete. Files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/labeled-data'\n",
    "# model_name = 'model1'\n",
    "# base_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15'\n",
    "# kp_to_keep = ['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/labeled-data'\n",
    "model_name = 'model1'\n",
    "base_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02'\n",
    "kp_to_keep = ['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Files saved.\n"
     ]
    }
   ],
   "source": [
    "process_labelled_images(parent_dir, model_name, base_dir, kp_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. check the labels and relabel where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by model1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:07<00:00,  1.28it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.47it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.25it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.55it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.32it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.50it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.46it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|| 10/10 [00:09<00:00,  1.10it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.13it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.16it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.21it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.34it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.45it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.39it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.45it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.49it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.51it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.22it/s]\n",
      "100%|| 10/10 [00:05<00:00,  1.68it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.25it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.35it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.47it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.41it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.15it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.35it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|| 10/10 [00:06<00:00,  1.57it/s]\n",
      "100%|| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(config_path, visualizeindividuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/config3.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Using `skeleton` from the config file as a paf_graph. Data-driven skeleton will not be computed.\n",
      "Utilizing the following graph: [[0, 1], [0, 2], [2, 3], [2, 4], [2, 5], [5, 6], [5, 7]]\n",
      "Creating training data for: Shuffle: 1 TrainFraction:  0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 356/356 [00:00<00:00, 3694.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# paf_graph='config' use the skeleton defined\n",
    "print('hello')\n",
    "deeplabcut.create_multianimaltraining_dataset(config_path, paf_graph='config')#, augmenter_type='imgaug', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using `skeleton` from the config file as a paf_graph. Data-driven skeleton will not be computed.\n",
      "Utilizing the following graph: [[0, 1], [0, 2], [2, 3], [2, 4], [2, 5], [5, 6], [5, 7]]\n",
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "test editting\n",
      "Creating training data for: Shuffle: 5 TrainFraction:  0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 356/356 [00:00<00:00, 1432.11it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'aliases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_multianimaltraining_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaf_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/generate_training_dataset/multiple_individuals_trainingsetmanipulation.py:438\u001b[0m, in \u001b[0;36mcreate_multianimaltraining_dataset\u001b[0;34m(config, num_shuffles, Shuffles, windows2linux, net_type, detector_type, numdigits, crop_size, crop_sampling, paf_graph, trainIndices, testIndices, n_edges_threshold, paf_graph_degree, userfeedback, weight_init, engine)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# Saving metadata and data file (Pickle file)\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m    431\u001b[0m auxiliaryfunctions\u001b[38;5;241m.\u001b[39msave_metadata(\n\u001b[1;32m    432\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(project_path, metadatafilename),\n\u001b[1;32m    433\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m     trainFraction,\n\u001b[1;32m    437\u001b[0m )\n\u001b[0;32m--> 438\u001b[0m \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainFraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainIndices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestIndices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muserfeedback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m datafilename \u001b[38;5;241m=\u001b[39m datafilename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/generate_training_dataset/metadata.py:382\u001b[0m, in \u001b[0;36mupdate_metadata\u001b[0;34m(cfg, train_fraction, shuffle, engine, train_indices, test_indices, overwrite)\u001b[0m\n\u001b[1;32m    371\u001b[0m new_shuffle \u001b[38;5;241m=\u001b[39m ShuffleMetadata(\n\u001b[1;32m    372\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-trainset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m100\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mtrain_fraction)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshuffle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     train_fraction\u001b[38;5;241m=\u001b[39mtrain_fraction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m )\n\u001b[1;32m    381\u001b[0m metadata \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39madd(shuffle\u001b[38;5;241m=\u001b[39mnew_shuffle, overwrite\u001b[38;5;241m=\u001b[39moverwrite)\n\u001b[0;32m--> 382\u001b[0m \u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.10/site-packages/deeplabcut/generate_training_dataset/metadata.py:229\u001b[0m, in \u001b[0;36mTrainingDatasetMetadata.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m         split_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_splits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    223\u001b[0m         data_splits[s\u001b[38;5;241m.\u001b[39msplit] \u001b[38;5;241m=\u001b[39m split_index\n\u001b[1;32m    225\u001b[0m     metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshuffles\u001b[39m\u001b[38;5;124m\"\u001b[39m][s\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_fraction\u001b[39m\u001b[38;5;124m\"\u001b[39m: s\u001b[38;5;241m.\u001b[39mtrain_fraction,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: s\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m: split_index,\n\u001b[0;32m--> 229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maliases\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    230\u001b[0m     }\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_config), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    233\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_header) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'aliases'"
     ]
    }
   ],
   "source": [
    "#deeplabcut.create_multianimaltraining_dataset(config_path, paf_graph='config', engine=Engine.TENSORFLOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Look at the breakdown of the created pickle file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_pickle(file_path):\n",
    "    \"\"\"\n",
    "    Load a pickle file and return its content.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path (str): Path to the pickle file.\n",
    "    \n",
    "    Returns:\n",
    "    - data: The data loaded from the pickle file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_pickle(data, file_path):\n",
    "    \"\"\"\n",
    "    Save data back to a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The data to save.\n",
    "    - file_path (str): Path to save the pickle file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    \n",
    "    print(f\"Data saved to {file_path}\")\n",
    "\n",
    "# # Load the pickle file\n",
    "# file_path = 'path_to_your_pickle_file.pickle'\n",
    "# data = load_pickle(file_path)\n",
    "\n",
    "# # View the data\n",
    "# print(\"Data loaded from pickle file:\", data)\n",
    "\n",
    "# # Modify the data (example: if it's a dictionary, you can update a key-value pair)\n",
    "# if isinstance(data, dict):\n",
    "#     data['new_key'] = 'new_value'\n",
    "#     print(\"Updated data:\", data)\n",
    "\n",
    "# # Save the modified data back to the pickle file\n",
    "# save_pickle(data, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'nms radius': 5.0, 'minimal confidence': 0.01, 'sigma': 1, 'PAFgraph': [[0, 1], [0, 2], [2, 3], [2, 4], [2, 5], [5, 6], [5, 7]], 'PAFinds': array([0, 1, 2, 3, 4, 5, 6]), 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]], 'all_joints_names': ['Head', 'Beak', 'Body_top', 'RFlipper_mid', 'LFlipper_mid', 'Body_bottom', 'RFoot', 'LFoot'], 'stride': 8.0}}\n"
     ]
    }
   ],
   "source": [
    "#file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep2/DLC_simple_dataset_model195shuffle1.pickle'\n",
    "file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-02/training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep2/Documentation_data-DLC_simple_dataset_95shuffle1.pickle'\n",
    "file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/evaluation-results/iteration-2/DLC_simple_datasetSep18-trainset99shuffle1/DLC_dlcrnetms5_DLC_simple_datasetSep18shuffle1_5000-snapshot-5000_meta.pickle'\n",
    "file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/evaluation-results/iteration-0/DLC_simple_datasetSep18-trainset99shuffle1/DLC_dlcrnetms5_DLC_simple_datasetSep18shuffle1_50000-snapshot-50000_meta.pickle'\n",
    "file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/evaluation-results/iteration-2/DLC_simple_datasetSep18-trainset99shuffle1/DLC_dlcrnetms5_DLC_simple_datasetSep18shuffle1_5000-snapshot-5000_full.pickle'\n",
    "#file_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/evaluation-results/iteration-0/DLC_simple_datasetSep18-trainset99shuffle1/DLC_dlcrnetms5_DLC_simple_datasetSep18shuffle1_50000-snapshot-50000_full.pickle'\n",
    "# Load the pickle file\n",
    "\n",
    "data = load_pickle(file_path)\n",
    "\n",
    "print(data)\n",
    "\n",
    "# # Save it as a JSON file for easier editing\n",
    "# json_file_path = file_path.replace('.pickle', '.json')\n",
    "# with open(json_file_path, 'w') as json_file:\n",
    "#     json.dump(data, json_file, indent=4)\n",
    "\n",
    "# print(f\"Pickle data saved as JSON to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Train the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/config3.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "#deeplabcut.train_network(config_path, shuffle=1, batch_size=1)#, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Beak',\n",
      "                      'Body_top',\n",
      "                      'RFlipper_mid',\n",
      "                      'LFlipper_mid',\n",
      "                      'Body_bottom',\n",
      "                      'RFoot',\n",
      "                      'LFoot'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.05,\n",
      " 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_DLC_simple_datasetSep18/DLC_simple_dataset_model199shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.3,\n",
      " 'init_weights': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-3/DLC_simple_datasetSep18-trainset99shuffle1/train/snapshot-5000',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-3/UnaugmentedDataSet_DLC_simple_datasetSep18/Documentation_data-DLC_simple_dataset_99shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 8,\n",
      " 'num_limbs': 7,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1],\n",
      "                             [0, 2],\n",
      "                             [2, 3],\n",
      "                             [2, 4],\n",
      "                             [2, 5],\n",
      "                             [5, 6],\n",
      "                             [5, 7]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 1.0,\n",
      " 'scale_jitter_up': 1.0,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-3/DLC_simple_datasetSep18-trainset99shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting multi-animal trainer\n",
      "Activating limb prediction...\n",
      "Batch Size is 1\n",
      "Getting specs multi-animal-imgaug 7 8\n",
      "Loading already trained DLC with backbone: resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 17:20:45.714464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 17:20:45.720497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 17:20:45.723505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 17:20:45.726415: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 17:20:45.730871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 17:20:45.738357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-19 17:20:49.372341: W tensorflow/c/c_api.cc:300] Operation '{name:'resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Adam/Assign' id:7269 op device:{requested: '', assigned: ''} def:{{{node resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Adam/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Adam, resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Adam/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-09-19 17:20:59.920304: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B (rounded to 256)requested by op beta1_power/Initializer/initial_value\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-09-19 17:20:59.920486: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-09-19 17:20:59.920511: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 1048, Chunks in use: 1048. 262.0KiB allocated for chunks. 262.0KiB in use in bin. 101.6KiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920522: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 448, Chunks in use: 448. 224.0KiB allocated for chunks. 224.0KiB in use in bin. 224.0KiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920532: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 904, Chunks in use: 904. 907.5KiB allocated for chunks. 907.5KiB in use in bin. 904.0KiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920541: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 616, Chunks in use: 616. 1.20MiB allocated for chunks. 1.20MiB in use in bin. 1.20MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920550: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 392, Chunks in use: 392. 1.54MiB allocated for chunks. 1.54MiB in use in bin. 1.53MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920558: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 224, Chunks in use: 224. 1.75MiB allocated for chunks. 1.75MiB in use in bin. 1.75MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920568: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 16, Chunks in use: 16. 271.5KiB allocated for chunks. 271.5KiB in use in bin. 256.0KiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920577: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 15, Chunks in use: 15. 551.2KiB allocated for chunks. 551.2KiB in use in bin. 551.2KiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920586: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 96, Chunks in use: 96. 6.25MiB allocated for chunks. 6.25MiB in use in bin. 6.00MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920595: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 62, Chunks in use: 62. 9.12MiB allocated for chunks. 9.12MiB in use in bin. 8.47MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920605: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 113, Chunks in use: 113. 28.55MiB allocated for chunks. 28.55MiB in use in bin. 28.03MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920614: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 122, Chunks in use: 122. 74.73MiB allocated for chunks. 74.73MiB in use in bin. 72.11MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920624: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 198, Chunks in use: 198. 207.71MiB allocated for chunks. 207.71MiB in use in bin. 198.64MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920634: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 127, Chunks in use: 127. 289.76MiB allocated for chunks. 289.76MiB in use in bin. 277.75MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920643: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 80, Chunks in use: 80. 324.57MiB allocated for chunks. 324.57MiB in use in bin. 318.25MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920653: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 64, Chunks in use: 64. 602.66MiB allocated for chunks. 602.66MiB in use in bin. 560.00MiB client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920664: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920674: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920683: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920692: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920700: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-09-19 17:20:59.920709: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 256B was 256B, Chunk State: \n",
      "2024-09-19 17:20:59.920717: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 553648128\n",
      "2024-09-19 17:20:59.920734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee000000 of size 2359296 next 3459\n",
      "2024-09-19 17:20:59.920744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee240000 of size 256 next 3466\n",
      "2024-09-19 17:20:59.920752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee240100 of size 1024 next 3467\n",
      "2024-09-19 17:20:59.920760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee240500 of size 1024 next 3468\n",
      "2024-09-19 17:20:59.920767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee240900 of size 1024 next 3469\n",
      "2024-09-19 17:20:59.920775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee240d00 of size 1024 next 3470\n",
      "2024-09-19 17:20:59.920782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee241100 of size 1024 next 3471\n",
      "2024-09-19 17:20:59.920790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee241500 of size 1048576 next 3472\n",
      "2024-09-19 17:20:59.920798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee341500 of size 256 next 3473\n",
      "2024-09-19 17:20:59.920806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee341600 of size 1024 next 3474\n",
      "2024-09-19 17:20:59.920813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee341a00 of size 1024 next 3475\n",
      "2024-09-19 17:20:59.920821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee341e00 of size 1024 next 3476\n",
      "2024-09-19 17:20:59.920828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee342200 of size 1024 next 3477\n",
      "2024-09-19 17:20:59.920836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee342600 of size 1024 next 3478\n",
      "2024-09-19 17:20:59.920844: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee342a00 of size 2359296 next 3479\n",
      "2024-09-19 17:20:59.920851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee582a00 of size 256 next 3480\n",
      "2024-09-19 17:20:59.920871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee582b00 of size 4096 next 3481\n",
      "2024-09-19 17:20:59.920879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee583b00 of size 4096 next 3482\n",
      "2024-09-19 17:20:59.920887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee584b00 of size 4096 next 3483\n",
      "2024-09-19 17:20:59.920894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee585b00 of size 4096 next 3484\n",
      "2024-09-19 17:20:59.920902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee586b00 of size 4096 next 3485\n",
      "2024-09-19 17:20:59.920909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee587b00 of size 1048576 next 3486\n",
      "2024-09-19 17:20:59.920917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee687b00 of size 256 next 3487\n",
      "2024-09-19 17:20:59.920925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee687c00 of size 1024 next 3488\n",
      "2024-09-19 17:20:59.920932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee688000 of size 1024 next 3489\n",
      "2024-09-19 17:20:59.920940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee688400 of size 1024 next 3490\n",
      "2024-09-19 17:20:59.920948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee688800 of size 1024 next 3491\n",
      "2024-09-19 17:20:59.920956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee688c00 of size 1024 next 3492\n",
      "2024-09-19 17:20:59.920963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee689000 of size 1048576 next 3493\n",
      "2024-09-19 17:20:59.920971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee789000 of size 256 next 3494\n",
      "2024-09-19 17:20:59.920978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee789100 of size 1024 next 3495\n",
      "2024-09-19 17:20:59.920986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee789500 of size 1024 next 3496\n",
      "2024-09-19 17:20:59.920993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee789900 of size 1024 next 3497\n",
      "2024-09-19 17:20:59.921001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee789d00 of size 1024 next 3498\n",
      "2024-09-19 17:20:59.921008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee78a100 of size 1024 next 3499\n",
      "2024-09-19 17:20:59.921016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee78a500 of size 2359296 next 3500\n",
      "2024-09-19 17:20:59.921023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9ca500 of size 256 next 3501\n",
      "2024-09-19 17:20:59.921031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9ca600 of size 4096 next 3502\n",
      "2024-09-19 17:20:59.921038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9cb600 of size 4096 next 3503\n",
      "2024-09-19 17:20:59.921046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9cc600 of size 4096 next 3504\n",
      "2024-09-19 17:20:59.921054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9cd600 of size 4096 next 3505\n",
      "2024-09-19 17:20:59.921061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9ce600 of size 4096 next 3506\n",
      "2024-09-19 17:20:59.921069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ee9cf600 of size 1048576 next 3507\n",
      "2024-09-19 17:20:59.921076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eeacf600 of size 256 next 3508\n",
      "2024-09-19 17:20:59.921085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eeacf700 of size 2048 next 3509\n",
      "2024-09-19 17:20:59.921092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eeacff00 of size 2048 next 3510\n",
      "2024-09-19 17:20:59.921103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eead0700 of size 2048 next 3511\n",
      "2024-09-19 17:20:59.921117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eead0f00 of size 2048 next 3512\n",
      "2024-09-19 17:20:59.921133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eead1700 of size 2048 next 3513\n",
      "2024-09-19 17:20:59.921147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eead1f00 of size 2097152 next 3514\n",
      "2024-09-19 17:20:59.921166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd1f00 of size 256 next 3515\n",
      "2024-09-19 17:20:59.921181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd2000 of size 2048 next 3516\n",
      "2024-09-19 17:20:59.921191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd2800 of size 2048 next 3517\n",
      "2024-09-19 17:20:59.921199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd3000 of size 2048 next 3518\n",
      "2024-09-19 17:20:59.921206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd3800 of size 2048 next 3519\n",
      "2024-09-19 17:20:59.921214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd4000 of size 2048 next 3520\n",
      "2024-09-19 17:20:59.921221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4eecd4800 of size 9437184 next 3521\n",
      "2024-09-19 17:20:59.921229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5d4800 of size 256 next 3522\n",
      "2024-09-19 17:20:59.921236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5d4900 of size 8192 next 3523\n",
      "2024-09-19 17:20:59.921244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5d6900 of size 8192 next 3524\n",
      "2024-09-19 17:20:59.921251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5d8900 of size 8192 next 3525\n",
      "2024-09-19 17:20:59.921259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5da900 of size 8192 next 3526\n",
      "2024-09-19 17:20:59.921266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5dc900 of size 8192 next 3527\n",
      "2024-09-19 17:20:59.921274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef5de900 of size 4194304 next 3528\n",
      "2024-09-19 17:20:59.921282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9de900 of size 256 next 3529\n",
      "2024-09-19 17:20:59.921289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9dea00 of size 8192 next 3530\n",
      "2024-09-19 17:20:59.921300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9e0a00 of size 8192 next 3531\n",
      "2024-09-19 17:20:59.921314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9e2a00 of size 8192 next 3532\n",
      "2024-09-19 17:20:59.921328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9e4a00 of size 8192 next 3533\n",
      "2024-09-19 17:20:59.921336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9e6a00 of size 8192 next 3534\n",
      "2024-09-19 17:20:59.921344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ef9e8a00 of size 8388608 next 3535\n",
      "2024-09-19 17:20:59.921352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01e8a00 of size 256 next 3536\n",
      "2024-09-19 17:20:59.921359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01e8b00 of size 2048 next 3537\n",
      "2024-09-19 17:20:59.921367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01e9300 of size 2048 next 3538\n",
      "2024-09-19 17:20:59.921374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01e9b00 of size 2048 next 3539\n",
      "2024-09-19 17:20:59.921382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01ea300 of size 2048 next 3540\n",
      "2024-09-19 17:20:59.921389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01eab00 of size 2048 next 3541\n",
      "2024-09-19 17:20:59.921403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f01eb300 of size 4194304 next 3542\n",
      "2024-09-19 17:20:59.921411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05eb300 of size 256 next 3543\n",
      "2024-09-19 17:20:59.921419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05eb400 of size 2048 next 3544\n",
      "2024-09-19 17:20:59.921426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05ebc00 of size 2048 next 3545\n",
      "2024-09-19 17:20:59.921434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05ec400 of size 2048 next 3546\n",
      "2024-09-19 17:20:59.921441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05ecc00 of size 2048 next 3547\n",
      "2024-09-19 17:20:59.921448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05ed400 of size 2048 next 3548\n",
      "2024-09-19 17:20:59.921456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f05edc00 of size 9437184 next 3549\n",
      "2024-09-19 17:20:59.921463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0eedc00 of size 256 next 3550\n",
      "2024-09-19 17:20:59.921471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0eedd00 of size 8192 next 3551\n",
      "2024-09-19 17:20:59.921478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0eefd00 of size 8192 next 3552\n",
      "2024-09-19 17:20:59.921486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0ef1d00 of size 8192 next 3553\n",
      "2024-09-19 17:20:59.921493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0ef3d00 of size 8192 next 3554\n",
      "2024-09-19 17:20:59.921501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0ef5d00 of size 8192 next 3555\n",
      "2024-09-19 17:20:59.921508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f0ef7d00 of size 4194304 next 3556\n",
      "2024-09-19 17:20:59.921515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f7d00 of size 256 next 3557\n",
      "2024-09-19 17:20:59.921523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f7e00 of size 2048 next 3558\n",
      "2024-09-19 17:20:59.921530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f8600 of size 2048 next 3559\n",
      "2024-09-19 17:20:59.921538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f8e00 of size 2048 next 3560\n",
      "2024-09-19 17:20:59.921545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f9600 of size 2048 next 3561\n",
      "2024-09-19 17:20:59.921553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12f9e00 of size 2048 next 3562\n",
      "2024-09-19 17:20:59.921560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f12fa600 of size 4194304 next 3563\n",
      "2024-09-19 17:20:59.921567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fa600 of size 256 next 3564\n",
      "2024-09-19 17:20:59.921575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fa700 of size 2048 next 3565\n",
      "2024-09-19 17:20:59.921582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16faf00 of size 2048 next 3566\n",
      "2024-09-19 17:20:59.921590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fb700 of size 2048 next 3567\n",
      "2024-09-19 17:20:59.921598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fbf00 of size 2048 next 3568\n",
      "2024-09-19 17:20:59.921605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fc700 of size 2048 next 3569\n",
      "2024-09-19 17:20:59.921613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f16fcf00 of size 9437184 next 3570\n",
      "2024-09-19 17:20:59.921620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f1ffcf00 of size 256 next 3571\n",
      "2024-09-19 17:20:59.921628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f1ffd000 of size 8192 next 3572\n",
      "2024-09-19 17:20:59.921635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f1fff000 of size 8192 next 3573\n",
      "2024-09-19 17:20:59.921643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2001000 of size 8192 next 3574\n",
      "2024-09-19 17:20:59.921650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2003000 of size 8192 next 3575\n",
      "2024-09-19 17:20:59.921657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2005000 of size 8192 next 3576\n",
      "2024-09-19 17:20:59.921665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2007000 of size 4194304 next 3577\n",
      "2024-09-19 17:20:59.921672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407000 of size 256 next 3578\n",
      "2024-09-19 17:20:59.921680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407100 of size 256 next 3579\n",
      "2024-09-19 17:20:59.921687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407200 of size 256 next 3580\n",
      "2024-09-19 17:20:59.921694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407300 of size 256 next 3581\n",
      "2024-09-19 17:20:59.921702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407400 of size 256 next 3582\n",
      "2024-09-19 17:20:59.921709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407500 of size 256 next 3583\n",
      "2024-09-19 17:20:59.921717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2407600 of size 37632 next 3584\n",
      "2024-09-19 17:20:59.921725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2410900 of size 256 next 3585\n",
      "2024-09-19 17:20:59.921733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2410a00 of size 1280 next 3586\n",
      "2024-09-19 17:20:59.921741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2410f00 of size 65536 next 3587\n",
      "2024-09-19 17:20:59.921748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2420f00 of size 589824 next 3588\n",
      "2024-09-19 17:20:59.921758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f24b0f00 of size 65536 next 3589\n",
      "2024-09-19 17:20:59.921766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f24c0f00 of size 65536 next 3590\n",
      "2024-09-19 17:20:59.921774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f24d0f00 of size 9437184 next 3591\n",
      "2024-09-19 17:20:59.921781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2dd0f00 of size 131072 next 3592\n",
      "2024-09-19 17:20:59.921789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2df0f00 of size 16384 next 3593\n",
      "2024-09-19 17:20:59.921797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2df4f00 of size 147456 next 3594\n",
      "2024-09-19 17:20:59.921805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2e18f00 of size 147456 next 3595\n",
      "2024-09-19 17:20:59.921812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2e3cf00 of size 37632 next 3596\n",
      "2024-09-19 17:20:59.921820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2e46200 of size 1048576 next 3597\n",
      "2024-09-19 17:20:59.921827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f2f46200 of size 2359296 next 3598\n",
      "2024-09-19 17:20:59.921835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f3186200 of size 1048576 next 3599\n",
      "2024-09-19 17:20:59.921842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f3286200 of size 4194304 next 3600\n",
      "2024-09-19 17:20:59.921849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f3686200 of size 2097152 next 3601\n",
      "2024-09-19 17:20:59.921857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f3886200 of size 4194304 next 3602\n",
      "2024-09-19 17:20:59.921864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f3c86200 of size 4194304 next 3603\n",
      "2024-09-19 17:20:59.921872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f4086200 of size 9437184 next 3604\n",
      "2024-09-19 17:20:59.921879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f4986200 of size 8388608 next 3605\n",
      "2024-09-19 17:20:59.921887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f5186200 of size 9437184 next 3606\n",
      "2024-09-19 17:20:59.921892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f5a86200 of size 4194304 next 3607\n",
      "2024-09-19 17:20:59.921897: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f5e86200 of size 4194304 next 3608\n",
      "2024-09-19 17:20:59.921901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6286200 of size 1048576 next 3609\n",
      "2024-09-19 17:20:59.921904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6386200 of size 2359296 next 3610\n",
      "2024-09-19 17:20:59.921906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f65c6200 of size 1048576 next 3611\n",
      "2024-09-19 17:20:59.921908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f66c6200 of size 1048576 next 3612\n",
      "2024-09-19 17:20:59.921911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f67c6200 of size 1048576 next 3613\n",
      "2024-09-19 17:20:59.921913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f68c6200 of size 1048576 next 3614\n",
      "2024-09-19 17:20:59.921915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f69c6200 of size 2359296 next 3615\n",
      "2024-09-19 17:20:59.921917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6c06200 of size 1048576 next 3616\n",
      "2024-09-19 17:20:59.921920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6d06200 of size 1048576 next 3617\n",
      "2024-09-19 17:20:59.921922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6e06200 of size 1048576 next 3618\n",
      "2024-09-19 17:20:59.921924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6f06200 of size 262144 next 3619\n",
      "2024-09-19 17:20:59.921927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6f46200 of size 262144 next 3620\n",
      "2024-09-19 17:20:59.921929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f6f86200 of size 589824 next 3621\n",
      "2024-09-19 17:20:59.921932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7016200 of size 524288 next 3622\n",
      "2024-09-19 17:20:59.921934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7096200 of size 2097152 next 3623\n",
      "2024-09-19 17:20:59.921936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7296200 of size 262144 next 3624\n",
      "2024-09-19 17:20:59.921938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f72d6200 of size 262144 next 3625\n",
      "2024-09-19 17:20:59.921941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7316200 of size 262144 next 3626\n",
      "2024-09-19 17:20:59.921943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7356200 of size 589824 next 3627\n",
      "2024-09-19 17:20:59.921945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f73e6200 of size 589824 next 3628\n",
      "2024-09-19 17:20:59.921948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7476200 of size 262144 next 3629\n",
      "2024-09-19 17:20:59.921950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f74b6200 of size 262144 next 3630\n",
      "2024-09-19 17:20:59.921952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f74f6200 of size 2359296 next 3631\n",
      "2024-09-19 17:20:59.921955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7736200 of size 2359296 next 3632\n",
      "2024-09-19 17:20:59.921957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7976200 of size 1048576 next 3633\n",
      "2024-09-19 17:20:59.921959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7a76200 of size 65536 next 3634\n",
      "2024-09-19 17:20:59.921961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7a86200 of size 524288 next 3635\n",
      "2024-09-19 17:20:59.921964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7b06200 of size 2359296 next 3636\n",
      "2024-09-19 17:20:59.921966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7d46200 of size 65536 next 3637\n",
      "2024-09-19 17:20:59.921968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7d56200 of size 1179648 next 3638\n",
      "2024-09-19 17:20:59.921971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7e76200 of size 1032192 next 3639\n",
      "2024-09-19 17:20:59.921973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7f72200 of size 147456 next 3640\n",
      "2024-09-19 17:20:59.921975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7f96200 of size 65536 next 3641\n",
      "2024-09-19 17:20:59.921978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f7fa6200 of size 589824 next 3642\n",
      "2024-09-19 17:20:59.921980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8036200 of size 256 next 3643\n",
      "2024-09-19 17:20:59.921982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8036300 of size 256 next 3644\n",
      "2024-09-19 17:20:59.921985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8036400 of size 256 next 3645\n",
      "2024-09-19 17:20:59.921987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8036500 of size 256 next 3646\n",
      "2024-09-19 17:20:59.921989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8036600 of size 1179648 next 3647\n",
      "2024-09-19 17:20:59.921992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8156600 of size 256 next 3648\n",
      "2024-09-19 17:20:59.921994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8156700 of size 256 next 3649\n",
      "2024-09-19 17:20:59.921996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8156800 of size 256 next 3650\n",
      "2024-09-19 17:20:59.921999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8156900 of size 1032192 next 3651\n",
      "2024-09-19 17:20:59.922001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8252900 of size 256 next 3652\n",
      "2024-09-19 17:20:59.922003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8252a00 of size 256 next 3653\n",
      "2024-09-19 17:20:59.922005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8252b00 of size 256 next 3654\n",
      "2024-09-19 17:20:59.922008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8252c00 of size 589824 next 3655\n",
      "2024-09-19 17:20:59.922010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e2c00 of size 256 next 3656\n",
      "2024-09-19 17:20:59.922012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e2d00 of size 256 next 3657\n",
      "2024-09-19 17:20:59.922014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e2e00 of size 256 next 3658\n",
      "2024-09-19 17:20:59.922017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e2f00 of size 256 next 3659\n",
      "2024-09-19 17:20:59.922019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e3000 of size 256 next 3660\n",
      "2024-09-19 17:20:59.922021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e3100 of size 256 next 3661\n",
      "2024-09-19 17:20:59.922023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e3200 of size 256 next 3662\n",
      "2024-09-19 17:20:59.922026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e3300 of size 16384 next 3663\n",
      "2024-09-19 17:20:59.922028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7300 of size 256 next 3664\n",
      "2024-09-19 17:20:59.922030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7400 of size 256 next 3665\n",
      "2024-09-19 17:20:59.922033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7500 of size 256 next 3666\n",
      "2024-09-19 17:20:59.922035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7600 of size 256 next 3667\n",
      "2024-09-19 17:20:59.922037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7700 of size 256 next 3668\n",
      "2024-09-19 17:20:59.922039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7800 of size 256 next 3669\n",
      "2024-09-19 17:20:59.922042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f82e7900 of size 147456 next 3670\n",
      "2024-09-19 17:20:59.922044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830b900 of size 256 next 3671\n",
      "2024-09-19 17:20:59.922046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830ba00 of size 1024 next 3672\n",
      "2024-09-19 17:20:59.922049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830be00 of size 1024 next 3673\n",
      "2024-09-19 17:20:59.922051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830c200 of size 1024 next 3674\n",
      "2024-09-19 17:20:59.922053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830c600 of size 1024 next 3675\n",
      "2024-09-19 17:20:59.922056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830ca00 of size 1024 next 3676\n",
      "2024-09-19 17:20:59.922058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f830ce00 of size 65536 next 3677\n",
      "2024-09-19 17:20:59.922060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831ce00 of size 256 next 3678\n",
      "2024-09-19 17:20:59.922062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831cf00 of size 1024 next 3679\n",
      "2024-09-19 17:20:59.922065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831d300 of size 1024 next 3680\n",
      "2024-09-19 17:20:59.922067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831d700 of size 1024 next 3681\n",
      "2024-09-19 17:20:59.922069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831db00 of size 1024 next 3682\n",
      "2024-09-19 17:20:59.922072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831df00 of size 1024 next 3683\n",
      "2024-09-19 17:20:59.922074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f831e300 of size 65536 next 3684\n",
      "2024-09-19 17:20:59.922076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e300 of size 256 next 3685\n",
      "2024-09-19 17:20:59.922079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e400 of size 256 next 3686\n",
      "2024-09-19 17:20:59.922081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e500 of size 256 next 3687\n",
      "2024-09-19 17:20:59.922083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e600 of size 256 next 3688\n",
      "2024-09-19 17:20:59.922085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e700 of size 256 next 3689\n",
      "2024-09-19 17:20:59.922088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e800 of size 256 next 3690\n",
      "2024-09-19 17:20:59.922090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f832e900 of size 65536 next 3691\n",
      "2024-09-19 17:20:59.922092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833e900 of size 256 next 3692\n",
      "2024-09-19 17:20:59.922095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833ea00 of size 256 next 3693\n",
      "2024-09-19 17:20:59.922097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833eb00 of size 256 next 3694\n",
      "2024-09-19 17:20:59.922099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833ec00 of size 256 next 3695\n",
      "2024-09-19 17:20:59.922101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833ed00 of size 256 next 3696\n",
      "2024-09-19 17:20:59.922104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833ee00 of size 256 next 3697\n",
      "2024-09-19 17:20:59.922106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f833ef00 of size 147456 next 3698\n",
      "2024-09-19 17:20:59.922108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8362f00 of size 256 next 3699\n",
      "2024-09-19 17:20:59.922110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8363000 of size 1024 next 3700\n",
      "2024-09-19 17:20:59.922113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8363400 of size 1024 next 3701\n",
      "2024-09-19 17:20:59.922115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8363800 of size 1024 next 3702\n",
      "2024-09-19 17:20:59.922117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8363c00 of size 1024 next 3703\n",
      "2024-09-19 17:20:59.922120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8364000 of size 1024 next 3704\n",
      "2024-09-19 17:20:59.922122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8364400 of size 65536 next 3705\n",
      "2024-09-19 17:20:59.922124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374400 of size 256 next 3706\n",
      "2024-09-19 17:20:59.922127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374500 of size 256 next 3707\n",
      "2024-09-19 17:20:59.922129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374600 of size 256 next 3708\n",
      "2024-09-19 17:20:59.922131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374700 of size 256 next 3709\n",
      "2024-09-19 17:20:59.922134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374800 of size 256 next 3710\n",
      "2024-09-19 17:20:59.922136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374900 of size 256 next 3711\n",
      "2024-09-19 17:20:59.922138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8374a00 of size 65536 next 3712\n",
      "2024-09-19 17:20:59.922140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384a00 of size 256 next 3713\n",
      "2024-09-19 17:20:59.922143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384b00 of size 256 next 3714\n",
      "2024-09-19 17:20:59.922145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384c00 of size 256 next 3715\n",
      "2024-09-19 17:20:59.922147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384d00 of size 256 next 3716\n",
      "2024-09-19 17:20:59.922149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384e00 of size 256 next 3717\n",
      "2024-09-19 17:20:59.922152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8384f00 of size 256 next 3718\n",
      "2024-09-19 17:20:59.922154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8385000 of size 147456 next 3719\n",
      "2024-09-19 17:20:59.922156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83a9000 of size 256 next 3720\n",
      "2024-09-19 17:20:59.922158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83a9100 of size 1024 next 3721\n",
      "2024-09-19 17:20:59.922161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83a9500 of size 1024 next 3722\n",
      "2024-09-19 17:20:59.922163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83a9900 of size 1024 next 3723\n",
      "2024-09-19 17:20:59.922165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83a9d00 of size 1024 next 3724\n",
      "2024-09-19 17:20:59.922168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83aa100 of size 1024 next 3725\n",
      "2024-09-19 17:20:59.922170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83aa500 of size 65536 next 3726\n",
      "2024-09-19 17:20:59.922173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83ba500 of size 256 next 3727\n",
      "2024-09-19 17:20:59.922177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83ba600 of size 512 next 3728\n",
      "2024-09-19 17:20:59.922182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83ba800 of size 512 next 3729\n",
      "2024-09-19 17:20:59.922186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83baa00 of size 512 next 3730\n",
      "2024-09-19 17:20:59.922191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83bac00 of size 512 next 3731\n",
      "2024-09-19 17:20:59.922195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83bae00 of size 512 next 3732\n",
      "2024-09-19 17:20:59.922198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83bb000 of size 131072 next 3733\n",
      "2024-09-19 17:20:59.922201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db000 of size 256 next 3734\n",
      "2024-09-19 17:20:59.922203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db100 of size 512 next 3735\n",
      "2024-09-19 17:20:59.922205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db300 of size 512 next 3736\n",
      "2024-09-19 17:20:59.922207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db500 of size 512 next 3737\n",
      "2024-09-19 17:20:59.922210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db700 of size 512 next 3738\n",
      "2024-09-19 17:20:59.922212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83db900 of size 512 next 3739\n",
      "2024-09-19 17:20:59.922214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f83dbb00 of size 589824 next 3740\n",
      "2024-09-19 17:20:59.922217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846bb00 of size 256 next 3741\n",
      "2024-09-19 17:20:59.922221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846bc00 of size 2048 next 3742\n",
      "2024-09-19 17:20:59.922225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846c400 of size 2048 next 3743\n",
      "2024-09-19 17:20:59.922230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846cc00 of size 2048 next 3744\n",
      "2024-09-19 17:20:59.922233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846d400 of size 2048 next 3745\n",
      "2024-09-19 17:20:59.922235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846dc00 of size 2048 next 3746\n",
      "2024-09-19 17:20:59.922238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f846e400 of size 262144 next 3747\n",
      "2024-09-19 17:20:59.922240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84ae400 of size 256 next 3748\n",
      "2024-09-19 17:20:59.922242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84ae500 of size 2048 next 3749\n",
      "2024-09-19 17:20:59.922245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84aed00 of size 2048 next 3750\n",
      "2024-09-19 17:20:59.922247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84af500 of size 2048 next 3751\n",
      "2024-09-19 17:20:59.922249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84afd00 of size 2048 next 3752\n",
      "2024-09-19 17:20:59.922251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84b0500 of size 2048 next 3753\n",
      "2024-09-19 17:20:59.922254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f84b0d00 of size 524288 next 3754\n",
      "2024-09-19 17:20:59.922256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8530d00 of size 256 next 3755\n",
      "2024-09-19 17:20:59.922258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8530e00 of size 512 next 3756\n",
      "2024-09-19 17:20:59.922261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8531000 of size 512 next 3757\n",
      "2024-09-19 17:20:59.922263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8531200 of size 512 next 3758\n",
      "2024-09-19 17:20:59.922265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8531400 of size 512 next 3759\n",
      "2024-09-19 17:20:59.922267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8531600 of size 512 next 3760\n",
      "2024-09-19 17:20:59.922270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8531800 of size 262144 next 3761\n",
      "2024-09-19 17:20:59.922272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8571800 of size 256 next 3762\n",
      "2024-09-19 17:20:59.922275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8571900 of size 512 next 3763\n",
      "2024-09-19 17:20:59.922277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8571b00 of size 512 next 3764\n",
      "2024-09-19 17:20:59.922279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8571d00 of size 512 next 3765\n",
      "2024-09-19 17:20:59.922281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8571f00 of size 512 next 3766\n",
      "2024-09-19 17:20:59.922284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8572100 of size 512 next 3767\n",
      "2024-09-19 17:20:59.922286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8572300 of size 589824 next 3768\n",
      "2024-09-19 17:20:59.922288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8602300 of size 256 next 3769\n",
      "2024-09-19 17:20:59.922291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8602400 of size 2048 next 3770\n",
      "2024-09-19 17:20:59.922293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8602c00 of size 2048 next 3771\n",
      "2024-09-19 17:20:59.922295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8603400 of size 2048 next 3772\n",
      "2024-09-19 17:20:59.922297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8603c00 of size 2048 next 3773\n",
      "2024-09-19 17:20:59.922300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8604400 of size 2048 next 3774\n",
      "2024-09-19 17:20:59.922302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8604c00 of size 262144 next 3775\n",
      "2024-09-19 17:20:59.922304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8644c00 of size 256 next 3776\n",
      "2024-09-19 17:20:59.922307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8644d00 of size 512 next 3777\n",
      "2024-09-19 17:20:59.922309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8644f00 of size 512 next 3778\n",
      "2024-09-19 17:20:59.922311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8645100 of size 512 next 3779\n",
      "2024-09-19 17:20:59.922313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8645300 of size 512 next 3780\n",
      "2024-09-19 17:20:59.922316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8645500 of size 512 next 3781\n",
      "2024-09-19 17:20:59.922318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8645700 of size 262144 next 3782\n",
      "2024-09-19 17:20:59.922320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8685700 of size 256 next 3783\n",
      "2024-09-19 17:20:59.922322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8685800 of size 512 next 3784\n",
      "2024-09-19 17:20:59.922325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8685a00 of size 512 next 3785\n",
      "2024-09-19 17:20:59.922327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8685c00 of size 512 next 3786\n",
      "2024-09-19 17:20:59.922329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8685e00 of size 512 next 3787\n",
      "2024-09-19 17:20:59.922332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8686000 of size 512 next 3788\n",
      "2024-09-19 17:20:59.922334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8686200 of size 589824 next 3789\n",
      "2024-09-19 17:20:59.922336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8716200 of size 256 next 3790\n",
      "2024-09-19 17:20:59.922338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8716300 of size 2048 next 3791\n",
      "2024-09-19 17:20:59.922341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8716b00 of size 2048 next 3792\n",
      "2024-09-19 17:20:59.922343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8717300 of size 2048 next 3793\n",
      "2024-09-19 17:20:59.922345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8717b00 of size 2048 next 3794\n",
      "2024-09-19 17:20:59.922348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8718300 of size 2048 next 3795\n",
      "2024-09-19 17:20:59.922350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8718b00 of size 262144 next 3796\n",
      "2024-09-19 17:20:59.922352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8758b00 of size 256 next 3797\n",
      "2024-09-19 17:20:59.922354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8758c00 of size 512 next 3798\n",
      "2024-09-19 17:20:59.922357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8758e00 of size 512 next 3799\n",
      "2024-09-19 17:20:59.922359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8759000 of size 512 next 3800\n",
      "2024-09-19 17:20:59.922361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8759200 of size 512 next 3801\n",
      "2024-09-19 17:20:59.922363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8759400 of size 512 next 3802\n",
      "2024-09-19 17:20:59.922366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8759600 of size 262144 next 3803\n",
      "2024-09-19 17:20:59.922368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799600 of size 256 next 3804\n",
      "2024-09-19 17:20:59.922370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799700 of size 512 next 3805\n",
      "2024-09-19 17:20:59.922373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799900 of size 512 next 3806\n",
      "2024-09-19 17:20:59.922375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799b00 of size 512 next 3807\n",
      "2024-09-19 17:20:59.922377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799d00 of size 512 next 3808\n",
      "2024-09-19 17:20:59.922379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8799f00 of size 512 next 3809\n",
      "2024-09-19 17:20:59.922382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f879a100 of size 589824 next 3810\n",
      "2024-09-19 17:20:59.922384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882a100 of size 256 next 3811\n",
      "2024-09-19 17:20:59.922386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882a200 of size 2048 next 3812\n",
      "2024-09-19 17:20:59.922388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882aa00 of size 2048 next 3813\n",
      "2024-09-19 17:20:59.922391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882b200 of size 2048 next 3814\n",
      "2024-09-19 17:20:59.922393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882ba00 of size 2048 next 3815\n",
      "2024-09-19 17:20:59.922395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882c200 of size 2048 next 3816\n",
      "2024-09-19 17:20:59.922398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f882ca00 of size 262144 next 3817\n",
      "2024-09-19 17:20:59.922400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886ca00 of size 256 next 3818\n",
      "2024-09-19 17:20:59.922402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886cb00 of size 1024 next 3819\n",
      "2024-09-19 17:20:59.922405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886cf00 of size 1024 next 3820\n",
      "2024-09-19 17:20:59.922407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886d300 of size 1024 next 3821\n",
      "2024-09-19 17:20:59.922409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886d700 of size 1024 next 3822\n",
      "2024-09-19 17:20:59.922411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886db00 of size 1024 next 3823\n",
      "2024-09-19 17:20:59.922414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f886df00 of size 524288 next 3824\n",
      "2024-09-19 17:20:59.922416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88edf00 of size 256 next 3825\n",
      "2024-09-19 17:20:59.922418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88ee000 of size 1024 next 3826\n",
      "2024-09-19 17:20:59.922421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88ee400 of size 1024 next 3827\n",
      "2024-09-19 17:20:59.922423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88ee800 of size 1024 next 3828\n",
      "2024-09-19 17:20:59.922425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88eec00 of size 1024 next 3829\n",
      "2024-09-19 17:20:59.922427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88ef000 of size 1024 next 3830\n",
      "2024-09-19 17:20:59.922430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f88ef400 of size 2359296 next 3831\n",
      "2024-09-19 17:20:59.922432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b2f400 of size 256 next 3832\n",
      "2024-09-19 17:20:59.922434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b2f500 of size 4096 next 3833\n",
      "2024-09-19 17:20:59.922436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b30500 of size 4096 next 3834\n",
      "2024-09-19 17:20:59.922439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b31500 of size 4096 next 3835\n",
      "2024-09-19 17:20:59.922441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b32500 of size 4096 next 3836\n",
      "2024-09-19 17:20:59.922443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b33500 of size 4096 next 3837\n",
      "2024-09-19 17:20:59.922446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8b34500 of size 1048576 next 3838\n",
      "2024-09-19 17:20:59.922448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c34500 of size 256 next 3839\n",
      "2024-09-19 17:20:59.922450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c34600 of size 4096 next 3840\n",
      "2024-09-19 17:20:59.922452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c35600 of size 4096 next 3841\n",
      "2024-09-19 17:20:59.922455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c36600 of size 4096 next 3842\n",
      "2024-09-19 17:20:59.922457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c37600 of size 4096 next 3843\n",
      "2024-09-19 17:20:59.922459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c38600 of size 4096 next 3844\n",
      "2024-09-19 17:20:59.922462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8c39600 of size 2097152 next 3845\n",
      "2024-09-19 17:20:59.922464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e39600 of size 256 next 3846\n",
      "2024-09-19 17:20:59.922466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e39700 of size 1024 next 3847\n",
      "2024-09-19 17:20:59.922468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e39b00 of size 1024 next 3848\n",
      "2024-09-19 17:20:59.922471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e39f00 of size 1024 next 3849\n",
      "2024-09-19 17:20:59.922473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e3a300 of size 1024 next 3850\n",
      "2024-09-19 17:20:59.922475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e3a700 of size 1024 next 3851\n",
      "2024-09-19 17:20:59.922478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8e3ab00 of size 1048576 next 3852\n",
      "2024-09-19 17:20:59.922480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3ab00 of size 256 next 3853\n",
      "2024-09-19 17:20:59.922482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3ac00 of size 1024 next 3854\n",
      "2024-09-19 17:20:59.922484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3b000 of size 1024 next 3855\n",
      "2024-09-19 17:20:59.922487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3b400 of size 1024 next 3856\n",
      "2024-09-19 17:20:59.922489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3b800 of size 1024 next 3857\n",
      "2024-09-19 17:20:59.922491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3bc00 of size 1024 next 3858\n",
      "2024-09-19 17:20:59.922494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f8f3c000 of size 2359296 next 3859\n",
      "2024-09-19 17:20:59.922496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f917c000 of size 256 next 3860\n",
      "2024-09-19 17:20:59.922498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f917c100 of size 4096 next 3861\n",
      "2024-09-19 17:20:59.922501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f917d100 of size 4096 next 3862\n",
      "2024-09-19 17:20:59.922503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f917e100 of size 4096 next 3863\n",
      "2024-09-19 17:20:59.922505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f917f100 of size 4096 next 3864\n",
      "2024-09-19 17:20:59.922507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9180100 of size 4096 next 3865\n",
      "2024-09-19 17:20:59.922510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9181100 of size 1048576 next 3866\n",
      "2024-09-19 17:20:59.922512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9281100 of size 256 next 3867\n",
      "2024-09-19 17:20:59.922514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9281200 of size 1024 next 3868\n",
      "2024-09-19 17:20:59.922517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9281600 of size 1024 next 3869\n",
      "2024-09-19 17:20:59.922519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9281a00 of size 1024 next 3870\n",
      "2024-09-19 17:20:59.922521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9281e00 of size 1024 next 3871\n",
      "2024-09-19 17:20:59.922523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9282200 of size 1024 next 3872\n",
      "2024-09-19 17:20:59.922526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9282600 of size 1048576 next 3873\n",
      "2024-09-19 17:20:59.922528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9382600 of size 256 next 3874\n",
      "2024-09-19 17:20:59.922530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9382700 of size 1024 next 3875\n",
      "2024-09-19 17:20:59.922532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9382b00 of size 1024 next 3876\n",
      "2024-09-19 17:20:59.922535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9382f00 of size 1024 next 3877\n",
      "2024-09-19 17:20:59.922537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9383300 of size 1024 next 3878\n",
      "2024-09-19 17:20:59.922540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9383700 of size 1024 next 3879\n",
      "2024-09-19 17:20:59.922542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9383b00 of size 2359296 next 3880\n",
      "2024-09-19 17:20:59.922544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c3b00 of size 256 next 3881\n",
      "2024-09-19 17:20:59.922546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c3c00 of size 4096 next 3882\n",
      "2024-09-19 17:20:59.922549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c4c00 of size 4096 next 3883\n",
      "2024-09-19 17:20:59.922551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c5c00 of size 4096 next 3884\n",
      "2024-09-19 17:20:59.922553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c6c00 of size 4096 next 3885\n",
      "2024-09-19 17:20:59.922555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c7c00 of size 4096 next 3886\n",
      "2024-09-19 17:20:59.922558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f95c8c00 of size 1048576 next 3887\n",
      "2024-09-19 17:20:59.922560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c8c00 of size 256 next 3888\n",
      "2024-09-19 17:20:59.922562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c8d00 of size 1024 next 3889\n",
      "2024-09-19 17:20:59.922565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c9100 of size 1024 next 3890\n",
      "2024-09-19 17:20:59.922567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c9500 of size 1024 next 3891\n",
      "2024-09-19 17:20:59.922569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c9900 of size 1024 next 3892\n",
      "2024-09-19 17:20:59.922571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96c9d00 of size 1024 next 3893\n",
      "2024-09-19 17:20:59.922574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f96ca100 of size 1048576 next 3894\n",
      "2024-09-19 17:20:59.922576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97ca100 of size 256 next 3895\n",
      "2024-09-19 17:20:59.922578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97ca200 of size 1024 next 3896\n",
      "2024-09-19 17:20:59.922580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97ca600 of size 1024 next 3897\n",
      "2024-09-19 17:20:59.922583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97caa00 of size 1024 next 3898\n",
      "2024-09-19 17:20:59.922585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97cae00 of size 1024 next 3899\n",
      "2024-09-19 17:20:59.922587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97cb200 of size 1024 next 3900\n",
      "2024-09-19 17:20:59.922590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f97cb600 of size 2359296 next 3901\n",
      "2024-09-19 17:20:59.922592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0b600 of size 256 next 3902\n",
      "2024-09-19 17:20:59.922594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0b700 of size 4096 next 3903\n",
      "2024-09-19 17:20:59.922597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0c700 of size 4096 next 3904\n",
      "2024-09-19 17:20:59.922599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0d700 of size 4096 next 3905\n",
      "2024-09-19 17:20:59.922601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0e700 of size 4096 next 3906\n",
      "2024-09-19 17:20:59.922603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a0f700 of size 4096 next 3907\n",
      "2024-09-19 17:20:59.922606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9a10700 of size 1048576 next 3908\n",
      "2024-09-19 17:20:59.922608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b10700 of size 256 next 3909\n",
      "2024-09-19 17:20:59.922610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b10800 of size 1024 next 3910\n",
      "2024-09-19 17:20:59.922613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b10c00 of size 1024 next 3911\n",
      "2024-09-19 17:20:59.922615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b11000 of size 1024 next 3912\n",
      "2024-09-19 17:20:59.922619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b11400 of size 1024 next 3913\n",
      "2024-09-19 17:20:59.922623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b11800 of size 1024 next 3914\n",
      "2024-09-19 17:20:59.922627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9b11c00 of size 1048576 next 3915\n",
      "2024-09-19 17:20:59.922631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c11c00 of size 256 next 3916\n",
      "2024-09-19 17:20:59.922635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c11d00 of size 1024 next 3917\n",
      "2024-09-19 17:20:59.922638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c12100 of size 1024 next 3918\n",
      "2024-09-19 17:20:59.922641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c12500 of size 1024 next 3919\n",
      "2024-09-19 17:20:59.922643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c12900 of size 1024 next 3920\n",
      "2024-09-19 17:20:59.922646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c12d00 of size 1024 next 3921\n",
      "2024-09-19 17:20:59.922648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9c13100 of size 2359296 next 3922\n",
      "2024-09-19 17:20:59.922650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e53100 of size 256 next 3923\n",
      "2024-09-19 17:20:59.922652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e53200 of size 4096 next 3924\n",
      "2024-09-19 17:20:59.922655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e54200 of size 4096 next 3925\n",
      "2024-09-19 17:20:59.922657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e55200 of size 4096 next 3926\n",
      "2024-09-19 17:20:59.922659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e56200 of size 4096 next 3927\n",
      "2024-09-19 17:20:59.922661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e57200 of size 4096 next 3928\n",
      "2024-09-19 17:20:59.922664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9e58200 of size 1048576 next 3929\n",
      "2024-09-19 17:20:59.922666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f58200 of size 256 next 3930\n",
      "2024-09-19 17:20:59.922668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f58300 of size 1024 next 3931\n",
      "2024-09-19 17:20:59.922671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f58700 of size 1024 next 3932\n",
      "2024-09-19 17:20:59.922673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f58b00 of size 1024 next 3933\n",
      "2024-09-19 17:20:59.922675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f58f00 of size 1024 next 3934\n",
      "2024-09-19 17:20:59.922677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f59300 of size 1024 next 3935\n",
      "2024-09-19 17:20:59.922680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4f9f59700 of size 1048576 next 3936\n",
      "2024-09-19 17:20:59.922682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa059700 of size 256 next 3937\n",
      "2024-09-19 17:20:59.922684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa059800 of size 1024 next 3938\n",
      "2024-09-19 17:20:59.922687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa059c00 of size 1024 next 3939\n",
      "2024-09-19 17:20:59.922689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa05a000 of size 1024 next 3940\n",
      "2024-09-19 17:20:59.922691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa05a400 of size 1024 next 3941\n",
      "2024-09-19 17:20:59.922694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa05a800 of size 1024 next 3942\n",
      "2024-09-19 17:20:59.922696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa05ac00 of size 2359296 next 3943\n",
      "2024-09-19 17:20:59.922698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29ac00 of size 256 next 3944\n",
      "2024-09-19 17:20:59.922701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29ad00 of size 4096 next 3945\n",
      "2024-09-19 17:20:59.922704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29bd00 of size 4096 next 3946\n",
      "2024-09-19 17:20:59.922706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29cd00 of size 4096 next 3947\n",
      "2024-09-19 17:20:59.922708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29dd00 of size 4096 next 3948\n",
      "2024-09-19 17:20:59.922710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29ed00 of size 4096 next 3949\n",
      "2024-09-19 17:20:59.922713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa29fd00 of size 1048576 next 3950\n",
      "2024-09-19 17:20:59.922715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa39fd00 of size 256 next 3951\n",
      "2024-09-19 17:20:59.922717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa39fe00 of size 2048 next 3952\n",
      "2024-09-19 17:20:59.922720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa3a0600 of size 2048 next 3953\n",
      "2024-09-19 17:20:59.922722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa3a0e00 of size 2048 next 3954\n",
      "2024-09-19 17:20:59.922724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa3a1600 of size 2048 next 3955\n",
      "2024-09-19 17:20:59.922726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa3a1e00 of size 2048 next 3956\n",
      "2024-09-19 17:20:59.922729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa3a2600 of size 2097152 next 3957\n",
      "2024-09-19 17:20:59.922731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a2600 of size 256 next 3958\n",
      "2024-09-19 17:20:59.922733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a2700 of size 2048 next 3959\n",
      "2024-09-19 17:20:59.922736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a2f00 of size 2048 next 3960\n",
      "2024-09-19 17:20:59.922738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a3700 of size 2048 next 3961\n",
      "2024-09-19 17:20:59.922740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a3f00 of size 2048 next 3962\n",
      "2024-09-19 17:20:59.922743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a4700 of size 2048 next 3963\n",
      "2024-09-19 17:20:59.922745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fa5a4f00 of size 9437184 next 3964\n",
      "2024-09-19 17:20:59.922747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faea4f00 of size 256 next 3965\n",
      "2024-09-19 17:20:59.922750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faea5000 of size 8192 next 3966\n",
      "2024-09-19 17:20:59.922752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faea7000 of size 8192 next 3967\n",
      "2024-09-19 17:20:59.922754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faea9000 of size 8192 next 3968\n",
      "2024-09-19 17:20:59.922756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faeab000 of size 8192 next 3969\n",
      "2024-09-19 17:20:59.922759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faead000 of size 8192 next 3970\n",
      "2024-09-19 17:20:59.922761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4faeaf000 of size 4194304 next 3971\n",
      "2024-09-19 17:20:59.922763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2af000 of size 256 next 3972\n",
      "2024-09-19 17:20:59.922765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2af100 of size 8192 next 3973\n",
      "2024-09-19 17:20:59.922768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2b1100 of size 8192 next 3974\n",
      "2024-09-19 17:20:59.922770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2b3100 of size 8192 next 3975\n",
      "2024-09-19 17:20:59.922772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2b5100 of size 8192 next 3976\n",
      "2024-09-19 17:20:59.922775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2b7100 of size 8192 next 3977\n",
      "2024-09-19 17:20:59.922777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fb2b9100 of size 8388608 next 3978\n",
      "2024-09-19 17:20:59.922779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbab9100 of size 256 next 3979\n",
      "2024-09-19 17:20:59.922781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbab9200 of size 2048 next 3980\n",
      "2024-09-19 17:20:59.922784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbab9a00 of size 2048 next 3981\n",
      "2024-09-19 17:20:59.922786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbaba200 of size 2048 next 3982\n",
      "2024-09-19 17:20:59.922788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbabaa00 of size 2048 next 3983\n",
      "2024-09-19 17:20:59.922791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbabb200 of size 2048 next 3984\n",
      "2024-09-19 17:20:59.922793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbabba00 of size 4194304 next 3985\n",
      "2024-09-19 17:20:59.922795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebba00 of size 256 next 3986\n",
      "2024-09-19 17:20:59.922797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebbb00 of size 2048 next 3987\n",
      "2024-09-19 17:20:59.922800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebc300 of size 2048 next 3988\n",
      "2024-09-19 17:20:59.922802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebcb00 of size 2048 next 3989\n",
      "2024-09-19 17:20:59.922804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebd300 of size 2048 next 3990\n",
      "2024-09-19 17:20:59.922807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebdb00 of size 2048 next 3991\n",
      "2024-09-19 17:20:59.922809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fbebe300 of size 9437184 next 3992\n",
      "2024-09-19 17:20:59.922811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7be300 of size 256 next 3993\n",
      "2024-09-19 17:20:59.922813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7be400 of size 8192 next 3994\n",
      "2024-09-19 17:20:59.922816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7c0400 of size 8192 next 3995\n",
      "2024-09-19 17:20:59.922818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7c2400 of size 8192 next 3996\n",
      "2024-09-19 17:20:59.922820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7c4400 of size 8192 next 3997\n",
      "2024-09-19 17:20:59.922823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7c6400 of size 8192 next 3998\n",
      "2024-09-19 17:20:59.922825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fc7c8400 of size 4194304 next 3999\n",
      "2024-09-19 17:20:59.922827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbc8400 of size 256 next 4000\n",
      "2024-09-19 17:20:59.922829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbc8500 of size 2048 next 4001\n",
      "2024-09-19 17:20:59.922832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbc8d00 of size 2048 next 4002\n",
      "2024-09-19 17:20:59.922834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbc9500 of size 2048 next 4003\n",
      "2024-09-19 17:20:59.922836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbc9d00 of size 2048 next 4004\n",
      "2024-09-19 17:20:59.922838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbca500 of size 2048 next 4005\n",
      "2024-09-19 17:20:59.922841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcbcad00 of size 4194304 next 4006\n",
      "2024-09-19 17:20:59.922843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcad00 of size 256 next 4007\n",
      "2024-09-19 17:20:59.922845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcae00 of size 2048 next 4008\n",
      "2024-09-19 17:20:59.922848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcb600 of size 2048 next 4009\n",
      "2024-09-19 17:20:59.922850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcbe00 of size 2048 next 4010\n",
      "2024-09-19 17:20:59.922852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcc600 of size 2048 next 4011\n",
      "2024-09-19 17:20:59.922854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcce00 of size 2048 next 4012\n",
      "2024-09-19 17:20:59.922857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fcfcd600 of size 9437184 next 4013\n",
      "2024-09-19 17:20:59.922859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8cd600 of size 256 next 4014\n",
      "2024-09-19 17:20:59.922861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8cd700 of size 8192 next 4015\n",
      "2024-09-19 17:20:59.922864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8cf700 of size 8192 next 4016\n",
      "2024-09-19 17:20:59.922866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8d1700 of size 8192 next 4017\n",
      "2024-09-19 17:20:59.922868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8d3700 of size 8192 next 4018\n",
      "2024-09-19 17:20:59.922870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8d5700 of size 8192 next 4019\n",
      "2024-09-19 17:20:59.922873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fd8d7700 of size 4194304 next 4020\n",
      "2024-09-19 17:20:59.922875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7700 of size 256 next 4021\n",
      "2024-09-19 17:20:59.922877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7800 of size 256 next 4022\n",
      "2024-09-19 17:20:59.922879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7900 of size 256 next 4023\n",
      "2024-09-19 17:20:59.922882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7a00 of size 256 next 4024\n",
      "2024-09-19 17:20:59.922884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7b00 of size 256 next 4025\n",
      "2024-09-19 17:20:59.922886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7c00 of size 256 next 4026\n",
      "2024-09-19 17:20:59.922889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdcd7d00 of size 37632 next 4027\n",
      "2024-09-19 17:20:59.922891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdce1000 of size 256 next 4028\n",
      "2024-09-19 17:20:59.922893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdce1100 of size 1280 next 4029\n",
      "2024-09-19 17:20:59.922895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdce1600 of size 1048576 next 4030\n",
      "2024-09-19 17:20:59.922898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdde1600 of size 1048576 next 4031\n",
      "2024-09-19 17:20:59.922900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdee1600 of size 1048576 next 4032\n",
      "2024-09-19 17:20:59.922902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fdfe1600 of size 1048576 next 4033\n",
      "2024-09-19 17:20:59.922905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe0e1600 of size 1048576 next 4034\n",
      "2024-09-19 17:20:59.922907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe1e1600 of size 262144 next 4035\n",
      "2024-09-19 17:20:59.922909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe221600 of size 2359296 next 4036\n",
      "2024-09-19 17:20:59.922911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe461600 of size 262144 next 4037\n",
      "2024-09-19 17:20:59.922914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe4a1600 of size 524288 next 4038\n",
      "2024-09-19 17:20:59.922916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe521600 of size 589824 next 4039\n",
      "2024-09-19 17:20:59.922918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe5b1600 of size 2359296 next 4040\n",
      "2024-09-19 17:20:59.922921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe7f1600 of size 1048576 next 4041\n",
      "2024-09-19 17:20:59.922923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe8f1600 of size 1048576 next 4042\n",
      "2024-09-19 17:20:59.922925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fe9f1600 of size 1048576 next 4043\n",
      "2024-09-19 17:20:59.922927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4feaf1600 of size 2359296 next 4044\n",
      "2024-09-19 17:20:59.922930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fed31600 of size 1048576 next 4045\n",
      "2024-09-19 17:20:59.922932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4fee31600 of size 2359296 next 4046\n",
      "2024-09-19 17:20:59.922934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff071600 of size 262144 next 4047\n",
      "2024-09-19 17:20:59.922937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff0b1600 of size 1048576 next 4048\n",
      "2024-09-19 17:20:59.922939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff1b1600 of size 2359296 next 4049\n",
      "2024-09-19 17:20:59.922941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff3f1600 of size 4194304 next 4050\n",
      "2024-09-19 17:20:59.922943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff7f1600 of size 262144 next 4051\n",
      "2024-09-19 17:20:59.922946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff831600 of size 589824 next 4052\n",
      "2024-09-19 17:20:59.922948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ff8c1600 of size 2359296 next 4053\n",
      "2024-09-19 17:20:59.922950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffb01600 of size 2097152 next 4054\n",
      "2024-09-19 17:20:59.922953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffd01600 of size 262144 next 4055\n",
      "2024-09-19 17:20:59.922955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffd41600 of size 262144 next 4056\n",
      "2024-09-19 17:20:59.922957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffd81600 of size 262144 next 4057\n",
      "2024-09-19 17:20:59.922959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffdc1600 of size 589824 next 4058\n",
      "2024-09-19 17:20:59.922962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa4ffe51600 of size 9437184 next 4059\n",
      "2024-09-19 17:20:59.922964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa500751600 of size 4194304 next 4060\n",
      "2024-09-19 17:20:59.922966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa500b51600 of size 524288 next 4061\n",
      "2024-09-19 17:20:59.922969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa500bd1600 of size 4194304 next 4062\n",
      "2024-09-19 17:20:59.922971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa500fd1600 of size 9437184 next 4063\n",
      "2024-09-19 17:20:59.922973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5018d1600 of size 2097152 next 4064\n",
      "2024-09-19 17:20:59.922976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa501ad1600 of size 8388608 next 4065\n",
      "2024-09-19 17:20:59.922978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5022d1600 of size 1179648 next 4066\n",
      "2024-09-19 17:20:59.922980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5023f1600 of size 65536 next 4067\n",
      "2024-09-19 17:20:59.922982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502401600 of size 589824 next 4068\n",
      "2024-09-19 17:20:59.922985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502491600 of size 65536 next 4069\n",
      "2024-09-19 17:20:59.922987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5024a1600 of size 1032192 next 4070\n",
      "2024-09-19 17:20:59.922990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50259d600 of size 65536 next 4071\n",
      "2024-09-19 17:20:59.922992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5025ad600 of size 16384 next 4072\n",
      "2024-09-19 17:20:59.922994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5025b1600 of size 147456 next 4073\n",
      "2024-09-19 17:20:59.922997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5025d5600 of size 589824 next 4074\n",
      "2024-09-19 17:20:59.922999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502665600 of size 131072 next 4075\n",
      "2024-09-19 17:20:59.923001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502685600 of size 65536 next 4076\n",
      "2024-09-19 17:20:59.923003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502695600 of size 65536 next 4077\n",
      "2024-09-19 17:20:59.923006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5026a5600 of size 147456 next 4078\n",
      "2024-09-19 17:20:59.923008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5026c9600 of size 65536 next 4079\n",
      "2024-09-19 17:20:59.923010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5026d9600 of size 147456 next 4080\n",
      "2024-09-19 17:20:59.923013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5026fd600 of size 4194304 next 4081\n",
      "2024-09-19 17:20:59.923015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502afd600 of size 1048576 next 4082\n",
      "2024-09-19 17:20:59.923017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502bfd600 of size 37632 next 4083\n",
      "2024-09-19 17:20:59.923019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa502c06900 of size 9437184 next 4084\n",
      "2024-09-19 17:20:59.923022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503506900 of size 4194304 next 4085\n",
      "2024-09-19 17:20:59.923024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503906900 of size 256 next 4086\n",
      "2024-09-19 17:20:59.923026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503906a00 of size 256 next 4087\n",
      "2024-09-19 17:20:59.923029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503906b00 of size 256 next 4088\n",
      "2024-09-19 17:20:59.923031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503906c00 of size 256 next 4089\n",
      "2024-09-19 17:20:59.923033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503906d00 of size 1179648 next 4090\n",
      "2024-09-19 17:20:59.923035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503a26d00 of size 256 next 4091\n",
      "2024-09-19 17:20:59.923038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503a26e00 of size 256 next 4092\n",
      "2024-09-19 17:20:59.923040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503a26f00 of size 256 next 4093\n",
      "2024-09-19 17:20:59.923042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503a27000 of size 1032192 next 4094\n",
      "2024-09-19 17:20:59.923044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503b23000 of size 256 next 4095\n",
      "2024-09-19 17:20:59.923047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503b23100 of size 256 next 4096\n",
      "2024-09-19 17:20:59.923049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503b23200 of size 256 next 4097\n",
      "2024-09-19 17:20:59.923051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503b23300 of size 589824 next 4098\n",
      "2024-09-19 17:20:59.923054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3300 of size 256 next 4099\n",
      "2024-09-19 17:20:59.923056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3400 of size 256 next 4100\n",
      "2024-09-19 17:20:59.923058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3500 of size 256 next 4101\n",
      "2024-09-19 17:20:59.923060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3600 of size 256 next 4102\n",
      "2024-09-19 17:20:59.923063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3700 of size 256 next 4103\n",
      "2024-09-19 17:20:59.923065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3800 of size 256 next 4104\n",
      "2024-09-19 17:20:59.923067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3900 of size 256 next 4105\n",
      "2024-09-19 17:20:59.923069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb3a00 of size 16384 next 4106\n",
      "2024-09-19 17:20:59.923072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7a00 of size 256 next 4107\n",
      "2024-09-19 17:20:59.923074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7b00 of size 256 next 4108\n",
      "2024-09-19 17:20:59.923076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7c00 of size 256 next 4109\n",
      "2024-09-19 17:20:59.923078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7d00 of size 256 next 4110\n",
      "2024-09-19 17:20:59.923081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7e00 of size 256 next 4111\n",
      "2024-09-19 17:20:59.923083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb7f00 of size 256 next 4112\n",
      "2024-09-19 17:20:59.923085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bb8000 of size 147456 next 4113\n",
      "2024-09-19 17:20:59.923088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdc000 of size 256 next 4114\n",
      "2024-09-19 17:20:59.923090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdc100 of size 1024 next 4115\n",
      "2024-09-19 17:20:59.923092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdc500 of size 1024 next 4116\n",
      "2024-09-19 17:20:59.923094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdc900 of size 1024 next 4117\n",
      "2024-09-19 17:20:59.923097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdcd00 of size 1024 next 4118\n",
      "2024-09-19 17:20:59.923099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdd100 of size 1024 next 4119\n",
      "2024-09-19 17:20:59.923101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bdd500 of size 65536 next 4120\n",
      "2024-09-19 17:20:59.923104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bed500 of size 256 next 4121\n",
      "2024-09-19 17:20:59.923106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bed600 of size 1024 next 4122\n",
      "2024-09-19 17:20:59.923108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503beda00 of size 1024 next 4123\n",
      "2024-09-19 17:20:59.923111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bede00 of size 1024 next 4124\n",
      "2024-09-19 17:20:59.923113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bee200 of size 1024 next 4125\n",
      "2024-09-19 17:20:59.923115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bee600 of size 1024 next 4126\n",
      "2024-09-19 17:20:59.923117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503beea00 of size 65536 next 4127\n",
      "2024-09-19 17:20:59.923120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfea00 of size 256 next 4128\n",
      "2024-09-19 17:20:59.923122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfeb00 of size 256 next 4129\n",
      "2024-09-19 17:20:59.923124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfec00 of size 256 next 4130\n",
      "2024-09-19 17:20:59.923126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfed00 of size 256 next 4131\n",
      "2024-09-19 17:20:59.923129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfee00 of size 256 next 4132\n",
      "2024-09-19 17:20:59.923131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bfef00 of size 256 next 4133\n",
      "2024-09-19 17:20:59.923133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503bff000 of size 65536 next 4134\n",
      "2024-09-19 17:20:59.923135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f000 of size 256 next 4135\n",
      "2024-09-19 17:20:59.923138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f100 of size 256 next 4136\n",
      "2024-09-19 17:20:59.923140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f200 of size 256 next 4137\n",
      "2024-09-19 17:20:59.923142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f300 of size 256 next 4138\n",
      "2024-09-19 17:20:59.923145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f400 of size 256 next 4139\n",
      "2024-09-19 17:20:59.923147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f500 of size 256 next 4140\n",
      "2024-09-19 17:20:59.923149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c0f600 of size 147456 next 4141\n",
      "2024-09-19 17:20:59.923151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c33600 of size 256 next 4142\n",
      "2024-09-19 17:20:59.923154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c33700 of size 1024 next 4143\n",
      "2024-09-19 17:20:59.923156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c33b00 of size 1024 next 4144\n",
      "2024-09-19 17:20:59.923158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c33f00 of size 1024 next 4145\n",
      "2024-09-19 17:20:59.923161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c34300 of size 1024 next 4146\n",
      "2024-09-19 17:20:59.923163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c34700 of size 1024 next 4147\n",
      "2024-09-19 17:20:59.923165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c34b00 of size 65536 next 4148\n",
      "2024-09-19 17:20:59.923167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c44b00 of size 256 next 4149\n",
      "2024-09-19 17:20:59.923170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c44c00 of size 256 next 4150\n",
      "2024-09-19 17:20:59.923172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c44d00 of size 256 next 4151\n",
      "2024-09-19 17:20:59.923174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c44e00 of size 256 next 4152\n",
      "2024-09-19 17:20:59.923177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c44f00 of size 256 next 4153\n",
      "2024-09-19 17:20:59.923179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c45000 of size 256 next 4154\n",
      "2024-09-19 17:20:59.923181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c45100 of size 65536 next 4155\n",
      "2024-09-19 17:20:59.923183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55100 of size 256 next 4156\n",
      "2024-09-19 17:20:59.923186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55200 of size 256 next 4157\n",
      "2024-09-19 17:20:59.923188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55300 of size 256 next 4158\n",
      "2024-09-19 17:20:59.923190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55400 of size 256 next 4159\n",
      "2024-09-19 17:20:59.923193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55500 of size 256 next 4160\n",
      "2024-09-19 17:20:59.923195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55600 of size 256 next 4161\n",
      "2024-09-19 17:20:59.923197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c55700 of size 147456 next 4162\n",
      "2024-09-19 17:20:59.923199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c79700 of size 256 next 4163\n",
      "2024-09-19 17:20:59.923202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c79800 of size 1024 next 4164\n",
      "2024-09-19 17:20:59.923204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c79c00 of size 1024 next 4165\n",
      "2024-09-19 17:20:59.923206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c7a000 of size 1024 next 4166\n",
      "2024-09-19 17:20:59.923208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c7a400 of size 1024 next 4167\n",
      "2024-09-19 17:20:59.923211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c7a800 of size 1024 next 4168\n",
      "2024-09-19 17:20:59.923213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c7ac00 of size 65536 next 4169\n",
      "2024-09-19 17:20:59.923215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8ac00 of size 256 next 4170\n",
      "2024-09-19 17:20:59.923218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8ad00 of size 512 next 4171\n",
      "2024-09-19 17:20:59.923220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8af00 of size 512 next 4172\n",
      "2024-09-19 17:20:59.923222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8b100 of size 512 next 4173\n",
      "2024-09-19 17:20:59.923225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8b300 of size 512 next 4174\n",
      "2024-09-19 17:20:59.923227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8b500 of size 512 next 4175\n",
      "2024-09-19 17:20:59.923229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503c8b700 of size 131072 next 4176\n",
      "2024-09-19 17:20:59.923232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cab700 of size 256 next 4177\n",
      "2024-09-19 17:20:59.923234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cab800 of size 512 next 4178\n",
      "2024-09-19 17:20:59.923236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503caba00 of size 512 next 4179\n",
      "2024-09-19 17:20:59.923238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cabc00 of size 512 next 4180\n",
      "2024-09-19 17:20:59.923241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cabe00 of size 512 next 4181\n",
      "2024-09-19 17:20:59.923243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cac000 of size 512 next 4182\n",
      "2024-09-19 17:20:59.923245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503cac200 of size 589824 next 4183\n",
      "2024-09-19 17:20:59.923248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3c200 of size 256 next 4184\n",
      "2024-09-19 17:20:59.923250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3c300 of size 2048 next 4185\n",
      "2024-09-19 17:20:59.923252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3cb00 of size 2048 next 4186\n",
      "2024-09-19 17:20:59.923254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3d300 of size 2048 next 4187\n",
      "2024-09-19 17:20:59.923257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3db00 of size 2048 next 4188\n",
      "2024-09-19 17:20:59.923259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3e300 of size 2048 next 4189\n",
      "2024-09-19 17:20:59.923261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d3eb00 of size 262144 next 4190\n",
      "2024-09-19 17:20:59.923264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d7eb00 of size 256 next 4191\n",
      "2024-09-19 17:20:59.923266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d7ec00 of size 2048 next 4192\n",
      "2024-09-19 17:20:59.923268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d7f400 of size 2048 next 4193\n",
      "2024-09-19 17:20:59.923270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d7fc00 of size 2048 next 4194\n",
      "2024-09-19 17:20:59.923273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d80400 of size 2048 next 4195\n",
      "2024-09-19 17:20:59.923275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d80c00 of size 2048 next 4196\n",
      "2024-09-19 17:20:59.923277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503d81400 of size 524288 next 4197\n",
      "2024-09-19 17:20:59.923279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01400 of size 256 next 4198\n",
      "2024-09-19 17:20:59.923282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01500 of size 512 next 4199\n",
      "2024-09-19 17:20:59.923284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01700 of size 512 next 4200\n",
      "2024-09-19 17:20:59.923287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01900 of size 512 next 4201\n",
      "2024-09-19 17:20:59.923289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01b00 of size 512 next 4202\n",
      "2024-09-19 17:20:59.923292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01d00 of size 512 next 4203\n",
      "2024-09-19 17:20:59.923294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e01f00 of size 262144 next 4204\n",
      "2024-09-19 17:20:59.923296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e41f00 of size 256 next 4205\n",
      "2024-09-19 17:20:59.923299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42000 of size 512 next 4206\n",
      "2024-09-19 17:20:59.923301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42200 of size 512 next 4207\n",
      "2024-09-19 17:20:59.923303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42400 of size 512 next 4208\n",
      "2024-09-19 17:20:59.923305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42600 of size 512 next 4209\n",
      "2024-09-19 17:20:59.923308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42800 of size 512 next 4210\n",
      "2024-09-19 17:20:59.923310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503e42a00 of size 589824 next 4211\n",
      "2024-09-19 17:20:59.923312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed2a00 of size 256 next 4212\n",
      "2024-09-19 17:20:59.923315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed2b00 of size 2048 next 4213\n",
      "2024-09-19 17:20:59.923317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed3300 of size 2048 next 4214\n",
      "2024-09-19 17:20:59.923319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed3b00 of size 2048 next 4215\n",
      "2024-09-19 17:20:59.923321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed4300 of size 2048 next 4216\n",
      "2024-09-19 17:20:59.923324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed4b00 of size 2048 next 4217\n",
      "2024-09-19 17:20:59.923326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503ed5300 of size 262144 next 4218\n",
      "2024-09-19 17:20:59.923328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15300 of size 256 next 4219\n",
      "2024-09-19 17:20:59.923330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15400 of size 512 next 4220\n",
      "2024-09-19 17:20:59.923333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15600 of size 512 next 4221\n",
      "2024-09-19 17:20:59.923335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15800 of size 512 next 4222\n",
      "2024-09-19 17:20:59.923337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15a00 of size 512 next 4223\n",
      "2024-09-19 17:20:59.923340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15c00 of size 512 next 4224\n",
      "2024-09-19 17:20:59.923342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f15e00 of size 262144 next 4225\n",
      "2024-09-19 17:20:59.923346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f55e00 of size 256 next 4226\n",
      "2024-09-19 17:20:59.923348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f55f00 of size 512 next 4227\n",
      "2024-09-19 17:20:59.923350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f56100 of size 512 next 4228\n",
      "2024-09-19 17:20:59.923353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f56300 of size 512 next 4229\n",
      "2024-09-19 17:20:59.923355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f56500 of size 512 next 4230\n",
      "2024-09-19 17:20:59.923357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f56700 of size 512 next 4231\n",
      "2024-09-19 17:20:59.923359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503f56900 of size 589824 next 4232\n",
      "2024-09-19 17:20:59.923362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe6900 of size 256 next 4233\n",
      "2024-09-19 17:20:59.923364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe6a00 of size 2048 next 4234\n",
      "2024-09-19 17:20:59.923366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe7200 of size 2048 next 4235\n",
      "2024-09-19 17:20:59.923369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe7a00 of size 2048 next 4236\n",
      "2024-09-19 17:20:59.923371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe8200 of size 2048 next 4237\n",
      "2024-09-19 17:20:59.923373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe8a00 of size 2048 next 4238\n",
      "2024-09-19 17:20:59.923375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa503fe9200 of size 262144 next 4239\n",
      "2024-09-19 17:20:59.923378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029200 of size 256 next 4240\n",
      "2024-09-19 17:20:59.923380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029300 of size 512 next 4241\n",
      "2024-09-19 17:20:59.923382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029500 of size 512 next 4242\n",
      "2024-09-19 17:20:59.923385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029700 of size 512 next 4243\n",
      "2024-09-19 17:20:59.923387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029900 of size 512 next 4244\n",
      "2024-09-19 17:20:59.923389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029b00 of size 512 next 4245\n",
      "2024-09-19 17:20:59.923391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504029d00 of size 262144 next 4246\n",
      "2024-09-19 17:20:59.923394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504069d00 of size 256 next 4247\n",
      "2024-09-19 17:20:59.923396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504069e00 of size 512 next 4248\n",
      "2024-09-19 17:20:59.923398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50406a000 of size 512 next 4249\n",
      "2024-09-19 17:20:59.923401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50406a200 of size 512 next 4250\n",
      "2024-09-19 17:20:59.923403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50406a400 of size 512 next 4251\n",
      "2024-09-19 17:20:59.923405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50406a600 of size 512 next 4252\n",
      "2024-09-19 17:20:59.923407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50406a800 of size 589824 next 4253\n",
      "2024-09-19 17:20:59.923410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fa800 of size 256 next 4254\n",
      "2024-09-19 17:20:59.923412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fa900 of size 2048 next 4255\n",
      "2024-09-19 17:20:59.923414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fb100 of size 2048 next 4256\n",
      "2024-09-19 17:20:59.923417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fb900 of size 2048 next 4257\n",
      "2024-09-19 17:20:59.923419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fc100 of size 2048 next 4258\n",
      "2024-09-19 17:20:59.923421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fc900 of size 2048 next 4259\n",
      "2024-09-19 17:20:59.923423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5040fd100 of size 262144 next 4260\n",
      "2024-09-19 17:20:59.923426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413d100 of size 256 next 4261\n",
      "2024-09-19 17:20:59.923428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413d200 of size 1024 next 4262\n",
      "2024-09-19 17:20:59.923430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413d600 of size 1024 next 4263\n",
      "2024-09-19 17:20:59.923433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413da00 of size 1024 next 4264\n",
      "2024-09-19 17:20:59.923435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413de00 of size 1024 next 4265\n",
      "2024-09-19 17:20:59.923437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413e200 of size 1024 next 4266\n",
      "2024-09-19 17:20:59.923440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50413e600 of size 524288 next 4267\n",
      "2024-09-19 17:20:59.923442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041be600 of size 256 next 4268\n",
      "2024-09-19 17:20:59.923444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041be700 of size 1024 next 4269\n",
      "2024-09-19 17:20:59.923446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041beb00 of size 1024 next 4270\n",
      "2024-09-19 17:20:59.923449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041bef00 of size 1024 next 4271\n",
      "2024-09-19 17:20:59.923451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041bf300 of size 1024 next 4272\n",
      "2024-09-19 17:20:59.923453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041bf700 of size 1024 next 4273\n",
      "2024-09-19 17:20:59.923456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5041bfb00 of size 2359296 next 4274\n",
      "2024-09-19 17:20:59.923458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5043ffb00 of size 256 next 4275\n",
      "2024-09-19 17:20:59.923460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5043ffc00 of size 4096 next 4276\n",
      "2024-09-19 17:20:59.923462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504400c00 of size 4096 next 4277\n",
      "2024-09-19 17:20:59.923465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504401c00 of size 4096 next 4278\n",
      "2024-09-19 17:20:59.923467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504402c00 of size 4096 next 4279\n",
      "2024-09-19 17:20:59.923470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504403c00 of size 4096 next 4280\n",
      "2024-09-19 17:20:59.923472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504404c00 of size 1048576 next 4281\n",
      "2024-09-19 17:20:59.923474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504504c00 of size 256 next 4282\n",
      "2024-09-19 17:20:59.923476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504504d00 of size 4096 next 4283\n",
      "2024-09-19 17:20:59.923479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504505d00 of size 4096 next 4284\n",
      "2024-09-19 17:20:59.923481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504506d00 of size 4096 next 4285\n",
      "2024-09-19 17:20:59.923483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504507d00 of size 4096 next 4286\n",
      "2024-09-19 17:20:59.923485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504508d00 of size 4096 next 4287\n",
      "2024-09-19 17:20:59.923488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504509d00 of size 2097152 next 4288\n",
      "2024-09-19 17:20:59.923490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504709d00 of size 256 next 4289\n",
      "2024-09-19 17:20:59.923492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504709e00 of size 1024 next 4290\n",
      "2024-09-19 17:20:59.923495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50470a200 of size 1024 next 4291\n",
      "2024-09-19 17:20:59.923497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50470a600 of size 1024 next 4292\n",
      "2024-09-19 17:20:59.923499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50470aa00 of size 1024 next 4293\n",
      "2024-09-19 17:20:59.923501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50470ae00 of size 1024 next 4294\n",
      "2024-09-19 17:20:59.923504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50470b200 of size 1048576 next 4295\n",
      "2024-09-19 17:20:59.923506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480b200 of size 256 next 4296\n",
      "2024-09-19 17:20:59.923508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480b300 of size 1024 next 4297\n",
      "2024-09-19 17:20:59.923511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480b700 of size 1024 next 4298\n",
      "2024-09-19 17:20:59.923513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480bb00 of size 1024 next 4299\n",
      "2024-09-19 17:20:59.923515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480bf00 of size 1024 next 4300\n",
      "2024-09-19 17:20:59.923517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480c300 of size 1024 next 4301\n",
      "2024-09-19 17:20:59.923520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50480c700 of size 2359296 next 4302\n",
      "2024-09-19 17:20:59.923522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a4c700 of size 256 next 4303\n",
      "2024-09-19 17:20:59.923524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a4c800 of size 4096 next 4304\n",
      "2024-09-19 17:20:59.923527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a4d800 of size 4096 next 4305\n",
      "2024-09-19 17:20:59.923529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a4e800 of size 4096 next 4306\n",
      "2024-09-19 17:20:59.923531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a4f800 of size 4096 next 4307\n",
      "2024-09-19 17:20:59.923533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a50800 of size 4096 next 4308\n",
      "2024-09-19 17:20:59.923536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504a51800 of size 1048576 next 4309\n",
      "2024-09-19 17:20:59.923538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b51800 of size 256 next 4310\n",
      "2024-09-19 17:20:59.923540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b51900 of size 1024 next 4311\n",
      "2024-09-19 17:20:59.923542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b51d00 of size 1024 next 4312\n",
      "2024-09-19 17:20:59.923545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b52100 of size 1024 next 4313\n",
      "2024-09-19 17:20:59.923547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b52500 of size 1024 next 4314\n",
      "2024-09-19 17:20:59.923549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b52900 of size 1024 next 4315\n",
      "2024-09-19 17:20:59.923552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504b52d00 of size 1048576 next 4316\n",
      "2024-09-19 17:20:59.923554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c52d00 of size 256 next 4317\n",
      "2024-09-19 17:20:59.923556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c52e00 of size 1024 next 4318\n",
      "2024-09-19 17:20:59.923558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c53200 of size 1024 next 4319\n",
      "2024-09-19 17:20:59.923561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c53600 of size 1024 next 4320\n",
      "2024-09-19 17:20:59.923563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c53a00 of size 1024 next 4321\n",
      "2024-09-19 17:20:59.923565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c53e00 of size 1024 next 4322\n",
      "2024-09-19 17:20:59.923567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504c54200 of size 2359296 next 4323\n",
      "2024-09-19 17:20:59.923570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e94200 of size 256 next 4324\n",
      "2024-09-19 17:20:59.923572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e94300 of size 4096 next 4325\n",
      "2024-09-19 17:20:59.923574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e95300 of size 4096 next 4326\n",
      "2024-09-19 17:20:59.923576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e96300 of size 4096 next 4327\n",
      "2024-09-19 17:20:59.923579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e97300 of size 4096 next 4328\n",
      "2024-09-19 17:20:59.923581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e98300 of size 4096 next 4329\n",
      "2024-09-19 17:20:59.923584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504e99300 of size 1048576 next 4330\n",
      "2024-09-19 17:20:59.923586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f99300 of size 256 next 4331\n",
      "2024-09-19 17:20:59.923588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f99400 of size 1024 next 4332\n",
      "2024-09-19 17:20:59.923590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f99800 of size 1024 next 4333\n",
      "2024-09-19 17:20:59.923593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f99c00 of size 1024 next 4334\n",
      "2024-09-19 17:20:59.923595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f9a000 of size 1024 next 4335\n",
      "2024-09-19 17:20:59.923597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f9a400 of size 1024 next 4336\n",
      "2024-09-19 17:20:59.923599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa504f9a800 of size 1048576 next 4337\n",
      "2024-09-19 17:20:59.923602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509a800 of size 256 next 4338\n",
      "2024-09-19 17:20:59.923604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509a900 of size 1024 next 4339\n",
      "2024-09-19 17:20:59.923606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509ad00 of size 1024 next 4340\n",
      "2024-09-19 17:20:59.923609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509b100 of size 1024 next 4341\n",
      "2024-09-19 17:20:59.923611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509b500 of size 1024 next 4342\n",
      "2024-09-19 17:20:59.923613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509b900 of size 1024 next 4343\n",
      "2024-09-19 17:20:59.923615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50509bd00 of size 2359296 next 4344\n",
      "2024-09-19 17:20:59.923618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dbd00 of size 256 next 4345\n",
      "2024-09-19 17:20:59.923620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dbe00 of size 4096 next 4346\n",
      "2024-09-19 17:20:59.923622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dce00 of size 4096 next 4347\n",
      "2024-09-19 17:20:59.923624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dde00 of size 4096 next 4348\n",
      "2024-09-19 17:20:59.923627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dee00 of size 4096 next 4349\n",
      "2024-09-19 17:20:59.923629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052dfe00 of size 4096 next 4350\n",
      "2024-09-19 17:20:59.923631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5052e0e00 of size 1048576 next 4351\n",
      "2024-09-19 17:20:59.923634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e0e00 of size 256 next 4352\n",
      "2024-09-19 17:20:59.923636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e0f00 of size 1024 next 4353\n",
      "2024-09-19 17:20:59.923638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e1300 of size 1024 next 4354\n",
      "2024-09-19 17:20:59.923640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e1700 of size 1024 next 4355\n",
      "2024-09-19 17:20:59.923643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e1b00 of size 1024 next 4356\n",
      "2024-09-19 17:20:59.923645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e1f00 of size 1024 next 4357\n",
      "2024-09-19 17:20:59.923647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5053e2300 of size 1048576 next 4358\n",
      "2024-09-19 17:20:59.923650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e2300 of size 256 next 4359\n",
      "2024-09-19 17:20:59.923652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e2400 of size 1024 next 4360\n",
      "2024-09-19 17:20:59.923654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e2800 of size 1024 next 4361\n",
      "2024-09-19 17:20:59.923657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e2c00 of size 1024 next 4362\n",
      "2024-09-19 17:20:59.923659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e3000 of size 1024 next 4363\n",
      "2024-09-19 17:20:59.923661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e3400 of size 1024 next 4364\n",
      "2024-09-19 17:20:59.923663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5054e3800 of size 2359296 next 4365\n",
      "2024-09-19 17:20:59.923666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505723800 of size 256 next 4366\n",
      "2024-09-19 17:20:59.923668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505723900 of size 4096 next 4367\n",
      "2024-09-19 17:20:59.923670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505724900 of size 4096 next 4368\n",
      "2024-09-19 17:20:59.923672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505725900 of size 4096 next 4369\n",
      "2024-09-19 17:20:59.923675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505726900 of size 4096 next 4370\n",
      "2024-09-19 17:20:59.923677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505727900 of size 4096 next 4371\n",
      "2024-09-19 17:20:59.923679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505728900 of size 1048576 next 4372\n",
      "2024-09-19 17:20:59.923682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505828900 of size 256 next 4373\n",
      "2024-09-19 17:20:59.923684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505828a00 of size 1024 next 4374\n",
      "2024-09-19 17:20:59.923686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505828e00 of size 1024 next 4375\n",
      "2024-09-19 17:20:59.923689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505829200 of size 1024 next 4376\n",
      "2024-09-19 17:20:59.923691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505829600 of size 1024 next 4377\n",
      "2024-09-19 17:20:59.923693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505829a00 of size 1024 next 4378\n",
      "2024-09-19 17:20:59.923695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505829e00 of size 1048576 next 4379\n",
      "2024-09-19 17:20:59.923698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505929e00 of size 256 next 4380\n",
      "2024-09-19 17:20:59.923700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505929f00 of size 1024 next 4381\n",
      "2024-09-19 17:20:59.923702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50592a300 of size 1024 next 4382\n",
      "2024-09-19 17:20:59.923704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50592a700 of size 1024 next 4383\n",
      "2024-09-19 17:20:59.923707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50592ab00 of size 1024 next 4384\n",
      "2024-09-19 17:20:59.923709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50592af00 of size 1024 next 4385\n",
      "2024-09-19 17:20:59.923711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50592b300 of size 2359296 next 4386\n",
      "2024-09-19 17:20:59.923714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6b300 of size 256 next 4387\n",
      "2024-09-19 17:20:59.923716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6b400 of size 4096 next 4388\n",
      "2024-09-19 17:20:59.923718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6c400 of size 4096 next 4389\n",
      "2024-09-19 17:20:59.923720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6d400 of size 4096 next 4390\n",
      "2024-09-19 17:20:59.923723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6e400 of size 4096 next 4391\n",
      "2024-09-19 17:20:59.923725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b6f400 of size 4096 next 4392\n",
      "2024-09-19 17:20:59.923727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505b70400 of size 1048576 next 4393\n",
      "2024-09-19 17:20:59.923729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c70400 of size 256 next 4394\n",
      "2024-09-19 17:20:59.923732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c70500 of size 2048 next 4395\n",
      "2024-09-19 17:20:59.923734: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c70d00 of size 2048 next 4396\n",
      "2024-09-19 17:20:59.923736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c71500 of size 2048 next 4397\n",
      "2024-09-19 17:20:59.923739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c71d00 of size 2048 next 4398\n",
      "2024-09-19 17:20:59.923741: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c72500 of size 2048 next 4399\n",
      "2024-09-19 17:20:59.923743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505c72d00 of size 2097152 next 4400\n",
      "2024-09-19 17:20:59.923745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e72d00 of size 256 next 4401\n",
      "2024-09-19 17:20:59.923748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e72e00 of size 2048 next 4402\n",
      "2024-09-19 17:20:59.923750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e73600 of size 2048 next 4403\n",
      "2024-09-19 17:20:59.923752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e73e00 of size 2048 next 4404\n",
      "2024-09-19 17:20:59.923754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e74600 of size 2048 next 4405\n",
      "2024-09-19 17:20:59.923757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e74e00 of size 2048 next 4406\n",
      "2024-09-19 17:20:59.923759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa505e75600 of size 9437184 next 4407\n",
      "2024-09-19 17:20:59.923761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506775600 of size 256 next 4408\n",
      "2024-09-19 17:20:59.923764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506775700 of size 8192 next 4409\n",
      "2024-09-19 17:20:59.923766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506777700 of size 8192 next 4410\n",
      "2024-09-19 17:20:59.923768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506779700 of size 8192 next 4411\n",
      "2024-09-19 17:20:59.923770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50677b700 of size 8192 next 4412\n",
      "2024-09-19 17:20:59.923773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50677d700 of size 8192 next 4413\n",
      "2024-09-19 17:20:59.923775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50677f700 of size 4194304 next 4414\n",
      "2024-09-19 17:20:59.923777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b7f700 of size 256 next 4415\n",
      "2024-09-19 17:20:59.923780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b7f800 of size 8192 next 4416\n",
      "2024-09-19 17:20:59.923782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b81800 of size 8192 next 4417\n",
      "2024-09-19 17:20:59.923784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b83800 of size 8192 next 4418\n",
      "2024-09-19 17:20:59.923786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b85800 of size 8192 next 4419\n",
      "2024-09-19 17:20:59.923789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b87800 of size 8192 next 4420\n",
      "2024-09-19 17:20:59.923791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa506b89800 of size 8388608 next 4421\n",
      "2024-09-19 17:20:59.923793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa507389800 of size 256 next 4422\n",
      "2024-09-19 17:20:59.923796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa507389900 of size 2048 next 4423\n",
      "2024-09-19 17:20:59.923798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50738a100 of size 2048 next 4424\n",
      "2024-09-19 17:20:59.923800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50738a900 of size 2048 next 4425\n",
      "2024-09-19 17:20:59.923802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50738b100 of size 2048 next 4426\n",
      "2024-09-19 17:20:59.923805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50738b900 of size 2048 next 4427\n",
      "2024-09-19 17:20:59.923807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50738c100 of size 4194304 next 4428\n",
      "2024-09-19 17:20:59.923809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778c100 of size 256 next 4429\n",
      "2024-09-19 17:20:59.923812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778c200 of size 2048 next 4430\n",
      "2024-09-19 17:20:59.923814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778ca00 of size 2048 next 4431\n",
      "2024-09-19 17:20:59.923816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778d200 of size 2048 next 4432\n",
      "2024-09-19 17:20:59.923818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778da00 of size 2048 next 4433\n",
      "2024-09-19 17:20:59.923821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778e200 of size 2048 next 4434\n",
      "2024-09-19 17:20:59.923823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50778ea00 of size 9437184 next 4435\n",
      "2024-09-19 17:20:59.923825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50808ea00 of size 256 next 4436\n",
      "2024-09-19 17:20:59.923827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50808eb00 of size 8192 next 4437\n",
      "2024-09-19 17:20:59.923830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508090b00 of size 8192 next 4438\n",
      "2024-09-19 17:20:59.923832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508092b00 of size 8192 next 4439\n",
      "2024-09-19 17:20:59.923834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508094b00 of size 8192 next 4440\n",
      "2024-09-19 17:20:59.923837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508096b00 of size 8192 next 4441\n",
      "2024-09-19 17:20:59.923839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508098b00 of size 4194304 next 4442\n",
      "2024-09-19 17:20:59.923841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508498b00 of size 256 next 4443\n",
      "2024-09-19 17:20:59.923843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508498c00 of size 2048 next 4444\n",
      "2024-09-19 17:20:59.923846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508499400 of size 2048 next 4445\n",
      "2024-09-19 17:20:59.923848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa508499c00 of size 2048 next 4446\n",
      "2024-09-19 17:20:59.923851: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50849a400 of size 2048 next 4447\n",
      "2024-09-19 17:20:59.923853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50849ac00 of size 2048 next 4448\n",
      "2024-09-19 17:20:59.923855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50849b400 of size 4194304 next 4449\n",
      "2024-09-19 17:20:59.923857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889b400 of size 256 next 4450\n",
      "2024-09-19 17:20:59.923860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889b500 of size 2048 next 4451\n",
      "2024-09-19 17:20:59.923862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889bd00 of size 2048 next 4452\n",
      "2024-09-19 17:20:59.923864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889c500 of size 2048 next 4453\n",
      "2024-09-19 17:20:59.923866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889cd00 of size 2048 next 4454\n",
      "2024-09-19 17:20:59.923869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889d500 of size 2048 next 4455\n",
      "2024-09-19 17:20:59.923871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50889dd00 of size 9437184 next 4456\n",
      "2024-09-19 17:20:59.923873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50919dd00 of size 256 next 4457\n",
      "2024-09-19 17:20:59.923876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50919de00 of size 8192 next 4458\n",
      "2024-09-19 17:20:59.923878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50919fe00 of size 8192 next 4459\n",
      "2024-09-19 17:20:59.923880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5091a1e00 of size 8192 next 4460\n",
      "2024-09-19 17:20:59.923882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5091a3e00 of size 8192 next 4461\n",
      "2024-09-19 17:20:59.923885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5091a5e00 of size 8192 next 4462\n",
      "2024-09-19 17:20:59.923887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5091a7e00 of size 4194304 next 4463\n",
      "2024-09-19 17:20:59.923889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a7e00 of size 256 next 4464\n",
      "2024-09-19 17:20:59.923891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a7f00 of size 256 next 4465\n",
      "2024-09-19 17:20:59.923894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a8000 of size 256 next 4466\n",
      "2024-09-19 17:20:59.923896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a8100 of size 256 next 4467\n",
      "2024-09-19 17:20:59.923898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a8200 of size 256 next 4468\n",
      "2024-09-19 17:20:59.923901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a8300 of size 256 next 4469\n",
      "2024-09-19 17:20:59.923903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095a8400 of size 37632 next 4470\n",
      "2024-09-19 17:20:59.923905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095b1700 of size 256 next 4471\n",
      "2024-09-19 17:20:59.923907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095b1800 of size 1280 next 4472\n",
      "2024-09-19 17:20:59.923910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5095b1d00 of size 2359296 next 4473\n",
      "2024-09-19 17:20:59.923912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5097f1d00 of size 2097152 next 4474\n",
      "2024-09-19 17:20:59.923914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa5099f1d00 of size 1048576 next 4475\n",
      "2024-09-19 17:20:59.923917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa509af1d00 of size 1048576 next 4476\n",
      "2024-09-19 17:20:59.923919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa509bf1d00 of size 8388608 next 4477\n",
      "2024-09-19 17:20:59.923921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50a3f1d00 of size 9437184 next 4478\n",
      "2024-09-19 17:20:59.923924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50acf1d00 of size 9437184 next 4479\n",
      "2024-09-19 17:20:59.923926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50b5f1d00 of size 4194304 next 4480\n",
      "2024-09-19 17:20:59.923928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50b9f1d00 of size 4194304 next 4481\n",
      "2024-09-19 17:20:59.923931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50bdf1d00 of size 4194304 next 4482\n",
      "2024-09-19 17:20:59.923933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50c1f1d00 of size 4194304 next 4483\n",
      "2024-09-19 17:20:59.923935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50c5f1d00 of size 2359296 next 4484\n",
      "2024-09-19 17:20:59.923937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50c831d00 of size 1048576 next 4485\n",
      "2024-09-19 17:20:59.923940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50c931d00 of size 1048576 next 4486\n",
      "2024-09-19 17:20:59.923942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50ca31d00 of size 1048576 next 4487\n",
      "2024-09-19 17:20:59.923944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50cb31d00 of size 2359296 next 4488\n",
      "2024-09-19 17:20:59.923947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50cd71d00 of size 1048576 next 4489\n",
      "2024-09-19 17:20:59.923949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50ce71d00 of size 1048576 next 4490\n",
      "2024-09-19 17:20:59.923951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50cf71d00 of size 2097152 next 4491\n",
      "2024-09-19 17:20:59.923953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d171d00 of size 1048576 next 4492\n",
      "2024-09-19 17:20:59.923956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d271d00 of size 2359296 next 4493\n",
      "2024-09-19 17:20:59.923958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d4b1d00 of size 2359296 next 4494\n",
      "2024-09-19 17:20:59.923960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d6f1d00 of size 1048576 next 4495\n",
      "2024-09-19 17:20:59.923962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d7f1d00 of size 524288 next 4496\n",
      "2024-09-19 17:20:59.923965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d871d00 of size 262144 next 4497\n",
      "2024-09-19 17:20:59.923967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d8b1d00 of size 589824 next 4498\n",
      "2024-09-19 17:20:59.923969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d941d00 of size 262144 next 4499\n",
      "2024-09-19 17:20:59.923972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d981d00 of size 262144 next 4500\n",
      "2024-09-19 17:20:59.923974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50d9c1d00 of size 262144 next 4501\n",
      "2024-09-19 17:20:59.923976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50da01d00 of size 589824 next 4502\n",
      "2024-09-19 17:20:59.923979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50da91d00 of size 262144 next 4503\n",
      "2024-09-19 17:20:59.923981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dad1d00 of size 262144 next 4504\n",
      "2024-09-19 17:20:59.923983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50db11d00 of size 524288 next 4505\n",
      "2024-09-19 17:20:59.923985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50db91d00 of size 589824 next 4506\n",
      "2024-09-19 17:20:59.923988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dc21d00 of size 131072 next 4507\n",
      "2024-09-19 17:20:59.923990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dc41d00 of size 589824 next 4508\n",
      "2024-09-19 17:20:59.923992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dcd1d00 of size 1032192 next 4509\n",
      "2024-09-19 17:20:59.923994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50ddcdd00 of size 147456 next 4510\n",
      "2024-09-19 17:20:59.923997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50ddf1d00 of size 65536 next 4511\n",
      "2024-09-19 17:20:59.923999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50de01d00 of size 1179648 next 4512\n",
      "2024-09-19 17:20:59.924001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50df21d00 of size 16384 next 4513\n",
      "2024-09-19 17:20:59.924004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50df25d00 of size 65536 next 4514\n",
      "2024-09-19 17:20:59.924006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50df35d00 of size 65536 next 4515\n",
      "2024-09-19 17:20:59.924008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50df45d00 of size 589824 next 4516\n",
      "2024-09-19 17:20:59.924010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dfd5d00 of size 65536 next 4517\n",
      "2024-09-19 17:20:59.924013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50dfe5d00 of size 147456 next 4518\n",
      "2024-09-19 17:20:59.924015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e009d00 of size 65536 next 4519\n",
      "2024-09-19 17:20:59.924017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e019d00 of size 1048576 next 4520\n",
      "2024-09-19 17:20:59.924019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e119d00 of size 65536 next 4521\n",
      "2024-09-19 17:20:59.924022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e129d00 of size 147456 next 4522\n",
      "2024-09-19 17:20:59.924024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e14dd00 of size 1048576 next 4523\n",
      "2024-09-19 17:20:59.924026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e24dd00 of size 2359296 next 4524\n",
      "2024-09-19 17:20:59.924029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa50e48dd00 of size 12002048 next 18446744073709551615\n",
      "2024-09-19 17:20:59.924032: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 536870912\n",
      "2024-09-19 17:20:59.924034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660000000 of size 1179648 next 496\n",
      "2024-09-19 17:20:59.924037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660120000 of size 1032192 next 271\n",
      "2024-09-19 17:20:59.924039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66021c000 of size 147456 next 205\n",
      "2024-09-19 17:20:59.924041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240000 of size 256 next 198\n",
      "2024-09-19 17:20:59.924044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240100 of size 512 next 197\n",
      "2024-09-19 17:20:59.924046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240300 of size 512 next 196\n",
      "2024-09-19 17:20:59.924048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240500 of size 512 next 195\n",
      "2024-09-19 17:20:59.924051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240700 of size 512 next 194\n",
      "2024-09-19 17:20:59.924053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240900 of size 512 next 193\n",
      "2024-09-19 17:20:59.924055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660240b00 of size 131072 next 192\n",
      "2024-09-19 17:20:59.924058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660260b00 of size 256 next 191\n",
      "2024-09-19 17:20:59.924060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660260c00 of size 512 next 190\n",
      "2024-09-19 17:20:59.924062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660260e00 of size 512 next 189\n",
      "2024-09-19 17:20:59.924064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660261000 of size 512 next 188\n",
      "2024-09-19 17:20:59.924067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660261200 of size 512 next 187\n",
      "2024-09-19 17:20:59.924069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660261400 of size 512 next 186\n",
      "2024-09-19 17:20:59.924071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660261600 of size 589824 next 185\n",
      "2024-09-19 17:20:59.924074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f1600 of size 256 next 184\n",
      "2024-09-19 17:20:59.924076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f1700 of size 2048 next 183\n",
      "2024-09-19 17:20:59.924078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f1f00 of size 2048 next 182\n",
      "2024-09-19 17:20:59.924080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f2700 of size 2048 next 181\n",
      "2024-09-19 17:20:59.924083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f2f00 of size 2048 next 180\n",
      "2024-09-19 17:20:59.924085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f3700 of size 2048 next 179\n",
      "2024-09-19 17:20:59.924087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6602f3f00 of size 262144 next 178\n",
      "2024-09-19 17:20:59.924090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660333f00 of size 256 next 177\n",
      "2024-09-19 17:20:59.924092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660334000 of size 2048 next 176\n",
      "2024-09-19 17:20:59.924094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660334800 of size 2048 next 175\n",
      "2024-09-19 17:20:59.924096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660335000 of size 2048 next 174\n",
      "2024-09-19 17:20:59.924099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660335800 of size 2048 next 173\n",
      "2024-09-19 17:20:59.924101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660336000 of size 2048 next 172\n",
      "2024-09-19 17:20:59.924104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660336800 of size 862976 next 543\n",
      "2024-09-19 17:20:59.924106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660409300 of size 2048 next 403\n",
      "2024-09-19 17:20:59.924108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660409b00 of size 2048 next 404\n",
      "2024-09-19 17:20:59.924110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040a300 of size 2048 next 397\n",
      "2024-09-19 17:20:59.924113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040ab00 of size 2048 next 398\n",
      "2024-09-19 17:20:59.924115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040b300 of size 2048 next 515\n",
      "2024-09-19 17:20:59.924118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040bb00 of size 2048 next 516\n",
      "2024-09-19 17:20:59.924120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040c300 of size 2048 next 354\n",
      "2024-09-19 17:20:59.924122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040cb00 of size 512 next 355\n",
      "2024-09-19 17:20:59.924124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040cd00 of size 512 next 483\n",
      "2024-09-19 17:20:59.924127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66040cf00 of size 262144 next 484\n",
      "2024-09-19 17:20:59.924129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66044cf00 of size 589824 next 525\n",
      "2024-09-19 17:20:59.924131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604dcf00 of size 2048 next 529\n",
      "2024-09-19 17:20:59.924133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604dd700 of size 2048 next 405\n",
      "2024-09-19 17:20:59.924136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604ddf00 of size 2048 next 315\n",
      "2024-09-19 17:20:59.924138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604de700 of size 512 next 409\n",
      "2024-09-19 17:20:59.924140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604de900 of size 2048 next 555\n",
      "2024-09-19 17:20:59.924143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604df100 of size 2048 next 573\n",
      "2024-09-19 17:20:59.924145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6604df900 of size 262144 next 442\n",
      "2024-09-19 17:20:59.924147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66051f900 of size 2048 next 443\n",
      "2024-09-19 17:20:59.924149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660520100 of size 524288 next 560\n",
      "2024-09-19 17:20:59.924152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6605a0100 of size 512 next 561\n",
      "2024-09-19 17:20:59.924154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6605a0300 of size 262144 next 570\n",
      "2024-09-19 17:20:59.924156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6605e0300 of size 262144 next 363\n",
      "2024-09-19 17:20:59.924159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660620300 of size 589824 next 533\n",
      "2024-09-19 17:20:59.924161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6606b0300 of size 1048576 next 348\n",
      "2024-09-19 17:20:59.924163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6607b0300 of size 2359296 next 482\n",
      "2024-09-19 17:20:59.924166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6609f0300 of size 4194304 next 490\n",
      "2024-09-19 17:20:59.924168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa660df0300 of size 2359296 next 427\n",
      "2024-09-19 17:20:59.924170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa661030300 of size 1048576 next 334\n",
      "2024-09-19 17:20:59.924172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa661130300 of size 1048576 next 371\n",
      "2024-09-19 17:20:59.924175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa661230300 of size 1048576 next 538\n",
      "2024-09-19 17:20:59.924177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa661330300 of size 524288 next 392\n",
      "2024-09-19 17:20:59.924179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6613b0300 of size 2097152 next 387\n",
      "2024-09-19 17:20:59.924182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6615b0300 of size 4194304 next 465\n",
      "2024-09-19 17:20:59.924184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6619b0300 of size 4194304 next 451\n",
      "2024-09-19 17:20:59.924186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa661db0300 of size 4194304 next 524\n",
      "2024-09-19 17:20:59.924189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6621b0300 of size 8388608 next 526\n",
      "2024-09-19 17:20:59.924191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6629b0300 of size 4194304 next 391\n",
      "2024-09-19 17:20:59.924193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa662db0300 of size 9437184 next 540\n",
      "2024-09-19 17:20:59.924196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6636b0300 of size 9437184 next 430\n",
      "2024-09-19 17:20:59.924198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa663fb0300 of size 2359296 next 418\n",
      "2024-09-19 17:20:59.924200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6641f0300 of size 2359296 next 419\n",
      "2024-09-19 17:20:59.924202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa664430300 of size 2359296 next 478\n",
      "2024-09-19 17:20:59.924205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa664670300 of size 9437184 next 343\n",
      "2024-09-19 17:20:59.924207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa664f70300 of size 4194304 next 2285\n",
      "2024-09-19 17:20:59.924209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa665370300 of size 4194304 next 2292\n",
      "2024-09-19 17:20:59.924212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa665770300 of size 9437184 next 2299\n",
      "2024-09-19 17:20:59.924214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666070300 of size 4194304 next 2306\n",
      "2024-09-19 17:20:59.924216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666470300 of size 2359296 next 2898\n",
      "2024-09-19 17:20:59.924218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b0300 of size 256 next 2905\n",
      "2024-09-19 17:20:59.924221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b0400 of size 1024 next 2906\n",
      "2024-09-19 17:20:59.924223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b0800 of size 1024 next 2907\n",
      "2024-09-19 17:20:59.924225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b0c00 of size 1024 next 2908\n",
      "2024-09-19 17:20:59.924228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b1000 of size 1024 next 2909\n",
      "2024-09-19 17:20:59.924230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b1400 of size 1024 next 2910\n",
      "2024-09-19 17:20:59.924232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6666b1800 of size 1048576 next 2911\n",
      "2024-09-19 17:20:59.924234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b1800 of size 256 next 2912\n",
      "2024-09-19 17:20:59.924237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b1900 of size 1024 next 2913\n",
      "2024-09-19 17:20:59.924239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b1d00 of size 1024 next 2914\n",
      "2024-09-19 17:20:59.924241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b2100 of size 1024 next 2915\n",
      "2024-09-19 17:20:59.924244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b2500 of size 1024 next 2916\n",
      "2024-09-19 17:20:59.924246: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b2900 of size 1024 next 2917\n",
      "2024-09-19 17:20:59.924248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6667b2d00 of size 2359296 next 2918\n",
      "2024-09-19 17:20:59.924250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f2d00 of size 256 next 2919\n",
      "2024-09-19 17:20:59.924253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f2e00 of size 4096 next 2920\n",
      "2024-09-19 17:20:59.924255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f3e00 of size 4096 next 2921\n",
      "2024-09-19 17:20:59.924257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f4e00 of size 4096 next 2922\n",
      "2024-09-19 17:20:59.924260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f5e00 of size 4096 next 2923\n",
      "2024-09-19 17:20:59.924262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f6e00 of size 4096 next 2924\n",
      "2024-09-19 17:20:59.924264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6669f7e00 of size 1048576 next 2925\n",
      "2024-09-19 17:20:59.924266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af7e00 of size 256 next 2926\n",
      "2024-09-19 17:20:59.924269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af7f00 of size 2048 next 2927\n",
      "2024-09-19 17:20:59.924271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af8700 of size 2048 next 2928\n",
      "2024-09-19 17:20:59.924274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af8f00 of size 2048 next 2929\n",
      "2024-09-19 17:20:59.924276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af9700 of size 2048 next 2930\n",
      "2024-09-19 17:20:59.924278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666af9f00 of size 2048 next 2931\n",
      "2024-09-19 17:20:59.924280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666afa700 of size 2097152 next 2932\n",
      "2024-09-19 17:20:59.924283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfa700 of size 256 next 2933\n",
      "2024-09-19 17:20:59.924285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfa800 of size 2048 next 2934\n",
      "2024-09-19 17:20:59.924287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfb000 of size 2048 next 2935\n",
      "2024-09-19 17:20:59.924289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfb800 of size 2048 next 2936\n",
      "2024-09-19 17:20:59.924292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfc000 of size 2048 next 2937\n",
      "2024-09-19 17:20:59.924294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfc800 of size 2048 next 2938\n",
      "2024-09-19 17:20:59.924296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa666cfd000 of size 9437184 next 2939\n",
      "2024-09-19 17:20:59.924299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6675fd000 of size 256 next 2940\n",
      "2024-09-19 17:20:59.924301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6675fd100 of size 8192 next 2941\n",
      "2024-09-19 17:20:59.924303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6675ff100 of size 8192 next 2942\n",
      "2024-09-19 17:20:59.924305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667601100 of size 8192 next 2943\n",
      "2024-09-19 17:20:59.924308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667603100 of size 8192 next 2944\n",
      "2024-09-19 17:20:59.924310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667605100 of size 8192 next 2945\n",
      "2024-09-19 17:20:59.924312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667607100 of size 4194304 next 2946\n",
      "2024-09-19 17:20:59.924314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a07100 of size 256 next 2947\n",
      "2024-09-19 17:20:59.924317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a07200 of size 8192 next 2948\n",
      "2024-09-19 17:20:59.924319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a09200 of size 8192 next 2949\n",
      "2024-09-19 17:20:59.924321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a0b200 of size 8192 next 2950\n",
      "2024-09-19 17:20:59.924324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a0d200 of size 8192 next 2951\n",
      "2024-09-19 17:20:59.924326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a0f200 of size 8192 next 2952\n",
      "2024-09-19 17:20:59.924328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa667a11200 of size 8388608 next 2953\n",
      "2024-09-19 17:20:59.924330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668211200 of size 256 next 2954\n",
      "2024-09-19 17:20:59.924333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668211300 of size 2048 next 2955\n",
      "2024-09-19 17:20:59.924335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668211b00 of size 2048 next 2956\n",
      "2024-09-19 17:20:59.924337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668212300 of size 2048 next 2957\n",
      "2024-09-19 17:20:59.924340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668212b00 of size 2048 next 2958\n",
      "2024-09-19 17:20:59.924342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668213300 of size 2048 next 2959\n",
      "2024-09-19 17:20:59.924344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668213b00 of size 4194304 next 2960\n",
      "2024-09-19 17:20:59.924346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668613b00 of size 256 next 2961\n",
      "2024-09-19 17:20:59.924349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668613c00 of size 2048 next 2962\n",
      "2024-09-19 17:20:59.924351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668614400 of size 2048 next 2963\n",
      "2024-09-19 17:20:59.924353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668614c00 of size 2048 next 2964\n",
      "2024-09-19 17:20:59.924356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668615400 of size 2048 next 2965\n",
      "2024-09-19 17:20:59.924358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668615c00 of size 2048 next 2966\n",
      "2024-09-19 17:20:59.924360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668616400 of size 10067712 next 2328\n",
      "2024-09-19 17:20:59.924363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668fb0300 of size 2048 next 2411\n",
      "2024-09-19 17:20:59.924365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa668fb0b00 of size 4192256 next 2329\n",
      "2024-09-19 17:20:59.924368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b0300 of size 256 next 2822\n",
      "2024-09-19 17:20:59.924370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b0400 of size 1024 next 2823\n",
      "2024-09-19 17:20:59.924372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b0800 of size 1024 next 2824\n",
      "2024-09-19 17:20:59.924375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b0c00 of size 1024 next 2825\n",
      "2024-09-19 17:20:59.924377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b1000 of size 1024 next 2826\n",
      "2024-09-19 17:20:59.924379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b1400 of size 1024 next 2827\n",
      "2024-09-19 17:20:59.924381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6693b1800 of size 1048576 next 2828\n",
      "2024-09-19 17:20:59.924384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b1800 of size 256 next 2829\n",
      "2024-09-19 17:20:59.924386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b1900 of size 1024 next 2830\n",
      "2024-09-19 17:20:59.924388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b1d00 of size 1024 next 2831\n",
      "2024-09-19 17:20:59.924391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b2100 of size 1024 next 2832\n",
      "2024-09-19 17:20:59.924393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b2500 of size 1024 next 2833\n",
      "2024-09-19 17:20:59.924395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b2900 of size 1024 next 2834\n",
      "2024-09-19 17:20:59.924397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6694b2d00 of size 2359296 next 2835\n",
      "2024-09-19 17:20:59.924400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f2d00 of size 256 next 2836\n",
      "2024-09-19 17:20:59.924402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f2e00 of size 4096 next 2837\n",
      "2024-09-19 17:20:59.924404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f3e00 of size 4096 next 2838\n",
      "2024-09-19 17:20:59.924406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f4e00 of size 4096 next 2839\n",
      "2024-09-19 17:20:59.924409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f5e00 of size 4096 next 2840\n",
      "2024-09-19 17:20:59.924411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f6e00 of size 4096 next 2841\n",
      "2024-09-19 17:20:59.924413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6696f7e00 of size 1048576 next 2842\n",
      "2024-09-19 17:20:59.924416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f7e00 of size 256 next 2843\n",
      "2024-09-19 17:20:59.924418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f7f00 of size 1024 next 2844\n",
      "2024-09-19 17:20:59.924420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f8300 of size 1024 next 2845\n",
      "2024-09-19 17:20:59.924422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f8700 of size 1024 next 2846\n",
      "2024-09-19 17:20:59.924425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f8b00 of size 1024 next 2847\n",
      "2024-09-19 17:20:59.924427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f8f00 of size 1024 next 2848\n",
      "2024-09-19 17:20:59.924429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6697f9300 of size 1048576 next 2849\n",
      "2024-09-19 17:20:59.924431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698f9300 of size 256 next 2850\n",
      "2024-09-19 17:20:59.924434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698f9400 of size 1024 next 2851\n",
      "2024-09-19 17:20:59.924436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698f9800 of size 1024 next 2852\n",
      "2024-09-19 17:20:59.924438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698f9c00 of size 1024 next 2853\n",
      "2024-09-19 17:20:59.924441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698fa000 of size 1024 next 2854\n",
      "2024-09-19 17:20:59.924443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698fa400 of size 1024 next 2855\n",
      "2024-09-19 17:20:59.924445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6698fa800 of size 2359296 next 2856\n",
      "2024-09-19 17:20:59.924447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3a800 of size 256 next 2857\n",
      "2024-09-19 17:20:59.924450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3a900 of size 4096 next 2858\n",
      "2024-09-19 17:20:59.924452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3b900 of size 4096 next 2859\n",
      "2024-09-19 17:20:59.924454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3c900 of size 4096 next 2860\n",
      "2024-09-19 17:20:59.924457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3d900 of size 4096 next 2861\n",
      "2024-09-19 17:20:59.924459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3e900 of size 4096 next 2862\n",
      "2024-09-19 17:20:59.924461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669b3f900 of size 1048576 next 2863\n",
      "2024-09-19 17:20:59.924463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c3f900 of size 256 next 2864\n",
      "2024-09-19 17:20:59.924466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c3fa00 of size 1024 next 2865\n",
      "2024-09-19 17:20:59.924468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c3fe00 of size 1024 next 2866\n",
      "2024-09-19 17:20:59.924470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c40200 of size 1024 next 2867\n",
      "2024-09-19 17:20:59.924473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c40600 of size 1024 next 2868\n",
      "2024-09-19 17:20:59.924475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c40a00 of size 1024 next 2869\n",
      "2024-09-19 17:20:59.924477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669c40e00 of size 1048576 next 2870\n",
      "2024-09-19 17:20:59.924479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d40e00 of size 256 next 2871\n",
      "2024-09-19 17:20:59.924482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d40f00 of size 1024 next 2872\n",
      "2024-09-19 17:20:59.924484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d41300 of size 1024 next 2873\n",
      "2024-09-19 17:20:59.924486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d41700 of size 1024 next 2874\n",
      "2024-09-19 17:20:59.924488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d41b00 of size 1024 next 2875\n",
      "2024-09-19 17:20:59.924491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d41f00 of size 1024 next 2876\n",
      "2024-09-19 17:20:59.924493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669d42300 of size 2359296 next 2877\n",
      "2024-09-19 17:20:59.924495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f82300 of size 256 next 2878\n",
      "2024-09-19 17:20:59.924498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f82400 of size 4096 next 2879\n",
      "2024-09-19 17:20:59.924500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f83400 of size 4096 next 2880\n",
      "2024-09-19 17:20:59.924502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f84400 of size 4096 next 2881\n",
      "2024-09-19 17:20:59.924505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f85400 of size 4096 next 2882\n",
      "2024-09-19 17:20:59.924507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f86400 of size 4096 next 2883\n",
      "2024-09-19 17:20:59.924509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa669f87400 of size 1048576 next 2884\n",
      "2024-09-19 17:20:59.924512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a087400 of size 256 next 2885\n",
      "2024-09-19 17:20:59.924514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a087500 of size 1024 next 2886\n",
      "2024-09-19 17:20:59.924516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a087900 of size 1024 next 2887\n",
      "2024-09-19 17:20:59.924518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a087d00 of size 1024 next 2888\n",
      "2024-09-19 17:20:59.924521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a088100 of size 1024 next 2889\n",
      "2024-09-19 17:20:59.924523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a088500 of size 1024 next 2890\n",
      "2024-09-19 17:20:59.924525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a088900 of size 1048576 next 2891\n",
      "2024-09-19 17:20:59.924527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a188900 of size 256 next 2892\n",
      "2024-09-19 17:20:59.924530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a188a00 of size 1024 next 2893\n",
      "2024-09-19 17:20:59.924532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a188e00 of size 1024 next 2894\n",
      "2024-09-19 17:20:59.924534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a189200 of size 1024 next 2895\n",
      "2024-09-19 17:20:59.924536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a189600 of size 1024 next 2896\n",
      "2024-09-19 17:20:59.924539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a189a00 of size 1024 next 2897\n",
      "2024-09-19 17:20:59.924541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a189e00 of size 256 next 2899\n",
      "2024-09-19 17:20:59.924543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a189f00 of size 4096 next 2900\n",
      "2024-09-19 17:20:59.924546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a18af00 of size 4096 next 2901\n",
      "2024-09-19 17:20:59.924548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a18bf00 of size 4096 next 2902\n",
      "2024-09-19 17:20:59.924550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a18cf00 of size 4096 next 2903\n",
      "2024-09-19 17:20:59.924553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a18df00 of size 4096 next 2904\n",
      "2024-09-19 17:20:59.924555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a18ef00 of size 1184768 next 2333\n",
      "2024-09-19 17:20:59.924557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a2b0300 of size 1048576 next 2334\n",
      "2024-09-19 17:20:59.924560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a3b0300 of size 1048576 next 2335\n",
      "2024-09-19 17:20:59.924562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a4b0300 of size 1048576 next 2574\n",
      "2024-09-19 17:20:59.924564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a5b0300 of size 1048576 next 2336\n",
      "2024-09-19 17:20:59.924566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a6b0300 of size 65536 next 2705\n",
      "2024-09-19 17:20:59.924569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a6c0300 of size 131072 next 2712\n",
      "2024-09-19 17:20:59.924571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a6e0300 of size 589824 next 2719\n",
      "2024-09-19 17:20:59.924573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a770300 of size 2048 next 2721\n",
      "2024-09-19 17:20:59.924576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a770b00 of size 2048 next 2722\n",
      "2024-09-19 17:20:59.924578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a771300 of size 2048 next 2723\n",
      "2024-09-19 17:20:59.924580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a771b00 of size 2048 next 2724\n",
      "2024-09-19 17:20:59.924583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a772300 of size 2048 next 2725\n",
      "2024-09-19 17:20:59.924585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a772b00 of size 262144 next 2726\n",
      "2024-09-19 17:20:59.924587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b2b00 of size 2048 next 2728\n",
      "2024-09-19 17:20:59.924589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b3300 of size 2048 next 2729\n",
      "2024-09-19 17:20:59.924592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b3b00 of size 2048 next 2730\n",
      "2024-09-19 17:20:59.924594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b4300 of size 2048 next 2731\n",
      "2024-09-19 17:20:59.924596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b4b00 of size 2048 next 2732\n",
      "2024-09-19 17:20:59.924599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a7b5300 of size 524288 next 2733\n",
      "2024-09-19 17:20:59.924601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a835300 of size 512 next 2735\n",
      "2024-09-19 17:20:59.924603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a835500 of size 512 next 2736\n",
      "2024-09-19 17:20:59.924605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a835700 of size 512 next 2737\n",
      "2024-09-19 17:20:59.924608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a835900 of size 512 next 2738\n",
      "2024-09-19 17:20:59.924610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a835b00 of size 262144 next 2739\n",
      "2024-09-19 17:20:59.924612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a875b00 of size 256 next 2740\n",
      "2024-09-19 17:20:59.924615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a875c00 of size 512 next 2741\n",
      "2024-09-19 17:20:59.924617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a875e00 of size 512 next 2742\n",
      "2024-09-19 17:20:59.924619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a876000 of size 512 next 2743\n",
      "2024-09-19 17:20:59.924621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a876200 of size 512 next 2744\n",
      "2024-09-19 17:20:59.924624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a876400 of size 512 next 2745\n",
      "2024-09-19 17:20:59.924626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a876600 of size 589824 next 2746\n",
      "2024-09-19 17:20:59.924628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a906600 of size 256 next 2747\n",
      "2024-09-19 17:20:59.924630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a906700 of size 2048 next 2748\n",
      "2024-09-19 17:20:59.924633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a906f00 of size 2048 next 2749\n",
      "2024-09-19 17:20:59.924635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a907700 of size 2048 next 2750\n",
      "2024-09-19 17:20:59.924637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a907f00 of size 2048 next 2751\n",
      "2024-09-19 17:20:59.924640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a908700 of size 2048 next 2752\n",
      "2024-09-19 17:20:59.924642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a908f00 of size 262144 next 2753\n",
      "2024-09-19 17:20:59.924644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a948f00 of size 256 next 2754\n",
      "2024-09-19 17:20:59.924646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949000 of size 512 next 2755\n",
      "2024-09-19 17:20:59.924649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949200 of size 512 next 2756\n",
      "2024-09-19 17:20:59.924651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949400 of size 512 next 2757\n",
      "2024-09-19 17:20:59.924653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949600 of size 512 next 2758\n",
      "2024-09-19 17:20:59.924656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949800 of size 512 next 2759\n",
      "2024-09-19 17:20:59.924658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a949a00 of size 262144 next 2760\n",
      "2024-09-19 17:20:59.924660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a989a00 of size 256 next 2761\n",
      "2024-09-19 17:20:59.924662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a989b00 of size 512 next 2762\n",
      "2024-09-19 17:20:59.924665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a989d00 of size 512 next 2763\n",
      "2024-09-19 17:20:59.924667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a989f00 of size 512 next 2764\n",
      "2024-09-19 17:20:59.924669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98a100 of size 512 next 2765\n",
      "2024-09-19 17:20:59.924672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98a300 of size 512 next 2766\n",
      "2024-09-19 17:20:59.924674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98a500 of size 256 next 2768\n",
      "2024-09-19 17:20:59.924676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98a600 of size 2048 next 2769\n",
      "2024-09-19 17:20:59.924678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98ae00 of size 2048 next 2770\n",
      "2024-09-19 17:20:59.924681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98b600 of size 2048 next 2771\n",
      "2024-09-19 17:20:59.924683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98be00 of size 2048 next 2772\n",
      "2024-09-19 17:20:59.924685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98c600 of size 2048 next 2773\n",
      "2024-09-19 17:20:59.924688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a98ce00 of size 406784 next 2338\n",
      "2024-09-19 17:20:59.924690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66a9f0300 of size 2097152 next 2340\n",
      "2024-09-19 17:20:59.924692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66abf0300 of size 589824 next 2767\n",
      "2024-09-19 17:20:59.924694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80300 of size 256 next 2774\n",
      "2024-09-19 17:20:59.924697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80400 of size 512 next 2775\n",
      "2024-09-19 17:20:59.924699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80600 of size 512 next 2776\n",
      "2024-09-19 17:20:59.924701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80800 of size 512 next 2777\n",
      "2024-09-19 17:20:59.924704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80a00 of size 512 next 2778\n",
      "2024-09-19 17:20:59.924706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80c00 of size 512 next 2779\n",
      "2024-09-19 17:20:59.924708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ac80e00 of size 262144 next 2780\n",
      "2024-09-19 17:20:59.924710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc0e00 of size 256 next 2781\n",
      "2024-09-19 17:20:59.924713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc0f00 of size 512 next 2782\n",
      "2024-09-19 17:20:59.924715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc1100 of size 512 next 2783\n",
      "2024-09-19 17:20:59.924717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc1300 of size 512 next 2784\n",
      "2024-09-19 17:20:59.924720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc1500 of size 512 next 2785\n",
      "2024-09-19 17:20:59.924722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc1700 of size 512 next 2786\n",
      "2024-09-19 17:20:59.924724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66acc1900 of size 589824 next 2787\n",
      "2024-09-19 17:20:59.924727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad51900 of size 256 next 2788\n",
      "2024-09-19 17:20:59.924729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad51a00 of size 2048 next 2789\n",
      "2024-09-19 17:20:59.924731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad52200 of size 2048 next 2790\n",
      "2024-09-19 17:20:59.924733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad52a00 of size 2048 next 2791\n",
      "2024-09-19 17:20:59.924736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad53200 of size 2048 next 2792\n",
      "2024-09-19 17:20:59.924738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad53a00 of size 2048 next 2793\n",
      "2024-09-19 17:20:59.924740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad54200 of size 262144 next 2794\n",
      "2024-09-19 17:20:59.924742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad94200 of size 256 next 2795\n",
      "2024-09-19 17:20:59.924745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad94300 of size 1024 next 2796\n",
      "2024-09-19 17:20:59.924749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad94700 of size 1024 next 2797\n",
      "2024-09-19 17:20:59.924751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad94b00 of size 1024 next 2798\n",
      "2024-09-19 17:20:59.924754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad94f00 of size 1024 next 2799\n",
      "2024-09-19 17:20:59.924756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad95300 of size 1024 next 2800\n",
      "2024-09-19 17:20:59.924758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ad95700 of size 524288 next 2801\n",
      "2024-09-19 17:20:59.924761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae15700 of size 256 next 2802\n",
      "2024-09-19 17:20:59.924763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae15800 of size 1024 next 2803\n",
      "2024-09-19 17:20:59.924765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae15c00 of size 1024 next 2804\n",
      "2024-09-19 17:20:59.924768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae16000 of size 1024 next 2805\n",
      "2024-09-19 17:20:59.924770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae16400 of size 1024 next 2806\n",
      "2024-09-19 17:20:59.924772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae16800 of size 1024 next 2807\n",
      "2024-09-19 17:20:59.924775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ae16c00 of size 2359296 next 2808\n",
      "2024-09-19 17:20:59.924777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b056c00 of size 256 next 2809\n",
      "2024-09-19 17:20:59.924779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b056d00 of size 4096 next 2810\n",
      "2024-09-19 17:20:59.924781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b057d00 of size 4096 next 2811\n",
      "2024-09-19 17:20:59.924784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b058d00 of size 4096 next 2812\n",
      "2024-09-19 17:20:59.924786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b059d00 of size 4096 next 2813\n",
      "2024-09-19 17:20:59.924788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b05ad00 of size 4096 next 2814\n",
      "2024-09-19 17:20:59.924791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b05bd00 of size 1048576 next 2815\n",
      "2024-09-19 17:20:59.924793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15bd00 of size 256 next 2816\n",
      "2024-09-19 17:20:59.924795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15be00 of size 4096 next 2817\n",
      "2024-09-19 17:20:59.924797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15ce00 of size 4096 next 2818\n",
      "2024-09-19 17:20:59.924800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15de00 of size 4096 next 2819\n",
      "2024-09-19 17:20:59.924802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15ee00 of size 4096 next 2820\n",
      "2024-09-19 17:20:59.924804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b15fe00 of size 4096 next 2821\n",
      "2024-09-19 17:20:59.924807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b160e00 of size 3470592 next 2345\n",
      "2024-09-19 17:20:59.924809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b0300 of size 2048 next 2413\n",
      "2024-09-19 17:20:59.924811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b0b00 of size 512 next 2414\n",
      "2024-09-19 17:20:59.924814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b0d00 of size 2048 next 2415\n",
      "2024-09-19 17:20:59.924816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b1500 of size 1024 next 2416\n",
      "2024-09-19 17:20:59.924818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b1900 of size 2048 next 2417\n",
      "2024-09-19 17:20:59.924820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b2100 of size 512 next 2418\n",
      "2024-09-19 17:20:59.924823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b2300 of size 2048 next 2419\n",
      "2024-09-19 17:20:59.924825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b2b00 of size 512 next 2420\n",
      "2024-09-19 17:20:59.924827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b2d00 of size 2048 next 2421\n",
      "2024-09-19 17:20:59.924830: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b3500 of size 1024 next 2422\n",
      "2024-09-19 17:20:59.924832: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b3900 of size 2048 next 2423\n",
      "2024-09-19 17:20:59.924834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b4100 of size 1024 next 2424\n",
      "2024-09-19 17:20:59.924836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b4500 of size 4096 next 2425\n",
      "2024-09-19 17:20:59.924839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b5500 of size 512 next 2426\n",
      "2024-09-19 17:20:59.924841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b5700 of size 512 next 2427\n",
      "2024-09-19 17:20:59.924843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b5900 of size 2048 next 2350\n",
      "2024-09-19 17:20:59.924846: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b6100 of size 512 next 2428\n",
      "2024-09-19 17:20:59.924848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b6300 of size 2048 next 2429\n",
      "2024-09-19 17:20:59.924850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b6b00 of size 4096 next 2431\n",
      "2024-09-19 17:20:59.924853: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b7b00 of size 6912 next 2346\n",
      "2024-09-19 17:20:59.924859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b4b9600 of size 786432 next 2348\n",
      "2024-09-19 17:20:59.924862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b579600 of size 3211264 next 2351\n",
      "2024-09-19 17:20:59.924864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b889600 of size 262144 next 2412\n",
      "2024-09-19 17:20:59.924866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b8c9600 of size 262144 next 2352\n",
      "2024-09-19 17:20:59.924869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b909600 of size 256 next 2494\n",
      "2024-09-19 17:20:59.924871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b909700 of size 65536 next 2495\n",
      "2024-09-19 17:20:59.924873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919700 of size 256 next 2496\n",
      "2024-09-19 17:20:59.924876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919800 of size 256 next 2497\n",
      "2024-09-19 17:20:59.924878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919900 of size 256 next 2498\n",
      "2024-09-19 17:20:59.924880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919a00 of size 256 next 2499\n",
      "2024-09-19 17:20:59.924882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919b00 of size 256 next 2500\n",
      "2024-09-19 17:20:59.924885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b919c00 of size 1024 next 2501\n",
      "2024-09-19 17:20:59.924887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b91a000 of size 256 next 2502\n",
      "2024-09-19 17:20:59.924889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b91a100 of size 193792 next 2353\n",
      "2024-09-19 17:20:59.924892: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b949600 of size 262144 next 2354\n",
      "2024-09-19 17:20:59.924894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b989600 of size 1024 next 2432\n",
      "2024-09-19 17:20:59.924896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b989a00 of size 4096 next 2433\n",
      "2024-09-19 17:20:59.924898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98aa00 of size 1024 next 2434\n",
      "2024-09-19 17:20:59.924901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98ae00 of size 512 next 2435\n",
      "2024-09-19 17:20:59.924903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98b000 of size 512 next 2437\n",
      "2024-09-19 17:20:59.924906: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98b200 of size 2048 next 2438\n",
      "2024-09-19 17:20:59.924908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98ba00 of size 1024 next 2439\n",
      "2024-09-19 17:20:59.924910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98be00 of size 4096 next 2440\n",
      "2024-09-19 17:20:59.924913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98ce00 of size 1024 next 2442\n",
      "2024-09-19 17:20:59.924915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98d200 of size 1024 next 2444\n",
      "2024-09-19 17:20:59.924917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98d600 of size 256 next 2445\n",
      "2024-09-19 17:20:59.924920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98d700 of size 1024 next 2447\n",
      "2024-09-19 17:20:59.924922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98db00 of size 512 next 2448\n",
      "2024-09-19 17:20:59.924924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98dd00 of size 512 next 2449\n",
      "2024-09-19 17:20:59.924927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98df00 of size 1024 next 2450\n",
      "2024-09-19 17:20:59.924929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98e300 of size 1024 next 2451\n",
      "2024-09-19 17:20:59.924931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98e700 of size 4096 next 2452\n",
      "2024-09-19 17:20:59.924933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98f700 of size 1024 next 2453\n",
      "2024-09-19 17:20:59.924936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98fb00 of size 1024 next 2454\n",
      "2024-09-19 17:20:59.924938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b98ff00 of size 1024 next 2455\n",
      "2024-09-19 17:20:59.924940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b990300 of size 1024 next 2456\n",
      "2024-09-19 17:20:59.924942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b990700 of size 8192 next 2457\n",
      "2024-09-19 17:20:59.924945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b992700 of size 1024 next 2458\n",
      "2024-09-19 17:20:59.924947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b992b00 of size 1024 next 2459\n",
      "2024-09-19 17:20:59.924949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b992f00 of size 1024 next 2460\n",
      "2024-09-19 17:20:59.924951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b993300 of size 512 next 2461\n",
      "2024-09-19 17:20:59.924954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b993500 of size 1024 next 2462\n",
      "2024-09-19 17:20:59.924956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b993900 of size 1024 next 2463\n",
      "2024-09-19 17:20:59.924959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b993d00 of size 4096 next 2464\n",
      "2024-09-19 17:20:59.924961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b994d00 of size 1024 next 2465\n",
      "2024-09-19 17:20:59.924963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b995100 of size 1024 next 2466\n",
      "2024-09-19 17:20:59.924965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b995500 of size 1024 next 2467\n",
      "2024-09-19 17:20:59.924968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b995900 of size 1024 next 2469\n",
      "2024-09-19 17:20:59.924970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b995d00 of size 1024 next 2349\n",
      "2024-09-19 17:20:59.924972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b996100 of size 1024 next 2470\n",
      "2024-09-19 17:20:59.924975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b996500 of size 1024 next 2471\n",
      "2024-09-19 17:20:59.924977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b996900 of size 1024 next 2472\n",
      "2024-09-19 17:20:59.924979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b996d00 of size 1024 next 2474\n",
      "2024-09-19 17:20:59.924981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997100 of size 1024 next 2475\n",
      "2024-09-19 17:20:59.924984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997500 of size 1024 next 2477\n",
      "2024-09-19 17:20:59.924986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997900 of size 256 next 2479\n",
      "2024-09-19 17:20:59.924988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997a00 of size 256 next 2480\n",
      "2024-09-19 17:20:59.924990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997b00 of size 256 next 2481\n",
      "2024-09-19 17:20:59.924993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997c00 of size 256 next 2482\n",
      "2024-09-19 17:20:59.924995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b997d00 of size 16384 next 2483\n",
      "2024-09-19 17:20:59.924997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b99bd00 of size 1024 next 2484\n",
      "2024-09-19 17:20:59.925000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b99c100 of size 1024 next 2485\n",
      "2024-09-19 17:20:59.925002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b99c500 of size 256 next 2486\n",
      "2024-09-19 17:20:59.925004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b99c600 of size 1024 next 2487\n",
      "2024-09-19 17:20:59.925006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b99ca00 of size 65536 next 2488\n",
      "2024-09-19 17:20:59.925009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9aca00 of size 256 next 2489\n",
      "2024-09-19 17:20:59.925011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9acb00 of size 256 next 2347\n",
      "2024-09-19 17:20:59.925013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9acc00 of size 1024 next 2490\n",
      "2024-09-19 17:20:59.925016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9ad000 of size 8192 next 2491\n",
      "2024-09-19 17:20:59.925018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9af000 of size 256 next 2492\n",
      "2024-09-19 17:20:59.925020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9af100 of size 256 next 2493\n",
      "2024-09-19 17:20:59.925023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9af200 of size 107520 next 2355\n",
      "2024-09-19 17:20:59.925025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9c9600 of size 1024 next 2518\n",
      "2024-09-19 17:20:59.925027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9c9a00 of size 512 next 2520\n",
      "2024-09-19 17:20:59.925029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9c9c00 of size 4096 next 2521\n",
      "2024-09-19 17:20:59.925032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cac00 of size 1024 next 2522\n",
      "2024-09-19 17:20:59.925034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cb000 of size 4096 next 2523\n",
      "2024-09-19 17:20:59.925036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cc000 of size 256 next 2524\n",
      "2024-09-19 17:20:59.925039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cc100 of size 1024 next 2525\n",
      "2024-09-19 17:20:59.925042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cc500 of size 1024 next 2526\n",
      "2024-09-19 17:20:59.925044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9cc900 of size 65536 next 2527\n",
      "2024-09-19 17:20:59.925046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9dc900 of size 1024 next 2528\n",
      "2024-09-19 17:20:59.925049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9dcd00 of size 512 next 2529\n",
      "2024-09-19 17:20:59.925051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9dcf00 of size 2048 next 2530\n",
      "2024-09-19 17:20:59.925054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9dd700 of size 8192 next 2532\n",
      "2024-09-19 17:20:59.925056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9df700 of size 2048 next 2533\n",
      "2024-09-19 17:20:59.925058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9dff00 of size 8192 next 2534\n",
      "2024-09-19 17:20:59.925061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e1f00 of size 2048 next 2535\n",
      "2024-09-19 17:20:59.925063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e2700 of size 2048 next 2536\n",
      "2024-09-19 17:20:59.925065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e2f00 of size 1024 next 2537\n",
      "2024-09-19 17:20:59.925067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e3300 of size 256 next 2538\n",
      "2024-09-19 17:20:59.925070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e3400 of size 1024 next 2539\n",
      "2024-09-19 17:20:59.925072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66b9e3800 of size 155136 next 2356\n",
      "2024-09-19 17:20:59.925074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ba09600 of size 589824 next 2357\n",
      "2024-09-19 17:20:59.925077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ba99600 of size 1032192 next 2358\n",
      "2024-09-19 17:20:59.925079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bb95600 of size 262144 next 2359\n",
      "2024-09-19 17:20:59.925081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bbd5600 of size 147456 next 2652\n",
      "2024-09-19 17:20:59.925084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bbf9600 of size 65536 next 2665\n",
      "2024-09-19 17:20:59.925086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc09600 of size 65536 next 2672\n",
      "2024-09-19 17:20:59.925088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc19600 of size 81920 next 2362\n",
      "2024-09-19 17:20:59.925091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc2d600 of size 262144 next 2436\n",
      "2024-09-19 17:20:59.925093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc6d600 of size 256 next 2503\n",
      "2024-09-19 17:20:59.925095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc6d700 of size 256 next 2504\n",
      "2024-09-19 17:20:59.925098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc6d800 of size 2048 next 2505\n",
      "2024-09-19 17:20:59.925100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc6e000 of size 512 next 2506\n",
      "2024-09-19 17:20:59.925102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc6e200 of size 147456 next 2507\n",
      "2024-09-19 17:20:59.925105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc92200 of size 1024 next 2508\n",
      "2024-09-19 17:20:59.925107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc92600 of size 256 next 2509\n",
      "2024-09-19 17:20:59.925109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc92700 of size 1024 next 2510\n",
      "2024-09-19 17:20:59.925111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc92b00 of size 256 next 2511\n",
      "2024-09-19 17:20:59.925114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bc92c00 of size 174592 next 2363\n",
      "2024-09-19 17:20:59.925116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbd600 of size 256 next 2324\n",
      "2024-09-19 17:20:59.925118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbd700 of size 256 next 2325\n",
      "2024-09-19 17:20:59.925121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbd800 of size 256 next 2343\n",
      "2024-09-19 17:20:59.925123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbd900 of size 256 next 2344\n",
      "2024-09-19 17:20:59.925125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbda00 of size 256 next 2320\n",
      "2024-09-19 17:20:59.925128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbdb00 of size 256 next 2321\n",
      "2024-09-19 17:20:59.925130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbdc00 of size 256 next 2319\n",
      "2024-09-19 17:20:59.925132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbdd00 of size 256 next 2332\n",
      "2024-09-19 17:20:59.925135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbde00 of size 256 next 2330\n",
      "2024-09-19 17:20:59.925137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbdf00 of size 256 next 2331\n",
      "2024-09-19 17:20:59.925139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe000 of size 256 next 2326\n",
      "2024-09-19 17:20:59.925141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe100 of size 256 next 2327\n",
      "2024-09-19 17:20:59.925144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe200 of size 256 next 2337\n",
      "2024-09-19 17:20:59.925146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe300 of size 256 next 2322\n",
      "2024-09-19 17:20:59.925148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe400 of size 256 next 2342\n",
      "2024-09-19 17:20:59.925150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe500 of size 256 next 2366\n",
      "2024-09-19 17:20:59.925153: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe600 of size 256 next 2367\n",
      "2024-09-19 17:20:59.925155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe700 of size 256 next 2318\n",
      "2024-09-19 17:20:59.925157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe800 of size 256 next 2323\n",
      "2024-09-19 17:20:59.925160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbe900 of size 256 next 2369\n",
      "2024-09-19 17:20:59.925162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbea00 of size 256 next 2360\n",
      "2024-09-19 17:20:59.925164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbeb00 of size 256 next 2361\n",
      "2024-09-19 17:20:59.925167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbec00 of size 256 next 2368\n",
      "2024-09-19 17:20:59.925169: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbed00 of size 256 next 2341\n",
      "2024-09-19 17:20:59.925171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbee00 of size 256 next 2618\n",
      "2024-09-19 17:20:59.925173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbef00 of size 256 next 2619\n",
      "2024-09-19 17:20:59.925176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf000 of size 256 next 2620\n",
      "2024-09-19 17:20:59.925178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf100 of size 256 next 2621\n",
      "2024-09-19 17:20:59.925180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf200 of size 256 next 2622\n",
      "2024-09-19 17:20:59.925183: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf300 of size 256 next 2623\n",
      "2024-09-19 17:20:59.925185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf400 of size 256 next 2624\n",
      "2024-09-19 17:20:59.925187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf500 of size 256 next 2625\n",
      "2024-09-19 17:20:59.925189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf600 of size 256 next 2626\n",
      "2024-09-19 17:20:59.925192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf700 of size 256 next 2627\n",
      "2024-09-19 17:20:59.925194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf800 of size 256 next 2628\n",
      "2024-09-19 17:20:59.925196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbf900 of size 256 next 2629\n",
      "2024-09-19 17:20:59.925199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbfa00 of size 256 next 2632\n",
      "2024-09-19 17:20:59.925201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbfb00 of size 256 next 2633\n",
      "2024-09-19 17:20:59.925203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbfc00 of size 256 next 2630\n",
      "2024-09-19 17:20:59.925205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbfd00 of size 256 next 2631\n",
      "2024-09-19 17:20:59.925208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbfe00 of size 256 next 2634\n",
      "2024-09-19 17:20:59.925210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcbff00 of size 256 next 2635\n",
      "2024-09-19 17:20:59.925212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0000 of size 256 next 2636\n",
      "2024-09-19 17:20:59.925214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0100 of size 256 next 2637\n",
      "2024-09-19 17:20:59.925217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0200 of size 256 next 2638\n",
      "2024-09-19 17:20:59.925219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0300 of size 256 next 2639\n",
      "2024-09-19 17:20:59.925221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0400 of size 256 next 2640\n",
      "2024-09-19 17:20:59.925223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0500 of size 256 next 2641\n",
      "2024-09-19 17:20:59.925226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0600 of size 256 next 2642\n",
      "2024-09-19 17:20:59.925228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0700 of size 256 next 2643\n",
      "2024-09-19 17:20:59.925231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0800 of size 256 next 2644\n",
      "2024-09-19 17:20:59.925233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc0900 of size 16384 next 2645\n",
      "2024-09-19 17:20:59.925235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4900 of size 256 next 2646\n",
      "2024-09-19 17:20:59.925237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4a00 of size 256 next 2647\n",
      "2024-09-19 17:20:59.925240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4b00 of size 256 next 2648\n",
      "2024-09-19 17:20:59.925243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4c00 of size 256 next 2649\n",
      "2024-09-19 17:20:59.925245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4d00 of size 256 next 2650\n",
      "2024-09-19 17:20:59.925248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4e00 of size 256 next 2651\n",
      "2024-09-19 17:20:59.925250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc4f00 of size 256 next 2653\n",
      "2024-09-19 17:20:59.925252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc5000 of size 1024 next 2654\n",
      "2024-09-19 17:20:59.925255: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc5400 of size 1024 next 2655\n",
      "2024-09-19 17:20:59.925257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc5800 of size 1024 next 2656\n",
      "2024-09-19 17:20:59.925259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc5c00 of size 1024 next 2657\n",
      "2024-09-19 17:20:59.925262: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc6000 of size 1024 next 2658\n",
      "2024-09-19 17:20:59.925264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc6400 of size 256 next 2659\n",
      "2024-09-19 17:20:59.925266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc6500 of size 1024 next 2660\n",
      "2024-09-19 17:20:59.925268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc6900 of size 1024 next 2661\n",
      "2024-09-19 17:20:59.925271: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc6d00 of size 1024 next 2662\n",
      "2024-09-19 17:20:59.925273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7100 of size 1024 next 2663\n",
      "2024-09-19 17:20:59.925275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7500 of size 1024 next 2664\n",
      "2024-09-19 17:20:59.925277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7900 of size 256 next 2666\n",
      "2024-09-19 17:20:59.925280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7a00 of size 256 next 2667\n",
      "2024-09-19 17:20:59.925282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7b00 of size 256 next 2668\n",
      "2024-09-19 17:20:59.925284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7c00 of size 256 next 2669\n",
      "2024-09-19 17:20:59.925287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7d00 of size 256 next 2670\n",
      "2024-09-19 17:20:59.925289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7e00 of size 256 next 2671\n",
      "2024-09-19 17:20:59.925291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc7f00 of size 256 next 2673\n",
      "2024-09-19 17:20:59.925293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8000 of size 256 next 2674\n",
      "2024-09-19 17:20:59.925296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8100 of size 256 next 2675\n",
      "2024-09-19 17:20:59.925298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8200 of size 256 next 2676\n",
      "2024-09-19 17:20:59.925300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8300 of size 256 next 2677\n",
      "2024-09-19 17:20:59.925302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8400 of size 256 next 2678\n",
      "2024-09-19 17:20:59.925305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8500 of size 256 next 2680\n",
      "2024-09-19 17:20:59.925307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8600 of size 1024 next 2681\n",
      "2024-09-19 17:20:59.925309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8a00 of size 1024 next 2682\n",
      "2024-09-19 17:20:59.925312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc8e00 of size 1024 next 2683\n",
      "2024-09-19 17:20:59.925314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9200 of size 1024 next 2684\n",
      "2024-09-19 17:20:59.925316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9600 of size 1024 next 2685\n",
      "2024-09-19 17:20:59.925318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9a00 of size 256 next 2686\n",
      "2024-09-19 17:20:59.925321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9b00 of size 256 next 2687\n",
      "2024-09-19 17:20:59.925323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9c00 of size 256 next 2688\n",
      "2024-09-19 17:20:59.925325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9d00 of size 256 next 2689\n",
      "2024-09-19 17:20:59.925327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9e00 of size 256 next 2690\n",
      "2024-09-19 17:20:59.925330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcc9f00 of size 256 next 2691\n",
      "2024-09-19 17:20:59.925332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca000 of size 256 next 2693\n",
      "2024-09-19 17:20:59.925335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca100 of size 256 next 2694\n",
      "2024-09-19 17:20:59.925337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca200 of size 256 next 2695\n",
      "2024-09-19 17:20:59.925339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca300 of size 256 next 2696\n",
      "2024-09-19 17:20:59.925341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca400 of size 256 next 2697\n",
      "2024-09-19 17:20:59.925344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca500 of size 256 next 2698\n",
      "2024-09-19 17:20:59.925346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca600 of size 256 next 2699\n",
      "2024-09-19 17:20:59.925348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcca700 of size 1024 next 2700\n",
      "2024-09-19 17:20:59.925350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccab00 of size 1024 next 2701\n",
      "2024-09-19 17:20:59.925353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccaf00 of size 1024 next 2702\n",
      "2024-09-19 17:20:59.925355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccb300 of size 1024 next 2703\n",
      "2024-09-19 17:20:59.925357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccb700 of size 1024 next 2704\n",
      "2024-09-19 17:20:59.925359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccbb00 of size 256 next 2706\n",
      "2024-09-19 17:20:59.925362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccbc00 of size 512 next 2707\n",
      "2024-09-19 17:20:59.925364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccbe00 of size 512 next 2708\n",
      "2024-09-19 17:20:59.925366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc000 of size 512 next 2709\n",
      "2024-09-19 17:20:59.925369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc200 of size 512 next 2710\n",
      "2024-09-19 17:20:59.925371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc400 of size 512 next 2711\n",
      "2024-09-19 17:20:59.925373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc600 of size 256 next 2713\n",
      "2024-09-19 17:20:59.925375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc700 of size 512 next 2714\n",
      "2024-09-19 17:20:59.925378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccc900 of size 512 next 2715\n",
      "2024-09-19 17:20:59.925380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcccb00 of size 512 next 2716\n",
      "2024-09-19 17:20:59.925382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcccd00 of size 512 next 2717\n",
      "2024-09-19 17:20:59.925385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bcccf00 of size 512 next 2718\n",
      "2024-09-19 17:20:59.925387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccd100 of size 256 next 2720\n",
      "2024-09-19 17:20:59.925389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccd200 of size 256 next 2727\n",
      "2024-09-19 17:20:59.925391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccd300 of size 256 next 2734\n",
      "2024-09-19 17:20:59.925394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccd400 of size 512 next 2364\n",
      "2024-09-19 17:20:59.925396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bccd600 of size 589824 next 2365\n",
      "2024-09-19 17:20:59.925398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bd5d600 of size 147456 next 2679\n",
      "2024-09-19 17:20:59.925401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bd81600 of size 65536 next 2692\n",
      "2024-09-19 17:20:59.925403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bd91600 of size 147456 next 2370\n",
      "2024-09-19 17:20:59.925405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdb5600 of size 8192 next 2371\n",
      "2024-09-19 17:20:59.925407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdb7600 of size 8192 next 2372\n",
      "2024-09-19 17:20:59.925410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdb9600 of size 2048 next 2373\n",
      "2024-09-19 17:20:59.925412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdb9e00 of size 37632 next 2374\n",
      "2024-09-19 17:20:59.925414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdc3100 of size 8192 next 2375\n",
      "2024-09-19 17:20:59.925417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdc5100 of size 2048 next 2376\n",
      "2024-09-19 17:20:59.925419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66bdc5900 of size 589824 next 2377\n",
      "2024-09-19 17:20:59.925421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66be55900 of size 2048 next 2378\n",
      "2024-09-19 17:20:59.925423: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66be56100 of size 512 next 2379\n",
      "2024-09-19 17:20:59.925426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66be56300 of size 8192 next 2380\n",
      "2024-09-19 17:20:59.925428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66be58300 of size 4194304 next 2381\n",
      "2024-09-19 17:20:59.925430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c258300 of size 2048 next 2382\n",
      "2024-09-19 17:20:59.925432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c258b00 of size 524288 next 2383\n",
      "2024-09-19 17:20:59.925435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2d8b00 of size 512 next 2384\n",
      "2024-09-19 17:20:59.925437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2d8d00 of size 2048 next 2385\n",
      "2024-09-19 17:20:59.925439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2d9500 of size 8192 next 2386\n",
      "2024-09-19 17:20:59.925442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2db500 of size 512 next 2387\n",
      "2024-09-19 17:20:59.925444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2db700 of size 512 next 2388\n",
      "2024-09-19 17:20:59.925446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2db900 of size 512 next 2389\n",
      "2024-09-19 17:20:59.925449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c2dbb00 of size 262144 next 2390\n",
      "2024-09-19 17:20:59.925451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c31bb00 of size 512 next 2391\n",
      "2024-09-19 17:20:59.925453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c31bd00 of size 589824 next 2392\n",
      "2024-09-19 17:20:59.925455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3abd00 of size 512 next 2393\n",
      "2024-09-19 17:20:59.925458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3abf00 of size 2048 next 2394\n",
      "2024-09-19 17:20:59.925460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3ac700 of size 512 next 2395\n",
      "2024-09-19 17:20:59.925462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3ac900 of size 512 next 2396\n",
      "2024-09-19 17:20:59.925465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3acb00 of size 2048 next 2397\n",
      "2024-09-19 17:20:59.925467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3ad300 of size 512 next 2398\n",
      "2024-09-19 17:20:59.925469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c3ad500 of size 589824 next 2399\n",
      "2024-09-19 17:20:59.925471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43d500 of size 512 next 2400\n",
      "2024-09-19 17:20:59.925474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43d700 of size 2048 next 2401\n",
      "2024-09-19 17:20:59.925476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43df00 of size 512 next 2402\n",
      "2024-09-19 17:20:59.925478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43e100 of size 2048 next 2403\n",
      "2024-09-19 17:20:59.925480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43e900 of size 512 next 2404\n",
      "2024-09-19 17:20:59.925483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43eb00 of size 2048 next 2405\n",
      "2024-09-19 17:20:59.925485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43f300 of size 512 next 2406\n",
      "2024-09-19 17:20:59.925487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c43f500 of size 589824 next 2407\n",
      "2024-09-19 17:20:59.925490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c4cf500 of size 2048 next 2408\n",
      "2024-09-19 17:20:59.925492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c4cfd00 of size 2048 next 2409\n",
      "2024-09-19 17:20:59.925494: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c4d0500 of size 262144 next 2410\n",
      "2024-09-19 17:20:59.925496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c510500 of size 1048576 next 2430\n",
      "2024-09-19 17:20:59.925499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c610500 of size 2097152 next 2441\n",
      "2024-09-19 17:20:59.925501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c810500 of size 1048576 next 2443\n",
      "2024-09-19 17:20:59.925503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66c910500 of size 1048576 next 2446\n",
      "2024-09-19 17:20:59.925506: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ca10500 of size 2359296 next 2468\n",
      "2024-09-19 17:20:59.925508: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66cc50500 of size 4194304 next 2473\n",
      "2024-09-19 17:20:59.925510: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66d050500 of size 1048576 next 2476\n",
      "2024-09-19 17:20:59.925513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66d150500 of size 2359296 next 2478\n",
      "2024-09-19 17:20:59.925515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66d390500 of size 2359296 next 2339\n",
      "2024-09-19 17:20:59.925517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66d5d0500 of size 4194304 next 2519\n",
      "2024-09-19 17:20:59.925520: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66d9d0500 of size 9437184 next 2531\n",
      "2024-09-19 17:20:59.925522: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66e2d0500 of size 2359296 next 2543\n",
      "2024-09-19 17:20:59.925524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66e510500 of size 4194304 next 2552\n",
      "2024-09-19 17:20:59.925527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66e910500 of size 4194304 next 2572\n",
      "2024-09-19 17:20:59.925529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66ed10500 of size 8388608 next 2585\n",
      "2024-09-19 17:20:59.925532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66f510500 of size 1048576 next 2595\n",
      "2024-09-19 17:20:59.925534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66f610500 of size 1048576 next 2597\n",
      "2024-09-19 17:20:59.925536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa66f710500 of size 9437184 next 2604\n",
      "2024-09-19 17:20:59.925538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670010500 of size 1048576 next 2605\n",
      "2024-09-19 17:20:59.925541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670110500 of size 1048576 next 2611\n",
      "2024-09-19 17:20:59.925543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670210500 of size 9437184 next 2616\n",
      "2024-09-19 17:20:59.925545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b10500 of size 256 next 2967\n",
      "2024-09-19 17:20:59.925548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b10600 of size 8192 next 2968\n",
      "2024-09-19 17:20:59.925550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b12600 of size 8192 next 2969\n",
      "2024-09-19 17:20:59.925552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b14600 of size 8192 next 2970\n",
      "2024-09-19 17:20:59.925555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b16600 of size 8192 next 2971\n",
      "2024-09-19 17:20:59.925557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b18600 of size 8192 next 2972\n",
      "2024-09-19 17:20:59.925559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670b1a600 of size 4194304 next 2973\n",
      "2024-09-19 17:20:59.925561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1a600 of size 256 next 2974\n",
      "2024-09-19 17:20:59.925564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1a700 of size 2048 next 2975\n",
      "2024-09-19 17:20:59.925566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1af00 of size 2048 next 2976\n",
      "2024-09-19 17:20:59.925568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1b700 of size 2048 next 2977\n",
      "2024-09-19 17:20:59.925571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1bf00 of size 2048 next 2978\n",
      "2024-09-19 17:20:59.925573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1c700 of size 2048 next 2979\n",
      "2024-09-19 17:20:59.925575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa670f1cf00 of size 4194304 next 2980\n",
      "2024-09-19 17:20:59.925577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131cf00 of size 256 next 2981\n",
      "2024-09-19 17:20:59.925580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131d000 of size 2048 next 2982\n",
      "2024-09-19 17:20:59.925582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131d800 of size 2048 next 2983\n",
      "2024-09-19 17:20:59.925585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131e000 of size 2048 next 2984\n",
      "2024-09-19 17:20:59.925587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131e800 of size 2048 next 2985\n",
      "2024-09-19 17:20:59.925591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131f000 of size 2048 next 2986\n",
      "2024-09-19 17:20:59.925594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67131f800 of size 9437184 next 2987\n",
      "2024-09-19 17:20:59.925596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c1f800 of size 256 next 2988\n",
      "2024-09-19 17:20:59.925598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c1f900 of size 8192 next 2989\n",
      "2024-09-19 17:20:59.925600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c21900 of size 8192 next 2990\n",
      "2024-09-19 17:20:59.925603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c23900 of size 8192 next 2991\n",
      "2024-09-19 17:20:59.925605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c25900 of size 8192 next 2992\n",
      "2024-09-19 17:20:59.925607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c27900 of size 8192 next 2993\n",
      "2024-09-19 17:20:59.925610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa671c29900 of size 4194304 next 2994\n",
      "2024-09-19 17:20:59.925612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029900 of size 256 next 2995\n",
      "2024-09-19 17:20:59.925614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029a00 of size 256 next 2996\n",
      "2024-09-19 17:20:59.925616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029b00 of size 256 next 2997\n",
      "2024-09-19 17:20:59.925619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029c00 of size 256 next 2998\n",
      "2024-09-19 17:20:59.925621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029d00 of size 256 next 2999\n",
      "2024-09-19 17:20:59.925623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029e00 of size 256 next 3000\n",
      "2024-09-19 17:20:59.925625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672029f00 of size 37632 next 3001\n",
      "2024-09-19 17:20:59.925628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672033200 of size 256 next 3002\n",
      "2024-09-19 17:20:59.925630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672033300 of size 1280 next 3003\n",
      "2024-09-19 17:20:59.925633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672033800 of size 2359296 next 2150\n",
      "2024-09-19 17:20:59.925636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672273800 of size 256 next 2008\n",
      "2024-09-19 17:20:59.925638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672273900 of size 1024 next 2027\n",
      "2024-09-19 17:20:59.925640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672273d00 of size 1024 next 2146\n",
      "2024-09-19 17:20:59.925643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672274100 of size 1024 next 2147\n",
      "2024-09-19 17:20:59.925645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672274500 of size 1024 next 2092\n",
      "2024-09-19 17:20:59.925648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672274900 of size 1024 next 2124\n",
      "2024-09-19 17:20:59.925650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672274d00 of size 1048576 next 2023\n",
      "2024-09-19 17:20:59.925652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672374d00 of size 256 next 1956\n",
      "2024-09-19 17:20:59.925655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672374e00 of size 1024 next 2037\n",
      "2024-09-19 17:20:59.925657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672375200 of size 1024 next 2104\n",
      "2024-09-19 17:20:59.925659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672375600 of size 1024 next 2053\n",
      "2024-09-19 17:20:59.925662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672375a00 of size 1024 next 2054\n",
      "2024-09-19 17:20:59.925664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672375e00 of size 1024 next 2093\n",
      "2024-09-19 17:20:59.925666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672376200 of size 2359296 next 2094\n",
      "2024-09-19 17:20:59.925669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725b6200 of size 256 next 2192\n",
      "2024-09-19 17:20:59.925671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725b6300 of size 4096 next 2172\n",
      "2024-09-19 17:20:59.925674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725b7300 of size 4096 next 2174\n",
      "2024-09-19 17:20:59.925676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725b8300 of size 4096 next 1995\n",
      "2024-09-19 17:20:59.925678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725b9300 of size 4096 next 1996\n",
      "2024-09-19 17:20:59.925681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725ba300 of size 4096 next 2068\n",
      "2024-09-19 17:20:59.925683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6725bb300 of size 1048576 next 2069\n",
      "2024-09-19 17:20:59.925686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bb300 of size 256 next 2070\n",
      "2024-09-19 17:20:59.925688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bb400 of size 1024 next 2118\n",
      "2024-09-19 17:20:59.925690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bb800 of size 1024 next 2119\n",
      "2024-09-19 17:20:59.925693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bbc00 of size 1024 next 2168\n",
      "2024-09-19 17:20:59.925695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bc000 of size 1024 next 1997\n",
      "2024-09-19 17:20:59.925697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bc400 of size 1024 next 2122\n",
      "2024-09-19 17:20:59.925700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6726bc800 of size 1048576 next 2026\n",
      "2024-09-19 17:20:59.925702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bc800 of size 256 next 2012\n",
      "2024-09-19 17:20:59.925704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bc900 of size 1024 next 2095\n",
      "2024-09-19 17:20:59.925707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bcd00 of size 1024 next 2078\n",
      "2024-09-19 17:20:59.925709: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bd100 of size 1024 next 2079\n",
      "2024-09-19 17:20:59.925711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bd500 of size 1024 next 2105\n",
      "2024-09-19 17:20:59.925713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bd900 of size 1024 next 1977\n",
      "2024-09-19 17:20:59.925716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bdd00 of size 256 next 1933\n",
      "2024-09-19 17:20:59.925718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bde00 of size 4096 next 1932\n",
      "2024-09-19 17:20:59.925720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bee00 of size 4096 next 1931\n",
      "2024-09-19 17:20:59.925723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727bfe00 of size 4096 next 1930\n",
      "2024-09-19 17:20:59.925725: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727c0e00 of size 4096 next 1929\n",
      "2024-09-19 17:20:59.925728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727c1e00 of size 4096 next 1928\n",
      "2024-09-19 17:20:59.925730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6727c2e00 of size 1509888 next 3004\n",
      "2024-09-19 17:20:59.925733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672933800 of size 256 next 3162\n",
      "2024-09-19 17:20:59.925736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672933900 of size 256 next 3163\n",
      "2024-09-19 17:20:59.925738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672933a00 of size 65536 next 3164\n",
      "2024-09-19 17:20:59.925740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672943a00 of size 512 next 3165\n",
      "2024-09-19 17:20:59.925743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672943c00 of size 4127744 next 3005\n",
      "2024-09-19 17:20:59.925745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d33800 of size 256 next 2064\n",
      "2024-09-19 17:20:59.925747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d33900 of size 512 next 2074\n",
      "2024-09-19 17:20:59.925750: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d33b00 of size 512 next 1991\n",
      "2024-09-19 17:20:59.925752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d33d00 of size 512 next 1992\n",
      "2024-09-19 17:20:59.925754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d33f00 of size 512 next 2185\n",
      "2024-09-19 17:20:59.925756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d34100 of size 512 next 2204\n",
      "2024-09-19 17:20:59.925759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d34300 of size 262144 next 2009\n",
      "2024-09-19 17:20:59.925761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74300 of size 256 next 2010\n",
      "2024-09-19 17:20:59.925763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74400 of size 512 next 2198\n",
      "2024-09-19 17:20:59.925766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74600 of size 512 next 2199\n",
      "2024-09-19 17:20:59.925768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74800 of size 512 next 2039\n",
      "2024-09-19 17:20:59.925770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74a00 of size 512 next 2040\n",
      "2024-09-19 17:20:59.925772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74c00 of size 512 next 2194\n",
      "2024-09-19 17:20:59.925775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672d74e00 of size 589824 next 2196\n",
      "2024-09-19 17:20:59.925777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e04e00 of size 256 next 2108\n",
      "2024-09-19 17:20:59.925780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e04f00 of size 2048 next 2109\n",
      "2024-09-19 17:20:59.925782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e05700 of size 2048 next 2059\n",
      "2024-09-19 17:20:59.925784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e05f00 of size 2048 next 2060\n",
      "2024-09-19 17:20:59.925787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e06700 of size 2048 next 2182\n",
      "2024-09-19 17:20:59.925789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e06f00 of size 2048 next 2001\n",
      "2024-09-19 17:20:59.925791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e07700 of size 262144 next 2002\n",
      "2024-09-19 17:20:59.925794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e47700 of size 256 next 2034\n",
      "2024-09-19 17:20:59.925796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e47800 of size 512 next 2193\n",
      "2024-09-19 17:20:59.925798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e47a00 of size 512 next 2081\n",
      "2024-09-19 17:20:59.925801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e47c00 of size 512 next 2057\n",
      "2024-09-19 17:20:59.925803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e47e00 of size 512 next 2058\n",
      "2024-09-19 17:20:59.925805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e48000 of size 512 next 2103\n",
      "2024-09-19 17:20:59.925808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e48200 of size 262144 next 2073\n",
      "2024-09-19 17:20:59.925810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88200 of size 256 next 2056\n",
      "2024-09-19 17:20:59.925812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88300 of size 512 next 2205\n",
      "2024-09-19 17:20:59.925815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88500 of size 512 next 2141\n",
      "2024-09-19 17:20:59.925817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88700 of size 512 next 2156\n",
      "2024-09-19 17:20:59.925820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88900 of size 512 next 2157\n",
      "2024-09-19 17:20:59.925822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88b00 of size 512 next 2066\n",
      "2024-09-19 17:20:59.925826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672e88d00 of size 699136 next 3006\n",
      "2024-09-19 17:20:59.925828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa672f33800 of size 1048576 next 3007\n",
      "2024-09-19 17:20:59.925831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673033800 of size 256 next 2067\n",
      "2024-09-19 17:20:59.925833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673033900 of size 2048 next 2055\n",
      "2024-09-19 17:20:59.925836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673034100 of size 2048 next 1986\n",
      "2024-09-19 17:20:59.925838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673034900 of size 2048 next 1987\n",
      "2024-09-19 17:20:59.925840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673035100 of size 2048 next 2190\n",
      "2024-09-19 17:20:59.925843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673035900 of size 2048 next 2191\n",
      "2024-09-19 17:20:59.925845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673036100 of size 262144 next 1985\n",
      "2024-09-19 17:20:59.925847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076100 of size 256 next 2228\n",
      "2024-09-19 17:20:59.925850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076200 of size 512 next 2230\n",
      "2024-09-19 17:20:59.925852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076400 of size 512 next 2160\n",
      "2024-09-19 17:20:59.925854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076600 of size 512 next 2161\n",
      "2024-09-19 17:20:59.925857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076800 of size 512 next 2217\n",
      "2024-09-19 17:20:59.925859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076a00 of size 512 next 2188\n",
      "2024-09-19 17:20:59.925861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673076c00 of size 262144 next 2189\n",
      "2024-09-19 17:20:59.925864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b6c00 of size 256 next 2112\n",
      "2024-09-19 17:20:59.925866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b6d00 of size 512 next 2113\n",
      "2024-09-19 17:20:59.925868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b6f00 of size 512 next 2031\n",
      "2024-09-19 17:20:59.925871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b7100 of size 512 next 2024\n",
      "2024-09-19 17:20:59.925873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b7300 of size 512 next 2025\n",
      "2024-09-19 17:20:59.925875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b7500 of size 512 next 2142\n",
      "2024-09-19 17:20:59.925878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6730b7700 of size 589824 next 2144\n",
      "2024-09-19 17:20:59.925880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673147700 of size 256 next 1982\n",
      "2024-09-19 17:20:59.925882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673147800 of size 2048 next 2206\n",
      "2024-09-19 17:20:59.925884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673148000 of size 2048 next 2048\n",
      "2024-09-19 17:20:59.925887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673148800 of size 2048 next 2145\n",
      "2024-09-19 17:20:59.925889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673149000 of size 2048 next 2169\n",
      "2024-09-19 17:20:59.925891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673149800 of size 2048 next 2087\n",
      "2024-09-19 17:20:59.925894: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67314a000 of size 262144 next 2018\n",
      "2024-09-19 17:20:59.925896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318a000 of size 256 next 2195\n",
      "2024-09-19 17:20:59.925899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318a100 of size 1024 next 2186\n",
      "2024-09-19 17:20:59.925901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318a500 of size 1024 next 2065\n",
      "2024-09-19 17:20:59.925903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318a900 of size 1024 next 2197\n",
      "2024-09-19 17:20:59.925905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318ad00 of size 1024 next 2038\n",
      "2024-09-19 17:20:59.925908: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318b100 of size 1024 next 2003\n",
      "2024-09-19 17:20:59.925910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67318b500 of size 688896 next 3009\n",
      "2024-09-19 17:20:59.925913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673233800 of size 2359296 next 3010\n",
      "2024-09-19 17:20:59.925915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673473800 of size 1048576 next 3260\n",
      "2024-09-19 17:20:59.925917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673573800 of size 1310720 next 3011\n",
      "2024-09-19 17:20:59.925920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6736b3800 of size 3145728 next 3014\n",
      "2024-09-19 17:20:59.925922: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6739b3800 of size 2359296 next 3015\n",
      "2024-09-19 17:20:59.925925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673bf3800 of size 1048576 next 3016\n",
      "2024-09-19 17:20:59.925927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673cf3800 of size 1024 next 3130\n",
      "2024-09-19 17:20:59.925929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673cf3c00 of size 65536 next 3131\n",
      "2024-09-19 17:20:59.925931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d03c00 of size 16384 next 3132\n",
      "2024-09-19 17:20:59.925934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d07c00 of size 1024 next 3133\n",
      "2024-09-19 17:20:59.925936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08000 of size 1024 next 3134\n",
      "2024-09-19 17:20:59.925938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08400 of size 256 next 3135\n",
      "2024-09-19 17:20:59.925941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08500 of size 1024 next 3136\n",
      "2024-09-19 17:20:59.925943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08900 of size 256 next 3137\n",
      "2024-09-19 17:20:59.925945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08a00 of size 1024 next 3138\n",
      "2024-09-19 17:20:59.925947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d08e00 of size 65536 next 3139\n",
      "2024-09-19 17:20:59.925950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d18e00 of size 8192 next 3140\n",
      "2024-09-19 17:20:59.925952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1ae00 of size 256 next 3141\n",
      "2024-09-19 17:20:59.925954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1af00 of size 1024 next 3142\n",
      "2024-09-19 17:20:59.925957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1b300 of size 256 next 3143\n",
      "2024-09-19 17:20:59.925959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1b400 of size 256 next 3144\n",
      "2024-09-19 17:20:59.925961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1b500 of size 1024 next 3145\n",
      "2024-09-19 17:20:59.925963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1b900 of size 256 next 3146\n",
      "2024-09-19 17:20:59.925966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1ba00 of size 256 next 3147\n",
      "2024-09-19 17:20:59.925968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d1bb00 of size 97536 next 3017\n",
      "2024-09-19 17:20:59.925970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673d33800 of size 589824 next 3018\n",
      "2024-09-19 17:20:59.925973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673dc3800 of size 262144 next 3019\n",
      "2024-09-19 17:20:59.925975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673e03800 of size 589824 next 3020\n",
      "2024-09-19 17:20:59.925977: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673e93800 of size 524288 next 3021\n",
      "2024-09-19 17:20:59.925980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f13800 of size 1024 next 3181\n",
      "2024-09-19 17:20:59.925982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f13c00 of size 256 next 3182\n",
      "2024-09-19 17:20:59.925984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f13d00 of size 1024 next 3183\n",
      "2024-09-19 17:20:59.925987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f14100 of size 512 next 3184\n",
      "2024-09-19 17:20:59.925989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f14300 of size 4096 next 3185\n",
      "2024-09-19 17:20:59.925991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f15300 of size 512 next 3186\n",
      "2024-09-19 17:20:59.925994: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f15500 of size 1024 next 3188\n",
      "2024-09-19 17:20:59.925996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f15900 of size 1024 next 3189\n",
      "2024-09-19 17:20:59.925998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f15d00 of size 65536 next 3028\n",
      "2024-09-19 17:20:59.926001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f25d00 of size 187136 next 3022\n",
      "2024-09-19 17:20:59.926003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f53800 of size 262144 next 3023\n",
      "2024-09-19 17:20:59.926005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f93800 of size 2048 next 3080\n",
      "2024-09-19 17:20:59.926007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f94000 of size 512 next 3082\n",
      "2024-09-19 17:20:59.926010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f94200 of size 2048 next 3084\n",
      "2024-09-19 17:20:59.926012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f94a00 of size 512 next 3085\n",
      "2024-09-19 17:20:59.926015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f94c00 of size 2048 next 3086\n",
      "2024-09-19 17:20:59.926017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f95400 of size 512 next 3087\n",
      "2024-09-19 17:20:59.926019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f95600 of size 2048 next 3088\n",
      "2024-09-19 17:20:59.926021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f95e00 of size 2048 next 3089\n",
      "2024-09-19 17:20:59.926024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f96600 of size 512 next 3090\n",
      "2024-09-19 17:20:59.926027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f96800 of size 512 next 3091\n",
      "2024-09-19 17:20:59.926029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f96a00 of size 512 next 3093\n",
      "2024-09-19 17:20:59.926031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f96c00 of size 2048 next 3094\n",
      "2024-09-19 17:20:59.926034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f97400 of size 512 next 3095\n",
      "2024-09-19 17:20:59.926036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f97600 of size 2048 next 3096\n",
      "2024-09-19 17:20:59.926038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f97e00 of size 512 next 3097\n",
      "2024-09-19 17:20:59.926040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f98000 of size 512 next 3098\n",
      "2024-09-19 17:20:59.926043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f98200 of size 512 next 3099\n",
      "2024-09-19 17:20:59.926045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f98400 of size 512 next 3100\n",
      "2024-09-19 17:20:59.926047: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f98600 of size 2048 next 3101\n",
      "2024-09-19 17:20:59.926050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f98e00 of size 512 next 3102\n",
      "2024-09-19 17:20:59.926052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f99000 of size 2048 next 3103\n",
      "2024-09-19 17:20:59.926054: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f99800 of size 1024 next 3104\n",
      "2024-09-19 17:20:59.926056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f99c00 of size 4096 next 3106\n",
      "2024-09-19 17:20:59.926059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9ac00 of size 1024 next 3107\n",
      "2024-09-19 17:20:59.926061: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9b000 of size 512 next 3108\n",
      "2024-09-19 17:20:59.926063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9b200 of size 512 next 3109\n",
      "2024-09-19 17:20:59.926065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9b400 of size 512 next 3111\n",
      "2024-09-19 17:20:59.926068: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9b600 of size 1024 next 3113\n",
      "2024-09-19 17:20:59.926070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9ba00 of size 4096 next 3114\n",
      "2024-09-19 17:20:59.926072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9ca00 of size 1024 next 3115\n",
      "2024-09-19 17:20:59.926075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9ce00 of size 1024 next 3116\n",
      "2024-09-19 17:20:59.926077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9d200 of size 1024 next 3117\n",
      "2024-09-19 17:20:59.926079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9d600 of size 512 next 3118\n",
      "2024-09-19 17:20:59.926081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9d800 of size 512 next 3119\n",
      "2024-09-19 17:20:59.926084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9da00 of size 512 next 3121\n",
      "2024-09-19 17:20:59.926086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9dc00 of size 256 next 3122\n",
      "2024-09-19 17:20:59.926088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9dd00 of size 2048 next 3123\n",
      "2024-09-19 17:20:59.926090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9e500 of size 256 next 3124\n",
      "2024-09-19 17:20:59.926093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9e600 of size 256 next 3125\n",
      "2024-09-19 17:20:59.926095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9e700 of size 256 next 3126\n",
      "2024-09-19 17:20:59.926097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673f9e800 of size 217088 next 3024\n",
      "2024-09-19 17:20:59.926101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa673fd3800 of size 1179648 next 3025\n",
      "2024-09-19 17:20:59.926103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6740f3800 of size 256 next 3148\n",
      "2024-09-19 17:20:59.926106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6740f3900 of size 1024 next 3149\n",
      "2024-09-19 17:20:59.926108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6740f3d00 of size 256 next 3150\n",
      "2024-09-19 17:20:59.926110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6740f3e00 of size 65536 next 3151\n",
      "2024-09-19 17:20:59.926113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674103e00 of size 256 next 3152\n",
      "2024-09-19 17:20:59.926115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674103f00 of size 2048 next 3153\n",
      "2024-09-19 17:20:59.926117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674104700 of size 256 next 3154\n",
      "2024-09-19 17:20:59.926119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674104800 of size 256 next 3155\n",
      "2024-09-19 17:20:59.926122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674104900 of size 256 next 3156\n",
      "2024-09-19 17:20:59.926124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674104a00 of size 1024 next 3157\n",
      "2024-09-19 17:20:59.926126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674104e00 of size 512 next 3158\n",
      "2024-09-19 17:20:59.926129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674105000 of size 1024 next 3159\n",
      "2024-09-19 17:20:59.926131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674105400 of size 1024 next 3160\n",
      "2024-09-19 17:20:59.926133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674105800 of size 256 next 3161\n",
      "2024-09-19 17:20:59.926136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674105900 of size 188160 next 3026\n",
      "2024-09-19 17:20:59.926138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674133800 of size 37632 next 3264\n",
      "2024-09-19 17:20:59.926140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67413cb00 of size 8192 next 3268\n",
      "2024-09-19 17:20:59.926143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67413eb00 of size 2048 next 3271\n",
      "2024-09-19 17:20:59.926145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67413f300 of size 8192 next 3037\n",
      "2024-09-19 17:20:59.926147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674141300 of size 256 next 3272\n",
      "2024-09-19 17:20:59.926149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674141400 of size 1024 next 3274\n",
      "2024-09-19 17:20:59.926152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674141800 of size 8192 next 3275\n",
      "2024-09-19 17:20:59.926154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674143800 of size 1024 next 3276\n",
      "2024-09-19 17:20:59.926156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674143c00 of size 1024 next 3277\n",
      "2024-09-19 17:20:59.926159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674144000 of size 4096 next 3278\n",
      "2024-09-19 17:20:59.926161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674145000 of size 1024 next 3279\n",
      "2024-09-19 17:20:59.926163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674145400 of size 1024 next 3280\n",
      "2024-09-19 17:20:59.926165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674145800 of size 1024 next 3281\n",
      "2024-09-19 17:20:59.926168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674145c00 of size 1024 next 3282\n",
      "2024-09-19 17:20:59.926170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674146000 of size 1024 next 3283\n",
      "2024-09-19 17:20:59.926172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674146400 of size 2048 next 3284\n",
      "2024-09-19 17:20:59.926174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674146c00 of size 8192 next 3286\n",
      "2024-09-19 17:20:59.926177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674148c00 of size 2048 next 3287\n",
      "2024-09-19 17:20:59.926179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674149400 of size 8192 next 3288\n",
      "2024-09-19 17:20:59.926181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414b400 of size 2048 next 3289\n",
      "2024-09-19 17:20:59.926184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414bc00 of size 8192 next 3290\n",
      "2024-09-19 17:20:59.926186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414dc00 of size 256 next 3291\n",
      "2024-09-19 17:20:59.926188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414dd00 of size 1024 next 3293\n",
      "2024-09-19 17:20:59.926190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414e100 of size 1024 next 3294\n",
      "2024-09-19 17:20:59.926193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414e500 of size 1024 next 3296\n",
      "2024-09-19 17:20:59.926195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414e900 of size 2048 next 3297\n",
      "2024-09-19 17:20:59.926197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67414f100 of size 8192 next 3298\n",
      "2024-09-19 17:20:59.926199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674151100 of size 8192 next 3299\n",
      "2024-09-19 17:20:59.926202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674153100 of size 8192 next 3301\n",
      "2024-09-19 17:20:59.926204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155100 of size 256 next 3049\n",
      "2024-09-19 17:20:59.926206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155200 of size 256 next 3050\n",
      "2024-09-19 17:20:59.926209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155300 of size 256 next 3046\n",
      "2024-09-19 17:20:59.926211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155400 of size 256 next 3047\n",
      "2024-09-19 17:20:59.926213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155500 of size 256 next 3012\n",
      "2024-09-19 17:20:59.926216: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155600 of size 256 next 3013\n",
      "2024-09-19 17:20:59.926218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155700 of size 256 next 3056\n",
      "2024-09-19 17:20:59.926220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155800 of size 256 next 3053\n",
      "2024-09-19 17:20:59.926222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155900 of size 256 next 3054\n",
      "2024-09-19 17:20:59.926225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155a00 of size 256 next 3055\n",
      "2024-09-19 17:20:59.926227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155b00 of size 256 next 3040\n",
      "2024-09-19 17:20:59.926229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155c00 of size 256 next 3041\n",
      "2024-09-19 17:20:59.926232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155d00 of size 256 next 3008\n",
      "2024-09-19 17:20:59.926234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155e00 of size 256 next 3051\n",
      "2024-09-19 17:20:59.926236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674155f00 of size 256 next 3052\n",
      "2024-09-19 17:20:59.926238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156000 of size 256 next 3045\n",
      "2024-09-19 17:20:59.926241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156100 of size 256 next 3042\n",
      "2024-09-19 17:20:59.926243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156200 of size 256 next 3039\n",
      "2024-09-19 17:20:59.926245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156300 of size 256 next 3048\n",
      "2024-09-19 17:20:59.926248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156400 of size 256 next 3302\n",
      "2024-09-19 17:20:59.926250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156500 of size 256 next 3303\n",
      "2024-09-19 17:20:59.926252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156600 of size 256 next 3304\n",
      "2024-09-19 17:20:59.926254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156700 of size 256 next 3305\n",
      "2024-09-19 17:20:59.926257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156800 of size 256 next 3306\n",
      "2024-09-19 17:20:59.926259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156900 of size 256 next 3307\n",
      "2024-09-19 17:20:59.926261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156a00 of size 256 next 3308\n",
      "2024-09-19 17:20:59.926264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156b00 of size 256 next 3309\n",
      "2024-09-19 17:20:59.926266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156c00 of size 256 next 3310\n",
      "2024-09-19 17:20:59.926268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156d00 of size 256 next 3311\n",
      "2024-09-19 17:20:59.926270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156e00 of size 256 next 3312\n",
      "2024-09-19 17:20:59.926273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674156f00 of size 256 next 3313\n",
      "2024-09-19 17:20:59.926275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674157000 of size 256 next 3314\n",
      "2024-09-19 17:20:59.926277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674157100 of size 256 next 3315\n",
      "2024-09-19 17:20:59.926279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674157200 of size 256 next 3316\n",
      "2024-09-19 17:20:59.926282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674157300 of size 148736 next 3030\n",
      "2024-09-19 17:20:59.926284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67417b800 of size 589824 next 3031\n",
      "2024-09-19 17:20:59.926286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420b800 of size 1024 next 3191\n",
      "2024-09-19 17:20:59.926289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420bc00 of size 4096 next 3192\n",
      "2024-09-19 17:20:59.926291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420cc00 of size 8192 next 3193\n",
      "2024-09-19 17:20:59.926293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420ec00 of size 1024 next 3029\n",
      "2024-09-19 17:20:59.926295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420f000 of size 512 next 3027\n",
      "2024-09-19 17:20:59.926298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67420f200 of size 4096 next 3194\n",
      "2024-09-19 17:20:59.926300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674210200 of size 4096 next 3195\n",
      "2024-09-19 17:20:59.926302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674211200 of size 1024 next 3196\n",
      "2024-09-19 17:20:59.926305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674211600 of size 1024 next 3197\n",
      "2024-09-19 17:20:59.926307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674211a00 of size 4096 next 3044\n",
      "2024-09-19 17:20:59.926309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674212a00 of size 512 next 3198\n",
      "2024-09-19 17:20:59.926312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674212c00 of size 2048 next 3199\n",
      "2024-09-19 17:20:59.926314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674213400 of size 1024 next 3200\n",
      "2024-09-19 17:20:59.926316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674213800 of size 1024 next 3201\n",
      "2024-09-19 17:20:59.926319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674213c00 of size 4096 next 3202\n",
      "2024-09-19 17:20:59.926321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674214c00 of size 512 next 3203\n",
      "2024-09-19 17:20:59.926323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674214e00 of size 4096 next 3204\n",
      "2024-09-19 17:20:59.926326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674215e00 of size 2048 next 3205\n",
      "2024-09-19 17:20:59.926328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674216600 of size 1024 next 3206\n",
      "2024-09-19 17:20:59.926330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674216a00 of size 1024 next 3208\n",
      "2024-09-19 17:20:59.926332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674216e00 of size 4096 next 3209\n",
      "2024-09-19 17:20:59.926335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674217e00 of size 4096 next 3211\n",
      "2024-09-19 17:20:59.926337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674218e00 of size 4096 next 3213\n",
      "2024-09-19 17:20:59.926339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa674219e00 of size 2048 next 3214\n",
      "2024-09-19 17:20:59.926342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67421a600 of size 1024 next 3034\n",
      "2024-09-19 17:20:59.926344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67421aa00 of size 1024 next 3223\n",
      "2024-09-19 17:20:59.926346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67421ae00 of size 1024 next 3225\n",
      "2024-09-19 17:20:59.926348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67421b200 of size 1536 next 3032\n",
      "2024-09-19 17:20:59.926351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67421b800 of size 589824 next 3033\n",
      "2024-09-19 17:20:59.926353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ab800 of size 8192 next 3215\n",
      "2024-09-19 17:20:59.926357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ad800 of size 4096 next 3217\n",
      "2024-09-19 17:20:59.926359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ae800 of size 4096 next 3219\n",
      "2024-09-19 17:20:59.926361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742af800 of size 8192 next 3220\n",
      "2024-09-19 17:20:59.926364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b1800 of size 4096 next 3222\n",
      "2024-09-19 17:20:59.926367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b2800 of size 4096 next 3224\n",
      "2024-09-19 17:20:59.926369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b3800 of size 4096 next 3226\n",
      "2024-09-19 17:20:59.926371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b4800 of size 2048 next 3228\n",
      "2024-09-19 17:20:59.926374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b5000 of size 8192 next 3229\n",
      "2024-09-19 17:20:59.926376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b7000 of size 2048 next 3230\n",
      "2024-09-19 17:20:59.926378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b7800 of size 8192 next 3231\n",
      "2024-09-19 17:20:59.926380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742b9800 of size 2048 next 3232\n",
      "2024-09-19 17:20:59.926383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ba000 of size 4096 next 3233\n",
      "2024-09-19 17:20:59.926385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bb000 of size 2048 next 3234\n",
      "2024-09-19 17:20:59.926387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bb800 of size 2048 next 3235\n",
      "2024-09-19 17:20:59.926389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bc000 of size 4096 next 3236\n",
      "2024-09-19 17:20:59.926392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bd000 of size 4096 next 3237\n",
      "2024-09-19 17:20:59.926394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742be000 of size 1024 next 3038\n",
      "2024-09-19 17:20:59.926396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742be400 of size 4096 next 3238\n",
      "2024-09-19 17:20:59.926399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bf400 of size 1024 next 3239\n",
      "2024-09-19 17:20:59.926401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742bf800 of size 4096 next 3240\n",
      "2024-09-19 17:20:59.926403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c0800 of size 4096 next 3242\n",
      "2024-09-19 17:20:59.926405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c1800 of size 1024 next 3243\n",
      "2024-09-19 17:20:59.926408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c1c00 of size 1024 next 3245\n",
      "2024-09-19 17:20:59.926410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c2000 of size 1024 next 3246\n",
      "2024-09-19 17:20:59.926412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c2400 of size 1024 next 3247\n",
      "2024-09-19 17:20:59.926415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c2800 of size 2048 next 3248\n",
      "2024-09-19 17:20:59.926417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c3000 of size 2048 next 3249\n",
      "2024-09-19 17:20:59.926419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c3800 of size 2048 next 3251\n",
      "2024-09-19 17:20:59.926422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c4000 of size 2048 next 3252\n",
      "2024-09-19 17:20:59.926424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c4800 of size 2048 next 3253\n",
      "2024-09-19 17:20:59.926426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c5000 of size 256 next 3254\n",
      "2024-09-19 17:20:59.926428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c5100 of size 4096 next 3256\n",
      "2024-09-19 17:20:59.926431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c6100 of size 1024 next 3257\n",
      "2024-09-19 17:20:59.926433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c6500 of size 4096 next 3258\n",
      "2024-09-19 17:20:59.926435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c7500 of size 1024 next 3259\n",
      "2024-09-19 17:20:59.926438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c7900 of size 4096 next 3261\n",
      "2024-09-19 17:20:59.926440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c8900 of size 1024 next 3262\n",
      "2024-09-19 17:20:59.926442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c8d00 of size 1024 next 3263\n",
      "2024-09-19 17:20:59.926444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c9100 of size 1024 next 3265\n",
      "2024-09-19 17:20:59.926447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c9500 of size 1024 next 3266\n",
      "2024-09-19 17:20:59.926449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742c9900 of size 2048 next 3267\n",
      "2024-09-19 17:20:59.926451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ca100 of size 2048 next 3269\n",
      "2024-09-19 17:20:59.926454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742ca900 of size 3840 next 3035\n",
      "2024-09-19 17:20:59.926456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6742cb800 of size 1032192 next 3036\n",
      "2024-09-19 17:20:59.926458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c7800 of size 256 next 2096\n",
      "2024-09-19 17:20:59.926461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c7900 of size 1024 next 2097\n",
      "2024-09-19 17:20:59.926463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c7d00 of size 1024 next 2126\n",
      "2024-09-19 17:20:59.926465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c8100 of size 1024 next 2128\n",
      "2024-09-19 17:20:59.926468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c8500 of size 1024 next 2181\n",
      "2024-09-19 17:20:59.926470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c8900 of size 1024 next 2035\n",
      "2024-09-19 17:20:59.926472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c8d00 of size 256 next 2036\n",
      "2024-09-19 17:20:59.926474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c8e00 of size 4096 next 1993\n",
      "2024-09-19 17:20:59.926477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743c9e00 of size 4096 next 2071\n",
      "2024-09-19 17:20:59.926479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743cae00 of size 4096 next 2072\n",
      "2024-09-19 17:20:59.926481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743cbe00 of size 4096 next 2151\n",
      "2024-09-19 17:20:59.926484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743cce00 of size 4096 next 2152\n",
      "2024-09-19 17:20:59.926486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6743cde00 of size 1048576 next 1978\n",
      "2024-09-19 17:20:59.926488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744cde00 of size 256 next 2153\n",
      "2024-09-19 17:20:59.926490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744cdf00 of size 4096 next 2047\n",
      "2024-09-19 17:20:59.926493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744cef00 of size 4096 next 2077\n",
      "2024-09-19 17:20:59.926495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744cff00 of size 4096 next 2110\n",
      "2024-09-19 17:20:59.926498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d0f00 of size 4096 next 2011\n",
      "2024-09-19 17:20:59.926500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d1f00 of size 4096 next 2121\n",
      "2024-09-19 17:20:59.926502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d2f00 of size 256 next 2179\n",
      "2024-09-19 17:20:59.926505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d3000 of size 1024 next 2045\n",
      "2024-09-19 17:20:59.926507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d3400 of size 1024 next 2042\n",
      "2024-09-19 17:20:59.926509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d3800 of size 1024 next 2013\n",
      "2024-09-19 17:20:59.926512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d3c00 of size 1024 next 2014\n",
      "2024-09-19 17:20:59.926514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d4000 of size 1024 next 2004\n",
      "2024-09-19 17:20:59.926517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6744d4400 of size 1066752 next 3043\n",
      "2024-09-19 17:20:59.926519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745d8b00 of size 1024 next 3177\n",
      "2024-09-19 17:20:59.926521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745d8f00 of size 1024 next 3178\n",
      "2024-09-19 17:20:59.926524: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745d9300 of size 2048 next 3179\n",
      "2024-09-19 17:20:59.926526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745d9b00 of size 1024 next 3180\n",
      "2024-09-19 17:20:59.926528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745d9f00 of size 256 next 1881\n",
      "2024-09-19 17:20:59.926531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745da000 of size 2048 next 1880\n",
      "2024-09-19 17:20:59.926533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745da800 of size 2048 next 1879\n",
      "2024-09-19 17:20:59.926536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745db000 of size 2048 next 1878\n",
      "2024-09-19 17:20:59.926538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745db800 of size 2048 next 1877\n",
      "2024-09-19 17:20:59.926540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745dc000 of size 2048 next 1876\n",
      "2024-09-19 17:20:59.926542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6745dc800 of size 4194304 next 1875\n",
      "2024-09-19 17:20:59.926545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749dc800 of size 256 next 1874\n",
      "2024-09-19 17:20:59.926547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749dc900 of size 2048 next 1873\n",
      "2024-09-19 17:20:59.926549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749dd100 of size 2048 next 1872\n",
      "2024-09-19 17:20:59.926552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749dd900 of size 2048 next 1871\n",
      "2024-09-19 17:20:59.926554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749de100 of size 2048 next 1870\n",
      "2024-09-19 17:20:59.926556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749de900 of size 2048 next 1869\n",
      "2024-09-19 17:20:59.926559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6749df100 of size 9437184 next 1868\n",
      "2024-09-19 17:20:59.926561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752df100 of size 256 next 1867\n",
      "2024-09-19 17:20:59.926563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752df200 of size 8192 next 1866\n",
      "2024-09-19 17:20:59.926566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752e1200 of size 8192 next 1865\n",
      "2024-09-19 17:20:59.926568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752e3200 of size 8192 next 1864\n",
      "2024-09-19 17:20:59.926570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752e5200 of size 8192 next 1863\n",
      "2024-09-19 17:20:59.926572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752e7200 of size 8192 next 1862\n",
      "2024-09-19 17:20:59.926575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6752e9200 of size 4194304 next 1861\n",
      "2024-09-19 17:20:59.926577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756e9200 of size 256 next 1860\n",
      "2024-09-19 17:20:59.926579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756e9300 of size 2048 next 1859\n",
      "2024-09-19 17:20:59.926581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756e9b00 of size 2048 next 1858\n",
      "2024-09-19 17:20:59.926584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756ea300 of size 2048 next 1857\n",
      "2024-09-19 17:20:59.926586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756eab00 of size 2048 next 1856\n",
      "2024-09-19 17:20:59.926588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756eb300 of size 2048 next 1855\n",
      "2024-09-19 17:20:59.926591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6756ebb00 of size 4194304 next 1854\n",
      "2024-09-19 17:20:59.926593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aebb00 of size 256 next 1853\n",
      "2024-09-19 17:20:59.926595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aebc00 of size 2048 next 1852\n",
      "2024-09-19 17:20:59.926597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aec400 of size 2048 next 1851\n",
      "2024-09-19 17:20:59.926600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aecc00 of size 2048 next 1850\n",
      "2024-09-19 17:20:59.926602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aed400 of size 2048 next 1849\n",
      "2024-09-19 17:20:59.926604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aedc00 of size 2048 next 1848\n",
      "2024-09-19 17:20:59.926607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa675aee400 of size 9437184 next 1847\n",
      "2024-09-19 17:20:59.926609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763ee400 of size 256 next 1846\n",
      "2024-09-19 17:20:59.926611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763ee500 of size 8192 next 1845\n",
      "2024-09-19 17:20:59.926613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763f0500 of size 8192 next 1844\n",
      "2024-09-19 17:20:59.926616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763f2500 of size 8192 next 1843\n",
      "2024-09-19 17:20:59.926618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763f4500 of size 8192 next 1842\n",
      "2024-09-19 17:20:59.926620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763f6500 of size 8192 next 1841\n",
      "2024-09-19 17:20:59.926623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6763f8500 of size 4194304 next 1840\n",
      "2024-09-19 17:20:59.926625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8500 of size 256 next 1839\n",
      "2024-09-19 17:20:59.926627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8600 of size 256 next 1838\n",
      "2024-09-19 17:20:59.926629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8700 of size 256 next 1837\n",
      "2024-09-19 17:20:59.926632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8800 of size 256 next 1836\n",
      "2024-09-19 17:20:59.926634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8900 of size 256 next 1835\n",
      "2024-09-19 17:20:59.926636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8a00 of size 256 next 1834\n",
      "2024-09-19 17:20:59.926639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6767f8b00 of size 37632 next 1833\n",
      "2024-09-19 17:20:59.926641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676801e00 of size 256 next 1832\n",
      "2024-09-19 17:20:59.926643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676801f00 of size 1280 next 1831\n",
      "2024-09-19 17:20:59.926646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676802400 of size 2359296 next 1830\n",
      "2024-09-19 17:20:59.926648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676a42400 of size 1048576 next 1829\n",
      "2024-09-19 17:20:59.926650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676b42400 of size 1048576 next 1828\n",
      "2024-09-19 17:20:59.926652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676c42400 of size 1048576 next 1827\n",
      "2024-09-19 17:20:59.926655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676d42400 of size 2359296 next 1826\n",
      "2024-09-19 17:20:59.926657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa676f82400 of size 1048576 next 1825\n",
      "2024-09-19 17:20:59.926659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677082400 of size 1048576 next 1824\n",
      "2024-09-19 17:20:59.926662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677182400 of size 2975488 next 3057\n",
      "2024-09-19 17:20:59.926664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677458b00 of size 589824 next 3187\n",
      "2024-09-19 17:20:59.926666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6774e8b00 of size 1048576 next 3190\n",
      "2024-09-19 17:20:59.926669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6775e8b00 of size 2555904 next 3058\n",
      "2024-09-19 17:20:59.926671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677858b00 of size 2097152 next 2178\n",
      "2024-09-19 17:20:59.926673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a58b00 of size 256 next 2148\n",
      "2024-09-19 17:20:59.926676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a58c00 of size 1024 next 2149\n",
      "2024-09-19 17:20:59.926678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a59000 of size 1024 next 2218\n",
      "2024-09-19 17:20:59.926680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a59400 of size 1024 next 2176\n",
      "2024-09-19 17:20:59.926683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a59800 of size 1024 next 2028\n",
      "2024-09-19 17:20:59.926685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a59c00 of size 1024 next 2041\n",
      "2024-09-19 17:20:59.926687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5a000 of size 256 next 2133\n",
      "2024-09-19 17:20:59.926690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5a100 of size 4096 next 2134\n",
      "2024-09-19 17:20:59.926692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5b100 of size 4096 next 2211\n",
      "2024-09-19 17:20:59.926694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5c100 of size 4096 next 2017\n",
      "2024-09-19 17:20:59.926697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5d100 of size 4096 next 2187\n",
      "2024-09-19 17:20:59.926699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5e100 of size 4096 next 1998\n",
      "2024-09-19 17:20:59.926701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677a5f100 of size 2071040 next 3059\n",
      "2024-09-19 17:20:59.926705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677c58b00 of size 512 next 3060\n",
      "2024-09-19 17:20:59.926708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677c58d00 of size 2048 next 3061\n",
      "2024-09-19 17:20:59.926710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677c59500 of size 589824 next 3062\n",
      "2024-09-19 17:20:59.926712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677ce9500 of size 512 next 3063\n",
      "2024-09-19 17:20:59.926714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677ce9700 of size 256 next 3064\n",
      "2024-09-19 17:20:59.926717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677ce9800 of size 2048 next 3065\n",
      "2024-09-19 17:20:59.926719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677cea000 of size 2048 next 3066\n",
      "2024-09-19 17:20:59.926721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677cea800 of size 2048 next 3067\n",
      "2024-09-19 17:20:59.926724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677ceb000 of size 262144 next 3068\n",
      "2024-09-19 17:20:59.926726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2b000 of size 2048 next 3069\n",
      "2024-09-19 17:20:59.926728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2b800 of size 2048 next 3070\n",
      "2024-09-19 17:20:59.926730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2c000 of size 512 next 3071\n",
      "2024-09-19 17:20:59.926733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2c200 of size 2048 next 3072\n",
      "2024-09-19 17:20:59.926735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2ca00 of size 2048 next 3073\n",
      "2024-09-19 17:20:59.926738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d2d200 of size 262144 next 3074\n",
      "2024-09-19 17:20:59.926740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6d200 of size 2048 next 3075\n",
      "2024-09-19 17:20:59.926742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6da00 of size 512 next 3076\n",
      "2024-09-19 17:20:59.926745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6dc00 of size 2048 next 3077\n",
      "2024-09-19 17:20:59.926747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6e400 of size 2048 next 3078\n",
      "2024-09-19 17:20:59.926749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6ec00 of size 512 next 3079\n",
      "2024-09-19 17:20:59.926751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677d6ee00 of size 262144 next 3081\n",
      "2024-09-19 17:20:59.926754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677daee00 of size 524288 next 3083\n",
      "2024-09-19 17:20:59.926756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa677e2ee00 of size 4194304 next 3092\n",
      "2024-09-19 17:20:59.926758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67822ee00 of size 4194304 next 3105\n",
      "2024-09-19 17:20:59.926761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67862ee00 of size 262144 next 3110\n",
      "2024-09-19 17:20:59.926763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67866ee00 of size 262144 next 3112\n",
      "2024-09-19 17:20:59.926765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6786aee00 of size 589824 next 3120\n",
      "2024-09-19 17:20:59.926767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67873ee00 of size 1024 next 3127\n",
      "2024-09-19 17:20:59.926770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67873f200 of size 256 next 3128\n",
      "2024-09-19 17:20:59.926772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67873f300 of size 1024 next 3129\n",
      "2024-09-19 17:20:59.926774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67873f700 of size 8192 next 3166\n",
      "2024-09-19 17:20:59.926777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678741700 of size 1024 next 3167\n",
      "2024-09-19 17:20:59.926779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678741b00 of size 4096 next 3168\n",
      "2024-09-19 17:20:59.926781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678742b00 of size 256 next 3169\n",
      "2024-09-19 17:20:59.926783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678742c00 of size 1024 next 3170\n",
      "2024-09-19 17:20:59.926786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678743000 of size 256 next 3171\n",
      "2024-09-19 17:20:59.926788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678743100 of size 147456 next 3172\n",
      "2024-09-19 17:20:59.926790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678767100 of size 512 next 3173\n",
      "2024-09-19 17:20:59.926793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678767300 of size 512 next 3174\n",
      "2024-09-19 17:20:59.926795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678767500 of size 1024 next 3175\n",
      "2024-09-19 17:20:59.926797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678767900 of size 2359296 next 3176\n",
      "2024-09-19 17:20:59.926800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6789a7900 of size 2359296 next 3207\n",
      "2024-09-19 17:20:59.926802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678be7900 of size 1048576 next 3210\n",
      "2024-09-19 17:20:59.926804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678ce7900 of size 1048576 next 3212\n",
      "2024-09-19 17:20:59.926806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa678de7900 of size 8388608 next 3216\n",
      "2024-09-19 17:20:59.926809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6795e7900 of size 1048576 next 3218\n",
      "2024-09-19 17:20:59.926811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6796e7900 of size 1048576 next 3221\n",
      "2024-09-19 17:20:59.926813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6797e7900 of size 1048576 next 3227\n",
      "2024-09-19 17:20:59.926816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6798e7900 of size 1048576 next 3241\n",
      "2024-09-19 17:20:59.926818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6799e7900 of size 1048576 next 3244\n",
      "2024-09-19 17:20:59.926820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa679ae7900 of size 4194304 next 3250\n",
      "2024-09-19 17:20:59.926822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa679ee7900 of size 9437184 next 3255\n",
      "2024-09-19 17:20:59.926825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67a7e7900 of size 9437184 next 3270\n",
      "2024-09-19 17:20:59.926827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67b0e7900 of size 2097152 next 3273\n",
      "2024-09-19 17:20:59.926829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67b2e7900 of size 9437184 next 3285\n",
      "2024-09-19 17:20:59.926831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67bbe7900 of size 4194304 next 3292\n",
      "2024-09-19 17:20:59.926834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67bfe7900 of size 2359296 next 3295\n",
      "2024-09-19 17:20:59.926836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67c227900 of size 4194304 next 3300\n",
      "2024-09-19 17:20:59.926838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67c627900 of size 9437184 next 1784\n",
      "2024-09-19 17:20:59.926841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67cf27900 of size 4194304 next 1783\n",
      "2024-09-19 17:20:59.926843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67d327900 of size 4194304 next 1782\n",
      "2024-09-19 17:20:59.926845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67d727900 of size 37632 next 1781\n",
      "2024-09-19 17:20:59.926848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67d730c00 of size 9437184 next 1780\n",
      "2024-09-19 17:20:59.926850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e030c00 of size 4194304 next 1779\n",
      "2024-09-19 17:20:59.926852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e430c00 of size 1048576 next 1778\n",
      "2024-09-19 17:20:59.926855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e530c00 of size 2097152 next 1777\n",
      "2024-09-19 17:20:59.926857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e730c00 of size 256 next 1776\n",
      "2024-09-19 17:20:59.926859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e730d00 of size 256 next 1775\n",
      "2024-09-19 17:20:59.926862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e730e00 of size 256 next 1774\n",
      "2024-09-19 17:20:59.926864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e730f00 of size 256 next 1773\n",
      "2024-09-19 17:20:59.926866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e731000 of size 1179648 next 1772\n",
      "2024-09-19 17:20:59.926868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e851000 of size 256 next 1771\n",
      "2024-09-19 17:20:59.926871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e851100 of size 256 next 1770\n",
      "2024-09-19 17:20:59.926873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e851200 of size 256 next 1769\n",
      "2024-09-19 17:20:59.926875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e851300 of size 1032192 next 1768\n",
      "2024-09-19 17:20:59.926878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e94d300 of size 256 next 1767\n",
      "2024-09-19 17:20:59.926880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e94d400 of size 256 next 1766\n",
      "2024-09-19 17:20:59.926882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e94d500 of size 256 next 1765\n",
      "2024-09-19 17:20:59.926884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e94d600 of size 589824 next 1764\n",
      "2024-09-19 17:20:59.926887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9dd600 of size 256 next 1763\n",
      "2024-09-19 17:20:59.926889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9dd700 of size 256 next 1762\n",
      "2024-09-19 17:20:59.926891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9dd800 of size 256 next 1761\n",
      "2024-09-19 17:20:59.926893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9dd900 of size 256 next 1760\n",
      "2024-09-19 17:20:59.926896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9dda00 of size 256 next 1759\n",
      "2024-09-19 17:20:59.926898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9ddb00 of size 256 next 1758\n",
      "2024-09-19 17:20:59.926900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9ddc00 of size 256 next 1757\n",
      "2024-09-19 17:20:59.926903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9ddd00 of size 16384 next 1756\n",
      "2024-09-19 17:20:59.926905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e1d00 of size 256 next 1755\n",
      "2024-09-19 17:20:59.926907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e1e00 of size 256 next 1754\n",
      "2024-09-19 17:20:59.926909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e1f00 of size 256 next 1753\n",
      "2024-09-19 17:20:59.926912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e2000 of size 256 next 1752\n",
      "2024-09-19 17:20:59.926914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e2100 of size 256 next 1751\n",
      "2024-09-19 17:20:59.926916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e2200 of size 256 next 1750\n",
      "2024-09-19 17:20:59.926918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67e9e2300 of size 147456 next 1749\n",
      "2024-09-19 17:20:59.926921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea06300 of size 256 next 1748\n",
      "2024-09-19 17:20:59.926923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea06400 of size 1024 next 1747\n",
      "2024-09-19 17:20:59.926925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea06800 of size 1024 next 1746\n",
      "2024-09-19 17:20:59.926927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea06c00 of size 1024 next 1745\n",
      "2024-09-19 17:20:59.926930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea07000 of size 1024 next 1744\n",
      "2024-09-19 17:20:59.926932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea07400 of size 1024 next 1743\n",
      "2024-09-19 17:20:59.926934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea07800 of size 65536 next 1742\n",
      "2024-09-19 17:20:59.926937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea17800 of size 256 next 1741\n",
      "2024-09-19 17:20:59.926939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea17900 of size 1024 next 1740\n",
      "2024-09-19 17:20:59.926941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea17d00 of size 1024 next 1739\n",
      "2024-09-19 17:20:59.926943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea18100 of size 1024 next 1738\n",
      "2024-09-19 17:20:59.926946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea18500 of size 1024 next 1737\n",
      "2024-09-19 17:20:59.926948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea18900 of size 1024 next 1736\n",
      "2024-09-19 17:20:59.926950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea18d00 of size 65536 next 1735\n",
      "2024-09-19 17:20:59.926952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea28d00 of size 256 next 1734\n",
      "2024-09-19 17:20:59.926955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea28e00 of size 256 next 1733\n",
      "2024-09-19 17:20:59.926957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea28f00 of size 256 next 1732\n",
      "2024-09-19 17:20:59.926959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea29000 of size 256 next 1731\n",
      "2024-09-19 17:20:59.926962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea29100 of size 256 next 1730\n",
      "2024-09-19 17:20:59.926964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea29200 of size 256 next 1729\n",
      "2024-09-19 17:20:59.926966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea29300 of size 65536 next 1728\n",
      "2024-09-19 17:20:59.926968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39300 of size 256 next 1727\n",
      "2024-09-19 17:20:59.926971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39400 of size 256 next 1726\n",
      "2024-09-19 17:20:59.926973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39500 of size 256 next 1725\n",
      "2024-09-19 17:20:59.926975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39600 of size 256 next 1724\n",
      "2024-09-19 17:20:59.926978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39700 of size 256 next 1723\n",
      "2024-09-19 17:20:59.926980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39800 of size 256 next 1722\n",
      "2024-09-19 17:20:59.926982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea39900 of size 147456 next 1721\n",
      "2024-09-19 17:20:59.926984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5d900 of size 256 next 1720\n",
      "2024-09-19 17:20:59.926987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5da00 of size 1024 next 1719\n",
      "2024-09-19 17:20:59.926989: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5de00 of size 1024 next 1718\n",
      "2024-09-19 17:20:59.926991: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5e200 of size 1024 next 1717\n",
      "2024-09-19 17:20:59.926993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5e600 of size 1024 next 1716\n",
      "2024-09-19 17:20:59.926996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5ea00 of size 1024 next 1715\n",
      "2024-09-19 17:20:59.926998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea5ee00 of size 65536 next 1714\n",
      "2024-09-19 17:20:59.927000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6ee00 of size 256 next 1713\n",
      "2024-09-19 17:20:59.927003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6ef00 of size 256 next 1712\n",
      "2024-09-19 17:20:59.927005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6f000 of size 256 next 1711\n",
      "2024-09-19 17:20:59.927007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6f100 of size 256 next 1710\n",
      "2024-09-19 17:20:59.927009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6f200 of size 256 next 1709\n",
      "2024-09-19 17:20:59.927012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6f300 of size 256 next 1708\n",
      "2024-09-19 17:20:59.927014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea6f400 of size 65536 next 1707\n",
      "2024-09-19 17:20:59.927016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f400 of size 256 next 1706\n",
      "2024-09-19 17:20:59.927018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f500 of size 256 next 1705\n",
      "2024-09-19 17:20:59.927021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f600 of size 256 next 1704\n",
      "2024-09-19 17:20:59.927023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f700 of size 256 next 1703\n",
      "2024-09-19 17:20:59.927025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f800 of size 256 next 1702\n",
      "2024-09-19 17:20:59.927028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7f900 of size 256 next 1701\n",
      "2024-09-19 17:20:59.927030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ea7fa00 of size 147456 next 1700\n",
      "2024-09-19 17:20:59.927032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa3a00 of size 256 next 1699\n",
      "2024-09-19 17:20:59.927034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa3b00 of size 1024 next 1698\n",
      "2024-09-19 17:20:59.927037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa3f00 of size 1024 next 1697\n",
      "2024-09-19 17:20:59.927039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa4300 of size 1024 next 1696\n",
      "2024-09-19 17:20:59.927041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa4700 of size 1024 next 1695\n",
      "2024-09-19 17:20:59.927043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa4b00 of size 1024 next 1694\n",
      "2024-09-19 17:20:59.927046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eaa4f00 of size 65536 next 1693\n",
      "2024-09-19 17:20:59.927048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab4f00 of size 256 next 1692\n",
      "2024-09-19 17:20:59.927050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5000 of size 512 next 1691\n",
      "2024-09-19 17:20:59.927053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5200 of size 512 next 1690\n",
      "2024-09-19 17:20:59.927055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5400 of size 512 next 1689\n",
      "2024-09-19 17:20:59.927057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5600 of size 512 next 1688\n",
      "2024-09-19 17:20:59.927059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5800 of size 512 next 1687\n",
      "2024-09-19 17:20:59.927062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eab5a00 of size 131072 next 1686\n",
      "2024-09-19 17:20:59.927064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead5a00 of size 256 next 1685\n",
      "2024-09-19 17:20:59.927066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead5b00 of size 512 next 1684\n",
      "2024-09-19 17:20:59.927069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead5d00 of size 512 next 1683\n",
      "2024-09-19 17:20:59.927071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead5f00 of size 512 next 1682\n",
      "2024-09-19 17:20:59.927073: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead6100 of size 512 next 1681\n",
      "2024-09-19 17:20:59.927075: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead6300 of size 512 next 1680\n",
      "2024-09-19 17:20:59.927078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ead6500 of size 589824 next 1679\n",
      "2024-09-19 17:20:59.927080: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb66500 of size 256 next 1678\n",
      "2024-09-19 17:20:59.927082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb66600 of size 2048 next 1677\n",
      "2024-09-19 17:20:59.927085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb66e00 of size 2048 next 1676\n",
      "2024-09-19 17:20:59.927087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb67600 of size 2048 next 1397\n",
      "2024-09-19 17:20:59.927089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb67e00 of size 2048 next 1418\n",
      "2024-09-19 17:20:59.927092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb68600 of size 2048 next 1398\n",
      "2024-09-19 17:20:59.927094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eb68e00 of size 262144 next 1399\n",
      "2024-09-19 17:20:59.927096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eba8e00 of size 256 next 1393\n",
      "2024-09-19 17:20:59.927099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eba8f00 of size 2048 next 1383\n",
      "2024-09-19 17:20:59.927101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eba9700 of size 2048 next 1391\n",
      "2024-09-19 17:20:59.927103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67eba9f00 of size 2048 next 1390\n",
      "2024-09-19 17:20:59.927105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ebaa700 of size 2048 next 1386\n",
      "2024-09-19 17:20:59.927108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ebaaf00 of size 2048 next 1388\n",
      "2024-09-19 17:20:59.927110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ebab700 of size 524288 next 1385\n",
      "2024-09-19 17:20:59.927113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2b700 of size 256 next 1424\n",
      "2024-09-19 17:20:59.927115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2b800 of size 512 next 1403\n",
      "2024-09-19 17:20:59.927117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2ba00 of size 512 next 1402\n",
      "2024-09-19 17:20:59.927120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2bc00 of size 512 next 1968\n",
      "2024-09-19 17:20:59.927122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2be00 of size 512 next 1967\n",
      "2024-09-19 17:20:59.927124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2c000 of size 512 next 3319\n",
      "2024-09-19 17:20:59.927127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec2c200 of size 262144 next 3321\n",
      "2024-09-19 17:20:59.927129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6c200 of size 256 next 3317\n",
      "2024-09-19 17:20:59.927131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6c300 of size 512 next 3322\n",
      "2024-09-19 17:20:59.927133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6c500 of size 512 next 3323\n",
      "2024-09-19 17:20:59.927136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6c700 of size 512 next 3318\n",
      "2024-09-19 17:20:59.927138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6c900 of size 512 next 3320\n",
      "2024-09-19 17:20:59.927140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6cb00 of size 512 next 3324\n",
      "2024-09-19 17:20:59.927143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ec6cd00 of size 589824 next 3325\n",
      "2024-09-19 17:20:59.927145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfcd00 of size 256 next 3326\n",
      "2024-09-19 17:20:59.927147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfce00 of size 2048 next 3327\n",
      "2024-09-19 17:20:59.927149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfd600 of size 2048 next 3328\n",
      "2024-09-19 17:20:59.927152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfde00 of size 2048 next 3329\n",
      "2024-09-19 17:20:59.927154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfe600 of size 2048 next 3330\n",
      "2024-09-19 17:20:59.927156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecfee00 of size 2048 next 3331\n",
      "2024-09-19 17:20:59.927159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ecff600 of size 262144 next 3332\n",
      "2024-09-19 17:20:59.927161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3f600 of size 256 next 3333\n",
      "2024-09-19 17:20:59.927163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3f700 of size 512 next 3334\n",
      "2024-09-19 17:20:59.927165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3f900 of size 512 next 3335\n",
      "2024-09-19 17:20:59.927168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3fb00 of size 512 next 3336\n",
      "2024-09-19 17:20:59.927170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3fd00 of size 512 next 3337\n",
      "2024-09-19 17:20:59.927172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed3ff00 of size 512 next 3338\n",
      "2024-09-19 17:20:59.927174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed40100 of size 262144 next 3339\n",
      "2024-09-19 17:20:59.927177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80100 of size 256 next 3340\n",
      "2024-09-19 17:20:59.927179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80200 of size 512 next 3341\n",
      "2024-09-19 17:20:59.927181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80400 of size 512 next 3342\n",
      "2024-09-19 17:20:59.927184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80600 of size 512 next 3343\n",
      "2024-09-19 17:20:59.927186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80800 of size 512 next 3344\n",
      "2024-09-19 17:20:59.927188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80a00 of size 512 next 3345\n",
      "2024-09-19 17:20:59.927190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ed80c00 of size 589824 next 3346\n",
      "2024-09-19 17:20:59.927193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee10c00 of size 256 next 3347\n",
      "2024-09-19 17:20:59.927195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee10d00 of size 2048 next 3348\n",
      "2024-09-19 17:20:59.927197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee11500 of size 2048 next 3349\n",
      "2024-09-19 17:20:59.927200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee11d00 of size 2048 next 3350\n",
      "2024-09-19 17:20:59.927202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee12500 of size 2048 next 3351\n",
      "2024-09-19 17:20:59.927204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee12d00 of size 2048 next 3352\n",
      "2024-09-19 17:20:59.927206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee13500 of size 262144 next 3353\n",
      "2024-09-19 17:20:59.927209: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53500 of size 256 next 3354\n",
      "2024-09-19 17:20:59.927211: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53600 of size 512 next 3355\n",
      "2024-09-19 17:20:59.927213: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53800 of size 512 next 3356\n",
      "2024-09-19 17:20:59.927215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53a00 of size 512 next 3357\n",
      "2024-09-19 17:20:59.927218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53c00 of size 512 next 3358\n",
      "2024-09-19 17:20:59.927220: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee53e00 of size 512 next 3359\n",
      "2024-09-19 17:20:59.927222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee54000 of size 262144 next 3360\n",
      "2024-09-19 17:20:59.927225: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94000 of size 256 next 3361\n",
      "2024-09-19 17:20:59.927227: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94100 of size 512 next 3362\n",
      "2024-09-19 17:20:59.927229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94300 of size 512 next 3363\n",
      "2024-09-19 17:20:59.927231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94500 of size 512 next 3364\n",
      "2024-09-19 17:20:59.927234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94700 of size 512 next 3365\n",
      "2024-09-19 17:20:59.927236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94900 of size 512 next 3366\n",
      "2024-09-19 17:20:59.927238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ee94b00 of size 589824 next 3367\n",
      "2024-09-19 17:20:59.927241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef24b00 of size 256 next 3368\n",
      "2024-09-19 17:20:59.927243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef24c00 of size 2048 next 3369\n",
      "2024-09-19 17:20:59.927245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef25400 of size 2048 next 3370\n",
      "2024-09-19 17:20:59.927247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef25c00 of size 2048 next 3371\n",
      "2024-09-19 17:20:59.927250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef26400 of size 2048 next 3372\n",
      "2024-09-19 17:20:59.927252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef26c00 of size 2048 next 3373\n",
      "2024-09-19 17:20:59.927254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef27400 of size 262144 next 3374\n",
      "2024-09-19 17:20:59.927256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef67400 of size 256 next 3375\n",
      "2024-09-19 17:20:59.927259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef67500 of size 1024 next 3376\n",
      "2024-09-19 17:20:59.927261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef67900 of size 1024 next 3377\n",
      "2024-09-19 17:20:59.927263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef67d00 of size 1024 next 3378\n",
      "2024-09-19 17:20:59.927266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef68100 of size 1024 next 3379\n",
      "2024-09-19 17:20:59.927268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef68500 of size 1024 next 3380\n",
      "2024-09-19 17:20:59.927270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67ef68900 of size 524288 next 3381\n",
      "2024-09-19 17:20:59.927272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe8900 of size 256 next 3382\n",
      "2024-09-19 17:20:59.927275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe8a00 of size 1024 next 3383\n",
      "2024-09-19 17:20:59.927277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe8e00 of size 1024 next 3384\n",
      "2024-09-19 17:20:59.927280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe9200 of size 1024 next 3385\n",
      "2024-09-19 17:20:59.927282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe9600 of size 1024 next 3386\n",
      "2024-09-19 17:20:59.927284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe9a00 of size 1024 next 3387\n",
      "2024-09-19 17:20:59.927286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67efe9e00 of size 2359296 next 3388\n",
      "2024-09-19 17:20:59.927289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f229e00 of size 256 next 3389\n",
      "2024-09-19 17:20:59.927291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f229f00 of size 4096 next 3390\n",
      "2024-09-19 17:20:59.927293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f22af00 of size 4096 next 3391\n",
      "2024-09-19 17:20:59.927296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f22bf00 of size 4096 next 3392\n",
      "2024-09-19 17:20:59.927298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f22cf00 of size 4096 next 3393\n",
      "2024-09-19 17:20:59.927300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f22df00 of size 4096 next 3394\n",
      "2024-09-19 17:20:59.927303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f22ef00 of size 1048576 next 3395\n",
      "2024-09-19 17:20:59.927305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f32ef00 of size 256 next 3396\n",
      "2024-09-19 17:20:59.927307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f32f000 of size 4096 next 3397\n",
      "2024-09-19 17:20:59.927309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f330000 of size 4096 next 3398\n",
      "2024-09-19 17:20:59.927312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f331000 of size 4096 next 3399\n",
      "2024-09-19 17:20:59.927314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f332000 of size 4096 next 3400\n",
      "2024-09-19 17:20:59.927316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f333000 of size 4096 next 3401\n",
      "2024-09-19 17:20:59.927319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f334000 of size 2097152 next 3402\n",
      "2024-09-19 17:20:59.927321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f534000 of size 256 next 3403\n",
      "2024-09-19 17:20:59.927323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f534100 of size 1024 next 3404\n",
      "2024-09-19 17:20:59.927325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f534500 of size 1024 next 3405\n",
      "2024-09-19 17:20:59.927328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f534900 of size 1024 next 3406\n",
      "2024-09-19 17:20:59.927330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f534d00 of size 1024 next 3407\n",
      "2024-09-19 17:20:59.927332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f535100 of size 1024 next 3408\n",
      "2024-09-19 17:20:59.927335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f535500 of size 1048576 next 3409\n",
      "2024-09-19 17:20:59.927337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f635500 of size 256 next 3410\n",
      "2024-09-19 17:20:59.927339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f635600 of size 1024 next 3411\n",
      "2024-09-19 17:20:59.927341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f635a00 of size 1024 next 3412\n",
      "2024-09-19 17:20:59.927344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f635e00 of size 1024 next 3413\n",
      "2024-09-19 17:20:59.927346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f636200 of size 1024 next 3414\n",
      "2024-09-19 17:20:59.927349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f636600 of size 1024 next 3415\n",
      "2024-09-19 17:20:59.927351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f636a00 of size 2359296 next 3416\n",
      "2024-09-19 17:20:59.927353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f876a00 of size 256 next 3417\n",
      "2024-09-19 17:20:59.927355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f876b00 of size 4096 next 3418\n",
      "2024-09-19 17:20:59.927358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f877b00 of size 4096 next 3419\n",
      "2024-09-19 17:20:59.927360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f878b00 of size 4096 next 3420\n",
      "2024-09-19 17:20:59.927362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f879b00 of size 4096 next 3421\n",
      "2024-09-19 17:20:59.927365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f87ab00 of size 4096 next 3422\n",
      "2024-09-19 17:20:59.927367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f87bb00 of size 1048576 next 3423\n",
      "2024-09-19 17:20:59.927369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97bb00 of size 256 next 3424\n",
      "2024-09-19 17:20:59.927371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97bc00 of size 1024 next 3425\n",
      "2024-09-19 17:20:59.927374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97c000 of size 1024 next 3426\n",
      "2024-09-19 17:20:59.927376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97c400 of size 1024 next 3427\n",
      "2024-09-19 17:20:59.927378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97c800 of size 1024 next 3428\n",
      "2024-09-19 17:20:59.927380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97cc00 of size 1024 next 3429\n",
      "2024-09-19 17:20:59.927383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67f97d000 of size 1048576 next 3430\n",
      "2024-09-19 17:20:59.927385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7d000 of size 256 next 3431\n",
      "2024-09-19 17:20:59.927387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7d100 of size 1024 next 3432\n",
      "2024-09-19 17:20:59.927389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7d500 of size 1024 next 3433\n",
      "2024-09-19 17:20:59.927392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7d900 of size 1024 next 3434\n",
      "2024-09-19 17:20:59.927394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7dd00 of size 1024 next 3435\n",
      "2024-09-19 17:20:59.927396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7e100 of size 1024 next 3436\n",
      "2024-09-19 17:20:59.927399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fa7e500 of size 2359296 next 3437\n",
      "2024-09-19 17:20:59.927401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcbe500 of size 256 next 3438\n",
      "2024-09-19 17:20:59.927403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcbe600 of size 4096 next 3439\n",
      "2024-09-19 17:20:59.927405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcbf600 of size 4096 next 3440\n",
      "2024-09-19 17:20:59.927408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcc0600 of size 4096 next 3441\n",
      "2024-09-19 17:20:59.927410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcc1600 of size 4096 next 3442\n",
      "2024-09-19 17:20:59.927412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcc2600 of size 4096 next 3443\n",
      "2024-09-19 17:20:59.927415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fcc3600 of size 1048576 next 3444\n",
      "2024-09-19 17:20:59.927417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc3600 of size 256 next 3445\n",
      "2024-09-19 17:20:59.927419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc3700 of size 1024 next 3446\n",
      "2024-09-19 17:20:59.927421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc3b00 of size 1024 next 3447\n",
      "2024-09-19 17:20:59.927424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc3f00 of size 1024 next 3448\n",
      "2024-09-19 17:20:59.927426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc4300 of size 1024 next 3449\n",
      "2024-09-19 17:20:59.927428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc4700 of size 1024 next 3450\n",
      "2024-09-19 17:20:59.927430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fdc4b00 of size 1048576 next 3451\n",
      "2024-09-19 17:20:59.927433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec4b00 of size 256 next 3452\n",
      "2024-09-19 17:20:59.927435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec4c00 of size 1024 next 3453\n",
      "2024-09-19 17:20:59.927437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec5000 of size 1024 next 3454\n",
      "2024-09-19 17:20:59.927440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec5400 of size 1024 next 3455\n",
      "2024-09-19 17:20:59.927442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec5800 of size 1024 next 3456\n",
      "2024-09-19 17:20:59.927444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec5c00 of size 1024 next 3457\n",
      "2024-09-19 17:20:59.927447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec6000 of size 256 next 3460\n",
      "2024-09-19 17:20:59.927449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec6100 of size 4096 next 3461\n",
      "2024-09-19 17:20:59.927451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec7100 of size 4096 next 3462\n",
      "2024-09-19 17:20:59.927453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec8100 of size 4096 next 3463\n",
      "2024-09-19 17:20:59.927456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fec9100 of size 4096 next 3464\n",
      "2024-09-19 17:20:59.927458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67feca100 of size 4096 next 3465\n",
      "2024-09-19 17:20:59.927460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa67fecb100 of size 1265408 next 18446744073709551615\n",
      "2024-09-19 17:20:59.927463: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 268435456\n",
      "2024-09-19 17:20:59.927465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688000000 of size 256 next 1668\n",
      "2024-09-19 17:20:59.927467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688000100 of size 4096 next 1546\n",
      "2024-09-19 17:20:59.927470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688001100 of size 4096 next 1409\n",
      "2024-09-19 17:20:59.927472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688002100 of size 4096 next 1410\n",
      "2024-09-19 17:20:59.927474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688003100 of size 4096 next 1412\n",
      "2024-09-19 17:20:59.927477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688004100 of size 4096 next 1477\n",
      "2024-09-19 17:20:59.927479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688005100 of size 2097152 next 1509\n",
      "2024-09-19 17:20:59.927481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688205100 of size 256 next 1470\n",
      "2024-09-19 17:20:59.927484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688205200 of size 1024 next 1420\n",
      "2024-09-19 17:20:59.927486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688205600 of size 1024 next 1425\n",
      "2024-09-19 17:20:59.927489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688205a00 of size 1024 next 1570\n",
      "2024-09-19 17:20:59.927491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688205e00 of size 1024 next 1537\n",
      "2024-09-19 17:20:59.927493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688206200 of size 1024 next 328\n",
      "2024-09-19 17:20:59.927495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688206600 of size 1048576 next 1501\n",
      "2024-09-19 17:20:59.927498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688306600 of size 256 next 1646\n",
      "2024-09-19 17:20:59.927500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688306700 of size 1024 next 1459\n",
      "2024-09-19 17:20:59.927502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688306b00 of size 1024 next 1439\n",
      "2024-09-19 17:20:59.927505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688306f00 of size 1024 next 1440\n",
      "2024-09-19 17:20:59.927507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688307300 of size 1024 next 1436\n",
      "2024-09-19 17:20:59.927509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688307700 of size 1024 next 1437\n",
      "2024-09-19 17:20:59.927512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688307b00 of size 2359296 next 1617\n",
      "2024-09-19 17:20:59.927514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688547b00 of size 256 next 1618\n",
      "2024-09-19 17:20:59.927516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688547c00 of size 4096 next 1395\n",
      "2024-09-19 17:20:59.927519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688548c00 of size 4096 next 1520\n",
      "2024-09-19 17:20:59.927521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688549c00 of size 4096 next 1521\n",
      "2024-09-19 17:20:59.927523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68854ac00 of size 4096 next 1426\n",
      "2024-09-19 17:20:59.927526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68854bc00 of size 4096 next 1467\n",
      "2024-09-19 17:20:59.927528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68854cc00 of size 1048576 next 1445\n",
      "2024-09-19 17:20:59.927530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864cc00 of size 256 next 1503\n",
      "2024-09-19 17:20:59.927533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864cd00 of size 1024 next 1641\n",
      "2024-09-19 17:20:59.927535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864d100 of size 1024 next 1438\n",
      "2024-09-19 17:20:59.927537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864d500 of size 1024 next 1525\n",
      "2024-09-19 17:20:59.927540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864d900 of size 1024 next 1527\n",
      "2024-09-19 17:20:59.927542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864dd00 of size 1024 next 1599\n",
      "2024-09-19 17:20:59.927544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68864e100 of size 1777408 next 927\n",
      "2024-09-19 17:20:59.927547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688800000 of size 256 next 1894\n",
      "2024-09-19 17:20:59.927549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688800100 of size 8192 next 1893\n",
      "2024-09-19 17:20:59.927551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688802100 of size 8192 next 1892\n",
      "2024-09-19 17:20:59.927554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688804100 of size 8192 next 1891\n",
      "2024-09-19 17:20:59.927556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688806100 of size 8192 next 1890\n",
      "2024-09-19 17:20:59.927558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688808100 of size 8192 next 1889\n",
      "2024-09-19 17:20:59.927560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68880a100 of size 4194304 next 1888\n",
      "2024-09-19 17:20:59.927563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c0a100 of size 256 next 1887\n",
      "2024-09-19 17:20:59.927565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c0a200 of size 8192 next 1886\n",
      "2024-09-19 17:20:59.927567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c0c200 of size 8192 next 1885\n",
      "2024-09-19 17:20:59.927569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c0e200 of size 8192 next 1884\n",
      "2024-09-19 17:20:59.927572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c10200 of size 8192 next 1883\n",
      "2024-09-19 17:20:59.927574: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c12200 of size 8192 next 1882\n",
      "2024-09-19 17:20:59.927576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa688c14200 of size 9354752 next 1937\n",
      "2024-09-19 17:20:59.927579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa689500000 of size 2097152 next 572\n",
      "2024-09-19 17:20:59.927581: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa689700000 of size 13664256 next 1415\n",
      "2024-09-19 17:20:59.927584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a408000 of size 32256 next 2183\n",
      "2024-09-19 17:20:59.927586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a40fe00 of size 8192 next 580\n",
      "2024-09-19 17:20:59.927588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a411e00 of size 2048 next 327\n",
      "2024-09-19 17:20:59.927591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a412600 of size 2048 next 414\n",
      "2024-09-19 17:20:59.927593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a412e00 of size 8192 next 548\n",
      "2024-09-19 17:20:59.927596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a414e00 of size 2048 next 283\n",
      "2024-09-19 17:20:59.927598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a415600 of size 8192 next 395\n",
      "2024-09-19 17:20:59.927601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a417600 of size 256 next 353\n",
      "2024-09-19 17:20:59.927603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a417700 of size 1024 next 326\n",
      "2024-09-19 17:20:59.927605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a417b00 of size 1024 next 411\n",
      "2024-09-19 17:20:59.927608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a417f00 of size 1024 next 477\n",
      "2024-09-19 17:20:59.927610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a418300 of size 2048 next 342\n",
      "2024-09-19 17:20:59.927612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a418b00 of size 8192 next 457\n",
      "2024-09-19 17:20:59.927614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a41ab00 of size 8192 next 470\n",
      "2024-09-19 17:20:59.927617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a41cb00 of size 2048 next 552\n",
      "2024-09-19 17:20:59.927619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a41d300 of size 2048 next 479\n",
      "2024-09-19 17:20:59.927622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a41db00 of size 8192 next 491\n",
      "2024-09-19 17:20:59.927624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a41fb00 of size 37632 next 493\n",
      "2024-09-19 17:20:59.927626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a428e00 of size 256 next 557\n",
      "2024-09-19 17:20:59.927629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a428f00 of size 256 next 558\n",
      "2024-09-19 17:20:59.927631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a429000 of size 256 next 428\n",
      "2024-09-19 17:20:59.927633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a429100 of size 256 next 429\n",
      "2024-09-19 17:20:59.927635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a429200 of size 16384 next 498\n",
      "2024-09-19 17:20:59.927638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a42d200 of size 1024 next 499\n",
      "2024-09-19 17:20:59.927640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a42d600 of size 256 next 474\n",
      "2024-09-19 17:20:59.927642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a42d700 of size 65536 next 475\n",
      "2024-09-19 17:20:59.927645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a43d700 of size 131072 next 559\n",
      "2024-09-19 17:20:59.927647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45d700 of size 1024 next 346\n",
      "2024-09-19 17:20:59.927649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45db00 of size 256 next 416\n",
      "2024-09-19 17:20:59.927652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45dc00 of size 256 next 310\n",
      "2024-09-19 17:20:59.927654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45dd00 of size 256 next 345\n",
      "2024-09-19 17:20:59.927656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45de00 of size 1024 next 349\n",
      "2024-09-19 17:20:59.927659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45e200 of size 256 next 514\n",
      "2024-09-19 17:20:59.927661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45e300 of size 256 next 375\n",
      "2024-09-19 17:20:59.927663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a45e400 of size 65536 next 351\n",
      "2024-09-19 17:20:59.927666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a46e400 of size 256 next 485\n",
      "2024-09-19 17:20:59.927668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a46e500 of size 65536 next 370\n",
      "2024-09-19 17:20:59.927670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47e500 of size 1024 next 447\n",
      "2024-09-19 17:20:59.927673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47e900 of size 256 next 476\n",
      "2024-09-19 17:20:59.927675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47ea00 of size 256 next 330\n",
      "2024-09-19 17:20:59.927677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47eb00 of size 256 next 417\n",
      "2024-09-19 17:20:59.927680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47ec00 of size 256 next 394\n",
      "2024-09-19 17:20:59.927682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a47ed00 of size 8192 next 413\n",
      "2024-09-19 17:20:59.927684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a480d00 of size 256 next 480\n",
      "2024-09-19 17:20:59.927687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a480e00 of size 1024 next 563\n",
      "2024-09-19 17:20:59.927689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481200 of size 256 next 421\n",
      "2024-09-19 17:20:59.927691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481300 of size 1024 next 488\n",
      "2024-09-19 17:20:59.927694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481700 of size 256 next 420\n",
      "2024-09-19 17:20:59.927696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481800 of size 256 next 439\n",
      "2024-09-19 17:20:59.927698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481900 of size 512 next 309\n",
      "2024-09-19 17:20:59.927700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481b00 of size 1024 next 357\n",
      "2024-09-19 17:20:59.927703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a481f00 of size 122624 next 581\n",
      "2024-09-19 17:20:59.927705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a49fe00 of size 8192 next 319\n",
      "2024-09-19 17:20:59.927707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a1e00 of size 512 next 408\n",
      "2024-09-19 17:20:59.927710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a2000 of size 1024 next 410\n",
      "2024-09-19 17:20:59.927712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a2400 of size 256 next 544\n",
      "2024-09-19 17:20:59.927714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a2500 of size 8192 next 547\n",
      "2024-09-19 17:20:59.927717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a4500 of size 1024 next 406\n",
      "2024-09-19 17:20:59.927719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a4900 of size 4096 next 407\n",
      "2024-09-19 17:20:59.927721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a5900 of size 1024 next 278\n",
      "2024-09-19 17:20:59.927724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a5d00 of size 1024 next 562\n",
      "2024-09-19 17:20:59.927726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a6100 of size 4096 next 512\n",
      "2024-09-19 17:20:59.927728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a7100 of size 4096 next 513\n",
      "2024-09-19 17:20:59.927731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a8100 of size 1024 next 340\n",
      "2024-09-19 17:20:59.927733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a8500 of size 4096 next 341\n",
      "2024-09-19 17:20:59.927735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a9500 of size 1024 next 374\n",
      "2024-09-19 17:20:59.927737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4a9900 of size 4096 next 338\n",
      "2024-09-19 17:20:59.927740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4aa900 of size 2048 next 339\n",
      "2024-09-19 17:20:59.927742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ab100 of size 8192 next 461\n",
      "2024-09-19 17:20:59.927744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ad100 of size 4096 next 550\n",
      "2024-09-19 17:20:59.927747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ae100 of size 1024 next 316\n",
      "2024-09-19 17:20:59.927749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ae500 of size 1024 next 492\n",
      "2024-09-19 17:20:59.927751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ae900 of size 1024 next 329\n",
      "2024-09-19 17:20:59.927754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4aed00 of size 4096 next 539\n",
      "2024-09-19 17:20:59.927756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4afd00 of size 1024 next 511\n",
      "2024-09-19 17:20:59.927758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b0100 of size 1024 next 382\n",
      "2024-09-19 17:20:59.927761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b0500 of size 8192 next 549\n",
      "2024-09-19 17:20:59.927763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b2500 of size 4096 next 545\n",
      "2024-09-19 17:20:59.927766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b3500 of size 2048 next 350\n",
      "2024-09-19 17:20:59.927768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b3d00 of size 2048 next 466\n",
      "2024-09-19 17:20:59.927771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b4500 of size 2048 next 402\n",
      "2024-09-19 17:20:59.927773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b4d00 of size 2048 next 424\n",
      "2024-09-19 17:20:59.927775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b5500 of size 1024 next 425\n",
      "2024-09-19 17:20:59.927777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b5900 of size 1024 next 578\n",
      "2024-09-19 17:20:59.927780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b5d00 of size 1024 next 518\n",
      "2024-09-19 17:20:59.927782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b6100 of size 1024 next 520\n",
      "2024-09-19 17:20:59.927784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b6500 of size 1024 next 546\n",
      "2024-09-19 17:20:59.927787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b6900 of size 1024 next 306\n",
      "2024-09-19 17:20:59.927789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b6d00 of size 1024 next 441\n",
      "2024-09-19 17:20:59.927791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b7100 of size 1024 next 376\n",
      "2024-09-19 17:20:59.927794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b7500 of size 1024 next 365\n",
      "2024-09-19 17:20:59.927796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b7900 of size 8192 next 366\n",
      "2024-09-19 17:20:59.927798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4b9900 of size 2048 next 504\n",
      "2024-09-19 17:20:59.927801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4ba100 of size 4096 next 519\n",
      "2024-09-19 17:20:59.927803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bb100 of size 2048 next 517\n",
      "2024-09-19 17:20:59.927805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bb900 of size 2048 next 509\n",
      "2024-09-19 17:20:59.927808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bc100 of size 256 next 431\n",
      "2024-09-19 17:20:59.927810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bc200 of size 1024 next 299\n",
      "2024-09-19 17:20:59.927812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bc600 of size 1024 next 361\n",
      "2024-09-19 17:20:59.927814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bca00 of size 1024 next 521\n",
      "2024-09-19 17:20:59.927817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bce00 of size 1024 next 494\n",
      "2024-09-19 17:20:59.927819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bd200 of size 1024 next 495\n",
      "2024-09-19 17:20:59.927822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bd600 of size 1024 next 527\n",
      "2024-09-19 17:20:59.927824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bda00 of size 1024 next 356\n",
      "2024-09-19 17:20:59.927826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bde00 of size 2048 next 379\n",
      "2024-09-19 17:20:59.927829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4be600 of size 512 next 553\n",
      "2024-09-19 17:20:59.927831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4be800 of size 1024 next 522\n",
      "2024-09-19 17:20:59.927833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bec00 of size 1024 next 542\n",
      "2024-09-19 17:20:59.927835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bf000 of size 512 next 335\n",
      "2024-09-19 17:20:59.927838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bf200 of size 256 next 437\n",
      "2024-09-19 17:20:59.927840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bf300 of size 1024 next 320\n",
      "2024-09-19 17:20:59.927842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bf700 of size 256 next 460\n",
      "2024-09-19 17:20:59.927845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bf800 of size 1024 next 523\n",
      "2024-09-19 17:20:59.927847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bfc00 of size 512 next 380\n",
      "2024-09-19 17:20:59.927849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4bfe00 of size 4096 next 276\n",
      "2024-09-19 17:20:59.927852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c0e00 of size 1024 next 450\n",
      "2024-09-19 17:20:59.927854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c1200 of size 4096 next 506\n",
      "2024-09-19 17:20:59.927856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c2200 of size 1024 next 469\n",
      "2024-09-19 17:20:59.927859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c2600 of size 256 next 449\n",
      "2024-09-19 17:20:59.927861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c2700 of size 1024 next 448\n",
      "2024-09-19 17:20:59.927863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4c2b00 of size 65536 next 497\n",
      "2024-09-19 17:20:59.927866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d2b00 of size 1024 next 415\n",
      "2024-09-19 17:20:59.927868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d2f00 of size 256 next 253\n",
      "2024-09-19 17:20:59.927870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d3000 of size 1024 next 252\n",
      "2024-09-19 17:20:59.927872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d3400 of size 1024 next 251\n",
      "2024-09-19 17:20:59.927875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d3800 of size 1024 next 250\n",
      "2024-09-19 17:20:59.927877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d3c00 of size 1024 next 249\n",
      "2024-09-19 17:20:59.927879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d4000 of size 1024 next 248\n",
      "2024-09-19 17:20:59.927882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4d4400 of size 65536 next 247\n",
      "2024-09-19 17:20:59.927884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e4400 of size 256 next 246\n",
      "2024-09-19 17:20:59.927886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e4500 of size 1024 next 245\n",
      "2024-09-19 17:20:59.927889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e4900 of size 1024 next 244\n",
      "2024-09-19 17:20:59.927891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e4d00 of size 1024 next 243\n",
      "2024-09-19 17:20:59.927893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e5100 of size 1024 next 242\n",
      "2024-09-19 17:20:59.927896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e5500 of size 1024 next 241\n",
      "2024-09-19 17:20:59.927898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4e5900 of size 65536 next 240\n",
      "2024-09-19 17:20:59.927900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5900 of size 256 next 239\n",
      "2024-09-19 17:20:59.927902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5a00 of size 256 next 238\n",
      "2024-09-19 17:20:59.927905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5b00 of size 256 next 237\n",
      "2024-09-19 17:20:59.927907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5c00 of size 256 next 236\n",
      "2024-09-19 17:20:59.927909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5d00 of size 256 next 235\n",
      "2024-09-19 17:20:59.927911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5e00 of size 256 next 234\n",
      "2024-09-19 17:20:59.927914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a4f5f00 of size 65536 next 233\n",
      "2024-09-19 17:20:59.927916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a505f00 of size 256 next 232\n",
      "2024-09-19 17:20:59.927918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506000 of size 256 next 231\n",
      "2024-09-19 17:20:59.927921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506100 of size 256 next 230\n",
      "2024-09-19 17:20:59.927923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506200 of size 256 next 229\n",
      "2024-09-19 17:20:59.927925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506300 of size 256 next 228\n",
      "2024-09-19 17:20:59.927928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506400 of size 256 next 227\n",
      "2024-09-19 17:20:59.927930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a506500 of size 147456 next 226\n",
      "2024-09-19 17:20:59.927932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52a500 of size 256 next 225\n",
      "2024-09-19 17:20:59.927935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52a600 of size 1024 next 224\n",
      "2024-09-19 17:20:59.927937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52aa00 of size 1024 next 223\n",
      "2024-09-19 17:20:59.927939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52ae00 of size 1024 next 222\n",
      "2024-09-19 17:20:59.927942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52b200 of size 1024 next 221\n",
      "2024-09-19 17:20:59.927944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52b600 of size 1024 next 220\n",
      "2024-09-19 17:20:59.927946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a52ba00 of size 65536 next 219\n",
      "2024-09-19 17:20:59.927948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53ba00 of size 256 next 218\n",
      "2024-09-19 17:20:59.927951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53bb00 of size 256 next 217\n",
      "2024-09-19 17:20:59.927953: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53bc00 of size 256 next 216\n",
      "2024-09-19 17:20:59.927955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53bd00 of size 256 next 215\n",
      "2024-09-19 17:20:59.927958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53be00 of size 256 next 214\n",
      "2024-09-19 17:20:59.927960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53bf00 of size 256 next 213\n",
      "2024-09-19 17:20:59.927963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a53c000 of size 65536 next 212\n",
      "2024-09-19 17:20:59.927965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c000 of size 256 next 211\n",
      "2024-09-19 17:20:59.927967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c100 of size 256 next 210\n",
      "2024-09-19 17:20:59.927970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c200 of size 256 next 209\n",
      "2024-09-19 17:20:59.927972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c300 of size 256 next 208\n",
      "2024-09-19 17:20:59.927974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c400 of size 256 next 207\n",
      "2024-09-19 17:20:59.927976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c500 of size 256 next 206\n",
      "2024-09-19 17:20:59.927979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c600 of size 256 next 204\n",
      "2024-09-19 17:20:59.927981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54c700 of size 1024 next 203\n",
      "2024-09-19 17:20:59.927983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54cb00 of size 1024 next 202\n",
      "2024-09-19 17:20:59.927986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54cf00 of size 1024 next 201\n",
      "2024-09-19 17:20:59.927988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54d300 of size 1024 next 200\n",
      "2024-09-19 17:20:59.927990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54d700 of size 1024 next 199\n",
      "2024-09-19 17:20:59.927993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a54db00 of size 74496 next 579\n",
      "2024-09-19 17:20:59.927995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a55fe00 of size 2621440 next 577\n",
      "2024-09-19 17:20:59.927998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a7dfe00 of size 1048576 next 576\n",
      "2024-09-19 17:20:59.928001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a8dfe00 of size 1048576 next 575\n",
      "2024-09-19 17:20:59.928003: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9dfe00 of size 256 next 171\n",
      "2024-09-19 17:20:59.928005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9dff00 of size 512 next 170\n",
      "2024-09-19 17:20:59.928008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9e0100 of size 512 next 169\n",
      "2024-09-19 17:20:59.928010: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9e0300 of size 512 next 168\n",
      "2024-09-19 17:20:59.928012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9e0500 of size 512 next 167\n",
      "2024-09-19 17:20:59.928015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9e0700 of size 512 next 166\n",
      "2024-09-19 17:20:59.928017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68a9e0900 of size 262144 next 165\n",
      "2024-09-19 17:20:59.928019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa20900 of size 256 next 164\n",
      "2024-09-19 17:20:59.928021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa20a00 of size 512 next 163\n",
      "2024-09-19 17:20:59.928024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa20c00 of size 512 next 162\n",
      "2024-09-19 17:20:59.928026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa20e00 of size 512 next 161\n",
      "2024-09-19 17:20:59.928028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa21000 of size 512 next 160\n",
      "2024-09-19 17:20:59.928031: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa21200 of size 512 next 159\n",
      "2024-09-19 17:20:59.928033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aa21400 of size 589824 next 158\n",
      "2024-09-19 17:20:59.928036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab1400 of size 256 next 157\n",
      "2024-09-19 17:20:59.928038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab1500 of size 2048 next 156\n",
      "2024-09-19 17:20:59.928041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab1d00 of size 2048 next 155\n",
      "2024-09-19 17:20:59.928043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab2500 of size 2048 next 154\n",
      "2024-09-19 17:20:59.928046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab2d00 of size 2048 next 153\n",
      "2024-09-19 17:20:59.928048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab3500 of size 2048 next 152\n",
      "2024-09-19 17:20:59.928051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aab3d00 of size 262144 next 151\n",
      "2024-09-19 17:20:59.928053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf3d00 of size 256 next 150\n",
      "2024-09-19 17:20:59.928055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf3e00 of size 512 next 149\n",
      "2024-09-19 17:20:59.928058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf4000 of size 512 next 148\n",
      "2024-09-19 17:20:59.928060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf4200 of size 512 next 147\n",
      "2024-09-19 17:20:59.928062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf4400 of size 512 next 146\n",
      "2024-09-19 17:20:59.928064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf4600 of size 512 next 145\n",
      "2024-09-19 17:20:59.928067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68aaf4800 of size 262144 next 144\n",
      "2024-09-19 17:20:59.928069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab34800 of size 256 next 143\n",
      "2024-09-19 17:20:59.928071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab34900 of size 512 next 142\n",
      "2024-09-19 17:20:59.928074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab34b00 of size 512 next 141\n",
      "2024-09-19 17:20:59.928076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab34d00 of size 512 next 140\n",
      "2024-09-19 17:20:59.928078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab34f00 of size 512 next 139\n",
      "2024-09-19 17:20:59.928081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab35100 of size 512 next 138\n",
      "2024-09-19 17:20:59.928083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ab35300 of size 589824 next 137\n",
      "2024-09-19 17:20:59.928085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc5300 of size 256 next 136\n",
      "2024-09-19 17:20:59.928087: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc5400 of size 2048 next 135\n",
      "2024-09-19 17:20:59.928090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc5c00 of size 2048 next 134\n",
      "2024-09-19 17:20:59.928092: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc6400 of size 2048 next 133\n",
      "2024-09-19 17:20:59.928094: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc6c00 of size 2048 next 132\n",
      "2024-09-19 17:20:59.928097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc7400 of size 2048 next 131\n",
      "2024-09-19 17:20:59.928099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68abc7c00 of size 262144 next 130\n",
      "2024-09-19 17:20:59.928101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac07c00 of size 256 next 129\n",
      "2024-09-19 17:20:59.928103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac07d00 of size 512 next 128\n",
      "2024-09-19 17:20:59.928106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac07f00 of size 512 next 127\n",
      "2024-09-19 17:20:59.928108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac08100 of size 512 next 126\n",
      "2024-09-19 17:20:59.928111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac08300 of size 512 next 125\n",
      "2024-09-19 17:20:59.928113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac08500 of size 512 next 124\n",
      "2024-09-19 17:20:59.928115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac08700 of size 262144 next 123\n",
      "2024-09-19 17:20:59.928117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac48700 of size 256 next 122\n",
      "2024-09-19 17:20:59.928120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac48800 of size 512 next 121\n",
      "2024-09-19 17:20:59.928122: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac48a00 of size 512 next 120\n",
      "2024-09-19 17:20:59.928124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac48c00 of size 512 next 119\n",
      "2024-09-19 17:20:59.928126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac48e00 of size 512 next 118\n",
      "2024-09-19 17:20:59.928129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac49000 of size 512 next 117\n",
      "2024-09-19 17:20:59.928131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ac49200 of size 589824 next 116\n",
      "2024-09-19 17:20:59.928133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acd9200 of size 256 next 115\n",
      "2024-09-19 17:20:59.928136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acd9300 of size 2048 next 114\n",
      "2024-09-19 17:20:59.928138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acd9b00 of size 2048 next 113\n",
      "2024-09-19 17:20:59.928140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acda300 of size 2048 next 112\n",
      "2024-09-19 17:20:59.928142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acdab00 of size 2048 next 111\n",
      "2024-09-19 17:20:59.928145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acdb300 of size 2048 next 110\n",
      "2024-09-19 17:20:59.928147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68acdbb00 of size 262144 next 109\n",
      "2024-09-19 17:20:59.928149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1bb00 of size 256 next 108\n",
      "2024-09-19 17:20:59.928151: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1bc00 of size 1024 next 107\n",
      "2024-09-19 17:20:59.928154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1c000 of size 1024 next 106\n",
      "2024-09-19 17:20:59.928156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1c400 of size 1024 next 105\n",
      "2024-09-19 17:20:59.928158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1c800 of size 1024 next 104\n",
      "2024-09-19 17:20:59.928161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1cc00 of size 1024 next 103\n",
      "2024-09-19 17:20:59.928163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad1d000 of size 524288 next 102\n",
      "2024-09-19 17:20:59.928165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9d000 of size 256 next 101\n",
      "2024-09-19 17:20:59.928167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9d100 of size 1024 next 100\n",
      "2024-09-19 17:20:59.928170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9d500 of size 1024 next 99\n",
      "2024-09-19 17:20:59.928172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9d900 of size 1024 next 98\n",
      "2024-09-19 17:20:59.928174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9dd00 of size 1024 next 97\n",
      "2024-09-19 17:20:59.928177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9e100 of size 1024 next 96\n",
      "2024-09-19 17:20:59.928179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9e500 of size 256 next 94\n",
      "2024-09-19 17:20:59.928181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9e600 of size 4096 next 93\n",
      "2024-09-19 17:20:59.928184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ad9f600 of size 4096 next 92\n",
      "2024-09-19 17:20:59.928186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ada0600 of size 4096 next 91\n",
      "2024-09-19 17:20:59.928188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ada1600 of size 4096 next 90\n",
      "2024-09-19 17:20:59.928190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ada2600 of size 4096 next 89\n",
      "2024-09-19 17:20:59.928193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ada3600 of size 1558528 next 311\n",
      "2024-09-19 17:20:59.928195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68af1fe00 of size 1048576 next 399\n",
      "2024-09-19 17:20:59.928198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68b01fe00 of size 1310720 next 312\n",
      "2024-09-19 17:20:59.928200: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68b15fe00 of size 1048576 next 290\n",
      "2024-09-19 17:20:59.928202: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68b25fe00 of size 9437184 next 2251\n",
      "2024-09-19 17:20:59.928205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68bb5fe00 of size 4194304 next 2258\n",
      "2024-09-19 17:20:59.928207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68bf5fe00 of size 8388608 next 2265\n",
      "2024-09-19 17:20:59.928210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68c75fe00 of size 4194304 next 2272\n",
      "2024-09-19 17:20:59.928212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68cb5fe00 of size 16515072 next 869\n",
      "2024-09-19 17:20:59.928215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68db1fe00 of size 2097152 next 551\n",
      "2024-09-19 17:20:59.928217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68dd1fe00 of size 1048576 next 481\n",
      "2024-09-19 17:20:59.928219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68de1fe00 of size 1048576 next 868\n",
      "2024-09-19 17:20:59.928222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68df1fe00 of size 2359296 next 95\n",
      "2024-09-19 17:20:59.928224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e15fe00 of size 256 next 88\n",
      "2024-09-19 17:20:59.928226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e15ff00 of size 4096 next 87\n",
      "2024-09-19 17:20:59.928228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e160f00 of size 4096 next 86\n",
      "2024-09-19 17:20:59.928231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e161f00 of size 4096 next 85\n",
      "2024-09-19 17:20:59.928233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e162f00 of size 4096 next 84\n",
      "2024-09-19 17:20:59.928235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e163f00 of size 4096 next 83\n",
      "2024-09-19 17:20:59.928238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e164f00 of size 2097152 next 82\n",
      "2024-09-19 17:20:59.928240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e364f00 of size 256 next 81\n",
      "2024-09-19 17:20:59.928242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e365000 of size 1024 next 80\n",
      "2024-09-19 17:20:59.928244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e365400 of size 1024 next 79\n",
      "2024-09-19 17:20:59.928247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e365800 of size 1024 next 78\n",
      "2024-09-19 17:20:59.928249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e365c00 of size 1024 next 77\n",
      "2024-09-19 17:20:59.928251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e366000 of size 1024 next 76\n",
      "2024-09-19 17:20:59.928254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e366400 of size 1048576 next 75\n",
      "2024-09-19 17:20:59.928256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e466400 of size 256 next 74\n",
      "2024-09-19 17:20:59.928258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e466500 of size 1024 next 73\n",
      "2024-09-19 17:20:59.928260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e466900 of size 1024 next 72\n",
      "2024-09-19 17:20:59.928263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e466d00 of size 1024 next 71\n",
      "2024-09-19 17:20:59.928265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e467100 of size 1024 next 70\n",
      "2024-09-19 17:20:59.928267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e467500 of size 1024 next 69\n",
      "2024-09-19 17:20:59.928270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e467900 of size 2359296 next 68\n",
      "2024-09-19 17:20:59.928272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6a7900 of size 256 next 67\n",
      "2024-09-19 17:20:59.928274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6a7a00 of size 4096 next 66\n",
      "2024-09-19 17:20:59.928276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6a8a00 of size 4096 next 65\n",
      "2024-09-19 17:20:59.928279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6a9a00 of size 4096 next 64\n",
      "2024-09-19 17:20:59.928281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6aaa00 of size 4096 next 63\n",
      "2024-09-19 17:20:59.928283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6aba00 of size 4096 next 62\n",
      "2024-09-19 17:20:59.928285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e6aca00 of size 1048576 next 61\n",
      "2024-09-19 17:20:59.928288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7aca00 of size 256 next 60\n",
      "2024-09-19 17:20:59.928290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7acb00 of size 1024 next 59\n",
      "2024-09-19 17:20:59.928292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7acf00 of size 1024 next 58\n",
      "2024-09-19 17:20:59.928295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7ad300 of size 1024 next 57\n",
      "2024-09-19 17:20:59.928297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7ad700 of size 1024 next 56\n",
      "2024-09-19 17:20:59.928299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7adb00 of size 1024 next 55\n",
      "2024-09-19 17:20:59.928301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e7adf00 of size 1048576 next 54\n",
      "2024-09-19 17:20:59.928304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8adf00 of size 256 next 53\n",
      "2024-09-19 17:20:59.928306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8ae000 of size 1024 next 52\n",
      "2024-09-19 17:20:59.928308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8ae400 of size 1024 next 51\n",
      "2024-09-19 17:20:59.928311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8ae800 of size 1024 next 50\n",
      "2024-09-19 17:20:59.928313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8aec00 of size 1024 next 49\n",
      "2024-09-19 17:20:59.928315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8af000 of size 1024 next 48\n",
      "2024-09-19 17:20:59.928317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68e8af400 of size 2359296 next 47\n",
      "2024-09-19 17:20:59.928320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaef400 of size 256 next 46\n",
      "2024-09-19 17:20:59.928322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaef500 of size 4096 next 45\n",
      "2024-09-19 17:20:59.928324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaf0500 of size 4096 next 44\n",
      "2024-09-19 17:20:59.928327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaf1500 of size 4096 next 43\n",
      "2024-09-19 17:20:59.928329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaf2500 of size 4096 next 42\n",
      "2024-09-19 17:20:59.928331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaf3500 of size 4096 next 41\n",
      "2024-09-19 17:20:59.928333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68eaf4500 of size 1048576 next 40\n",
      "2024-09-19 17:20:59.928336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf4500 of size 256 next 39\n",
      "2024-09-19 17:20:59.928338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf4600 of size 1024 next 38\n",
      "2024-09-19 17:20:59.928340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf4a00 of size 1024 next 37\n",
      "2024-09-19 17:20:59.928342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf4e00 of size 1024 next 36\n",
      "2024-09-19 17:20:59.928345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf5200 of size 1024 next 35\n",
      "2024-09-19 17:20:59.928347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf5600 of size 1024 next 34\n",
      "2024-09-19 17:20:59.928349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ebf5a00 of size 1048576 next 33\n",
      "2024-09-19 17:20:59.928352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf5a00 of size 256 next 32\n",
      "2024-09-19 17:20:59.928354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf5b00 of size 1024 next 31\n",
      "2024-09-19 17:20:59.928356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf5f00 of size 1024 next 30\n",
      "2024-09-19 17:20:59.928358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf6300 of size 1024 next 29\n",
      "2024-09-19 17:20:59.928361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf6700 of size 1024 next 28\n",
      "2024-09-19 17:20:59.928363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf6b00 of size 1024 next 27\n",
      "2024-09-19 17:20:59.928365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ecf6f00 of size 2359296 next 26\n",
      "2024-09-19 17:20:59.928368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef36f00 of size 256 next 25\n",
      "2024-09-19 17:20:59.928370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef37000 of size 4096 next 24\n",
      "2024-09-19 17:20:59.928372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef38000 of size 4096 next 23\n",
      "2024-09-19 17:20:59.928374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef39000 of size 4096 next 22\n",
      "2024-09-19 17:20:59.928377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef3a000 of size 4096 next 21\n",
      "2024-09-19 17:20:59.928379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef3b000 of size 4096 next 20\n",
      "2024-09-19 17:20:59.928381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68ef3c000 of size 1048576 next 19\n",
      "2024-09-19 17:20:59.928384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03c000 of size 256 next 18\n",
      "2024-09-19 17:20:59.928386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03c100 of size 1024 next 17\n",
      "2024-09-19 17:20:59.928388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03c500 of size 1024 next 16\n",
      "2024-09-19 17:20:59.928390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03c900 of size 1024 next 15\n",
      "2024-09-19 17:20:59.928393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03cd00 of size 1024 next 14\n",
      "2024-09-19 17:20:59.928395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03d100 of size 1024 next 13\n",
      "2024-09-19 17:20:59.928397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f03d500 of size 1048576 next 12\n",
      "2024-09-19 17:20:59.928399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13d500 of size 256 next 11\n",
      "2024-09-19 17:20:59.928402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13d600 of size 1024 next 10\n",
      "2024-09-19 17:20:59.928404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13da00 of size 1024 next 9\n",
      "2024-09-19 17:20:59.928406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13de00 of size 1024 next 8\n",
      "2024-09-19 17:20:59.928409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13e200 of size 1024 next 7\n",
      "2024-09-19 17:20:59.928411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13e600 of size 1024 next 6\n",
      "2024-09-19 17:20:59.928413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f13ea00 of size 2359296 next 5\n",
      "2024-09-19 17:20:59.928415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f37ea00 of size 256 next 4\n",
      "2024-09-19 17:20:59.928418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f37eb00 of size 4096 next 3\n",
      "2024-09-19 17:20:59.928420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f37fb00 of size 4096 next 2\n",
      "2024-09-19 17:20:59.928422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f380b00 of size 4096 next 1\n",
      "2024-09-19 17:20:59.928425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f381b00 of size 4096 next 1970\n",
      "2024-09-19 17:20:59.928427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f382b00 of size 4096 next 1974\n",
      "2024-09-19 17:20:59.928429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f383b00 of size 1048576 next 1975\n",
      "2024-09-19 17:20:59.928432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f483b00 of size 256 next 1973\n",
      "2024-09-19 17:20:59.928434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f483c00 of size 1024 next 1971\n",
      "2024-09-19 17:20:59.928436: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f484000 of size 1024 next 1972\n",
      "2024-09-19 17:20:59.928439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f484400 of size 1024 next 1963\n",
      "2024-09-19 17:20:59.928441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f484800 of size 1024 next 1964\n",
      "2024-09-19 17:20:59.928443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f484c00 of size 1024 next 1959\n",
      "2024-09-19 17:20:59.928446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f485000 of size 1048576 next 1960\n",
      "2024-09-19 17:20:59.928448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f585000 of size 256 next 1948\n",
      "2024-09-19 17:20:59.928450: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f585100 of size 1024 next 1961\n",
      "2024-09-19 17:20:59.928453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f585500 of size 1024 next 1965\n",
      "2024-09-19 17:20:59.928455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f585900 of size 1024 next 1946\n",
      "2024-09-19 17:20:59.928457: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f585d00 of size 1024 next 1966\n",
      "2024-09-19 17:20:59.928460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f586100 of size 1024 next 1962\n",
      "2024-09-19 17:20:59.928462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f586500 of size 2359296 next 1947\n",
      "2024-09-19 17:20:59.928464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7c6500 of size 256 next 1942\n",
      "2024-09-19 17:20:59.928466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7c6600 of size 4096 next 1944\n",
      "2024-09-19 17:20:59.928469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7c7600 of size 4096 next 1945\n",
      "2024-09-19 17:20:59.928471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7c8600 of size 4096 next 2234\n",
      "2024-09-19 17:20:59.928473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7c9600 of size 4096 next 2235\n",
      "2024-09-19 17:20:59.928476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7ca600 of size 4096 next 2236\n",
      "2024-09-19 17:20:59.928478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f7cb600 of size 1048576 next 2237\n",
      "2024-09-19 17:20:59.928480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cb600 of size 256 next 2238\n",
      "2024-09-19 17:20:59.928483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cb700 of size 2048 next 2239\n",
      "2024-09-19 17:20:59.928485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cbf00 of size 2048 next 2240\n",
      "2024-09-19 17:20:59.928487: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cc700 of size 2048 next 2241\n",
      "2024-09-19 17:20:59.928490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8ccf00 of size 2048 next 2242\n",
      "2024-09-19 17:20:59.928492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cd700 of size 2048 next 2243\n",
      "2024-09-19 17:20:59.928495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68f8cdf00 of size 2097152 next 2244\n",
      "2024-09-19 17:20:59.928497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68facdf00 of size 256 next 2245\n",
      "2024-09-19 17:20:59.928500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68face000 of size 2048 next 2246\n",
      "2024-09-19 17:20:59.928502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68face800 of size 2048 next 2247\n",
      "2024-09-19 17:20:59.928504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68facf000 of size 2048 next 2248\n",
      "2024-09-19 17:20:59.928507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68facf800 of size 2048 next 2249\n",
      "2024-09-19 17:20:59.928509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad0000 of size 2048 next 2250\n",
      "2024-09-19 17:20:59.928512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad0800 of size 256 next 2252\n",
      "2024-09-19 17:20:59.928514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad0900 of size 8192 next 2253\n",
      "2024-09-19 17:20:59.928516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad2900 of size 8192 next 2254\n",
      "2024-09-19 17:20:59.928519: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad4900 of size 8192 next 2255\n",
      "2024-09-19 17:20:59.928521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad6900 of size 8192 next 2256\n",
      "2024-09-19 17:20:59.928523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fad8900 of size 8192 next 2257\n",
      "2024-09-19 17:20:59.928526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fada900 of size 256 next 2259\n",
      "2024-09-19 17:20:59.928528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fadaa00 of size 8192 next 2260\n",
      "2024-09-19 17:20:59.928530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fadca00 of size 8192 next 2261\n",
      "2024-09-19 17:20:59.928533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fadea00 of size 8192 next 2262\n",
      "2024-09-19 17:20:59.928535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae0a00 of size 8192 next 2263\n",
      "2024-09-19 17:20:59.928537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae2a00 of size 8192 next 2264\n",
      "2024-09-19 17:20:59.928540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae4a00 of size 256 next 2266\n",
      "2024-09-19 17:20:59.928542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae4b00 of size 2048 next 2267\n",
      "2024-09-19 17:20:59.928545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae5300 of size 2048 next 2268\n",
      "2024-09-19 17:20:59.928547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae5b00 of size 2048 next 2269\n",
      "2024-09-19 17:20:59.928549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae6300 of size 2048 next 2270\n",
      "2024-09-19 17:20:59.928552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae6b00 of size 2048 next 2271\n",
      "2024-09-19 17:20:59.928554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae7300 of size 256 next 2273\n",
      "2024-09-19 17:20:59.928556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae7400 of size 2048 next 2274\n",
      "2024-09-19 17:20:59.928559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae7c00 of size 2048 next 2275\n",
      "2024-09-19 17:20:59.928561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae8400 of size 2048 next 2276\n",
      "2024-09-19 17:20:59.928563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae8c00 of size 2048 next 2277\n",
      "2024-09-19 17:20:59.928565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae9400 of size 2048 next 2278\n",
      "2024-09-19 17:20:59.928568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae9c00 of size 256 next 2279\n",
      "2024-09-19 17:20:59.928570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fae9d00 of size 8192 next 2280\n",
      "2024-09-19 17:20:59.928572: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faebd00 of size 8192 next 2281\n",
      "2024-09-19 17:20:59.928575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faedd00 of size 8192 next 2282\n",
      "2024-09-19 17:20:59.928577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faefd00 of size 8192 next 2283\n",
      "2024-09-19 17:20:59.928579: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf1d00 of size 8192 next 2284\n",
      "2024-09-19 17:20:59.928582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf3d00 of size 256 next 2286\n",
      "2024-09-19 17:20:59.928584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf3e00 of size 2048 next 2287\n",
      "2024-09-19 17:20:59.928586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf4600 of size 2048 next 2288\n",
      "2024-09-19 17:20:59.928588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf4e00 of size 2048 next 2289\n",
      "2024-09-19 17:20:59.928591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf5600 of size 2048 next 2290\n",
      "2024-09-19 17:20:59.928593: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf5e00 of size 2048 next 2291\n",
      "2024-09-19 17:20:59.928595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf6600 of size 256 next 2293\n",
      "2024-09-19 17:20:59.928597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf6700 of size 2048 next 2294\n",
      "2024-09-19 17:20:59.928600: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf6f00 of size 2048 next 2295\n",
      "2024-09-19 17:20:59.928602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf7700 of size 2048 next 2296\n",
      "2024-09-19 17:20:59.928604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf7f00 of size 2048 next 2297\n",
      "2024-09-19 17:20:59.928606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf8700 of size 2048 next 2298\n",
      "2024-09-19 17:20:59.928609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf8f00 of size 256 next 2300\n",
      "2024-09-19 17:20:59.928611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faf9000 of size 8192 next 2301\n",
      "2024-09-19 17:20:59.928613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fafb000 of size 8192 next 2302\n",
      "2024-09-19 17:20:59.928616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fafd000 of size 8192 next 2303\n",
      "2024-09-19 17:20:59.928618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68faff000 of size 8192 next 2304\n",
      "2024-09-19 17:20:59.928620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb01000 of size 8192 next 2305\n",
      "2024-09-19 17:20:59.928622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03000 of size 256 next 2307\n",
      "2024-09-19 17:20:59.928625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03100 of size 256 next 2308\n",
      "2024-09-19 17:20:59.928627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03200 of size 256 next 2309\n",
      "2024-09-19 17:20:59.928629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03300 of size 256 next 2310\n",
      "2024-09-19 17:20:59.928632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03400 of size 256 next 2311\n",
      "2024-09-19 17:20:59.928634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03500 of size 256 next 2312\n",
      "2024-09-19 17:20:59.928636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb03600 of size 37632 next 2313\n",
      "2024-09-19 17:20:59.928638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb0c900 of size 256 next 2314\n",
      "2024-09-19 17:20:59.928641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb0ca00 of size 1280 next 2315\n",
      "2024-09-19 17:20:59.928643: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb0cf00 of size 65536 next 2316\n",
      "2024-09-19 17:20:59.928645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fb1cf00 of size 1179648 next 2317\n",
      "2024-09-19 17:20:59.928648: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc3cf00 of size 512 next 2512\n",
      "2024-09-19 17:20:59.928650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc3d100 of size 1024 next 2513\n",
      "2024-09-19 17:20:59.928652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc3d500 of size 1024 next 2514\n",
      "2024-09-19 17:20:59.928655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc3d900 of size 1024 next 2515\n",
      "2024-09-19 17:20:59.928657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc3dd00 of size 65536 next 2516\n",
      "2024-09-19 17:20:59.928659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc4dd00 of size 256 next 2517\n",
      "2024-09-19 17:20:59.928661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc4de00 of size 4096 next 2540\n",
      "2024-09-19 17:20:59.928664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc4ee00 of size 1024 next 2541\n",
      "2024-09-19 17:20:59.928666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc4f200 of size 4096 next 2542\n",
      "2024-09-19 17:20:59.928668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc50200 of size 1024 next 2544\n",
      "2024-09-19 17:20:59.928671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc50600 of size 4096 next 2545\n",
      "2024-09-19 17:20:59.928673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc51600 of size 2048 next 2546\n",
      "2024-09-19 17:20:59.928675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc51e00 of size 1024 next 2547\n",
      "2024-09-19 17:20:59.928677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc52200 of size 256 next 2548\n",
      "2024-09-19 17:20:59.928680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc52300 of size 2048 next 2549\n",
      "2024-09-19 17:20:59.928682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc52b00 of size 1024 next 2550\n",
      "2024-09-19 17:20:59.928684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc52f00 of size 512 next 2551\n",
      "2024-09-19 17:20:59.928686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc53100 of size 2048 next 2553\n",
      "2024-09-19 17:20:59.928689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc53900 of size 8192 next 2554\n",
      "2024-09-19 17:20:59.928691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc55900 of size 4096 next 2555\n",
      "2024-09-19 17:20:59.928693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc56900 of size 1024 next 2556\n",
      "2024-09-19 17:20:59.928696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc56d00 of size 1024 next 2557\n",
      "2024-09-19 17:20:59.928698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc57100 of size 4096 next 2558\n",
      "2024-09-19 17:20:59.928700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc58100 of size 1024 next 2559\n",
      "2024-09-19 17:20:59.928702: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc58500 of size 4096 next 2560\n",
      "2024-09-19 17:20:59.928705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc59500 of size 4096 next 2561\n",
      "2024-09-19 17:20:59.928707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc5a500 of size 65536 next 2562\n",
      "2024-09-19 17:20:59.928710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6a500 of size 512 next 2563\n",
      "2024-09-19 17:20:59.928713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6a700 of size 1024 next 2564\n",
      "2024-09-19 17:20:59.928715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6ab00 of size 4096 next 2565\n",
      "2024-09-19 17:20:59.928717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6bb00 of size 2048 next 2566\n",
      "2024-09-19 17:20:59.928719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6c300 of size 8192 next 2567\n",
      "2024-09-19 17:20:59.928722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc6e300 of size 8192 next 2568\n",
      "2024-09-19 17:20:59.928724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc70300 of size 2048 next 2569\n",
      "2024-09-19 17:20:59.928726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc70b00 of size 2048 next 2570\n",
      "2024-09-19 17:20:59.928728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc71300 of size 2048 next 2571\n",
      "2024-09-19 17:20:59.928731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc71b00 of size 4096 next 2573\n",
      "2024-09-19 17:20:59.928733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc72b00 of size 512 next 2575\n",
      "2024-09-19 17:20:59.928735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc72d00 of size 4096 next 2576\n",
      "2024-09-19 17:20:59.928737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc73d00 of size 4096 next 2577\n",
      "2024-09-19 17:20:59.928740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc74d00 of size 1024 next 2578\n",
      "2024-09-19 17:20:59.928742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc75100 of size 4096 next 2579\n",
      "2024-09-19 17:20:59.928744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc76100 of size 1024 next 2580\n",
      "2024-09-19 17:20:59.928747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc76500 of size 1024 next 2581\n",
      "2024-09-19 17:20:59.928749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc76900 of size 4096 next 2582\n",
      "2024-09-19 17:20:59.928751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc77900 of size 4096 next 2583\n",
      "2024-09-19 17:20:59.928753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc78900 of size 8192 next 2584\n",
      "2024-09-19 17:20:59.928756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7a900 of size 2048 next 2586\n",
      "2024-09-19 17:20:59.928758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7b100 of size 2048 next 2587\n",
      "2024-09-19 17:20:59.928760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7b900 of size 2048 next 2588\n",
      "2024-09-19 17:20:59.928763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7c100 of size 256 next 2589\n",
      "2024-09-19 17:20:59.928765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7c200 of size 4096 next 2590\n",
      "2024-09-19 17:20:59.928767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7d200 of size 1024 next 2591\n",
      "2024-09-19 17:20:59.928769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7d600 of size 1024 next 2592\n",
      "2024-09-19 17:20:59.928772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7da00 of size 1024 next 2593\n",
      "2024-09-19 17:20:59.928774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7de00 of size 4096 next 2594\n",
      "2024-09-19 17:20:59.928776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7ee00 of size 4096 next 2596\n",
      "2024-09-19 17:20:59.928778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc7fe00 of size 4096 next 2598\n",
      "2024-09-19 17:20:59.928781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc80e00 of size 2048 next 2599\n",
      "2024-09-19 17:20:59.928783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc81600 of size 8192 next 2600\n",
      "2024-09-19 17:20:59.928785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc83600 of size 2048 next 2601\n",
      "2024-09-19 17:20:59.928788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc83e00 of size 2048 next 2602\n",
      "2024-09-19 17:20:59.928790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc84600 of size 2048 next 2603\n",
      "2024-09-19 17:20:59.928792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc84e00 of size 256 next 2606\n",
      "2024-09-19 17:20:59.928794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc84f00 of size 1024 next 2607\n",
      "2024-09-19 17:20:59.928797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc85300 of size 4096 next 2608\n",
      "2024-09-19 17:20:59.928799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc86300 of size 1024 next 2609\n",
      "2024-09-19 17:20:59.928801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc86700 of size 256 next 2610\n",
      "2024-09-19 17:20:59.928803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc86800 of size 2048 next 2612\n",
      "2024-09-19 17:20:59.928806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc87000 of size 8192 next 2613\n",
      "2024-09-19 17:20:59.928808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc89000 of size 8192 next 2614\n",
      "2024-09-19 17:20:59.928810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc8b000 of size 2048 next 2615\n",
      "2024-09-19 17:20:59.928813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc8b800 of size 2048 next 2617\n",
      "2024-09-19 17:20:59.928815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fc8c000 of size 1642496 next 1675\n",
      "2024-09-19 17:20:59.928817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa68fe1d000 of size 2359296 next 2166\n",
      "2024-09-19 17:20:59.928819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005d000 of size 256 next 1927\n",
      "2024-09-19 17:20:59.928822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005d100 of size 1024 next 1926\n",
      "2024-09-19 17:20:59.928824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005d500 of size 1024 next 1925\n",
      "2024-09-19 17:20:59.928826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005d900 of size 1024 next 1924\n",
      "2024-09-19 17:20:59.928829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005dd00 of size 1024 next 1923\n",
      "2024-09-19 17:20:59.928831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005e100 of size 1024 next 1922\n",
      "2024-09-19 17:20:59.928834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69005e500 of size 1048576 next 1921\n",
      "2024-09-19 17:20:59.928836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015e500 of size 256 next 1920\n",
      "2024-09-19 17:20:59.928838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015e600 of size 1024 next 1919\n",
      "2024-09-19 17:20:59.928841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015ea00 of size 1024 next 1918\n",
      "2024-09-19 17:20:59.928843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015ee00 of size 1024 next 1917\n",
      "2024-09-19 17:20:59.928845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015f200 of size 1024 next 1916\n",
      "2024-09-19 17:20:59.928848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015f600 of size 1024 next 1915\n",
      "2024-09-19 17:20:59.928850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69015fa00 of size 2359296 next 1914\n",
      "2024-09-19 17:20:59.928852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69039fa00 of size 256 next 1913\n",
      "2024-09-19 17:20:59.928857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69039fb00 of size 4096 next 1912\n",
      "2024-09-19 17:20:59.928859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6903a0b00 of size 4096 next 1911\n",
      "2024-09-19 17:20:59.928862: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6903a1b00 of size 4096 next 1910\n",
      "2024-09-19 17:20:59.928864: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6903a2b00 of size 4096 next 1909\n",
      "2024-09-19 17:20:59.928866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6903a3b00 of size 4096 next 1908\n",
      "2024-09-19 17:20:59.928869: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6903a4b00 of size 1048576 next 1907\n",
      "2024-09-19 17:20:59.928871: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a4b00 of size 256 next 1906\n",
      "2024-09-19 17:20:59.928873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a4c00 of size 2048 next 1905\n",
      "2024-09-19 17:20:59.928876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a5400 of size 2048 next 1904\n",
      "2024-09-19 17:20:59.928878: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a5c00 of size 2048 next 1903\n",
      "2024-09-19 17:20:59.928880: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a6400 of size 2048 next 1902\n",
      "2024-09-19 17:20:59.928882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a6c00 of size 2048 next 1901\n",
      "2024-09-19 17:20:59.928885: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6904a7400 of size 2579456 next 1938\n",
      "2024-09-19 17:20:59.928887: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69071d000 of size 1376256 next 1949\n",
      "2024-09-19 17:20:59.928890: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d000 of size 256 next 1943\n",
      "2024-09-19 17:20:59.928893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d100 of size 256 next 2219\n",
      "2024-09-19 17:20:59.928895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d200 of size 256 next 2208\n",
      "2024-09-19 17:20:59.928898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d300 of size 256 next 2209\n",
      "2024-09-19 17:20:59.928901: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d400 of size 256 next 2137\n",
      "2024-09-19 17:20:59.928904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d500 of size 256 next 2138\n",
      "2024-09-19 17:20:59.928907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69086d600 of size 260608 next 2165\n",
      "2024-09-19 17:20:59.928910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6908ad000 of size 65536 next 1643\n",
      "2024-09-19 17:20:59.928915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6908bd000 of size 65536 next 1581\n",
      "2024-09-19 17:20:59.928917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6908cd000 of size 65536 next 1427\n",
      "2024-09-19 17:20:59.928920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6908dd000 of size 196608 next 1951\n",
      "2024-09-19 17:20:59.928923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090d000 of size 256 next 2015\n",
      "2024-09-19 17:20:59.928926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090d100 of size 1024 next 2016\n",
      "2024-09-19 17:20:59.928929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090d500 of size 1024 next 2173\n",
      "2024-09-19 17:20:59.928932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090d900 of size 1024 next 2175\n",
      "2024-09-19 17:20:59.928935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090dd00 of size 1024 next 1983\n",
      "2024-09-19 17:20:59.928937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090e100 of size 1024 next 1984\n",
      "2024-09-19 17:20:59.928940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69090e500 of size 65536 next 2090\n",
      "2024-09-19 17:20:59.928943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091e500 of size 256 next 2091\n",
      "2024-09-19 17:20:59.928946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091e600 of size 512 next 2051\n",
      "2024-09-19 17:20:59.928948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091e800 of size 512 next 2052\n",
      "2024-09-19 17:20:59.928951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091ea00 of size 512 next 2232\n",
      "2024-09-19 17:20:59.928954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091ec00 of size 512 next 2233\n",
      "2024-09-19 17:20:59.928957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091ee00 of size 512 next 2102\n",
      "2024-09-19 17:20:59.928960: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69091f000 of size 131072 next 1988\n",
      "2024-09-19 17:20:59.928962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f000 of size 256 next 2164\n",
      "2024-09-19 17:20:59.928965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f100 of size 512 next 2120\n",
      "2024-09-19 17:20:59.928968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f300 of size 512 next 2129\n",
      "2024-09-19 17:20:59.928971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f500 of size 512 next 2130\n",
      "2024-09-19 17:20:59.928974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f700 of size 512 next 2136\n",
      "2024-09-19 17:20:59.928976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093f900 of size 512 next 2085\n",
      "2024-09-19 17:20:59.928979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093fb00 of size 256 next 2086\n",
      "2024-09-19 17:20:59.928982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69093fc00 of size 2048 next 2210\n",
      "2024-09-19 17:20:59.928984: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690940400 of size 2048 next 2088\n",
      "2024-09-19 17:20:59.928987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690940c00 of size 2048 next 2089\n",
      "2024-09-19 17:20:59.928990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690941400 of size 2048 next 2158\n",
      "2024-09-19 17:20:59.928993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690941c00 of size 2048 next 1936\n",
      "2024-09-19 17:20:59.928995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690942400 of size 313344 next 2167\n",
      "2024-09-19 17:20:59.928998: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69098ec00 of size 1024 next 1502\n",
      "2024-09-19 17:20:59.929001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69098f000 of size 1024 next 1429\n",
      "2024-09-19 17:20:59.929004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69098f400 of size 1024 next 1430\n",
      "2024-09-19 17:20:59.929007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69098f800 of size 1024 next 1422\n",
      "2024-09-19 17:20:59.929009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69098fc00 of size 65536 next 1566\n",
      "2024-09-19 17:20:59.929012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69099fc00 of size 256 next 1568\n",
      "2024-09-19 17:20:59.929015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69099fd00 of size 256 next 1482\n",
      "2024-09-19 17:20:59.929018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69099fe00 of size 256 next 1483\n",
      "2024-09-19 17:20:59.929021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69099ff00 of size 256 next 860\n",
      "2024-09-19 17:20:59.929024: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909a0000 of size 256 next 1414\n",
      "2024-09-19 17:20:59.929026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909a0100 of size 256 next 1443\n",
      "2024-09-19 17:20:59.929029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909a0200 of size 65536 next 1548\n",
      "2024-09-19 17:20:59.929032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0200 of size 256 next 1531\n",
      "2024-09-19 17:20:59.929035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0300 of size 256 next 1394\n",
      "2024-09-19 17:20:59.929038: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0400 of size 256 next 1602\n",
      "2024-09-19 17:20:59.929040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0500 of size 256 next 1604\n",
      "2024-09-19 17:20:59.929043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0600 of size 256 next 1579\n",
      "2024-09-19 17:20:59.929046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0700 of size 256 next 1659\n",
      "2024-09-19 17:20:59.929049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909b0800 of size 147456 next 1660\n",
      "2024-09-19 17:20:59.929052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d4800 of size 256 next 1404\n",
      "2024-09-19 17:20:59.929055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d4900 of size 1024 next 1405\n",
      "2024-09-19 17:20:59.929058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d4d00 of size 1024 next 1463\n",
      "2024-09-19 17:20:59.929060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d5100 of size 1024 next 1408\n",
      "2024-09-19 17:20:59.929064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d5500 of size 1024 next 1635\n",
      "2024-09-19 17:20:59.929066: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d5900 of size 1024 next 1636\n",
      "2024-09-19 17:20:59.929069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909d5d00 of size 65536 next 1515\n",
      "2024-09-19 17:20:59.929072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e5d00 of size 256 next 1516\n",
      "2024-09-19 17:20:59.929074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e5e00 of size 512 next 1658\n",
      "2024-09-19 17:20:59.929076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e6000 of size 512 next 1576\n",
      "2024-09-19 17:20:59.929079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e6200 of size 512 next 1491\n",
      "2024-09-19 17:20:59.929081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e6400 of size 512 next 1507\n",
      "2024-09-19 17:20:59.929083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e6600 of size 512 next 1634\n",
      "2024-09-19 17:20:59.929086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6909e6800 of size 206848 next 1953\n",
      "2024-09-19 17:20:59.929088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19000 of size 256 next 1934\n",
      "2024-09-19 17:20:59.929091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19100 of size 256 next 2162\n",
      "2024-09-19 17:20:59.929093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19200 of size 256 next 2163\n",
      "2024-09-19 17:20:59.929095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19300 of size 256 next 2061\n",
      "2024-09-19 17:20:59.929098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19400 of size 256 next 2062\n",
      "2024-09-19 17:20:59.929100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19500 of size 256 next 2215\n",
      "2024-09-19 17:20:59.929102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19600 of size 256 next 2216\n",
      "2024-09-19 17:20:59.929104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19700 of size 256 next 2154\n",
      "2024-09-19 17:20:59.929107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19800 of size 256 next 2155\n",
      "2024-09-19 17:20:59.929109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19900 of size 256 next 2043\n",
      "2024-09-19 17:20:59.929111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19a00 of size 256 next 2044\n",
      "2024-09-19 17:20:59.929113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19b00 of size 256 next 2123\n",
      "2024-09-19 17:20:59.929116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19c00 of size 256 next 2125\n",
      "2024-09-19 17:20:59.929119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19d00 of size 256 next 2114\n",
      "2024-09-19 17:20:59.929121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19e00 of size 256 next 2115\n",
      "2024-09-19 17:20:59.929123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a19f00 of size 256 next 1989\n",
      "2024-09-19 17:20:59.929126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a000 of size 256 next 1990\n",
      "2024-09-19 17:20:59.929128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a100 of size 256 next 2106\n",
      "2024-09-19 17:20:59.929130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a200 of size 256 next 2107\n",
      "2024-09-19 17:20:59.929132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a300 of size 256 next 2082\n",
      "2024-09-19 17:20:59.929135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a400 of size 256 next 2083\n",
      "2024-09-19 17:20:59.929137: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a500 of size 256 next 2019\n",
      "2024-09-19 17:20:59.929139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a600 of size 256 next 2020\n",
      "2024-09-19 17:20:59.929142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a700 of size 256 next 2049\n",
      "2024-09-19 17:20:59.929144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1a800 of size 1024 next 2050\n",
      "2024-09-19 17:20:59.929147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1ac00 of size 1024 next 2029\n",
      "2024-09-19 17:20:59.929149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1b000 of size 1024 next 2030\n",
      "2024-09-19 17:20:59.929152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1b400 of size 1024 next 1940\n",
      "2024-09-19 17:20:59.929154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1b800 of size 1024 next 1958\n",
      "2024-09-19 17:20:59.929156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1bc00 of size 256 next 2226\n",
      "2024-09-19 17:20:59.929159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1bd00 of size 1024 next 1979\n",
      "2024-09-19 17:20:59.929161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1c100 of size 1024 next 1980\n",
      "2024-09-19 17:20:59.929163: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1c500 of size 1024 next 2021\n",
      "2024-09-19 17:20:59.929165: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1c900 of size 1792 next 1954\n",
      "2024-09-19 17:20:59.929168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a1d000 of size 147456 next 1955\n",
      "2024-09-19 17:20:59.929170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690a41000 of size 1245184 next 1957\n",
      "2024-09-19 17:20:59.929173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690b71000 of size 4194304 next 1330\n",
      "2024-09-19 17:20:59.929175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa690f71000 of size 9437184 next 1323\n",
      "2024-09-19 17:20:59.929178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa691871000 of size 4194304 next 1316\n",
      "2024-09-19 17:20:59.929180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa691c71000 of size 6242304 next 1976\n",
      "2024-09-19 17:20:59.929182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692265000 of size 2359296 next 1823\n",
      "2024-09-19 17:20:59.929185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6924a5000 of size 1048576 next 1822\n",
      "2024-09-19 17:20:59.929187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6925a5000 of size 1048576 next 1821\n",
      "2024-09-19 17:20:59.929189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6926a5000 of size 1048576 next 1820\n",
      "2024-09-19 17:20:59.929192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6927a5000 of size 589824 next 1819\n",
      "2024-09-19 17:20:59.929194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692835000 of size 589824 next 1818\n",
      "2024-09-19 17:20:59.929196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6928c5000 of size 262144 next 1817\n",
      "2024-09-19 17:20:59.929198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692905000 of size 262144 next 1816\n",
      "2024-09-19 17:20:59.929201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692945000 of size 131072 next 1815\n",
      "2024-09-19 17:20:59.929203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692965000 of size 262144 next 1814\n",
      "2024-09-19 17:20:59.929205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6929a5000 of size 65536 next 1813\n",
      "2024-09-19 17:20:59.929208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6929b5000 of size 262144 next 1812\n",
      "2024-09-19 17:20:59.929210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6929f5000 of size 589824 next 1811\n",
      "2024-09-19 17:20:59.929212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692a85000 of size 1032192 next 1810\n",
      "2024-09-19 17:20:59.929214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692b81000 of size 65536 next 1809\n",
      "2024-09-19 17:20:59.929217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692b91000 of size 1179648 next 1808\n",
      "2024-09-19 17:20:59.929219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692cb1000 of size 147456 next 1807\n",
      "2024-09-19 17:20:59.929221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692cd5000 of size 589824 next 1806\n",
      "2024-09-19 17:20:59.929224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692d65000 of size 65536 next 1805\n",
      "2024-09-19 17:20:59.929226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692d75000 of size 65536 next 1804\n",
      "2024-09-19 17:20:59.929228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692d85000 of size 524288 next 1803\n",
      "2024-09-19 17:20:59.929231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692e05000 of size 147456 next 1802\n",
      "2024-09-19 17:20:59.929233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692e29000 of size 147456 next 1801\n",
      "2024-09-19 17:20:59.929235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692e4d000 of size 16384 next 1800\n",
      "2024-09-19 17:20:59.929237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692e51000 of size 65536 next 1799\n",
      "2024-09-19 17:20:59.929240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692e61000 of size 524288 next 1798\n",
      "2024-09-19 17:20:59.929242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692ee1000 of size 65536 next 1797\n",
      "2024-09-19 17:20:59.929244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692ef1000 of size 262144 next 1796\n",
      "2024-09-19 17:20:59.929247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692f31000 of size 589824 next 1795\n",
      "2024-09-19 17:20:59.929249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa692fc1000 of size 2359296 next 1794\n",
      "2024-09-19 17:20:59.929251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa693201000 of size 262144 next 1793\n",
      "2024-09-19 17:20:59.929253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa693241000 of size 262144 next 1792\n",
      "2024-09-19 17:20:59.929256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa693281000 of size 1048576 next 1791\n",
      "2024-09-19 17:20:59.929258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa693381000 of size 2359296 next 1790\n",
      "2024-09-19 17:20:59.929261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6935c1000 of size 1048576 next 1789\n",
      "2024-09-19 17:20:59.929263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6936c1000 of size 2097152 next 1788\n",
      "2024-09-19 17:20:59.929265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6938c1000 of size 4194304 next 1787\n",
      "2024-09-19 17:20:59.929268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa693cc1000 of size 4194304 next 1786\n",
      "2024-09-19 17:20:59.929270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6940c1000 of size 9437184 next 1785\n",
      "2024-09-19 17:20:59.929272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6949c1000 of size 14493952 next 2229\n",
      "2024-09-19 17:20:59.929275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695793900 of size 4096 next 1100\n",
      "2024-09-19 17:20:59.929277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695794900 of size 4096 next 1020\n",
      "2024-09-19 17:20:59.929279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695795900 of size 256 next 1021\n",
      "2024-09-19 17:20:59.929282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695795a00 of size 2048 next 882\n",
      "2024-09-19 17:20:59.929284: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695796200 of size 8192 next 883\n",
      "2024-09-19 17:20:59.929286: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695798200 of size 2048 next 959\n",
      "2024-09-19 17:20:59.929289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695798a00 of size 8192 next 837\n",
      "2024-09-19 17:20:59.929291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579aa00 of size 2048 next 1098\n",
      "2024-09-19 17:20:59.929293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579b200 of size 2048 next 960\n",
      "2024-09-19 17:20:59.929296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579ba00 of size 4096 next 964\n",
      "2024-09-19 17:20:59.929298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579ca00 of size 1024 next 834\n",
      "2024-09-19 17:20:59.929300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579ce00 of size 4096 next 945\n",
      "2024-09-19 17:20:59.929302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579de00 of size 1024 next 1059\n",
      "2024-09-19 17:20:59.929305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579e200 of size 4096 next 1060\n",
      "2024-09-19 17:20:59.929307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579f200 of size 1024 next 969\n",
      "2024-09-19 17:20:59.929309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69579f600 of size 4096 next 970\n",
      "2024-09-19 17:20:59.929312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a0600 of size 4096 next 934\n",
      "2024-09-19 17:20:59.929314: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a1600 of size 1024 next 993\n",
      "2024-09-19 17:20:59.929316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a1a00 of size 4096 next 996\n",
      "2024-09-19 17:20:59.929318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a2a00 of size 8192 next 324\n",
      "2024-09-19 17:20:59.929321: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a4a00 of size 2048 next 1016\n",
      "2024-09-19 17:20:59.929323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a5200 of size 8192 next 1017\n",
      "2024-09-19 17:20:59.929326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a7200 of size 2048 next 1069\n",
      "2024-09-19 17:20:59.929328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a7a00 of size 2048 next 1070\n",
      "2024-09-19 17:20:59.929330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a8200 of size 4096 next 947\n",
      "2024-09-19 17:20:59.929333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a9200 of size 1024 next 948\n",
      "2024-09-19 17:20:59.929335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957a9600 of size 4096 next 843\n",
      "2024-09-19 17:20:59.929338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957aa600 of size 1024 next 878\n",
      "2024-09-19 17:20:59.929340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957aaa00 of size 4096 next 879\n",
      "2024-09-19 17:20:59.929342: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957aba00 of size 1024 next 905\n",
      "2024-09-19 17:20:59.929344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957abe00 of size 4096 next 906\n",
      "2024-09-19 17:20:59.929347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957ace00 of size 1024 next 1018\n",
      "2024-09-19 17:20:59.929349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957ad200 of size 4096 next 853\n",
      "2024-09-19 17:20:59.929351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957ae200 of size 2048 next 998\n",
      "2024-09-19 17:20:59.929354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957aea00 of size 8192 next 1033\n",
      "2024-09-19 17:20:59.929356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b0a00 of size 2048 next 1086\n",
      "2024-09-19 17:20:59.929358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b1200 of size 2048 next 1087\n",
      "2024-09-19 17:20:59.929361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b1a00 of size 2048 next 907\n",
      "2024-09-19 17:20:59.929363: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b2200 of size 2048 next 884\n",
      "2024-09-19 17:20:59.929365: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b2a00 of size 256 next 1013\n",
      "2024-09-19 17:20:59.929367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b2b00 of size 1024 next 953\n",
      "2024-09-19 17:20:59.929370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b2f00 of size 1024 next 1037\n",
      "2024-09-19 17:20:59.929372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3300 of size 2048 next 962\n",
      "2024-09-19 17:20:59.929374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3b00 of size 256 next 1277\n",
      "2024-09-19 17:20:59.929377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3c00 of size 256 next 1276\n",
      "2024-09-19 17:20:59.929379: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3d00 of size 256 next 1278\n",
      "2024-09-19 17:20:59.929381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3e00 of size 256 next 1265\n",
      "2024-09-19 17:20:59.929384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b3f00 of size 256 next 1264\n",
      "2024-09-19 17:20:59.929386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4000 of size 256 next 1286\n",
      "2024-09-19 17:20:59.929388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4100 of size 256 next 1273\n",
      "2024-09-19 17:20:59.929391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4200 of size 256 next 1285\n",
      "2024-09-19 17:20:59.929393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4300 of size 256 next 1270\n",
      "2024-09-19 17:20:59.929395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4400 of size 256 next 1269\n",
      "2024-09-19 17:20:59.929398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4500 of size 256 next 1275\n",
      "2024-09-19 17:20:59.929400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4600 of size 256 next 1237\n",
      "2024-09-19 17:20:59.929403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4700 of size 256 next 1281\n",
      "2024-09-19 17:20:59.929405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4800 of size 256 next 1280\n",
      "2024-09-19 17:20:59.929407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4900 of size 256 next 1284\n",
      "2024-09-19 17:20:59.929410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4a00 of size 256 next 1279\n",
      "2024-09-19 17:20:59.929412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4b00 of size 256 next 1282\n",
      "2024-09-19 17:20:59.929414: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4c00 of size 256 next 1274\n",
      "2024-09-19 17:20:59.929417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4d00 of size 256 next 1283\n",
      "2024-09-19 17:20:59.929419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4e00 of size 256 next 875\n",
      "2024-09-19 17:20:59.929421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b4f00 of size 256 next 1255\n",
      "2024-09-19 17:20:59.929424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5000 of size 256 next 1240\n",
      "2024-09-19 17:20:59.929426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5100 of size 256 next 1256\n",
      "2024-09-19 17:20:59.929429: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5200 of size 256 next 1257\n",
      "2024-09-19 17:20:59.929431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5300 of size 256 next 995\n",
      "2024-09-19 17:20:59.929433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5400 of size 256 next 845\n",
      "2024-09-19 17:20:59.929435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5500 of size 256 next 848\n",
      "2024-09-19 17:20:59.929438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5600 of size 256 next 859\n",
      "2024-09-19 17:20:59.929440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5700 of size 256 next 1008\n",
      "2024-09-19 17:20:59.929442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5800 of size 256 next 890\n",
      "2024-09-19 17:20:59.929445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5900 of size 256 next 1014\n",
      "2024-09-19 17:20:59.929447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5a00 of size 256 next 871\n",
      "2024-09-19 17:20:59.929449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5b00 of size 256 next 974\n",
      "2024-09-19 17:20:59.929452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5c00 of size 256 next 976\n",
      "2024-09-19 17:20:59.929454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5d00 of size 256 next 855\n",
      "2024-09-19 17:20:59.929456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5e00 of size 256 next 973\n",
      "2024-09-19 17:20:59.929459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b5f00 of size 256 next 975\n",
      "2024-09-19 17:20:59.929461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6000 of size 256 next 898\n",
      "2024-09-19 17:20:59.929463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6100 of size 256 next 899\n",
      "2024-09-19 17:20:59.929466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6200 of size 256 next 971\n",
      "2024-09-19 17:20:59.929468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6300 of size 256 next 1003\n",
      "2024-09-19 17:20:59.929470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6400 of size 256 next 1101\n",
      "2024-09-19 17:20:59.929472: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6500 of size 256 next 1088\n",
      "2024-09-19 17:20:59.929475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6600 of size 256 next 1054\n",
      "2024-09-19 17:20:59.929477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6700 of size 256 next 1055\n",
      "2024-09-19 17:20:59.929479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6800 of size 256 next 980\n",
      "2024-09-19 17:20:59.929482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6900 of size 256 next 981\n",
      "2024-09-19 17:20:59.929484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6a00 of size 256 next 885\n",
      "2024-09-19 17:20:59.929486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6b00 of size 256 next 887\n",
      "2024-09-19 17:20:59.929489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6c00 of size 256 next 888\n",
      "2024-09-19 17:20:59.929491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6d00 of size 256 next 912\n",
      "2024-09-19 17:20:59.929493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957b6e00 of size 16384 next 1058\n",
      "2024-09-19 17:20:59.929495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bae00 of size 256 next 1039\n",
      "2024-09-19 17:20:59.929498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957baf00 of size 256 next 1080\n",
      "2024-09-19 17:20:59.929500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb000 of size 256 next 1081\n",
      "2024-09-19 17:20:59.929502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb100 of size 256 next 1046\n",
      "2024-09-19 17:20:59.929505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb200 of size 256 next 1091\n",
      "2024-09-19 17:20:59.929507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb300 of size 256 next 1092\n",
      "2024-09-19 17:20:59.929509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb400 of size 256 next 966\n",
      "2024-09-19 17:20:59.929512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb500 of size 1024 next 967\n",
      "2024-09-19 17:20:59.929514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bb900 of size 1024 next 916\n",
      "2024-09-19 17:20:59.929516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bbd00 of size 1024 next 917\n",
      "2024-09-19 17:20:59.929518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bc100 of size 1024 next 985\n",
      "2024-09-19 17:20:59.929521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bc500 of size 1024 next 1079\n",
      "2024-09-19 17:20:59.929523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957bc900 of size 82688 next 1261\n",
      "2024-09-19 17:20:59.929526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6957d0c00 of size 589824 next 1260\n",
      "2024-09-19 17:20:59.929528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695860c00 of size 1392640 next 1254\n",
      "2024-09-19 17:20:59.929531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6959b4c00 of size 262144 next 1253\n",
      "2024-09-19 17:20:59.929533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6959f4c00 of size 262144 next 1252\n",
      "2024-09-19 17:20:59.929536: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695a34c00 of size 1392640 next 1248\n",
      "2024-09-19 17:20:59.929538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b88c00 of size 256 next 1082\n",
      "2024-09-19 17:20:59.929540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b88d00 of size 1024 next 1043\n",
      "2024-09-19 17:20:59.929542: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b89100 of size 1024 next 279\n",
      "2024-09-19 17:20:59.929545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b89500 of size 1024 next 1078\n",
      "2024-09-19 17:20:59.929547: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b89900 of size 1024 next 846\n",
      "2024-09-19 17:20:59.929549: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b89d00 of size 1024 next 936\n",
      "2024-09-19 17:20:59.929552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b8a100 of size 65536 next 1075\n",
      "2024-09-19 17:20:59.929554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a100 of size 256 next 1076\n",
      "2024-09-19 17:20:59.929556: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a200 of size 256 next 902\n",
      "2024-09-19 17:20:59.929558: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a300 of size 256 next 972\n",
      "2024-09-19 17:20:59.929561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a400 of size 256 next 944\n",
      "2024-09-19 17:20:59.929563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a500 of size 256 next 1103\n",
      "2024-09-19 17:20:59.929566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a600 of size 256 next 1089\n",
      "2024-09-19 17:20:59.929568: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695b9a700 of size 65536 next 1090\n",
      "2024-09-19 17:20:59.929570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baa700 of size 256 next 954\n",
      "2024-09-19 17:20:59.929573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baa800 of size 256 next 840\n",
      "2024-09-19 17:20:59.929575: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baa900 of size 256 next 1066\n",
      "2024-09-19 17:20:59.929577: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baaa00 of size 256 next 992\n",
      "2024-09-19 17:20:59.929580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baab00 of size 256 next 994\n",
      "2024-09-19 17:20:59.929582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baac00 of size 256 next 983\n",
      "2024-09-19 17:20:59.929584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695baad00 of size 147456 next 984\n",
      "2024-09-19 17:20:59.929587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bced00 of size 256 next 1050\n",
      "2024-09-19 17:20:59.929589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bcee00 of size 1024 next 1051\n",
      "2024-09-19 17:20:59.929591: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bcf200 of size 1024 next 950\n",
      "2024-09-19 17:20:59.929594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bcf600 of size 1024 next 1007\n",
      "2024-09-19 17:20:59.929596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bcfa00 of size 1024 next 851\n",
      "2024-09-19 17:20:59.929598: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bcfe00 of size 1024 next 930\n",
      "2024-09-19 17:20:59.929601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bd0200 of size 65536 next 1001\n",
      "2024-09-19 17:20:59.929603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0200 of size 256 next 841\n",
      "2024-09-19 17:20:59.929605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0300 of size 256 next 929\n",
      "2024-09-19 17:20:59.929607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0400 of size 256 next 1006\n",
      "2024-09-19 17:20:59.929610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0500 of size 256 next 1094\n",
      "2024-09-19 17:20:59.929612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0600 of size 256 next 1095\n",
      "2024-09-19 17:20:59.929614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0700 of size 256 next 836\n",
      "2024-09-19 17:20:59.929617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695be0800 of size 65536 next 946\n",
      "2024-09-19 17:20:59.929619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0800 of size 256 next 997\n",
      "2024-09-19 17:20:59.929621: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0900 of size 256 next 1040\n",
      "2024-09-19 17:20:59.929624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0a00 of size 256 next 982\n",
      "2024-09-19 17:20:59.929626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0b00 of size 256 next 915\n",
      "2024-09-19 17:20:59.929628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0c00 of size 256 next 863\n",
      "2024-09-19 17:20:59.929630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0d00 of size 256 next 894\n",
      "2024-09-19 17:20:59.929633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0e00 of size 256 next 918\n",
      "2024-09-19 17:20:59.929635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf0f00 of size 1024 next 965\n",
      "2024-09-19 17:20:59.929637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf1300 of size 1024 next 1015\n",
      "2024-09-19 17:20:59.929640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf1700 of size 1024 next 1108\n",
      "2024-09-19 17:20:59.929642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf1b00 of size 1024 next 1047\n",
      "2024-09-19 17:20:59.929645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf1f00 of size 1024 next 874\n",
      "2024-09-19 17:20:59.929647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695bf2300 of size 92416 next 1247\n",
      "2024-09-19 17:20:59.929650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695c08c00 of size 512 next 1262\n",
      "2024-09-19 17:20:59.929652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695c08e00 of size 671232 next 1244\n",
      "2024-09-19 17:20:59.929655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695cacc00 of size 1179648 next 1243\n",
      "2024-09-19 17:20:59.929657: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695dccc00 of size 1032192 next 1242\n",
      "2024-09-19 17:20:59.929659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ec8c00 of size 2048 next 1263\n",
      "2024-09-19 17:20:59.929662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ec9400 of size 4096 next 831\n",
      "2024-09-19 17:20:59.929664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695eca400 of size 1024 next 1106\n",
      "2024-09-19 17:20:59.929666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695eca800 of size 512 next 1259\n",
      "2024-09-19 17:20:59.929669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecaa00 of size 2048 next 849\n",
      "2024-09-19 17:20:59.929671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecb200 of size 512 next 1044\n",
      "2024-09-19 17:20:59.929673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecb400 of size 512 next 1045\n",
      "2024-09-19 17:20:59.929676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecb600 of size 512 next 872\n",
      "2024-09-19 17:20:59.929678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecb800 of size 2048 next 857\n",
      "2024-09-19 17:20:59.929681: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecc000 of size 1024 next 956\n",
      "2024-09-19 17:20:59.929683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecc400 of size 4096 next 958\n",
      "2024-09-19 17:20:59.929685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecd400 of size 1024 next 1024\n",
      "2024-09-19 17:20:59.929688: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecd800 of size 1024 next 1025\n",
      "2024-09-19 17:20:59.929690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecdc00 of size 1024 next 919\n",
      "2024-09-19 17:20:59.929692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ece000 of size 1024 next 920\n",
      "2024-09-19 17:20:59.929694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ece400 of size 1024 next 937\n",
      "2024-09-19 17:20:59.929697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ece800 of size 1024 next 938\n",
      "2024-09-19 17:20:59.929699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecec00 of size 512 next 931\n",
      "2024-09-19 17:20:59.929701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecee00 of size 512 next 847\n",
      "2024-09-19 17:20:59.929704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecf000 of size 1024 next 1056\n",
      "2024-09-19 17:20:59.929706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ecf400 of size 4096 next 1057\n",
      "2024-09-19 17:20:59.929708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed0400 of size 1024 next 925\n",
      "2024-09-19 17:20:59.929711: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed0800 of size 8192 next 928\n",
      "2024-09-19 17:20:59.929713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed2800 of size 1024 next 900\n",
      "2024-09-19 17:20:59.929715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed2c00 of size 2048 next 901\n",
      "2024-09-19 17:20:59.929717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed3400 of size 1024 next 1251\n",
      "2024-09-19 17:20:59.929720: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed3800 of size 2048 next 858\n",
      "2024-09-19 17:20:59.929722: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed4000 of size 1024 next 854\n",
      "2024-09-19 17:20:59.929724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed4400 of size 1024 next 986\n",
      "2024-09-19 17:20:59.929727: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed4800 of size 1024 next 987\n",
      "2024-09-19 17:20:59.929729: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed4c00 of size 1024 next 891\n",
      "2024-09-19 17:20:59.929731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed5000 of size 1024 next 892\n",
      "2024-09-19 17:20:59.929733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed5400 of size 1024 next 923\n",
      "2024-09-19 17:20:59.929736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed5800 of size 1024 next 924\n",
      "2024-09-19 17:20:59.929738: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed5c00 of size 1024 next 1258\n",
      "2024-09-19 17:20:59.929740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed6000 of size 1024 next 1250\n",
      "2024-09-19 17:20:59.929743: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed6400 of size 1024 next 1249\n",
      "2024-09-19 17:20:59.929745: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed6800 of size 1024 next 935\n",
      "2024-09-19 17:20:59.929747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed6c00 of size 1024 next 1035\n",
      "2024-09-19 17:20:59.929749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed7000 of size 1024 next 861\n",
      "2024-09-19 17:20:59.929752: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695ed7400 of size 147456 next 957\n",
      "2024-09-19 17:20:59.929754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efb400 of size 256 next 963\n",
      "2024-09-19 17:20:59.929756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efb500 of size 512 next 880\n",
      "2024-09-19 17:20:59.929759: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efb700 of size 512 next 881\n",
      "2024-09-19 17:20:59.929761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efb900 of size 512 next 911\n",
      "2024-09-19 17:20:59.929763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efbb00 of size 512 next 1064\n",
      "2024-09-19 17:20:59.929766: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efbd00 of size 512 next 1067\n",
      "2024-09-19 17:20:59.929768: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695efbf00 of size 131072 next 1031\n",
      "2024-09-19 17:20:59.929770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1bf00 of size 256 next 865\n",
      "2024-09-19 17:20:59.929773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1c000 of size 512 next 897\n",
      "2024-09-19 17:20:59.929775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1c200 of size 512 next 989\n",
      "2024-09-19 17:20:59.929777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1c400 of size 512 next 990\n",
      "2024-09-19 17:20:59.929780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1c600 of size 512 next 932\n",
      "2024-09-19 17:20:59.929782: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1c800 of size 512 next 1052\n",
      "2024-09-19 17:20:59.929784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1ca00 of size 256 next 839\n",
      "2024-09-19 17:20:59.929786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1cb00 of size 2048 next 308\n",
      "2024-09-19 17:20:59.929789: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1d300 of size 2048 next 318\n",
      "2024-09-19 17:20:59.929791: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1db00 of size 2048 next 1109\n",
      "2024-09-19 17:20:59.929793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1e300 of size 2048 next 1074\n",
      "2024-09-19 17:20:59.929796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1eb00 of size 2048 next 940\n",
      "2024-09-19 17:20:59.929798: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f1f300 of size 262144 next 941\n",
      "2024-09-19 17:20:59.929800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f5f300 of size 256 next 284\n",
      "2024-09-19 17:20:59.929803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f5f400 of size 2048 next 285\n",
      "2024-09-19 17:20:59.929805: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f5fc00 of size 2048 next 1083\n",
      "2024-09-19 17:20:59.929807: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f60400 of size 2048 next 856\n",
      "2024-09-19 17:20:59.929810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f60c00 of size 2048 next 968\n",
      "2024-09-19 17:20:59.929812: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f61400 of size 2048 next 922\n",
      "2024-09-19 17:20:59.929814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f61c00 of size 256 next 896\n",
      "2024-09-19 17:20:59.929816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f61d00 of size 512 next 977\n",
      "2024-09-19 17:20:59.929819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f61f00 of size 512 next 1002\n",
      "2024-09-19 17:20:59.929821: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f62100 of size 512 next 1077\n",
      "2024-09-19 17:20:59.929823: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f62300 of size 512 next 1071\n",
      "2024-09-19 17:20:59.929825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f62500 of size 512 next 1041\n",
      "2024-09-19 17:20:59.929828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695f62700 of size 288000 next 1239\n",
      "2024-09-19 17:20:59.929831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fa8c00 of size 1024 next 1241\n",
      "2024-09-19 17:20:59.929833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fa9000 of size 1024 next 1022\n",
      "2024-09-19 17:20:59.929835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fa9400 of size 1024 next 1072\n",
      "2024-09-19 17:20:59.929838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fa9800 of size 1024 next 1062\n",
      "2024-09-19 17:20:59.929840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fa9c00 of size 4096 next 1063\n",
      "2024-09-19 17:20:59.929842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695faac00 of size 1024 next 1009\n",
      "2024-09-19 17:20:59.929845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fab000 of size 4096 next 1010\n",
      "2024-09-19 17:20:59.929847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fac000 of size 1024 next 908\n",
      "2024-09-19 17:20:59.929849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fac400 of size 4096 next 909\n",
      "2024-09-19 17:20:59.929852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fad400 of size 4096 next 1004\n",
      "2024-09-19 17:20:59.929854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fae400 of size 1024 next 1005\n",
      "2024-09-19 17:20:59.929856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fae800 of size 1024 next 913\n",
      "2024-09-19 17:20:59.929859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695faec00 of size 1024 next 914\n",
      "2024-09-19 17:20:59.929861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695faf000 of size 4096 next 1084\n",
      "2024-09-19 17:20:59.929863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb0000 of size 1024 next 1085\n",
      "2024-09-19 17:20:59.929865: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb0400 of size 4096 next 961\n",
      "2024-09-19 17:20:59.929868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb1400 of size 2048 next 921\n",
      "2024-09-19 17:20:59.929870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb1c00 of size 8192 next 978\n",
      "2024-09-19 17:20:59.929872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb3c00 of size 4096 next 1102\n",
      "2024-09-19 17:20:59.929875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb4c00 of size 4096 next 951\n",
      "2024-09-19 17:20:59.929877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb5c00 of size 4096 next 864\n",
      "2024-09-19 17:20:59.929879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb6c00 of size 1024 next 1048\n",
      "2024-09-19 17:20:59.929882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb7000 of size 7168 next 1238\n",
      "2024-09-19 17:20:59.929884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb8c00 of size 256 next 1042\n",
      "2024-09-19 17:20:59.929886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb8d00 of size 512 next 903\n",
      "2024-09-19 17:20:59.929889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb8f00 of size 512 next 904\n",
      "2024-09-19 17:20:59.929891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb9100 of size 512 next 842\n",
      "2024-09-19 17:20:59.929893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb9300 of size 512 next 979\n",
      "2024-09-19 17:20:59.929896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb9500 of size 512 next 1011\n",
      "2024-09-19 17:20:59.929898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa695fb9700 of size 589824 next 949\n",
      "2024-09-19 17:20:59.929900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696049700 of size 256 next 835\n",
      "2024-09-19 17:20:59.929903: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696049800 of size 2048 next 322\n",
      "2024-09-19 17:20:59.929905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69604a000 of size 2048 next 991\n",
      "2024-09-19 17:20:59.929907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69604a800 of size 2048 next 1065\n",
      "2024-09-19 17:20:59.929910: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69604b000 of size 2048 next 1036\n",
      "2024-09-19 17:20:59.929912: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69604b800 of size 2048 next 1019\n",
      "2024-09-19 17:20:59.929914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69604c000 of size 262144 next 999\n",
      "2024-09-19 17:20:59.929917: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c000 of size 256 next 939\n",
      "2024-09-19 17:20:59.929919: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c100 of size 512 next 1068\n",
      "2024-09-19 17:20:59.929921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c300 of size 512 next 955\n",
      "2024-09-19 17:20:59.929924: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c500 of size 512 next 895\n",
      "2024-09-19 17:20:59.929926: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c700 of size 512 next 1049\n",
      "2024-09-19 17:20:59.929928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608c900 of size 512 next 886\n",
      "2024-09-19 17:20:59.929931: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69608cb00 of size 262144 next 298\n",
      "2024-09-19 17:20:59.929933: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960ccb00 of size 256 next 838\n",
      "2024-09-19 17:20:59.929935: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960ccc00 of size 512 next 1027\n",
      "2024-09-19 17:20:59.929938: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960cce00 of size 512 next 1028\n",
      "2024-09-19 17:20:59.929940: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960cd000 of size 512 next 1096\n",
      "2024-09-19 17:20:59.929942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960cd200 of size 512 next 1097\n",
      "2024-09-19 17:20:59.929944: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960cd400 of size 512 next 889\n",
      "2024-09-19 17:20:59.929947: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6960cd600 of size 589824 next 873\n",
      "2024-09-19 17:20:59.929949: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615d600 of size 256 next 910\n",
      "2024-09-19 17:20:59.929951: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615d700 of size 2048 next 943\n",
      "2024-09-19 17:20:59.929954: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615df00 of size 2048 next 1029\n",
      "2024-09-19 17:20:59.929956: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615e700 of size 2048 next 1093\n",
      "2024-09-19 17:20:59.929958: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615ef00 of size 2048 next 287\n",
      "2024-09-19 17:20:59.929961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615f700 of size 2048 next 323\n",
      "2024-09-19 17:20:59.929963: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69615ff00 of size 262144 next 942\n",
      "2024-09-19 17:20:59.929965: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69619ff00 of size 256 next 1061\n",
      "2024-09-19 17:20:59.929967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0000 of size 512 next 1000\n",
      "2024-09-19 17:20:59.929970: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0200 of size 512 next 829\n",
      "2024-09-19 17:20:59.929972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0400 of size 512 next 828\n",
      "2024-09-19 17:20:59.929974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0600 of size 512 next 827\n",
      "2024-09-19 17:20:59.929976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0800 of size 512 next 826\n",
      "2024-09-19 17:20:59.929979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961a0a00 of size 262144 next 825\n",
      "2024-09-19 17:20:59.929981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e0a00 of size 256 next 824\n",
      "2024-09-19 17:20:59.929983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e0b00 of size 512 next 823\n",
      "2024-09-19 17:20:59.929986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e0d00 of size 512 next 822\n",
      "2024-09-19 17:20:59.929988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e0f00 of size 512 next 821\n",
      "2024-09-19 17:20:59.929990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e1100 of size 512 next 820\n",
      "2024-09-19 17:20:59.929992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e1300 of size 512 next 819\n",
      "2024-09-19 17:20:59.929995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6961e1500 of size 620288 next 1236\n",
      "2024-09-19 17:20:59.929997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696278c00 of size 4194304 next 852\n",
      "2024-09-19 17:20:59.930000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696678c00 of size 2048 next 1235\n",
      "2024-09-19 17:20:59.930002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696679400 of size 8192 next 1234\n",
      "2024-09-19 17:20:59.930004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69667b400 of size 9437184 next 1233\n",
      "2024-09-19 17:20:59.930007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f7b400 of size 8192 next 1232\n",
      "2024-09-19 17:20:59.930009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f7d400 of size 8192 next 1231\n",
      "2024-09-19 17:20:59.930011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f7f400 of size 8192 next 1230\n",
      "2024-09-19 17:20:59.930013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f81400 of size 8192 next 1229\n",
      "2024-09-19 17:20:59.930016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f83400 of size 37632 next 1228\n",
      "2024-09-19 17:20:59.930018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f8c700 of size 256 next 1227\n",
      "2024-09-19 17:20:59.930020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f8c800 of size 2048 next 1226\n",
      "2024-09-19 17:20:59.930023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa696f8d000 of size 4194304 next 1225\n",
      "2024-09-19 17:20:59.930025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69738d000 of size 8192 next 1224\n",
      "2024-09-19 17:20:59.930027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69738f000 of size 256 next 1223\n",
      "2024-09-19 17:20:59.930029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69738f100 of size 256 next 1222\n",
      "2024-09-19 17:20:59.930032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69738f200 of size 8192 next 1221\n",
      "2024-09-19 17:20:59.930034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa697391200 of size 256 next 1220\n",
      "2024-09-19 17:20:59.930036: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa697391300 of size 256 next 1219\n",
      "2024-09-19 17:20:59.930039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa697391400 of size 2048 next 1218\n",
      "2024-09-19 17:20:59.930041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa697391c00 of size 147456 next 1217\n",
      "2024-09-19 17:20:59.930043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973b5c00 of size 1024 next 1216\n",
      "2024-09-19 17:20:59.930045: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973b6000 of size 256 next 1215\n",
      "2024-09-19 17:20:59.930048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973b6100 of size 1024 next 1214\n",
      "2024-09-19 17:20:59.930050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973b6500 of size 1024 next 1213\n",
      "2024-09-19 17:20:59.930052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973b6900 of size 65536 next 1212\n",
      "2024-09-19 17:20:59.930055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6973c6900 of size 12818176 next 18446744073709551615\n",
      "2024-09-19 17:20:59.930057: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 134217728\n",
      "2024-09-19 17:20:59.930059: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c000000 of size 4194304 next 1026\n",
      "2024-09-19 17:20:59.930062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c400000 of size 1048576 next 1012\n",
      "2024-09-19 17:20:59.930064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c500000 of size 1048576 next 1030\n",
      "2024-09-19 17:20:59.930067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c600000 of size 1048576 next 877\n",
      "2024-09-19 17:20:59.930069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c700000 of size 1048576 next 1038\n",
      "2024-09-19 17:20:59.930071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c800000 of size 256 next 654\n",
      "2024-09-19 17:20:59.930074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c800100 of size 2048 next 653\n",
      "2024-09-19 17:20:59.930076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c800900 of size 2048 next 652\n",
      "2024-09-19 17:20:59.930079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c801100 of size 2048 next 651\n",
      "2024-09-19 17:20:59.930081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c801900 of size 2048 next 650\n",
      "2024-09-19 17:20:59.930083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c802100 of size 2048 next 649\n",
      "2024-09-19 17:20:59.930086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69c802900 of size 4194304 next 648\n",
      "2024-09-19 17:20:59.930088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc02900 of size 256 next 647\n",
      "2024-09-19 17:20:59.930090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc02a00 of size 2048 next 646\n",
      "2024-09-19 17:20:59.930093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc03200 of size 2048 next 645\n",
      "2024-09-19 17:20:59.930095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc03a00 of size 2048 next 644\n",
      "2024-09-19 17:20:59.930097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc04200 of size 2048 next 643\n",
      "2024-09-19 17:20:59.930099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc04a00 of size 2048 next 642\n",
      "2024-09-19 17:20:59.930102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69cc05200 of size 9437184 next 641\n",
      "2024-09-19 17:20:59.930104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d505200 of size 256 next 640\n",
      "2024-09-19 17:20:59.930106: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d505300 of size 8192 next 639\n",
      "2024-09-19 17:20:59.930109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d507300 of size 8192 next 638\n",
      "2024-09-19 17:20:59.930111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d509300 of size 8192 next 637\n",
      "2024-09-19 17:20:59.930114: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d50b300 of size 8192 next 636\n",
      "2024-09-19 17:20:59.930116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d50d300 of size 8192 next 635\n",
      "2024-09-19 17:20:59.930118: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d50f300 of size 4194304 next 634\n",
      "2024-09-19 17:20:59.930120: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d90f300 of size 256 next 633\n",
      "2024-09-19 17:20:59.930123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d90f400 of size 2048 next 632\n",
      "2024-09-19 17:20:59.930125: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d90fc00 of size 2048 next 631\n",
      "2024-09-19 17:20:59.930127: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d910400 of size 2048 next 630\n",
      "2024-09-19 17:20:59.930129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d910c00 of size 2048 next 629\n",
      "2024-09-19 17:20:59.930132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d911400 of size 2048 next 628\n",
      "2024-09-19 17:20:59.930134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69d911c00 of size 4194304 next 627\n",
      "2024-09-19 17:20:59.930136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd11c00 of size 256 next 626\n",
      "2024-09-19 17:20:59.930139: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd11d00 of size 2048 next 625\n",
      "2024-09-19 17:20:59.930141: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd12500 of size 2048 next 624\n",
      "2024-09-19 17:20:59.930143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd12d00 of size 2048 next 623\n",
      "2024-09-19 17:20:59.930145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd13500 of size 2048 next 622\n",
      "2024-09-19 17:20:59.930148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd13d00 of size 2048 next 621\n",
      "2024-09-19 17:20:59.930150: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69dd14500 of size 9437184 next 620\n",
      "2024-09-19 17:20:59.930152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e614500 of size 256 next 619\n",
      "2024-09-19 17:20:59.930154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e614600 of size 8192 next 618\n",
      "2024-09-19 17:20:59.930157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e616600 of size 8192 next 617\n",
      "2024-09-19 17:20:59.930159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e618600 of size 8192 next 616\n",
      "2024-09-19 17:20:59.930161: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e61a600 of size 8192 next 615\n",
      "2024-09-19 17:20:59.930164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e61c600 of size 8192 next 614\n",
      "2024-09-19 17:20:59.930166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69e61e600 of size 4194304 next 613\n",
      "2024-09-19 17:20:59.930168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1e600 of size 256 next 612\n",
      "2024-09-19 17:20:59.930170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1e700 of size 256 next 611\n",
      "2024-09-19 17:20:59.930173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1e800 of size 256 next 610\n",
      "2024-09-19 17:20:59.930175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1e900 of size 256 next 609\n",
      "2024-09-19 17:20:59.930177: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1ea00 of size 256 next 608\n",
      "2024-09-19 17:20:59.930179: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1eb00 of size 256 next 607\n",
      "2024-09-19 17:20:59.930182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea1ec00 of size 37632 next 606\n",
      "2024-09-19 17:20:59.930184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea27f00 of size 256 next 605\n",
      "2024-09-19 17:20:59.930186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea28000 of size 1280 next 604\n",
      "2024-09-19 17:20:59.930189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ea28500 of size 704512 next 598\n",
      "2024-09-19 17:20:59.930191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ead4500 of size 262144 next 385\n",
      "2024-09-19 17:20:59.930194: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69eb14500 of size 327680 next 597\n",
      "2024-09-19 17:20:59.930196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69eb64500 of size 1032192 next 596\n",
      "2024-09-19 17:20:59.930199: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60500 of size 256 next 600\n",
      "2024-09-19 17:20:59.930201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60600 of size 256 next 599\n",
      "2024-09-19 17:20:59.930203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60700 of size 256 next 595\n",
      "2024-09-19 17:20:59.930205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60800 of size 256 next 594\n",
      "2024-09-19 17:20:59.930208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60900 of size 256 next 601\n",
      "2024-09-19 17:20:59.930210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60a00 of size 256 next 603\n",
      "2024-09-19 17:20:59.930212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60b00 of size 256 next 602\n",
      "2024-09-19 17:20:59.930215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60c00 of size 256 next 593\n",
      "2024-09-19 17:20:59.930217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60d00 of size 256 next 592\n",
      "2024-09-19 17:20:59.930219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60e00 of size 256 next 305\n",
      "2024-09-19 17:20:59.930221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec60f00 of size 256 next 304\n",
      "2024-09-19 17:20:59.930224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61000 of size 256 next 303\n",
      "2024-09-19 17:20:59.930226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61100 of size 256 next 302\n",
      "2024-09-19 17:20:59.930228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61200 of size 256 next 293\n",
      "2024-09-19 17:20:59.930231: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61300 of size 256 next 295\n",
      "2024-09-19 17:20:59.930233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61400 of size 256 next 541\n",
      "2024-09-19 17:20:59.930235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61500 of size 256 next 288\n",
      "2024-09-19 17:20:59.930238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61600 of size 256 next 289\n",
      "2024-09-19 17:20:59.930240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61700 of size 256 next 317\n",
      "2024-09-19 17:20:59.930242: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61800 of size 256 next 274\n",
      "2024-09-19 17:20:59.930244: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61900 of size 256 next 275\n",
      "2024-09-19 17:20:59.930247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61a00 of size 256 next 301\n",
      "2024-09-19 17:20:59.930249: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61b00 of size 256 next 292\n",
      "2024-09-19 17:20:59.930251: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61c00 of size 256 next 574\n",
      "2024-09-19 17:20:59.930253: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61d00 of size 256 next 296\n",
      "2024-09-19 17:20:59.930256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61e00 of size 256 next 277\n",
      "2024-09-19 17:20:59.930258: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec61f00 of size 256 next 291\n",
      "2024-09-19 17:20:59.930260: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62000 of size 256 next 297\n",
      "2024-09-19 17:20:59.930263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62100 of size 256 next 554\n",
      "2024-09-19 17:20:59.930265: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62200 of size 256 next 381\n",
      "2024-09-19 17:20:59.930267: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62300 of size 256 next 344\n",
      "2024-09-19 17:20:59.930269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62400 of size 256 next 556\n",
      "2024-09-19 17:20:59.930272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62500 of size 256 next 433\n",
      "2024-09-19 17:20:59.930274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62600 of size 256 next 412\n",
      "2024-09-19 17:20:59.930276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62700 of size 256 next 372\n",
      "2024-09-19 17:20:59.930278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62800 of size 256 next 393\n",
      "2024-09-19 17:20:59.930281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62900 of size 256 next 432\n",
      "2024-09-19 17:20:59.930283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62a00 of size 256 next 510\n",
      "2024-09-19 17:20:59.930285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62b00 of size 256 next 502\n",
      "2024-09-19 17:20:59.930288: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62c00 of size 256 next 273\n",
      "2024-09-19 17:20:59.930290: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62d00 of size 256 next 272\n",
      "2024-09-19 17:20:59.930292: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62e00 of size 256 next 270\n",
      "2024-09-19 17:20:59.930295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec62f00 of size 256 next 269\n",
      "2024-09-19 17:20:59.930297: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63000 of size 256 next 268\n",
      "2024-09-19 17:20:59.930299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63100 of size 256 next 267\n",
      "2024-09-19 17:20:59.930301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63200 of size 256 next 266\n",
      "2024-09-19 17:20:59.930304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63300 of size 256 next 265\n",
      "2024-09-19 17:20:59.930306: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63400 of size 256 next 264\n",
      "2024-09-19 17:20:59.930308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63500 of size 256 next 263\n",
      "2024-09-19 17:20:59.930311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63600 of size 256 next 262\n",
      "2024-09-19 17:20:59.930313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63700 of size 256 next 261\n",
      "2024-09-19 17:20:59.930315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec63800 of size 16384 next 260\n",
      "2024-09-19 17:20:59.930318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67800 of size 256 next 259\n",
      "2024-09-19 17:20:59.930320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67900 of size 256 next 258\n",
      "2024-09-19 17:20:59.930322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67a00 of size 256 next 257\n",
      "2024-09-19 17:20:59.930325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67b00 of size 256 next 256\n",
      "2024-09-19 17:20:59.930327: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67c00 of size 256 next 255\n",
      "2024-09-19 17:20:59.930329: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67d00 of size 256 next 254\n",
      "2024-09-19 17:20:59.930332: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ec67e00 of size 247552 next 591\n",
      "2024-09-19 17:20:59.930334: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69eca4500 of size 1179648 next 590\n",
      "2024-09-19 17:20:59.930336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69edc4500 of size 1114112 next 588\n",
      "2024-09-19 17:20:59.930339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69eed4500 of size 262144 next 587\n",
      "2024-09-19 17:20:59.930341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef14500 of size 2048 next 396\n",
      "2024-09-19 17:20:59.930344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef14d00 of size 512 next 507\n",
      "2024-09-19 17:20:59.930346: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef14f00 of size 2048 next 508\n",
      "2024-09-19 17:20:59.930348: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef15700 of size 512 next 569\n",
      "2024-09-19 17:20:59.930350: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef15900 of size 512 next 571\n",
      "2024-09-19 17:20:59.930353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef15b00 of size 512 next 364\n",
      "2024-09-19 17:20:59.930355: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef15d00 of size 2048 next 383\n",
      "2024-09-19 17:20:59.930357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef16500 of size 2048 next 332\n",
      "2024-09-19 17:20:59.930360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef16d00 of size 512 next 333\n",
      "2024-09-19 17:20:59.930362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef16f00 of size 512 next 503\n",
      "2024-09-19 17:20:59.930364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef17100 of size 512 next 505\n",
      "2024-09-19 17:20:59.930366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef17300 of size 512 next 568\n",
      "2024-09-19 17:20:59.930369: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef17500 of size 2048 next 584\n",
      "2024-09-19 17:20:59.930371: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef17d00 of size 512 next 583\n",
      "2024-09-19 17:20:59.930373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef17f00 of size 2048 next 377\n",
      "2024-09-19 17:20:59.930376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef18700 of size 1024 next 378\n",
      "2024-09-19 17:20:59.930378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef18b00 of size 512 next 486\n",
      "2024-09-19 17:20:59.930381: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef18d00 of size 512 next 487\n",
      "2024-09-19 17:20:59.930383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef18f00 of size 512 next 313\n",
      "2024-09-19 17:20:59.930386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef19100 of size 512 next 401\n",
      "2024-09-19 17:20:59.930388: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef19300 of size 512 next 458\n",
      "2024-09-19 17:20:59.930390: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef19500 of size 1024 next 459\n",
      "2024-09-19 17:20:59.930392: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef19900 of size 4096 next 436\n",
      "2024-09-19 17:20:59.930395: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1a900 of size 1024 next 438\n",
      "2024-09-19 17:20:59.930397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1ad00 of size 256 next 440\n",
      "2024-09-19 17:20:59.930400: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1ae00 of size 2048 next 565\n",
      "2024-09-19 17:20:59.930402: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1b600 of size 512 next 567\n",
      "2024-09-19 17:20:59.930404: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1b800 of size 512 next 534\n",
      "2024-09-19 17:20:59.930406: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1ba00 of size 512 next 336\n",
      "2024-09-19 17:20:59.930409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1bc00 of size 1024 next 337\n",
      "2024-09-19 17:20:59.930411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1c000 of size 1024 next 347\n",
      "2024-09-19 17:20:59.930413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1c400 of size 1024 next 455\n",
      "2024-09-19 17:20:59.930416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1c800 of size 1024 next 589\n",
      "2024-09-19 17:20:59.930418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1cc00 of size 512 next 444\n",
      "2024-09-19 17:20:59.930420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1ce00 of size 2048 next 434\n",
      "2024-09-19 17:20:59.930422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1d600 of size 512 next 435\n",
      "2024-09-19 17:20:59.930425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1d800 of size 2048 next 471\n",
      "2024-09-19 17:20:59.930427: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1e000 of size 512 next 472\n",
      "2024-09-19 17:20:59.930430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1e200 of size 1024 next 282\n",
      "2024-09-19 17:20:59.930432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1e600 of size 1024 next 489\n",
      "2024-09-19 17:20:59.930434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1ea00 of size 4096 next 453\n",
      "2024-09-19 17:20:59.930437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef1fa00 of size 2048 next 456\n",
      "2024-09-19 17:20:59.930439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef20200 of size 1024 next 422\n",
      "2024-09-19 17:20:59.930441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef20600 of size 1024 next 423\n",
      "2024-09-19 17:20:59.930444: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef20a00 of size 4096 next 352\n",
      "2024-09-19 17:20:59.930446: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef21a00 of size 4096 next 367\n",
      "2024-09-19 17:20:59.930448: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef22a00 of size 1024 next 462\n",
      "2024-09-19 17:20:59.930451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef22e00 of size 2048 next 464\n",
      "2024-09-19 17:20:59.930453: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef23600 of size 512 next 532\n",
      "2024-09-19 17:20:59.930455: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef23800 of size 1024 next 426\n",
      "2024-09-19 17:20:59.930458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef23c00 of size 4096 next 530\n",
      "2024-09-19 17:20:59.930460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef24c00 of size 4096 next 473\n",
      "2024-09-19 17:20:59.930462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef25c00 of size 4096 next 373\n",
      "2024-09-19 17:20:59.930465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef26c00 of size 256 next 384\n",
      "2024-09-19 17:20:59.930467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef26d00 of size 1024 next 386\n",
      "2024-09-19 17:20:59.930469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef27100 of size 2048 next 368\n",
      "2024-09-19 17:20:59.930471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef27900 of size 4096 next 369\n",
      "2024-09-19 17:20:59.930474: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef28900 of size 1024 next 314\n",
      "2024-09-19 17:20:59.930476: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef28d00 of size 4096 next 535\n",
      "2024-09-19 17:20:59.930478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef29d00 of size 2048 next 536\n",
      "2024-09-19 17:20:59.930481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2a500 of size 1024 next 564\n",
      "2024-09-19 17:20:59.930483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2a900 of size 4096 next 566\n",
      "2024-09-19 17:20:59.930485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2b900 of size 4096 next 467\n",
      "2024-09-19 17:20:59.930488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2c900 of size 1024 next 468\n",
      "2024-09-19 17:20:59.930490: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2cd00 of size 4096 next 325\n",
      "2024-09-19 17:20:59.930492: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2dd00 of size 1024 next 362\n",
      "2024-09-19 17:20:59.930495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2e100 of size 4096 next 321\n",
      "2024-09-19 17:20:59.930497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef2f100 of size 4096 next 400\n",
      "2024-09-19 17:20:59.930499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef30100 of size 4096 next 537\n",
      "2024-09-19 17:20:59.930502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef31100 of size 2048 next 390\n",
      "2024-09-19 17:20:59.930504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef31900 of size 8192 next 359\n",
      "2024-09-19 17:20:59.930507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef33900 of size 4096 next 360\n",
      "2024-09-19 17:20:59.930509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef34900 of size 2048 next 528\n",
      "2024-09-19 17:20:59.930511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef35100 of size 4096 next 531\n",
      "2024-09-19 17:20:59.930514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef36100 of size 8192 next 463\n",
      "2024-09-19 17:20:59.930516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef38100 of size 512 next 307\n",
      "2024-09-19 17:20:59.930518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef38300 of size 8192 next 452\n",
      "2024-09-19 17:20:59.930521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef3a300 of size 8192 next 500\n",
      "2024-09-19 17:20:59.930523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef3c300 of size 2048 next 501\n",
      "2024-09-19 17:20:59.930526: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef3cb00 of size 512 next 445\n",
      "2024-09-19 17:20:59.930528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef3cd00 of size 96256 next 586\n",
      "2024-09-19 17:20:59.930530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef54500 of size 147456 next 446\n",
      "2024-09-19 17:20:59.930533: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef78500 of size 147456 next 388\n",
      "2024-09-19 17:20:59.930535: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef9c500 of size 1024 next 358\n",
      "2024-09-19 17:20:59.930538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef9c900 of size 256 next 389\n",
      "2024-09-19 17:20:59.930540: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69ef9ca00 of size 293632 next 585\n",
      "2024-09-19 17:20:59.930543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69efe4500 of size 786432 next 582\n",
      "2024-09-19 17:20:59.930545: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f0a4500 of size 903936 next 1105\n",
      "2024-09-19 17:20:59.930548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f181000 of size 256 next 1900\n",
      "2024-09-19 17:20:59.930550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f181100 of size 2048 next 1899\n",
      "2024-09-19 17:20:59.930552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f181900 of size 2048 next 1898\n",
      "2024-09-19 17:20:59.930554: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f182100 of size 2048 next 1897\n",
      "2024-09-19 17:20:59.930557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f182900 of size 2048 next 1896\n",
      "2024-09-19 17:20:59.930559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f183100 of size 2048 next 1895\n",
      "2024-09-19 17:20:59.930561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69f183900 of size 11711744 next 2223\n",
      "2024-09-19 17:20:59.930564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcaee00 of size 256 next 1407\n",
      "2024-09-19 17:20:59.930566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcaef00 of size 2048 next 1411\n",
      "2024-09-19 17:20:59.930569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcaf700 of size 2048 next 1492\n",
      "2024-09-19 17:20:59.930571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcaff00 of size 2048 next 1493\n",
      "2024-09-19 17:20:59.930573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcb0700 of size 2048 next 1589\n",
      "2024-09-19 17:20:59.930576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcb0f00 of size 2048 next 1590\n",
      "2024-09-19 17:20:59.930578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcb1700 of size 262144 next 1621\n",
      "2024-09-19 17:20:59.930580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf1700 of size 256 next 1569\n",
      "2024-09-19 17:20:59.930583: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf1800 of size 512 next 1649\n",
      "2024-09-19 17:20:59.930585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf1a00 of size 512 next 1615\n",
      "2024-09-19 17:20:59.930587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf1c00 of size 512 next 1616\n",
      "2024-09-19 17:20:59.930590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf1e00 of size 512 next 1664\n",
      "2024-09-19 17:20:59.930592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf2000 of size 512 next 1665\n",
      "2024-09-19 17:20:59.930594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fcf2200 of size 262144 next 1460\n",
      "2024-09-19 17:20:59.930597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32200 of size 256 next 1461\n",
      "2024-09-19 17:20:59.930599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32300 of size 512 next 1473\n",
      "2024-09-19 17:20:59.930601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32500 of size 512 next 1474\n",
      "2024-09-19 17:20:59.930604: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32700 of size 512 next 1654\n",
      "2024-09-19 17:20:59.930606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32900 of size 512 next 1655\n",
      "2024-09-19 17:20:59.930608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32b00 of size 512 next 1640\n",
      "2024-09-19 17:20:59.930611: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fd32d00 of size 589824 next 1611\n",
      "2024-09-19 17:20:59.930613: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc2d00 of size 256 next 1653\n",
      "2024-09-19 17:20:59.930615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc2e00 of size 2048 next 1469\n",
      "2024-09-19 17:20:59.930618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc3600 of size 2048 next 1650\n",
      "2024-09-19 17:20:59.930620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc3e00 of size 2048 next 1651\n",
      "2024-09-19 17:20:59.930623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc4600 of size 2048 next 1652\n",
      "2024-09-19 17:20:59.930625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc4e00 of size 2048 next 1607\n",
      "2024-09-19 17:20:59.930627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fdc5600 of size 262144 next 1464\n",
      "2024-09-19 17:20:59.930630: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe05600 of size 256 next 1567\n",
      "2024-09-19 17:20:59.930632: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe05700 of size 1024 next 1554\n",
      "2024-09-19 17:20:59.930634: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe05b00 of size 1024 next 1555\n",
      "2024-09-19 17:20:59.930637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe05f00 of size 1024 next 1406\n",
      "2024-09-19 17:20:59.930639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe06300 of size 1024 next 1441\n",
      "2024-09-19 17:20:59.930641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe06700 of size 1024 next 1442\n",
      "2024-09-19 17:20:59.930644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe06b00 of size 524288 next 1631\n",
      "2024-09-19 17:20:59.930646: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe86b00 of size 256 next 1585\n",
      "2024-09-19 17:20:59.930649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe86c00 of size 1024 next 1475\n",
      "2024-09-19 17:20:59.930651: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe87000 of size 1024 next 1510\n",
      "2024-09-19 17:20:59.930653: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe87400 of size 1024 next 1511\n",
      "2024-09-19 17:20:59.930655: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe87800 of size 1024 next 1512\n",
      "2024-09-19 17:20:59.930658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe87c00 of size 1024 next 1574\n",
      "2024-09-19 17:20:59.930660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe88000 of size 256 next 1627\n",
      "2024-09-19 17:20:59.930662: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe88100 of size 4096 next 1661\n",
      "2024-09-19 17:20:59.930665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe89100 of size 4096 next 1594\n",
      "2024-09-19 17:20:59.930667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe8a100 of size 4096 next 1462\n",
      "2024-09-19 17:20:59.930669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe8b100 of size 4096 next 1532\n",
      "2024-09-19 17:20:59.930672: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe8c100 of size 4096 next 1667\n",
      "2024-09-19 17:20:59.930674: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa69fe8d100 of size 2078464 next 1387\n",
      "2024-09-19 17:20:59.930677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0088800 of size 231424 next 1396\n",
      "2024-09-19 17:20:59.930679: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c1000 of size 256 next 1530\n",
      "2024-09-19 17:20:59.930682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c1100 of size 4096 next 1452\n",
      "2024-09-19 17:20:59.930684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c2100 of size 4096 next 1508\n",
      "2024-09-19 17:20:59.930686: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c3100 of size 4096 next 1496\n",
      "2024-09-19 17:20:59.930689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c4100 of size 4096 next 1523\n",
      "2024-09-19 17:20:59.930691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c5100 of size 4096 next 1526\n",
      "2024-09-19 17:20:59.930693: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a00c6100 of size 1048576 next 1591\n",
      "2024-09-19 17:20:59.930696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c6100 of size 256 next 1592\n",
      "2024-09-19 17:20:59.930698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c6200 of size 1024 next 1556\n",
      "2024-09-19 17:20:59.930700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c6600 of size 1024 next 1656\n",
      "2024-09-19 17:20:59.930703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c6a00 of size 1024 next 850\n",
      "2024-09-19 17:20:59.930705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c6e00 of size 1024 next 1487\n",
      "2024-09-19 17:20:59.930707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c7200 of size 1024 next 1417\n",
      "2024-09-19 17:20:59.930710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a01c7600 of size 1048576 next 1669\n",
      "2024-09-19 17:20:59.930712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c7600 of size 256 next 1670\n",
      "2024-09-19 17:20:59.930714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c7700 of size 1024 next 1504\n",
      "2024-09-19 17:20:59.930717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c7b00 of size 1024 next 1448\n",
      "2024-09-19 17:20:59.930719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c7f00 of size 1024 next 1505\n",
      "2024-09-19 17:20:59.930721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c8300 of size 1024 next 1416\n",
      "2024-09-19 17:20:59.930724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c8700 of size 1024 next 1673\n",
      "2024-09-19 17:20:59.930726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a02c8b00 of size 2359296 next 1674\n",
      "2024-09-19 17:20:59.930728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0508b00 of size 256 next 1506\n",
      "2024-09-19 17:20:59.930731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0508c00 of size 4096 next 1536\n",
      "2024-09-19 17:20:59.930733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0509c00 of size 4096 next 331\n",
      "2024-09-19 17:20:59.930735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a050ac00 of size 4096 next 1666\n",
      "2024-09-19 17:20:59.930737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a050bc00 of size 4096 next 1562\n",
      "2024-09-19 17:20:59.930740: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a050cc00 of size 4096 next 1563\n",
      "2024-09-19 17:20:59.930742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a050dc00 of size 1048576 next 1564\n",
      "2024-09-19 17:20:59.930744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060dc00 of size 256 next 1593\n",
      "2024-09-19 17:20:59.930747: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060dd00 of size 1024 next 1380\n",
      "2024-09-19 17:20:59.930749: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060e100 of size 1024 next 1379\n",
      "2024-09-19 17:20:59.930751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060e500 of size 1024 next 1378\n",
      "2024-09-19 17:20:59.930754: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060e900 of size 1024 next 1377\n",
      "2024-09-19 17:20:59.930756: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060ed00 of size 1024 next 1376\n",
      "2024-09-19 17:20:59.930758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a060f100 of size 1048576 next 1375\n",
      "2024-09-19 17:20:59.930761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a070f100 of size 256 next 1374\n",
      "2024-09-19 17:20:59.930763: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a070f200 of size 1024 next 1373\n",
      "2024-09-19 17:20:59.930765: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a070f600 of size 1024 next 1372\n",
      "2024-09-19 17:20:59.930767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a070fa00 of size 1024 next 1371\n",
      "2024-09-19 17:20:59.930770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a070fe00 of size 1024 next 1370\n",
      "2024-09-19 17:20:59.930772: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0710200 of size 1024 next 1369\n",
      "2024-09-19 17:20:59.930774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0710600 of size 2359296 next 1368\n",
      "2024-09-19 17:20:59.930777: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0950600 of size 256 next 1367\n",
      "2024-09-19 17:20:59.930779: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0950700 of size 4096 next 1366\n",
      "2024-09-19 17:20:59.930781: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0951700 of size 4096 next 1365\n",
      "2024-09-19 17:20:59.930784: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0952700 of size 4096 next 1364\n",
      "2024-09-19 17:20:59.930786: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0953700 of size 4096 next 1363\n",
      "2024-09-19 17:20:59.930788: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0954700 of size 4096 next 1362\n",
      "2024-09-19 17:20:59.930790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0955700 of size 1048576 next 1361\n",
      "2024-09-19 17:20:59.930793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a55700 of size 256 next 1360\n",
      "2024-09-19 17:20:59.930795: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a55800 of size 2048 next 1359\n",
      "2024-09-19 17:20:59.930797: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a56000 of size 2048 next 1358\n",
      "2024-09-19 17:20:59.930800: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a56800 of size 2048 next 1357\n",
      "2024-09-19 17:20:59.930802: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a57000 of size 2048 next 1356\n",
      "2024-09-19 17:20:59.930804: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a57800 of size 2048 next 1355\n",
      "2024-09-19 17:20:59.930806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a58000 of size 256 next 1354\n",
      "2024-09-19 17:20:59.930809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a58100 of size 2048 next 876\n",
      "2024-09-19 17:20:59.930811: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a58900 of size 2048 next 1353\n",
      "2024-09-19 17:20:59.930813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a59100 of size 2048 next 1352\n",
      "2024-09-19 17:20:59.930816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a59900 of size 2048 next 1351\n",
      "2024-09-19 17:20:59.930818: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a5a100 of size 2048 next 1350\n",
      "2024-09-19 17:20:59.930820: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a5a900 of size 256 next 1349\n",
      "2024-09-19 17:20:59.930822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a5aa00 of size 8192 next 1348\n",
      "2024-09-19 17:20:59.930825: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a5ca00 of size 8192 next 1347\n",
      "2024-09-19 17:20:59.930827: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a5ea00 of size 8192 next 1346\n",
      "2024-09-19 17:20:59.930829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a60a00 of size 8192 next 1345\n",
      "2024-09-19 17:20:59.930831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a62a00 of size 8192 next 1344\n",
      "2024-09-19 17:20:59.930834: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a64a00 of size 256 next 1342\n",
      "2024-09-19 17:20:59.930836: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a64b00 of size 8192 next 1341\n",
      "2024-09-19 17:20:59.930838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a66b00 of size 8192 next 1340\n",
      "2024-09-19 17:20:59.930841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a68b00 of size 8192 next 1339\n",
      "2024-09-19 17:20:59.930843: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6ab00 of size 8192 next 1338\n",
      "2024-09-19 17:20:59.930845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6cb00 of size 8192 next 1337\n",
      "2024-09-19 17:20:59.930848: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6eb00 of size 256 next 1336\n",
      "2024-09-19 17:20:59.930850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6ec00 of size 2048 next 1335\n",
      "2024-09-19 17:20:59.930852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6f400 of size 2048 next 1334\n",
      "2024-09-19 17:20:59.930854: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a6fc00 of size 2048 next 1333\n",
      "2024-09-19 17:20:59.930857: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a70400 of size 2048 next 1332\n",
      "2024-09-19 17:20:59.930859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a70c00 of size 2048 next 1331\n",
      "2024-09-19 17:20:59.930861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a71400 of size 256 next 1329\n",
      "2024-09-19 17:20:59.930863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a71500 of size 2048 next 1328\n",
      "2024-09-19 17:20:59.930866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a71d00 of size 2048 next 1327\n",
      "2024-09-19 17:20:59.930868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a72500 of size 2048 next 1326\n",
      "2024-09-19 17:20:59.930870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a72d00 of size 2048 next 1325\n",
      "2024-09-19 17:20:59.930872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a73500 of size 2048 next 1324\n",
      "2024-09-19 17:20:59.930875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a73d00 of size 256 next 1322\n",
      "2024-09-19 17:20:59.930877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a73e00 of size 8192 next 1321\n",
      "2024-09-19 17:20:59.930879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a75e00 of size 8192 next 1320\n",
      "2024-09-19 17:20:59.930882: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a77e00 of size 8192 next 1319\n",
      "2024-09-19 17:20:59.930884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a79e00 of size 8192 next 1318\n",
      "2024-09-19 17:20:59.930886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7be00 of size 8192 next 1317\n",
      "2024-09-19 17:20:59.930888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7de00 of size 256 next 1315\n",
      "2024-09-19 17:20:59.930891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7df00 of size 2048 next 1314\n",
      "2024-09-19 17:20:59.930893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7e700 of size 2048 next 1313\n",
      "2024-09-19 17:20:59.930895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7ef00 of size 2048 next 1312\n",
      "2024-09-19 17:20:59.930898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7f700 of size 2048 next 1311\n",
      "2024-09-19 17:20:59.930900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a7ff00 of size 2048 next 1310\n",
      "2024-09-19 17:20:59.930902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a80700 of size 256 next 1309\n",
      "2024-09-19 17:20:59.930904: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a80800 of size 2048 next 1308\n",
      "2024-09-19 17:20:59.930907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a81000 of size 2048 next 1307\n",
      "2024-09-19 17:20:59.930909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a81800 of size 2048 next 1306\n",
      "2024-09-19 17:20:59.930911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a82000 of size 2048 next 1305\n",
      "2024-09-19 17:20:59.930913: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a82800 of size 2048 next 1304\n",
      "2024-09-19 17:20:59.930916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a83000 of size 256 next 1302\n",
      "2024-09-19 17:20:59.930918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a83100 of size 8192 next 1301\n",
      "2024-09-19 17:20:59.930920: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a85100 of size 8192 next 1300\n",
      "2024-09-19 17:20:59.930923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a87100 of size 8192 next 1299\n",
      "2024-09-19 17:20:59.930925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a89100 of size 8192 next 1298\n",
      "2024-09-19 17:20:59.930927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8b100 of size 8192 next 1297\n",
      "2024-09-19 17:20:59.930929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d100 of size 256 next 1295\n",
      "2024-09-19 17:20:59.930932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d200 of size 256 next 1294\n",
      "2024-09-19 17:20:59.930934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d300 of size 256 next 1293\n",
      "2024-09-19 17:20:59.930936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d400 of size 256 next 1292\n",
      "2024-09-19 17:20:59.930939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d500 of size 256 next 1291\n",
      "2024-09-19 17:20:59.930941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d600 of size 256 next 1290\n",
      "2024-09-19 17:20:59.930943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a8d700 of size 37632 next 1289\n",
      "2024-09-19 17:20:59.930945: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a96a00 of size 256 next 1288\n",
      "2024-09-19 17:20:59.930948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a96b00 of size 1280 next 1287\n",
      "2024-09-19 17:20:59.930950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0a97000 of size 589824 next 1053\n",
      "2024-09-19 17:20:59.930952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0b27000 of size 937984 next 1384\n",
      "2024-09-19 17:20:59.930955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0c000 of size 256 next 2202\n",
      "2024-09-19 17:20:59.930957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0c100 of size 2048 next 2203\n",
      "2024-09-19 17:20:59.930959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0c900 of size 2048 next 2225\n",
      "2024-09-19 17:20:59.930962: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0d100 of size 2048 next 2227\n",
      "2024-09-19 17:20:59.930964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0d900 of size 2048 next 2084\n",
      "2024-09-19 17:20:59.930967: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0e100 of size 2048 next 2063\n",
      "2024-09-19 17:20:59.930969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0c0e900 of size 1038080 next 862\n",
      "2024-09-19 17:20:59.930972: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c000 of size 256 next 1479\n",
      "2024-09-19 17:20:59.930974: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c100 of size 512 next 1480\n",
      "2024-09-19 17:20:59.930976: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c300 of size 512 next 1573\n",
      "2024-09-19 17:20:59.930979: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c500 of size 512 next 1575\n",
      "2024-09-19 17:20:59.930981: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c700 of size 512 next 1534\n",
      "2024-09-19 17:20:59.930983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0c900 of size 512 next 1535\n",
      "2024-09-19 17:20:59.930986: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d0cb00 of size 589824 next 1484\n",
      "2024-09-19 17:20:59.930988: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9cb00 of size 256 next 1547\n",
      "2024-09-19 17:20:59.930990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9cc00 of size 2048 next 1565\n",
      "2024-09-19 17:20:59.930993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9d400 of size 2048 next 1601\n",
      "2024-09-19 17:20:59.930995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9dc00 of size 2048 next 1603\n",
      "2024-09-19 17:20:59.930997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9e400 of size 2048 next 1610\n",
      "2024-09-19 17:20:59.931000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9ec00 of size 2048 next 1560\n",
      "2024-09-19 17:20:59.931002: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0d9f400 of size 262144 next 1561\n",
      "2024-09-19 17:20:59.931005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ddf400 of size 256 next 1481\n",
      "2024-09-19 17:20:59.931007: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ddf500 of size 2048 next 1559\n",
      "2024-09-19 17:20:59.931009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ddfd00 of size 2048 next 1444\n",
      "2024-09-19 17:20:59.931012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0de0500 of size 2048 next 1671\n",
      "2024-09-19 17:20:59.931014: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0de0d00 of size 2048 next 1672\n",
      "2024-09-19 17:20:59.931016: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0de1500 of size 2048 next 1623\n",
      "2024-09-19 17:20:59.931019: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0de1d00 of size 524288 next 1629\n",
      "2024-09-19 17:20:59.931021: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e61d00 of size 256 next 1598\n",
      "2024-09-19 17:20:59.931023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e61e00 of size 512 next 1586\n",
      "2024-09-19 17:20:59.931026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e62000 of size 512 next 1587\n",
      "2024-09-19 17:20:59.931028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e62200 of size 512 next 1432\n",
      "2024-09-19 17:20:59.931030: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e62400 of size 512 next 1433\n",
      "2024-09-19 17:20:59.931033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e62600 of size 512 next 1596\n",
      "2024-09-19 17:20:59.931035: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0e62800 of size 262144 next 1490\n",
      "2024-09-19 17:20:59.931037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea2800 of size 256 next 1513\n",
      "2024-09-19 17:20:59.931039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea2900 of size 512 next 1514\n",
      "2024-09-19 17:20:59.931042: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea2b00 of size 512 next 1498\n",
      "2024-09-19 17:20:59.931044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea2d00 of size 512 next 1499\n",
      "2024-09-19 17:20:59.931046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea2f00 of size 512 next 1476\n",
      "2024-09-19 17:20:59.931049: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea3100 of size 512 next 1478\n",
      "2024-09-19 17:20:59.931051: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0ea3300 of size 589824 next 1431\n",
      "2024-09-19 17:20:59.931053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f33300 of size 256 next 1578\n",
      "2024-09-19 17:20:59.931056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f33400 of size 2048 next 1533\n",
      "2024-09-19 17:20:59.931058: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f33c00 of size 2048 next 1494\n",
      "2024-09-19 17:20:59.931060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f34400 of size 2048 next 1495\n",
      "2024-09-19 17:20:59.931063: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f34c00 of size 2048 next 1471\n",
      "2024-09-19 17:20:59.931065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f35400 of size 2048 next 1472\n",
      "2024-09-19 17:20:59.931067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f35c00 of size 262144 next 1517\n",
      "2024-09-19 17:20:59.931070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f75c00 of size 256 next 1612\n",
      "2024-09-19 17:20:59.931072: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f75d00 of size 512 next 1544\n",
      "2024-09-19 17:20:59.931074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f75f00 of size 512 next 1457\n",
      "2024-09-19 17:20:59.931077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f76100 of size 512 next 1465\n",
      "2024-09-19 17:20:59.931079: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f76300 of size 512 next 1619\n",
      "2024-09-19 17:20:59.931081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f76500 of size 512 next 1620\n",
      "2024-09-19 17:20:59.931084: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0f76700 of size 262144 next 1485\n",
      "2024-09-19 17:20:59.931086: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb6700 of size 256 next 1486\n",
      "2024-09-19 17:20:59.931089: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb6800 of size 512 next 1552\n",
      "2024-09-19 17:20:59.931091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb6a00 of size 512 next 1553\n",
      "2024-09-19 17:20:59.931093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb6c00 of size 512 next 1540\n",
      "2024-09-19 17:20:59.931096: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb6e00 of size 512 next 1628\n",
      "2024-09-19 17:20:59.931098: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb7000 of size 512 next 1630\n",
      "2024-09-19 17:20:59.931100: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a0fb7200 of size 1134080 next 866\n",
      "2024-09-19 17:20:59.931103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a10cc000 of size 2359296 next 2080\n",
      "2024-09-19 17:20:59.931105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130c000 of size 256 next 1999\n",
      "2024-09-19 17:20:59.931108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130c100 of size 1024 next 1994\n",
      "2024-09-19 17:20:59.931110: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130c500 of size 1024 next 2200\n",
      "2024-09-19 17:20:59.931112: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130c900 of size 1024 next 2046\n",
      "2024-09-19 17:20:59.931115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130cd00 of size 1024 next 1952\n",
      "2024-09-19 17:20:59.931117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130d100 of size 1024 next 2159\n",
      "2024-09-19 17:20:59.931119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a130d500 of size 1048576 next 2127\n",
      "2024-09-19 17:20:59.931121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140d500 of size 256 next 2143\n",
      "2024-09-19 17:20:59.931124: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140d600 of size 1024 next 2135\n",
      "2024-09-19 17:20:59.931126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140da00 of size 1024 next 2231\n",
      "2024-09-19 17:20:59.931128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140de00 of size 1024 next 2000\n",
      "2024-09-19 17:20:59.931131: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140e200 of size 1024 next 2177\n",
      "2024-09-19 17:20:59.931133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140e600 of size 1024 next 2201\n",
      "2024-09-19 17:20:59.931135: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140ea00 of size 256 next 2111\n",
      "2024-09-19 17:20:59.931138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140eb00 of size 4096 next 2005\n",
      "2024-09-19 17:20:59.931140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a140fb00 of size 4096 next 2207\n",
      "2024-09-19 17:20:59.931142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1410b00 of size 4096 next 2180\n",
      "2024-09-19 17:20:59.931145: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1411b00 of size 4096 next 2116\n",
      "2024-09-19 17:20:59.931147: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1412b00 of size 4096 next 2117\n",
      "2024-09-19 17:20:59.931149: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1413b00 of size 1606912 next 870\n",
      "2024-09-19 17:20:59.931152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159c000 of size 2048 next 1129\n",
      "2024-09-19 17:20:59.931154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159c800 of size 512 next 1128\n",
      "2024-09-19 17:20:59.931157: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159ca00 of size 2048 next 1127\n",
      "2024-09-19 17:20:59.931159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159d200 of size 512 next 1126\n",
      "2024-09-19 17:20:59.931162: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159d400 of size 2048 next 1125\n",
      "2024-09-19 17:20:59.931164: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a159dc00 of size 262144 next 1124\n",
      "2024-09-19 17:20:59.931166: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a15ddc00 of size 1024 next 1123\n",
      "2024-09-19 17:20:59.931168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a15de000 of size 2048 next 1122\n",
      "2024-09-19 17:20:59.931171: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a15de800 of size 524288 next 1121\n",
      "2024-09-19 17:20:59.931173: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a165e800 of size 512 next 1120\n",
      "2024-09-19 17:20:59.931175: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a165ea00 of size 2048 next 1119\n",
      "2024-09-19 17:20:59.931178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a165f200 of size 512 next 1118\n",
      "2024-09-19 17:20:59.931180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a165f400 of size 2048 next 1117\n",
      "2024-09-19 17:20:59.931182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a165fc00 of size 2048 next 1116\n",
      "2024-09-19 17:20:59.931184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1660400 of size 512 next 1115\n",
      "2024-09-19 17:20:59.931187: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1660600 of size 2048 next 1114\n",
      "2024-09-19 17:20:59.931189: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1660e00 of size 9437184 next 867\n",
      "2024-09-19 17:20:59.931191: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1f60e00 of size 1024 next 1112\n",
      "2024-09-19 17:20:59.931193: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1f61200 of size 4096 next 1111\n",
      "2024-09-19 17:20:59.931196: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1f62200 of size 4096 next 1110\n",
      "2024-09-19 17:20:59.931198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1f63200 of size 512 next 844\n",
      "2024-09-19 17:20:59.931201: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1f63400 of size 262144 next 1392\n",
      "2024-09-19 17:20:59.931203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a1fa3400 of size 2359296 next 1023\n",
      "2024-09-19 17:20:59.931205: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a21e3400 of size 2359296 next 1073\n",
      "2024-09-19 17:20:59.931207: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2423400 of size 2359296 next 988\n",
      "2024-09-19 17:20:59.931210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2663400 of size 1048576 next 1104\n",
      "2024-09-19 17:20:59.931212: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2763400 of size 1048576 next 952\n",
      "2024-09-19 17:20:59.931214: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2863400 of size 1048576 next 1032\n",
      "2024-09-19 17:20:59.931217: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2963400 of size 1048576 next 1099\n",
      "2024-09-19 17:20:59.931219: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2a63400 of size 1048576 next 933\n",
      "2024-09-19 17:20:59.931222: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2b63400 of size 2097152 next 832\n",
      "2024-09-19 17:20:59.931224: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a2d63400 of size 8388608 next 833\n",
      "2024-09-19 17:20:59.931226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a3563400 of size 4194304 next 893\n",
      "2024-09-19 17:20:59.931229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6a3963400 of size 6933504 next 18446744073709551615\n",
      "2024-09-19 17:20:59.931231: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 67108864\n",
      "2024-09-19 17:20:59.931233: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0000000 of size 9437184 next 1303\n",
      "2024-09-19 17:20:59.931236: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0900000 of size 4194304 next 1296\n",
      "2024-09-19 17:20:59.931238: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0d00000 of size 2359296 next 687\n",
      "2024-09-19 17:20:59.931240: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f40000 of size 256 next 680\n",
      "2024-09-19 17:20:59.931243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f40100 of size 2048 next 679\n",
      "2024-09-19 17:20:59.931245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f40900 of size 2048 next 678\n",
      "2024-09-19 17:20:59.931247: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f41100 of size 2048 next 677\n",
      "2024-09-19 17:20:59.931250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f41900 of size 2048 next 676\n",
      "2024-09-19 17:20:59.931252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f42100 of size 2048 next 675\n",
      "2024-09-19 17:20:59.931254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b0f42900 of size 2097152 next 674\n",
      "2024-09-19 17:20:59.931257: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1142900 of size 256 next 673\n",
      "2024-09-19 17:20:59.931259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1142a00 of size 2048 next 672\n",
      "2024-09-19 17:20:59.931261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1143200 of size 2048 next 671\n",
      "2024-09-19 17:20:59.931263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1143a00 of size 2048 next 670\n",
      "2024-09-19 17:20:59.931266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1144200 of size 2048 next 669\n",
      "2024-09-19 17:20:59.931268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1144a00 of size 2048 next 668\n",
      "2024-09-19 17:20:59.931270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1145200 of size 14962432 next 1663\n",
      "2024-09-19 17:20:59.931273: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a100 of size 256 next 2098\n",
      "2024-09-19 17:20:59.931275: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a200 of size 256 next 2099\n",
      "2024-09-19 17:20:59.931278: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a300 of size 256 next 1950\n",
      "2024-09-19 17:20:59.931280: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a400 of size 256 next 1941\n",
      "2024-09-19 17:20:59.931282: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a500 of size 256 next 2139\n",
      "2024-09-19 17:20:59.931285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a600 of size 256 next 2140\n",
      "2024-09-19 17:20:59.931287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f8a700 of size 65536 next 2220\n",
      "2024-09-19 17:20:59.931289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9a700 of size 256 next 2221\n",
      "2024-09-19 17:20:59.931291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9a800 of size 256 next 2170\n",
      "2024-09-19 17:20:59.931294: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9a900 of size 256 next 2171\n",
      "2024-09-19 17:20:59.931296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9aa00 of size 256 next 2212\n",
      "2024-09-19 17:20:59.931298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9ab00 of size 256 next 2213\n",
      "2024-09-19 17:20:59.931301: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9ac00 of size 256 next 2006\n",
      "2024-09-19 17:20:59.931303: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9ad00 of size 256 next 2007\n",
      "2024-09-19 17:20:59.931305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9ae00 of size 1024 next 2222\n",
      "2024-09-19 17:20:59.931308: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9b200 of size 1024 next 1981\n",
      "2024-09-19 17:20:59.931310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9b600 of size 1024 next 2100\n",
      "2024-09-19 17:20:59.931312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9ba00 of size 1024 next 2101\n",
      "2024-09-19 17:20:59.931315: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9be00 of size 1024 next 2214\n",
      "2024-09-19 17:20:59.931317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1f9c200 of size 65536 next 2131\n",
      "2024-09-19 17:20:59.931319: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac200 of size 256 next 2132\n",
      "2024-09-19 17:20:59.931322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac300 of size 256 next 2184\n",
      "2024-09-19 17:20:59.931324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac400 of size 256 next 2032\n",
      "2024-09-19 17:20:59.931326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac500 of size 256 next 2033\n",
      "2024-09-19 17:20:59.931328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac600 of size 256 next 2075\n",
      "2024-09-19 17:20:59.931331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac700 of size 256 next 2076\n",
      "2024-09-19 17:20:59.931333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fac800 of size 69888 next 1935\n",
      "2024-09-19 17:20:59.931336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbd900 of size 256 next 1381\n",
      "2024-09-19 17:20:59.931338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbda00 of size 256 next 1382\n",
      "2024-09-19 17:20:59.931340: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbdb00 of size 256 next 1571\n",
      "2024-09-19 17:20:59.931343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbdc00 of size 256 next 1572\n",
      "2024-09-19 17:20:59.931345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbdd00 of size 256 next 1557\n",
      "2024-09-19 17:20:59.931347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbde00 of size 256 next 1558\n",
      "2024-09-19 17:20:59.931349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbdf00 of size 256 next 1613\n",
      "2024-09-19 17:20:59.931352: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe000 of size 256 next 1549\n",
      "2024-09-19 17:20:59.931354: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe100 of size 256 next 1550\n",
      "2024-09-19 17:20:59.931356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe200 of size 256 next 1456\n",
      "2024-09-19 17:20:59.931359: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe300 of size 256 next 1458\n",
      "2024-09-19 17:20:59.931361: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe400 of size 256 next 1662\n",
      "2024-09-19 17:20:59.931364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe500 of size 256 next 1647\n",
      "2024-09-19 17:20:59.931366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe600 of size 256 next 1648\n",
      "2024-09-19 17:20:59.931368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe700 of size 256 next 1488\n",
      "2024-09-19 17:20:59.931370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe800 of size 256 next 1489\n",
      "2024-09-19 17:20:59.931373: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbe900 of size 256 next 1551\n",
      "2024-09-19 17:20:59.931375: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fbea00 of size 16384 next 1644\n",
      "2024-09-19 17:20:59.931377: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2a00 of size 256 next 1645\n",
      "2024-09-19 17:20:59.931380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2b00 of size 256 next 1542\n",
      "2024-09-19 17:20:59.931382: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2c00 of size 256 next 1543\n",
      "2024-09-19 17:20:59.931384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2d00 of size 256 next 1446\n",
      "2024-09-19 17:20:59.931387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2e00 of size 256 next 1447\n",
      "2024-09-19 17:20:59.931389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc2f00 of size 256 next 1632\n",
      "2024-09-19 17:20:59.931391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc3000 of size 256 next 1633\n",
      "2024-09-19 17:20:59.931394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc3100 of size 1024 next 1605\n",
      "2024-09-19 17:20:59.931396: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc3500 of size 1024 next 1606\n",
      "2024-09-19 17:20:59.931398: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc3900 of size 1024 next 1608\n",
      "2024-09-19 17:20:59.931401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc3d00 of size 1024 next 1609\n",
      "2024-09-19 17:20:59.931403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc4100 of size 1024 next 1642\n",
      "2024-09-19 17:20:59.931405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc4500 of size 256 next 1657\n",
      "2024-09-19 17:20:59.931408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc4600 of size 1024 next 1454\n",
      "2024-09-19 17:20:59.931410: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc4a00 of size 1024 next 1455\n",
      "2024-09-19 17:20:59.931412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc4e00 of size 1024 next 1588\n",
      "2024-09-19 17:20:59.931415: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5200 of size 1024 next 1595\n",
      "2024-09-19 17:20:59.931417: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5600 of size 1024 next 1580\n",
      "2024-09-19 17:20:59.931419: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5a00 of size 256 next 1582\n",
      "2024-09-19 17:20:59.931421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5b00 of size 256 next 1538\n",
      "2024-09-19 17:20:59.931424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5c00 of size 256 next 1539\n",
      "2024-09-19 17:20:59.931426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5d00 of size 256 next 1638\n",
      "2024-09-19 17:20:59.931428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5e00 of size 256 next 1639\n",
      "2024-09-19 17:20:59.931431: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc5f00 of size 256 next 1453\n",
      "2024-09-19 17:20:59.931433: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6000 of size 256 next 1428\n",
      "2024-09-19 17:20:59.931435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6100 of size 256 next 1583\n",
      "2024-09-19 17:20:59.931438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6200 of size 256 next 1622\n",
      "2024-09-19 17:20:59.931440: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6300 of size 256 next 1624\n",
      "2024-09-19 17:20:59.931442: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6400 of size 256 next 1423\n",
      "2024-09-19 17:20:59.931445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6500 of size 256 next 1421\n",
      "2024-09-19 17:20:59.931447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6600 of size 256 next 1500\n",
      "2024-09-19 17:20:59.931449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6700 of size 1280 next 1939\n",
      "2024-09-19 17:20:59.931452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fc6c00 of size 65536 next 2224\n",
      "2024-09-19 17:20:59.931454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fd6c00 of size 1024 next 2022\n",
      "2024-09-19 17:20:59.931456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fd7000 of size 92928 next 1969\n",
      "2024-09-19 17:20:59.931459: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1fedb00 of size 16384 next 1211\n",
      "2024-09-19 17:20:59.931461: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff1b00 of size 1024 next 1210\n",
      "2024-09-19 17:20:59.931463: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff1f00 of size 1024 next 1209\n",
      "2024-09-19 17:20:59.931466: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff2300 of size 256 next 1208\n",
      "2024-09-19 17:20:59.931468: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff2400 of size 256 next 1207\n",
      "2024-09-19 17:20:59.931470: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff2500 of size 1024 next 1206\n",
      "2024-09-19 17:20:59.931473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff2900 of size 1024 next 1205\n",
      "2024-09-19 17:20:59.931475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b1ff2d00 of size 65536 next 1204\n",
      "2024-09-19 17:20:59.931477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2002d00 of size 8192 next 1203\n",
      "2024-09-19 17:20:59.931480: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2004d00 of size 256 next 1202\n",
      "2024-09-19 17:20:59.931482: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2004e00 of size 1024 next 1201\n",
      "2024-09-19 17:20:59.931484: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005200 of size 256 next 1200\n",
      "2024-09-19 17:20:59.931486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005300 of size 256 next 1199\n",
      "2024-09-19 17:20:59.931489: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005400 of size 1024 next 1198\n",
      "2024-09-19 17:20:59.931491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005800 of size 256 next 1197\n",
      "2024-09-19 17:20:59.931493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005900 of size 256 next 1196\n",
      "2024-09-19 17:20:59.931496: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2005a00 of size 65536 next 1195\n",
      "2024-09-19 17:20:59.931498: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2015a00 of size 256 next 1194\n",
      "2024-09-19 17:20:59.931500: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2015b00 of size 1024 next 1193\n",
      "2024-09-19 17:20:59.931502: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2015f00 of size 256 next 1192\n",
      "2024-09-19 17:20:59.931505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2016000 of size 65536 next 1191\n",
      "2024-09-19 17:20:59.931507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026000 of size 2048 next 1190\n",
      "2024-09-19 17:20:59.931509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026800 of size 256 next 1189\n",
      "2024-09-19 17:20:59.931511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026900 of size 256 next 1188\n",
      "2024-09-19 17:20:59.931514: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026a00 of size 256 next 1187\n",
      "2024-09-19 17:20:59.931516: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026b00 of size 256 next 1186\n",
      "2024-09-19 17:20:59.931518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2026c00 of size 65536 next 1185\n",
      "2024-09-19 17:20:59.931521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2036c00 of size 512 next 1184\n",
      "2024-09-19 17:20:59.931523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2036e00 of size 1024 next 1183\n",
      "2024-09-19 17:20:59.931525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2037200 of size 256 next 1182\n",
      "2024-09-19 17:20:59.931528: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2037300 of size 147456 next 1181\n",
      "2024-09-19 17:20:59.931530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205b300 of size 256 next 1180\n",
      "2024-09-19 17:20:59.931532: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205b400 of size 256 next 1179\n",
      "2024-09-19 17:20:59.931534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205b500 of size 512 next 1178\n",
      "2024-09-19 17:20:59.931537: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205b700 of size 512 next 1177\n",
      "2024-09-19 17:20:59.931539: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205b900 of size 8192 next 1176\n",
      "2024-09-19 17:20:59.931541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205d900 of size 256 next 1175\n",
      "2024-09-19 17:20:59.931544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205da00 of size 2048 next 1174\n",
      "2024-09-19 17:20:59.931546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205e200 of size 1024 next 1173\n",
      "2024-09-19 17:20:59.931548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205e600 of size 256 next 1172\n",
      "2024-09-19 17:20:59.931550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b205e700 of size 147456 next 1171\n",
      "2024-09-19 17:20:59.931553: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2082700 of size 512 next 1170\n",
      "2024-09-19 17:20:59.931555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2082900 of size 1024 next 1169\n",
      "2024-09-19 17:20:59.931557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2082d00 of size 256 next 1168\n",
      "2024-09-19 17:20:59.931560: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2082e00 of size 1024 next 1167\n",
      "2024-09-19 17:20:59.931562: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2083200 of size 512 next 1166\n",
      "2024-09-19 17:20:59.931564: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2083400 of size 65536 next 1165\n",
      "2024-09-19 17:20:59.931566: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2093400 of size 1024 next 1164\n",
      "2024-09-19 17:20:59.931569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2093800 of size 512 next 1163\n",
      "2024-09-19 17:20:59.931571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2093a00 of size 1024 next 1162\n",
      "2024-09-19 17:20:59.931573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2093e00 of size 131072 next 1161\n",
      "2024-09-19 17:20:59.931576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b20b3e00 of size 512 next 1160\n",
      "2024-09-19 17:20:59.931578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b20b4000 of size 512 next 1159\n",
      "2024-09-19 17:20:59.931580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b20b4200 of size 589824 next 1158\n",
      "2024-09-19 17:20:59.931582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2144200 of size 2048 next 1157\n",
      "2024-09-19 17:20:59.931585: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2144a00 of size 2048 next 1156\n",
      "2024-09-19 17:20:59.931587: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2145200 of size 2048 next 1155\n",
      "2024-09-19 17:20:59.931589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2145a00 of size 2048 next 1154\n",
      "2024-09-19 17:20:59.931592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2146200 of size 512 next 1153\n",
      "2024-09-19 17:20:59.931594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2146400 of size 2048 next 1152\n",
      "2024-09-19 17:20:59.931596: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2146c00 of size 262144 next 1151\n",
      "2024-09-19 17:20:59.931599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2186c00 of size 512 next 1150\n",
      "2024-09-19 17:20:59.931601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2186e00 of size 512 next 1149\n",
      "2024-09-19 17:20:59.931603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2187000 of size 512 next 1148\n",
      "2024-09-19 17:20:59.931606: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2187200 of size 2048 next 1147\n",
      "2024-09-19 17:20:59.931608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2187a00 of size 512 next 1146\n",
      "2024-09-19 17:20:59.931610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2187c00 of size 589824 next 1145\n",
      "2024-09-19 17:20:59.931612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2217c00 of size 512 next 1144\n",
      "2024-09-19 17:20:59.931615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2217e00 of size 589824 next 1143\n",
      "2024-09-19 17:20:59.931617: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a7e00 of size 256 next 1142\n",
      "2024-09-19 17:20:59.931619: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a7f00 of size 2048 next 1141\n",
      "2024-09-19 17:20:59.931622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a8700 of size 512 next 1140\n",
      "2024-09-19 17:20:59.931624: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a8900 of size 2048 next 1139\n",
      "2024-09-19 17:20:59.931626: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a9100 of size 512 next 1138\n",
      "2024-09-19 17:20:59.931628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a9300 of size 2048 next 1137\n",
      "2024-09-19 17:20:59.931631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a9b00 of size 512 next 1136\n",
      "2024-09-19 17:20:59.931633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22a9d00 of size 2048 next 1135\n",
      "2024-09-19 17:20:59.931635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22aa500 of size 262144 next 1134\n",
      "2024-09-19 17:20:59.931638: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22ea500 of size 2048 next 1133\n",
      "2024-09-19 17:20:59.931640: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b22ead00 of size 262144 next 1132\n",
      "2024-09-19 17:20:59.931642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b232ad00 of size 2048 next 1131\n",
      "2024-09-19 17:20:59.931644: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b232b500 of size 512 next 1130\n",
      "2024-09-19 17:20:59.931647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b232b700 of size 795648 next 1268\n",
      "2024-09-19 17:20:59.931649: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b23edb00 of size 1048576 next 1267\n",
      "2024-09-19 17:20:59.931652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b24edb00 of size 1048576 next 1107\n",
      "2024-09-19 17:20:59.931654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b25edb00 of size 2359296 next 1245\n",
      "2024-09-19 17:20:59.931656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b282db00 of size 2359296 next 1034\n",
      "2024-09-19 17:20:59.931659: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2a6db00 of size 3670016 next 1266\n",
      "2024-09-19 17:20:59.931661: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b2dedb00 of size 2359296 next 770\n",
      "2024-09-19 17:20:59.931663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302db00 of size 256 next 763\n",
      "2024-09-19 17:20:59.931666: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302dc00 of size 1024 next 762\n",
      "2024-09-19 17:20:59.931668: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302e000 of size 1024 next 761\n",
      "2024-09-19 17:20:59.931670: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302e400 of size 1024 next 760\n",
      "2024-09-19 17:20:59.931673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302e800 of size 1024 next 759\n",
      "2024-09-19 17:20:59.931675: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302ec00 of size 1024 next 758\n",
      "2024-09-19 17:20:59.931677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b302f000 of size 1048576 next 757\n",
      "2024-09-19 17:20:59.931680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b312f000 of size 256 next 756\n",
      "2024-09-19 17:20:59.931682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b312f100 of size 1024 next 755\n",
      "2024-09-19 17:20:59.931684: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b312f500 of size 1024 next 754\n",
      "2024-09-19 17:20:59.931687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b312f900 of size 1024 next 753\n",
      "2024-09-19 17:20:59.931689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b312fd00 of size 1024 next 752\n",
      "2024-09-19 17:20:59.931691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3130100 of size 1024 next 751\n",
      "2024-09-19 17:20:59.931694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3130500 of size 2359296 next 750\n",
      "2024-09-19 17:20:59.931696: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3370500 of size 256 next 749\n",
      "2024-09-19 17:20:59.931698: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3370600 of size 4096 next 748\n",
      "2024-09-19 17:20:59.931700: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3371600 of size 4096 next 747\n",
      "2024-09-19 17:20:59.931703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3372600 of size 4096 next 746\n",
      "2024-09-19 17:20:59.931705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3373600 of size 4096 next 745\n",
      "2024-09-19 17:20:59.931707: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3374600 of size 4096 next 744\n",
      "2024-09-19 17:20:59.931710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3375600 of size 1048576 next 743\n",
      "2024-09-19 17:20:59.931712: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3475600 of size 256 next 742\n",
      "2024-09-19 17:20:59.931714: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3475700 of size 1024 next 741\n",
      "2024-09-19 17:20:59.931716: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3475b00 of size 1024 next 740\n",
      "2024-09-19 17:20:59.931719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3475f00 of size 1024 next 739\n",
      "2024-09-19 17:20:59.931721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3476300 of size 1024 next 738\n",
      "2024-09-19 17:20:59.931723: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3476700 of size 1024 next 737\n",
      "2024-09-19 17:20:59.931726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3476b00 of size 1048576 next 736\n",
      "2024-09-19 17:20:59.931728: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3576b00 of size 256 next 735\n",
      "2024-09-19 17:20:59.931730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3576c00 of size 1024 next 734\n",
      "2024-09-19 17:20:59.931732: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3577000 of size 1024 next 733\n",
      "2024-09-19 17:20:59.931735: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3577400 of size 1024 next 732\n",
      "2024-09-19 17:20:59.931737: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3577800 of size 1024 next 731\n",
      "2024-09-19 17:20:59.931739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3577c00 of size 1024 next 730\n",
      "2024-09-19 17:20:59.931742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3578000 of size 2359296 next 729\n",
      "2024-09-19 17:20:59.931744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37b8000 of size 256 next 728\n",
      "2024-09-19 17:20:59.931746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37b8100 of size 4096 next 727\n",
      "2024-09-19 17:20:59.931748: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37b9100 of size 4096 next 726\n",
      "2024-09-19 17:20:59.931751: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37ba100 of size 4096 next 725\n",
      "2024-09-19 17:20:59.931753: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37bb100 of size 4096 next 724\n",
      "2024-09-19 17:20:59.931755: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37bc100 of size 4096 next 723\n",
      "2024-09-19 17:20:59.931758: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b37bd100 of size 1048576 next 722\n",
      "2024-09-19 17:20:59.931760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38bd100 of size 256 next 721\n",
      "2024-09-19 17:20:59.931762: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38bd200 of size 1024 next 720\n",
      "2024-09-19 17:20:59.931764: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38bd600 of size 1024 next 719\n",
      "2024-09-19 17:20:59.931767: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38bda00 of size 1024 next 718\n",
      "2024-09-19 17:20:59.931769: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38bde00 of size 1024 next 717\n",
      "2024-09-19 17:20:59.931771: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38be200 of size 1024 next 716\n",
      "2024-09-19 17:20:59.931774: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b38be600 of size 1048576 next 715\n",
      "2024-09-19 17:20:59.931776: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39be600 of size 256 next 714\n",
      "2024-09-19 17:20:59.931778: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39be700 of size 1024 next 713\n",
      "2024-09-19 17:20:59.931780: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39beb00 of size 1024 next 712\n",
      "2024-09-19 17:20:59.931783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39bef00 of size 1024 next 711\n",
      "2024-09-19 17:20:59.931785: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39bf300 of size 1024 next 710\n",
      "2024-09-19 17:20:59.931787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39bf700 of size 1024 next 709\n",
      "2024-09-19 17:20:59.931790: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b39bfb00 of size 2359296 next 708\n",
      "2024-09-19 17:20:59.931792: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3bffb00 of size 256 next 707\n",
      "2024-09-19 17:20:59.931794: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3bffc00 of size 4096 next 706\n",
      "2024-09-19 17:20:59.931796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3c00c00 of size 4096 next 705\n",
      "2024-09-19 17:20:59.931799: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3c01c00 of size 4096 next 704\n",
      "2024-09-19 17:20:59.931801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3c02c00 of size 4096 next 703\n",
      "2024-09-19 17:20:59.931803: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3c03c00 of size 4096 next 702\n",
      "2024-09-19 17:20:59.931806: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3c04c00 of size 1048576 next 701\n",
      "2024-09-19 17:20:59.931808: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d04c00 of size 256 next 700\n",
      "2024-09-19 17:20:59.931810: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d04d00 of size 1024 next 699\n",
      "2024-09-19 17:20:59.931813: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d05100 of size 1024 next 698\n",
      "2024-09-19 17:20:59.931815: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d05500 of size 1024 next 697\n",
      "2024-09-19 17:20:59.931817: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d05900 of size 1024 next 696\n",
      "2024-09-19 17:20:59.931819: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d05d00 of size 1024 next 695\n",
      "2024-09-19 17:20:59.931822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3d06100 of size 1048576 next 694\n",
      "2024-09-19 17:20:59.931824: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e06100 of size 256 next 693\n",
      "2024-09-19 17:20:59.931826: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e06200 of size 1024 next 692\n",
      "2024-09-19 17:20:59.931829: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e06600 of size 1024 next 691\n",
      "2024-09-19 17:20:59.931831: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e06a00 of size 1024 next 690\n",
      "2024-09-19 17:20:59.931833: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e06e00 of size 1024 next 689\n",
      "2024-09-19 17:20:59.931835: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e07200 of size 1024 next 688\n",
      "2024-09-19 17:20:59.931838: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e07600 of size 256 next 686\n",
      "2024-09-19 17:20:59.931840: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e07700 of size 4096 next 685\n",
      "2024-09-19 17:20:59.931842: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e08700 of size 4096 next 684\n",
      "2024-09-19 17:20:59.931845: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e09700 of size 4096 next 683\n",
      "2024-09-19 17:20:59.931847: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e0a700 of size 4096 next 682\n",
      "2024-09-19 17:20:59.931849: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e0b700 of size 4096 next 681\n",
      "2024-09-19 17:20:59.931852: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6b3e0c700 of size 2046208 next 18446744073709551615\n",
      "2024-09-19 17:20:59.931854: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 33554432\n",
      "2024-09-19 17:20:59.931856: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba000000 of size 256 next 818\n",
      "2024-09-19 17:20:59.931859: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba000100 of size 2048 next 817\n",
      "2024-09-19 17:20:59.931861: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba000900 of size 2048 next 816\n",
      "2024-09-19 17:20:59.931863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba001100 of size 2048 next 815\n",
      "2024-09-19 17:20:59.931866: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba001900 of size 2048 next 814\n",
      "2024-09-19 17:20:59.931868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba002100 of size 2048 next 813\n",
      "2024-09-19 17:20:59.931870: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba002900 of size 262144 next 812\n",
      "2024-09-19 17:20:59.931872: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba042900 of size 256 next 811\n",
      "2024-09-19 17:20:59.931875: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba042a00 of size 1024 next 810\n",
      "2024-09-19 17:20:59.931877: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba042e00 of size 1024 next 809\n",
      "2024-09-19 17:20:59.931879: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba043200 of size 1024 next 808\n",
      "2024-09-19 17:20:59.931881: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba043600 of size 1024 next 807\n",
      "2024-09-19 17:20:59.931884: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba043a00 of size 1024 next 806\n",
      "2024-09-19 17:20:59.931886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba043e00 of size 524288 next 805\n",
      "2024-09-19 17:20:59.931888: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c3e00 of size 256 next 804\n",
      "2024-09-19 17:20:59.931891: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c3f00 of size 1024 next 803\n",
      "2024-09-19 17:20:59.931893: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c4300 of size 1024 next 802\n",
      "2024-09-19 17:20:59.931896: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c4700 of size 1024 next 801\n",
      "2024-09-19 17:20:59.931898: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c4b00 of size 1024 next 800\n",
      "2024-09-19 17:20:59.931900: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c4f00 of size 1024 next 799\n",
      "2024-09-19 17:20:59.931902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba0c5300 of size 2359296 next 798\n",
      "2024-09-19 17:20:59.931905: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba305300 of size 256 next 797\n",
      "2024-09-19 17:20:59.931907: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba305400 of size 4096 next 796\n",
      "2024-09-19 17:20:59.931909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba306400 of size 4096 next 795\n",
      "2024-09-19 17:20:59.931911: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba307400 of size 4096 next 794\n",
      "2024-09-19 17:20:59.931914: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba308400 of size 4096 next 793\n",
      "2024-09-19 17:20:59.931916: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba309400 of size 4096 next 792\n",
      "2024-09-19 17:20:59.931918: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba30a400 of size 1048576 next 791\n",
      "2024-09-19 17:20:59.931921: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40a400 of size 256 next 790\n",
      "2024-09-19 17:20:59.931923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40a500 of size 4096 next 789\n",
      "2024-09-19 17:20:59.931925: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40b500 of size 4096 next 788\n",
      "2024-09-19 17:20:59.931927: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40c500 of size 4096 next 787\n",
      "2024-09-19 17:20:59.931930: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40d500 of size 4096 next 786\n",
      "2024-09-19 17:20:59.931932: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40e500 of size 4096 next 785\n",
      "2024-09-19 17:20:59.931934: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba40f500 of size 2097152 next 784\n",
      "2024-09-19 17:20:59.931936: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba60f500 of size 256 next 783\n",
      "2024-09-19 17:20:59.931939: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba60f600 of size 1024 next 782\n",
      "2024-09-19 17:20:59.931941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba60fa00 of size 1024 next 781\n",
      "2024-09-19 17:20:59.931943: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba60fe00 of size 1024 next 780\n",
      "2024-09-19 17:20:59.931946: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba610200 of size 1024 next 779\n",
      "2024-09-19 17:20:59.931948: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba610600 of size 1024 next 778\n",
      "2024-09-19 17:20:59.931950: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba610a00 of size 1048576 next 777\n",
      "2024-09-19 17:20:59.931952: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba710a00 of size 256 next 776\n",
      "2024-09-19 17:20:59.931955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba710b00 of size 1024 next 775\n",
      "2024-09-19 17:20:59.931957: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba710f00 of size 1024 next 774\n",
      "2024-09-19 17:20:59.931959: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba711300 of size 1024 next 773\n",
      "2024-09-19 17:20:59.931961: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba711700 of size 1024 next 772\n",
      "2024-09-19 17:20:59.931964: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba711b00 of size 1024 next 771\n",
      "2024-09-19 17:20:59.931966: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba711f00 of size 256 next 769\n",
      "2024-09-19 17:20:59.931968: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba712000 of size 4096 next 768\n",
      "2024-09-19 17:20:59.931971: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba713000 of size 4096 next 767\n",
      "2024-09-19 17:20:59.931973: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba714000 of size 4096 next 766\n",
      "2024-09-19 17:20:59.931975: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba715000 of size 4096 next 765\n",
      "2024-09-19 17:20:59.931978: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba716000 of size 4096 next 764\n",
      "2024-09-19 17:20:59.931980: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba717000 of size 1478656 next 1272\n",
      "2024-09-19 17:20:59.931983: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba880000 of size 512 next 1389\n",
      "2024-09-19 17:20:59.931985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba880200 of size 262144 next 830\n",
      "2024-09-19 17:20:59.931987: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba8c0200 of size 524288 next 1246\n",
      "2024-09-19 17:20:59.931990: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6ba940200 of size 3407360 next 1271\n",
      "2024-09-19 17:20:59.931992: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac80000 of size 256 next 667\n",
      "2024-09-19 17:20:59.931995: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac80100 of size 8192 next 666\n",
      "2024-09-19 17:20:59.931997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac82100 of size 8192 next 665\n",
      "2024-09-19 17:20:59.931999: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac84100 of size 8192 next 664\n",
      "2024-09-19 17:20:59.932001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac86100 of size 8192 next 663\n",
      "2024-09-19 17:20:59.932004: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac88100 of size 8192 next 662\n",
      "2024-09-19 17:20:59.932006: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bac8a100 of size 4194304 next 661\n",
      "2024-09-19 17:20:59.932008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb08a100 of size 256 next 660\n",
      "2024-09-19 17:20:59.932011: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb08a200 of size 8192 next 659\n",
      "2024-09-19 17:20:59.932013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb08c200 of size 8192 next 658\n",
      "2024-09-19 17:20:59.932015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb08e200 of size 8192 next 657\n",
      "2024-09-19 17:20:59.932017: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb090200 of size 8192 next 656\n",
      "2024-09-19 17:20:59.932020: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb092200 of size 8192 next 655\n",
      "2024-09-19 17:20:59.932022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6bb094200 of size 16170496 next 18446744073709551615\n",
      "2024-09-19 17:20:59.932024: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 8388608\n",
      "2024-09-19 17:20:59.932027: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da000000 of size 256 next 1600\n",
      "2024-09-19 17:20:59.932029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da000100 of size 1024 next 1625\n",
      "2024-09-19 17:20:59.932032: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da000500 of size 1024 next 1541\n",
      "2024-09-19 17:20:59.932034: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da000900 of size 1024 next 1468\n",
      "2024-09-19 17:20:59.932037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da000d00 of size 1024 next 1400\n",
      "2024-09-19 17:20:59.932039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da001100 of size 1024 next 1401\n",
      "2024-09-19 17:20:59.932041: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da001500 of size 2359296 next 1519\n",
      "2024-09-19 17:20:59.932043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da241500 of size 256 next 1597\n",
      "2024-09-19 17:20:59.932046: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da241600 of size 4096 next 1466\n",
      "2024-09-19 17:20:59.932048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da242600 of size 4096 next 1449\n",
      "2024-09-19 17:20:59.932050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da243600 of size 4096 next 1584\n",
      "2024-09-19 17:20:59.932053: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da244600 of size 4096 next 1419\n",
      "2024-09-19 17:20:59.932055: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da245600 of size 4096 next 1577\n",
      "2024-09-19 17:20:59.932057: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da246600 of size 1048576 next 1528\n",
      "2024-09-19 17:20:59.932060: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da346600 of size 256 next 1529\n",
      "2024-09-19 17:20:59.932062: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da346700 of size 1024 next 1413\n",
      "2024-09-19 17:20:59.932064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da346b00 of size 1024 next 1450\n",
      "2024-09-19 17:20:59.932067: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da346f00 of size 1024 next 1451\n",
      "2024-09-19 17:20:59.932069: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da347300 of size 1024 next 1626\n",
      "2024-09-19 17:20:59.932071: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da347700 of size 1024 next 1637\n",
      "2024-09-19 17:20:59.932074: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da347b00 of size 1048576 next 1524\n",
      "2024-09-19 17:20:59.932076: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da447b00 of size 256 next 1545\n",
      "2024-09-19 17:20:59.932078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da447c00 of size 1024 next 1434\n",
      "2024-09-19 17:20:59.932081: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da448000 of size 1024 next 1435\n",
      "2024-09-19 17:20:59.932083: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da448400 of size 1024 next 1497\n",
      "2024-09-19 17:20:59.932085: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da448800 of size 1024 next 1518\n",
      "2024-09-19 17:20:59.932088: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da448c00 of size 1024 next 1522\n",
      "2024-09-19 17:20:59.932090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da449000 of size 3895296 next 18446744073709551615\n",
      "2024-09-19 17:20:59.932092: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 16777216\n",
      "2024-09-19 17:20:59.932095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6da800000 of size 4194304 next 1343\n",
      "2024-09-19 17:20:59.932097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa6dac00000 of size 12582912 next 18446744073709551615\n",
      "2024-09-19 17:20:59.932100: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 2097152\n",
      "2024-09-19 17:20:59.932102: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa707800000 of size 1032192 next 1614\n",
      "2024-09-19 17:20:59.932105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa7078fc000 of size 1064960 next 18446744073709551615\n",
      "2024-09-19 17:20:59.932107: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 4194304\n",
      "2024-09-19 17:20:59.932109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fa707a00000 of size 4194304 next 18446744073709551615\n",
      "2024-09-19 17:20:59.932112: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-09-19 17:20:59.932117: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1048 Chunks of size 256 totalling 262.0KiB\n",
      "2024-09-19 17:20:59.932121: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 448 Chunks of size 512 totalling 224.0KiB\n",
      "2024-09-19 17:20:59.932123: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 893 Chunks of size 1024 totalling 893.0KiB\n",
      "2024-09-19 17:20:59.932126: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 9 Chunks of size 1280 totalling 11.2KiB\n",
      "2024-09-19 17:20:59.932129: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2024-09-19 17:20:59.932132: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2024-09-19 17:20:59.932134: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 615 Chunks of size 2048 totalling 1.20MiB\n",
      "2024-09-19 17:20:59.932137: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2024-09-19 17:20:59.932139: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 390 Chunks of size 4096 totalling 1.52MiB\n",
      "2024-09-19 17:20:59.932142: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6912 totalling 6.8KiB\n",
      "2024-09-19 17:20:59.932144: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7168 totalling 7.0KiB\n",
      "2024-09-19 17:20:59.932147: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 224 Chunks of size 8192 totalling 1.75MiB\n",
      "2024-09-19 17:20:59.932150: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 15 Chunks of size 16384 totalling 240.0KiB\n",
      "2024-09-19 17:20:59.932152: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32256 totalling 31.5KiB\n",
      "2024-09-19 17:20:59.932155: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 15 Chunks of size 37632 totalling 551.2KiB\n",
      "2024-09-19 17:20:59.932157: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 86 Chunks of size 65536 totalling 5.38MiB\n",
      "2024-09-19 17:20:59.932160: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 69888 totalling 68.2KiB\n",
      "2024-09-19 17:20:59.932163: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 74496 totalling 72.8KiB\n",
      "2024-09-19 17:20:59.932165: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 81920 totalling 80.0KiB\n",
      "2024-09-19 17:20:59.932168: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 82688 totalling 80.8KiB\n",
      "2024-09-19 17:20:59.932170: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 92416 totalling 90.2KiB\n",
      "2024-09-19 17:20:59.932173: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 92928 totalling 90.8KiB\n",
      "2024-09-19 17:20:59.932176: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 96256 totalling 94.0KiB\n",
      "2024-09-19 17:20:59.932178: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 97536 totalling 95.2KiB\n",
      "2024-09-19 17:20:59.932181: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 107520 totalling 105.0KiB\n",
      "2024-09-19 17:20:59.932184: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 122624 totalling 119.8KiB\n",
      "2024-09-19 17:20:59.932186: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 131072 totalling 1.62MiB\n",
      "2024-09-19 17:20:59.932189: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 37 Chunks of size 147456 totalling 5.20MiB\n",
      "2024-09-19 17:20:59.932191: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 148736 totalling 145.2KiB\n",
      "2024-09-19 17:20:59.932194: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 155136 totalling 151.5KiB\n",
      "2024-09-19 17:20:59.932197: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 174592 totalling 170.5KiB\n",
      "2024-09-19 17:20:59.932199: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 187136 totalling 182.8KiB\n",
      "2024-09-19 17:20:59.932202: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 188160 totalling 183.8KiB\n",
      "2024-09-19 17:20:59.932204: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 193792 totalling 189.2KiB\n",
      "2024-09-19 17:20:59.932207: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 196608 totalling 192.0KiB\n",
      "2024-09-19 17:20:59.932210: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 206848 totalling 202.0KiB\n",
      "2024-09-19 17:20:59.932212: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 217088 totalling 212.0KiB\n",
      "2024-09-19 17:20:59.932215: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 231424 totalling 226.0KiB\n",
      "2024-09-19 17:20:59.932218: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 247552 totalling 241.8KiB\n",
      "2024-09-19 17:20:59.932220: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 260608 totalling 254.5KiB\n",
      "2024-09-19 17:20:59.932223: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 108 Chunks of size 262144 totalling 27.00MiB\n",
      "2024-09-19 17:20:59.932225: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 288000 totalling 281.2KiB\n",
      "2024-09-19 17:20:59.932228: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 293632 totalling 286.8KiB\n",
      "2024-09-19 17:20:59.932231: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 313344 totalling 306.0KiB\n",
      "2024-09-19 17:20:59.932233: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 327680 totalling 320.0KiB\n",
      "2024-09-19 17:20:59.932236: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 406784 totalling 397.2KiB\n",
      "2024-09-19 17:20:59.932238: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 27 Chunks of size 524288 totalling 13.50MiB\n",
      "2024-09-19 17:20:59.932241: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 70 Chunks of size 589824 totalling 39.38MiB\n",
      "2024-09-19 17:20:59.932244: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 620288 totalling 605.8KiB\n",
      "2024-09-19 17:20:59.932246: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 671232 totalling 655.5KiB\n",
      "2024-09-19 17:20:59.932249: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 688896 totalling 672.8KiB\n",
      "2024-09-19 17:20:59.932252: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 699136 totalling 682.8KiB\n",
      "2024-09-19 17:20:59.932254: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 704512 totalling 688.0KiB\n",
      "2024-09-19 17:20:59.932257: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 786432 totalling 1.50MiB\n",
      "2024-09-19 17:20:59.932259: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 795648 totalling 777.0KiB\n",
      "2024-09-19 17:20:59.932262: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 862976 totalling 842.8KiB\n",
      "2024-09-19 17:20:59.932265: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 903936 totalling 882.8KiB\n",
      "2024-09-19 17:20:59.932268: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 937984 totalling 916.0KiB\n",
      "2024-09-19 17:20:59.932270: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 13 Chunks of size 1032192 totalling 12.80MiB\n",
      "2024-09-19 17:20:59.932273: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1038080 totalling 1013.8KiB\n",
      "2024-09-19 17:20:59.932276: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 165 Chunks of size 1048576 totalling 165.00MiB\n",
      "2024-09-19 17:20:59.932278: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1064960 totalling 1.02MiB\n",
      "2024-09-19 17:20:59.932281: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1066752 totalling 1.02MiB\n",
      "2024-09-19 17:20:59.932283: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1114112 totalling 1.06MiB\n",
      "2024-09-19 17:20:59.932286: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1134080 totalling 1.08MiB\n",
      "2024-09-19 17:20:59.932288: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 1179648 totalling 13.50MiB\n",
      "2024-09-19 17:20:59.932291: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1184768 totalling 1.13MiB\n",
      "2024-09-19 17:20:59.932293: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1245184 totalling 1.19MiB\n",
      "2024-09-19 17:20:59.932296: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1265408 totalling 1.21MiB\n",
      "2024-09-19 17:20:59.932299: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1310720 totalling 2.50MiB\n",
      "2024-09-19 17:20:59.932301: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1376256 totalling 1.31MiB\n",
      "2024-09-19 17:20:59.932303: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1392640 totalling 2.66MiB\n",
      "2024-09-19 17:20:59.932306: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1478656 totalling 1.41MiB\n",
      "2024-09-19 17:20:59.932309: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1509888 totalling 1.44MiB\n",
      "2024-09-19 17:20:59.932311: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1558528 totalling 1.49MiB\n",
      "2024-09-19 17:20:59.932314: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1606912 totalling 1.53MiB\n",
      "2024-09-19 17:20:59.932316: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1642496 totalling 1.57MiB\n",
      "2024-09-19 17:20:59.932319: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1777408 totalling 1.69MiB\n",
      "2024-09-19 17:20:59.932321: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2046208 totalling 1.95MiB\n",
      "2024-09-19 17:20:59.932324: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2071040 totalling 1.97MiB\n",
      "2024-09-19 17:20:59.932326: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2078464 totalling 1.98MiB\n",
      "2024-09-19 17:20:59.932329: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 28 Chunks of size 2097152 totalling 56.00MiB\n",
      "2024-09-19 17:20:59.932332: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 87 Chunks of size 2359296 totalling 195.75MiB\n",
      "2024-09-19 17:20:59.932334: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2555904 totalling 2.44MiB\n",
      "2024-09-19 17:20:59.932337: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2579456 totalling 2.46MiB\n",
      "2024-09-19 17:20:59.932339: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2621440 totalling 2.50MiB\n",
      "2024-09-19 17:20:59.932342: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2975488 totalling 2.84MiB\n",
      "2024-09-19 17:20:59.932345: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3145728 totalling 3.00MiB\n",
      "2024-09-19 17:20:59.932347: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3211264 totalling 3.06MiB\n",
      "2024-09-19 17:20:59.932350: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3407360 totalling 3.25MiB\n",
      "2024-09-19 17:20:59.932353: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3470592 totalling 3.31MiB\n",
      "2024-09-19 17:20:59.932355: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3670016 totalling 3.50MiB\n",
      "2024-09-19 17:20:59.932358: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3895296 totalling 3.71MiB\n",
      "2024-09-19 17:20:59.932360: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4127744 totalling 3.94MiB\n",
      "2024-09-19 17:20:59.932363: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4192256 totalling 4.00MiB\n",
      "2024-09-19 17:20:59.932366: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 78 Chunks of size 4194304 totalling 312.00MiB\n",
      "2024-09-19 17:20:59.932368: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6242304 totalling 5.95MiB\n",
      "2024-09-19 17:20:59.932371: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6933504 totalling 6.61MiB\n",
      "2024-09-19 17:20:59.932374: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 8388608 totalling 96.00MiB\n",
      "2024-09-19 17:20:59.932376: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9354752 totalling 8.92MiB\n",
      "2024-09-19 17:20:59.932379: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 41 Chunks of size 9437184 totalling 369.00MiB\n",
      "2024-09-19 17:20:59.932381: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 10067712 totalling 9.60MiB\n",
      "2024-09-19 17:20:59.932384: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 11711744 totalling 11.17MiB\n",
      "2024-09-19 17:20:59.932387: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12002048 totalling 11.45MiB\n",
      "2024-09-19 17:20:59.932389: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12582912 totalling 12.00MiB\n",
      "2024-09-19 17:20:59.932392: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12818176 totalling 12.22MiB\n",
      "2024-09-19 17:20:59.932394: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 13664256 totalling 13.03MiB\n",
      "2024-09-19 17:20:59.932397: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14493952 totalling 13.82MiB\n",
      "2024-09-19 17:20:59.932400: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14962432 totalling 14.27MiB\n",
      "2024-09-19 17:20:59.932402: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16170496 totalling 15.42MiB\n",
      "2024-09-19 17:20:59.932405: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16515072 totalling 15.75MiB\n",
      "2024-09-19 17:20:59.932407: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 1.51GiB\n",
      "2024-09-19 17:20:59.932410: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 1625292800 memory_limit_: 1625292800 available bytes: 0 curr_region_allocation_bytes_: 2147483648\n",
      "2024-09-19 17:20:59.932416: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      1625292800\n",
      "InUse:                      1625292800\n",
      "MaxInUse:                   1625292800\n",
      "NumAllocs:                        7223\n",
      "MaxAllocSize:                184964096\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-09-19 17:20:59.932462: W tensorflow/tsl/framework/bfc_allocator.cc:497] ****************************************************************************************************\n",
      "2024-09-19 17:20:59.932485: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at constant_op.cc:81 : RESOURCE_EXHAUSTED: OOM when allocating tensor of shape [] and type float\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'beta1_power/Initializer/initial_value' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/3291506601.py\", line 2, in <cell line: 2>\n      deeplabcut.train_network(config_path, shuffle=1, maxiters=5000)#, device='cpu')\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 262, in train_network\n      train(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train_multianimal.py\", line 166, in train\n      learning_rate, train_op, tstep = get_optimizer(total_loss, cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 118, in get_optimizer\n      train_op = slim.learning.create_train_op(loss_op, optimizer)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/learning.py\", line 436, in create_train_op\n      return training.create_train_op(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/training/training.py\", line 463, in create_train_op\n      grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\nNode: 'beta1_power/Initializer/initial_value'\nOOM when allocating tensor of shape [] and type float\n\t [[{{node beta1_power/Initializer/initial_value}}]]\n\nOriginal stack trace for 'beta1_power/Initializer/initial_value':\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_334442/3291506601.py\", line 2, in <cell line: 2>\n    deeplabcut.train_network(config_path, shuffle=1, maxiters=5000)#, device='cpu')\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 262, in train_network\n    train(\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train_multianimal.py\", line 166, in train\n    learning_rate, train_op, tstep = get_optimizer(total_loss, cfg)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 118, in get_optimizer\n    train_op = slim.learning.create_train_op(loss_op, optimizer)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/learning.py\", line 436, in create_train_op\n    return training.create_train_op(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/training/training.py\", line 463, in create_train_op\n    grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 697, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/adam.py\", line 192, in _create_slots\n    self._create_non_slot_variable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 920, in _create_non_slot_variable\n    v = variable_scope.variable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 285, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 226, in _variable_v1_call\n    return previous_getter(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 219, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 2707, in default_variable_creator\n    return resource_variable_ops.ResourceVariable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 289, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1768, in __init__\n    self._init_from_args(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1957, in _init_from_args\n    initial_value = ops.convert_to_tensor(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1642, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 48, in _default_conversion_function\n    return constant_op.constant(value, dtype, name=name)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 268, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 290, in _constant_impl\n    const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [] and type float\n\t [[{{node beta1_power/Initializer/initial_value}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tensorflow\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, device='cpu')\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py:286\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    275\u001b[0m         train(\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;28mstr\u001b[39m(poseconfigfile),\n\u001b[1;32m    277\u001b[0m             displayiters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m             allow_growth\u001b[38;5;241m=\u001b[39mallow_growth,\n\u001b[1;32m    283\u001b[0m         )  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;28mstr\u001b[39m(start_path))\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py:262\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_tensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_multianimal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m         train,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelecting multi-animal trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mposeconfigfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_snapshots_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_tensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train_multianimal.py:168\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth, pseudo_labels, init_weights, pseudo_threshold, modelfolder, traintime_resize, video_path, superanimal, remove_head)\u001b[0m\n\u001b[1;32m    165\u001b[0m train_writer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mFileWriter(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m], sess\u001b[38;5;241m.\u001b[39mgraph)\n\u001b[1;32m    166\u001b[0m learning_rate, train_op, tstep \u001b[38;5;241m=\u001b[39m get_optimizer(total_loss, cfg)\n\u001b[0;32m--> 168\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_variables_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m sess\u001b[38;5;241m.\u001b[39mrun(tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlocal_variables_initializer())\n\u001b[1;32m    171\u001b[0m auxfun_models\u001b[38;5;241m.\u001b[39msmart_restore(restorer, sess, cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m], net_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1393\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1396\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'beta1_power/Initializer/initial_value' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/3291506601.py\", line 2, in <cell line: 2>\n      deeplabcut.train_network(config_path, shuffle=1, maxiters=5000)#, device='cpu')\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 262, in train_network\n      train(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train_multianimal.py\", line 166, in train\n      learning_rate, train_op, tstep = get_optimizer(total_loss, cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 118, in get_optimizer\n      train_op = slim.learning.create_train_op(loss_op, optimizer)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/learning.py\", line 436, in create_train_op\n      return training.create_train_op(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/training/training.py\", line 463, in create_train_op\n      grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\nNode: 'beta1_power/Initializer/initial_value'\nOOM when allocating tensor of shape [] and type float\n\t [[{{node beta1_power/Initializer/initial_value}}]]\n\nOriginal stack trace for 'beta1_power/Initializer/initial_value':\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_334442/3291506601.py\", line 2, in <cell line: 2>\n    deeplabcut.train_network(config_path, shuffle=1, maxiters=5000)#, device='cpu')\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 262, in train_network\n    train(\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train_multianimal.py\", line 166, in train\n    learning_rate, train_op, tstep = get_optimizer(total_loss, cfg)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 118, in get_optimizer\n    train_op = slim.learning.create_train_op(loss_op, optimizer)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/learning.py\", line 436, in create_train_op\n    return training.create_train_op(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/training/training.py\", line 463, in create_train_op\n    grad_updates = optimizer.apply_gradients(grads, global_step=global_step)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 697, in apply_gradients\n    self._create_slots(var_list)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/adam.py\", line 192, in _create_slots\n    self._create_non_slot_variable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/training/optimizer.py\", line 920, in _create_non_slot_variable\n    v = variable_scope.variable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 285, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 226, in _variable_v1_call\n    return previous_getter(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 219, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\", line 2707, in default_variable_creator\n    return resource_variable_ops.ResourceVariable(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\", line 289, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1768, in __init__\n    self._init_from_args(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1957, in _init_from_args\n    initial_value = ops.convert_to_tensor(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1642, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 48, in _default_conversion_function\n    return constant_op.constant(value, dtype, name=name)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 268, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 290, in _constant_impl\n    const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow\n",
    "deeplabcut.train_network(config_path, shuffle=1, maxiters=5000)#, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Beak',\n",
      "                      'Body_top',\n",
      "                      'RFlipper_mid',\n",
      "                      'LFlipper_mid',\n",
      "                      'Body_bottom',\n",
      "                      'RFoot',\n",
      "                      'LFoot'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep18/DLC_simple_dataset_model199shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/matthew/.local/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_smooth': False,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'minconfidence': 0.01,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 8,\n",
      " 'num_limbs': 7,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1],\n",
      "                             [0, 2],\n",
      "                             [2, 3],\n",
      "                             [2, 4],\n",
      "                             [2, 5],\n",
      "                             [5, 6],\n",
      "                             [5, 7]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'sigma': 1,\n",
      " 'snapshot_prefix': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-0/DLC_simple_datasetSep18-trainset99shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Beak',\n",
      "                      'Body_top',\n",
      "                      'RFlipper_mid',\n",
      "                      'LFlipper_mid',\n",
      "                      'Body_bottom',\n",
      "                      'RFoot',\n",
      "                      'LFoot'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 8,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep18/DLC_simple_dataset_model199shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 500,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/matthew/.local/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_DLC_simple_datasetSep18/Documentation_data-DLC_simple_dataset_99shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 200000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 8,\n",
      " 'num_limbs': 7,\n",
      " 'optimizer': 'adam',\n",
      " 'pafwidth': 20,\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_loss_weight': 0.1,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1],\n",
      "                             [0, 2],\n",
      "                             [2, 3],\n",
      "                             [2, 4],\n",
      "                             [2, 5],\n",
      "                             [5, 6],\n",
      "                             [5, 7]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 10000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-0/DLC_simple_datasetSep18-trainset99shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_dlcrnetms5_DLC_simple_datasetSep18shuffle1_50000  with # of trainingiterations: 50000\n",
      "Activating extracting of PAFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 16:25:38.138207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 16:25:38.144573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 16:25:38.148566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 16:25:38.151971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 16:25:38.156247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-19 16:25:38.161256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Evaluation underway...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2024-09-19 16:25:38.834407: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-09-19 16:25:38.835242: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1068 : UNIMPLEMENTED: DNN library is not found.\n",
      "2024-09-19 16:25:38.835285: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n",
      "2024-09-19 16:25:38.835304: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n",
      "\t [[pose/locref_pred/block4/BiasAdd/_551]]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'resnet_v1_50/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n      deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n      evaluate_multianimal_full(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n      ) = predict.setup_pose_prediction(test_pose_cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n      net_heads = PoseNetFactory.create(cfg).test(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n      heads = self.get_net(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n      net, end_points = self.extract_features(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n      net, end_points = net_fun(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n      return resnet_v1(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n      net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n      return layers_lib.conv2d(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n      return convolution(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n      outputs = layer.apply(inputs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n      return self.__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n      outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n      outputs = call_fn(cast_inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n      outputs = self._convolution_op(inputs, self.kernel)\nNode: 'resnet_v1_50/conv1/Conv2D'\nDetected at node 'resnet_v1_50/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n      deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n      evaluate_multianimal_full(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n      ) = predict.setup_pose_prediction(test_pose_cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n      net_heads = PoseNetFactory.create(cfg).test(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n      heads = self.get_net(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n      net, end_points = self.extract_features(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n      net, end_points = net_fun(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n      return resnet_v1(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n      net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n      return layers_lib.conv2d(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n      return convolution(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n      outputs = layer.apply(inputs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n      return self.__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n      outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n      outputs = call_fn(cast_inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n      outputs = self._convolution_op(inputs, self.kernel)\nNode: 'resnet_v1_50/conv1/Conv2D'\n2 root error(s) found.\n  (0) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n\t [[pose/locref_pred/block4/BiasAdd/_551]]\n  (1) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'resnet_v1_50/conv1/Conv2D':\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n    deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n    evaluate_multianimal_full(\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n    ) = predict.setup_pose_prediction(test_pose_cfg)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n    net_heads = PoseNetFactory.create(cfg).test(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n    heads = self.get_net(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n    net, end_points = self.extract_features(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n    net, end_points = net_fun(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n    return resnet_v1(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n    net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n    return layers_lib.conv2d(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n    return convolution(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n    outputs = layer.apply(inputs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n    return converted_call(f, args, kwargs, options=options)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 331, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n    return f(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1181, in convolution_v2\n    return convolution_internal(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1313, in convolution_internal\n    return op(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 2787, in _conv2d_expanded_batch\n    return gen_nn_ops.conv2d(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1144, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: 2 root error(s) found.\n  (0) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n\t [[pose/locref_pred/block4/BiasAdd/_551]]\n  (1) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, plotting=True)#, rescale=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py:648\u001b[0m, in \u001b[0;36mevaluate_network\u001b[0;34m(config, Shuffles, trainingsetindex, plotting, show_errors, comparisonbodyparts, gputouse, rescale, modelprefix, per_keypoint_evaluation, snapshots_to_evaluate)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluate_multianimal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate_multianimal_full\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# TODO: Make this code not so redundant!\u001b[39;00m\n\u001b[0;32m--> 648\u001b[0m     \u001b[43mevaluate_multianimal_full\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mShuffles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mShuffles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainingsetindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainingsetindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomparisonbodyparts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomparisonbodyparts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgputouse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgputouse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodelprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_keypoint_evaluation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_keypoint_evaluation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43msnapshots_to_evaluate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshots_to_evaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauxfun_videos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread, imresize\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py:373\u001b[0m, in \u001b[0;36mevaluate_multianimal_full\u001b[0;34m(config, Shuffles, trainingsetindex, plotting, show_errors, comparisonbodyparts, gputouse, modelprefix, per_keypoint_evaluation, snapshots_to_evaluate)\u001b[0m\n\u001b[1;32m    368\u001b[0m peaks_gt \u001b[38;5;241m=\u001b[39m temp\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m    369\u001b[0m     :, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbodyparts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    370\u001b[0m ]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m    371\u001b[0m peaks_gt[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m (peaks_gt[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m stride \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m stride\n\u001b[0;32m--> 373\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredictma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_batched_peaks_and_costs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_pose_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeaks_gt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pred:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict_multianimal.py:218\u001b[0m, in \u001b[0;36mpredict_batched_peaks_and_costs\u001b[0;34m(pose_cfg, images_batch, sess, inputs, outputs, peaks_gt, n_points, n_decimals, extra_dict)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_dict:\n\u001b[1;32m    216\u001b[0m     features \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun(extra_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m], feed_dict\u001b[38;5;241m=\u001b[39m{inputs: images_batch})\n\u001b[0;32m--> 218\u001b[0m scmaps, locrefs, \u001b[38;5;241m*\u001b[39mpafs, peaks \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_batch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39many(peaks):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/client/session.py:1397\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monly supports NHWC tensor format\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n\u001b[1;32m   1393\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA possible workaround: Try disabling Grappler optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1394\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mby modifying the config for creating the session eg.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1395\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msession_config.graph_options.rewrite_options.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1396\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_meta_optimizer = True\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1397\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(node_def, op, message)\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'resnet_v1_50/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n      deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n      evaluate_multianimal_full(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n      ) = predict.setup_pose_prediction(test_pose_cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n      net_heads = PoseNetFactory.create(cfg).test(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n      heads = self.get_net(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n      net, end_points = self.extract_features(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n      net, end_points = net_fun(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n      return resnet_v1(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n      net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n      return layers_lib.conv2d(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n      return convolution(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n      outputs = layer.apply(inputs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n      return self.__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n      outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n      outputs = call_fn(cast_inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n      outputs = self._convolution_op(inputs, self.kernel)\nNode: 'resnet_v1_50/conv1/Conv2D'\nDetected at node 'resnet_v1_50/conv1/Conv2D' defined at (most recent call last):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n      deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n      evaluate_multianimal_full(\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n      ) = predict.setup_pose_prediction(test_pose_cfg)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n      net_heads = PoseNetFactory.create(cfg).test(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n      heads = self.get_net(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n      net, end_points = self.extract_features(inputs)\n    File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n      net, end_points = net_fun(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n      return resnet_v1(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n      net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n      return layers_lib.conv2d(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n      return convolution(\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n      return func(*args, **current_args)\n    File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n      outputs = layer.apply(inputs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n      return self.__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n      outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n      outputs = call_fn(cast_inputs, *args, **kwargs)\n    File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n      outputs = self._convolution_op(inputs, self.kernel)\nNode: 'resnet_v1_50/conv1/Conv2D'\n2 root error(s) found.\n  (0) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n\t [[pose/locref_pred/block4/BiasAdd/_551]]\n  (1) UNIMPLEMENTED: DNN library is not found.\n\t [[{{node resnet_v1_50/conv1/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'resnet_v1_50/conv1/Conv2D':\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n    app.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n    self.io_loop.start()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n    self._run_once()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n    handle._run()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n    await self.process_one()\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n    await dispatch(*args)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n    await result\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n    reply_content = await reply_content\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n    res = shell.run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n    result = self._run_cell(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n    return runner(coro)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_334442/1255777010.py\", line 1, in <cell line: 1>\n    deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py\", line 648, in evaluate_network\n    evaluate_multianimal_full(\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate_multianimal.py\", line 321, in evaluate_multianimal_full\n    ) = predict.setup_pose_prediction(test_pose_cfg)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/predict.py\", line 26, in setup_pose_prediction\n    net_heads = PoseNetFactory.create(cfg).test(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/base.py\", line 83, in test\n    heads = self.get_net(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 79, in get_net\n    net, end_points = self.extract_features(inputs)\n  File \"/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnets/resnet.py\", line 41, in extract_features\n    net, end_points = net_fun(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 270, in resnet_v1_50\n    return resnet_v1(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_v1.py\", line 210, in resnet_v1\n    net = resnet_utils.conv2d_same(net, 64, 7, stride=2, scope='conv1')\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/nets/resnet_utils.py\", line 143, in conv2d_same\n    return layers_lib.conv2d(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1171, in convolution2d\n    return convolution(\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/ops/arg_scope.py\", line 184, in func_with_args\n    return func(*args, **current_args)\n  File \"/home/matthew/.local/lib/python3.9/site-packages/tf_slim/layers/layers.py\", line 1089, in convolution\n    outputs = layer.apply(inputs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1697, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 568, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 784, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n    return converted_call(f, args, kwargs, options=options)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 331, in converted_call\n    return _call_unconverted(f, args, kwargs, options, False)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n    return f(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 254, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 1176, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1181, in convolution_v2\n    return convolution_internal(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1313, in convolution_internal\n    return op(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 2787, in _conv2d_expanded_batch\n    return gen_nn_ops.conv2d(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 1144, in conv2d\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 795, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3814, in _create_op_internal\n    ret = Operation(\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config=config_path)#, plotting=True)#, rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_save_all_maps(config_path)#, shuffle=shuffle, Indices=[0, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyze_videos() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m destfolder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Analyze the images in the folder using the pre-trained model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvid_folder\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdestfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideotype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#  videotype='.jpg')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: analyze_videos() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "# Path to the DeepLabCut config file\n",
    "config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/config.yaml'\n",
    "\n",
    "# Path to the folder with images for inference\n",
    "image_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results'\n",
    "vid_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/videos'\n",
    "\n",
    "destfolder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results'\n",
    "\n",
    "# Analyze the images in the folder using the pre-trained model\n",
    "test = deeplabcut.analyze_videos(config_path, [vid_folder], save_as_csv=True, device='cpu', shuffle=6, destfolder=destfolder, videotype = '.mp4')#  videotype='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC_DlcrnetStride16Ms5_DLC_simple_datasetSep15shuffle3_snapshot_001\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 16:04:10.023139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-18 16:04:10.040098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-18 16:04:10.050469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Beak',\n",
      "                      'Body_top',\n",
      "                      'RFlipper_mid',\n",
      "                      'LFlipper_mid',\n",
      "                      'Body_bottom',\n",
      "                      'RFoot',\n",
      "                      'LFoot'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-3/UnaugmentedDataSet_DLC_simple_datasetSep18/DLC_simple_dataset_model199shuffle1.pickle',\n",
      " 'dataset_type': 'multi-animal-imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.3,\n",
      " 'init_weights': '/home/matthew/.local/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_smooth': False,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'minconfidence': 0.01,\n",
      " 'mirror': False,\n",
      " 'multi_stage': True,\n",
      " 'net_type': 'resnet_50',\n",
      " 'nmsradius': 5.0,\n",
      " 'num_idchannel': 0,\n",
      " 'num_joints': 8,\n",
      " 'num_limbs': 7,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_graph': [[0, 1],\n",
      "                             [0, 2],\n",
      "                             [2, 3],\n",
      "                             [2, 4],\n",
      "                             [2, 5],\n",
      "                             [5, 6],\n",
      "                             [5, 7]],\n",
      " 'partaffinityfield_predict': True,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'sigma': 1,\n",
      " 'snapshot_prefix': '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-3/DLC_simple_datasetSep18-trainset99shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/matthew/anaconda3/envs/DEEPLABCUT_TFv2/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-5000 for model /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-18/dlc-models/iteration-3/DLC_simple_datasetSep18-trainset99shuffle1\n",
      "Activating extracting of PAFs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 12:08:31.321308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-19 12:08:31.325865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-19 12:08:31.331143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-19 12:08:31.335964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-19 12:08:31.339324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-19 12:08:31.344828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1488 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all frames in the directory:  /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results\n",
      "Starting to extract posture\n",
      "Overall # of frames:  10  found with (before cropping) frame dimensions:  1920 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results...\n",
      "Saving csv poses!\n",
      "The folder was analyzed. Now your research can truly start!\n",
      "If the tracking is not satisfactory for some frame, consider expanding the training set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the DeepLabCut config file\n",
    "#config_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/config.yaml'\n",
    "\n",
    "# Path to the folder with images for inference\n",
    "image_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results'\n",
    "vid_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/videos'\n",
    "\n",
    "destfolder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/DLC_model/DLC_simple_dataset-model1-2024-09-15/test_results'\n",
    "\n",
    "# Analyze the images in the folder using the pre-trained model\n",
    "#test = deeplabcut.analyze_videos(config_path, [vid_folder], save_as_csv=True, device='cpu', shuffle=4, destfolder=destfolder, videotype = '.mp4')#  videotype='.jpg')\n",
    "\n",
    "deeplabcut.analyze_time_lapse_frames(config_path, image_folder, save_as_csv=True, shuffle=1, frametype='.png',gputouse=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all_cols(df):\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ids into list \n",
    "def load_file_to_list(file_path):\n",
    "    \"\"\"\n",
    "    loads a text file to a list with each entry on a new line becoming a new entry in the list.\n",
    "\n",
    "    :param file_path: Path to the file where the list should be saved.\n",
    "    :return list of data from file\n",
    "    \"\"\"\n",
    "    # Open the file for writing\n",
    "    lst = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Write each item on a new line\n",
    "        for line in file:\n",
    "            lst.append(line.strip())\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_json(df, path):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame to a .json file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be converted to JSON.\n",
    "    path (str): The path (including file name) where the .json file will be saved.\n",
    "    \"\"\"\n",
    "    df.to_json(path, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_to_df(path):\n",
    "    \"\"\"\n",
    "    Converts a .json file to a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the .json file that will be read.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame created from the JSON file.\n",
    "    \"\"\"\n",
    "    print(path)\n",
    "    df = pd.read_json(path, orient='records')\n",
    "    print(f\"JSON file has been successfully converted to DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dtypes_df_full_annotation_abs(df):\n",
    "    df['vid_id'] = df['vid_id'].astype(str)\n",
    "    df['img_id'] = df['img_id'].astype(str)\n",
    "    df['bbox_id'] = df['bbox_id'].astype(str)\n",
    "    df['bbox_c_x'] = df['bbox_c_x'].astype('float32')\n",
    "    df['bbox_c_y'] = df['bbox_c_y'].astype('float32')\n",
    "    df['bbox_w'] = df['bbox_w'].astype('float32')\n",
    "    df['bbox_h'] = df['bbox_h'].astype('float32')\n",
    "    df['Head_x'] = df['Head_x'].astype('float32')\n",
    "    df['Head_y'] = df['Head_y'].astype('float32')\n",
    "    df['Beak_x'] = df['Beak_x'].astype('float32')\n",
    "    df['Beak_y'] = df['Beak_y'].astype('float32')\n",
    "    df['Body_top_x'] = df['Body_top_x'].astype('float32')\n",
    "    df['Body_top_y'] = df['Body_top_y'].astype('float32')\n",
    "    df['RFlipper_mid_x'] = df['RFlipper_mid_x'].astype('float32')\n",
    "    df['RFlipper_mid_y'] = df['RFlipper_mid_y'].astype('float32')\n",
    "    df['LFlipper_mid_x'] = df['LFlipper_mid_x'].astype('float32')\n",
    "    df['LFlipper_mid_y'] = df['LFlipper_mid_y'].astype('float32')\n",
    "    df['Body_bottom_x'] = df['Body_bottom_x'].astype('float32')\n",
    "    df['Body_bottom_y'] = df['Body_bottom_y'].astype('float32')\n",
    "    df['RFoot_x'] = df['RFoot_x'].astype('float32')\n",
    "    df['RFoot_y'] = df['RFoot_y'].astype('float32')\n",
    "    df['LFoot_x'] = df['LFoot_x'].astype('float32')\n",
    "    df['LFoot_y'] = df['LFoot_y'].astype('float32')\n",
    "    df['kp_outside_best_bbox'] = df['kp_outside_best_bbox'].astype('float32')\n",
    "    df['kp_missing'] = df['kp_missing'].astype('float32')\n",
    "    df['kp_primary_missing'] = df['kp_primary_missing'].astype(bool)\n",
    "    df['img_width'] = df['img_width'].astype('float32')\n",
    "    df['img_height'] = df['img_height'].astype('float32')\n",
    "    df['bbox_max_h_w'] = df['bbox_max_h_w'].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnorm_keypoints(img_size, keypoints, kp_to_null=None):\n",
    "    \"\"\"\n",
    "    De-normalizes keypoints based on image size and returns the de-normalized keypoints along with \n",
    "    the positions of any missing or nullified keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    - img_size: Tuple of the image dimensions (height, width).\n",
    "    - keypoints: List of normalized keypoints (with values between -1 and 1).\n",
    "    - kp_to_null: Optional. List of indices where the keypoints should be nulled (set to NaN).\n",
    "\n",
    "    Returns:\n",
    "    - new_keypoints: List of de-normalized keypoints where each coordinate is scaled back to the \n",
    "                     image's pixel dimensions.\n",
    "    - missing_kp: List of indices where the keypoints were either originally set to -10 (indicating \n",
    "                  missing keypoints) or explicitly nullified by the kp_to_null list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract image width and height\n",
    "    readjust_x = img_size[0]  # width of the image\n",
    "    readjust_y = img_size[1]  # height of the image\n",
    "\n",
    "    new_keypoints = []  # List to store the de-normalized keypoints\n",
    "    missing_kp = []     # List to store the indices of missing or nullified keypoints\n",
    "\n",
    "    # Iterate through each keypoint\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        # Null keypoints if they are -10 or if they are specified in kp_to_null\n",
    "        if keypoint == -10 or (kp_to_null and i in kp_to_null):\n",
    "            keypoint = np.nan  # Set keypoint to NaN\n",
    "            missing_kp.append(i)  # Record the index of the missing or nullified keypoint\n",
    "\n",
    "        # De-normalize the x-coordinates\n",
    "        if i % 2 == 0:  # Even indices are x-coordinates\n",
    "            keypoint = keypoint * readjust_x + readjust_x / 2\n",
    "        # De-normalize the y-coordinates\n",
    "        else:  # Odd indices are y-coordinates\n",
    "            keypoint = keypoint * readjust_y + readjust_y / 2\n",
    "\n",
    "        new_keypoints.append(keypoint)  # Append the de-normalized keypoint to the list\n",
    "\n",
    "    return new_keypoints, missing_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_keypoints(img_size, keypoints):\n",
    "    \"\"\"\n",
    "    Normalizes keypoints based on image size and replaces any NaN values with -10.\n",
    "\n",
    "    Parameters:\n",
    "    - img_size: Tuple of the image dimensions (width, height).\n",
    "    - keypoints: List of de-normalized keypoints where each coordinate is in pixel dimensions.\n",
    "\n",
    "    Returns:\n",
    "    - norm_keypoints: List of normalized keypoints where each coordinate is scaled to the range \n",
    "                      [-1, 1] relative to the image size, with NaNs replaced by -10.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract image width and height\n",
    "    readjust_x = img_size[0]  # width of the image\n",
    "    readjust_y = img_size[1]  # height of the image\n",
    "\n",
    "    norm_keypoints = []  # List to store the normalized keypoints\n",
    "\n",
    "    # Iterate through each keypoint\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        # Replace NaN values with -10\n",
    "        if np.isnan(keypoint):\n",
    "            keypoint = -10.0\n",
    "        else:\n",
    "            # Normalize the x-coordinates\n",
    "            if i % 2 == 0:  # Even indices are x-coordinates\n",
    "                keypoint = (keypoint - readjust_x / 2) / readjust_x\n",
    "            # Normalize the y-coordinates\n",
    "            else:  # Odd indices are y-coordinates\n",
    "                keypoint = (keypoint - readjust_y / 2) / readjust_y\n",
    "\n",
    "        norm_keypoints.append(keypoint)  # Append the normalized keypoint to the list\n",
    "\n",
    "    return norm_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_keypoint(img, keypoints, nkeypoints=8, keypoint_labels=None):\n",
    "  fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "  plt.imshow(img)\n",
    "  print(keypoints)\n",
    "  x_keypoints = keypoints[::2]\n",
    "  y_keypoints = keypoints[1::2]\n",
    "  print(x_keypoints)\n",
    "  print(y_keypoints)\n",
    "  plt.scatter(x_keypoints, y_keypoints, marker='.', c=np.arange(nkeypoints), cmap='jet')\n",
    "\n",
    "    # If labels are provided, add them to the plot\n",
    "  if keypoint_labels is not None:\n",
    "      for i, (x, y) in enumerate(zip(x_keypoints, y_keypoints)):\n",
    "          plt.text(x, y, keypoint_labels[i], fontsize=12, color='white', \n",
    "                    bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Extract and save only the desired keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the video names\n",
    "def get_unique_video_names(directory):\n",
    "    \"\"\"\n",
    "    Scans the given directory for video files and returns a list of unique file names without the extension.\n",
    "    \n",
    "    Parameters:\n",
    "    directory (str): The path to the directory containing the video files.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique video file names without extensions.\n",
    "    \"\"\"\n",
    "    unique_names = set()\n",
    "    \n",
    "    # Supported video file extensions\n",
    "    video_extensions = {'.mp4', '.mjpeg'}\n",
    "    \n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Split the filename and extension\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        # Check if the file has a video extension\n",
    "        if ext.lower() in video_extensions:\n",
    "            unique_names.add(name)  # Add the name to the set (ensures uniqueness)\n",
    "    \n",
    "    # Convert the set to a list and return\n",
    "    return list(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple\n",
    "list_of_vids = get_unique_video_names('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_videos')\n",
    "print(len(list_of_vids))\n",
    "print(list_of_vids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and rename csv files that contain annotations\n",
    "def copy_csv_files(ids, source_dir, destination_dir):\n",
    "    \"\"\"\n",
    "    Copies CSV files from sub-directories that match the given IDs and renames them to the ID.\n",
    "    \n",
    "    Parameters:\n",
    "    ids (list): A list of IDs (sub-directory names) to search for.\n",
    "    source_dir (str): The path to the root directory containing sub-directories.\n",
    "    destination_dir (str): The path to the directory where the CSV files should be copied and renamed.\n",
    "    \"\"\"\n",
    "    # Ensure the destination directory exists\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    for id_ in ids:\n",
    "        subdir_path = os.path.join(source_dir, id_)\n",
    "        \n",
    "        if os.path.isdir(subdir_path):\n",
    "            # Find the CSV file in the sub-directory\n",
    "            for file_name in os.listdir(subdir_path):\n",
    "                if file_name.endswith('.csv'):\n",
    "                    csv_file_path = os.path.join(subdir_path, file_name)\n",
    "                    \n",
    "                    # Create the destination file path\n",
    "                    destination_file_path = os.path.join(destination_dir, f\"{id_}.csv\")\n",
    "                    \n",
    "                    # Copy the CSV file to the destination directory with the new name\n",
    "                    shutil.copy(csv_file_path, destination_file_path)\n",
    "                    print(f\"Copied {csv_file_path} to {destination_file_path}\")\n",
    "                    break  # Assuming there is only one CSV file per sub-directory\n",
    "        else:\n",
    "            print(f\"Sub-directory '{id_}' not found in '{source_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = '/home/matthew/Desktop/Masters/Masters-data/Roanne Penguins 2022/Penguin Project Annotation and Videos/Penguin Annotations/P1_labeled-data'\n",
    "destination_directory = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/DLC_Annotations'\n",
    "\n",
    "copy_csv_files(list_of_vids, source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load csv to a dataframe and remove the keypoints not required\n",
    "need it to look like:\n",
    "vid_id,img_id,Head,Head,Beak,Beak,Body_top,Body_top,RFlipper_mid,RFlipper_mid,LFlipper_mid,LFlipper_mid,Body_bottom,Body_bottom,RFoot,RFoot,LFoot,LFoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv into a df\n",
    "df = pd.read_csv('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/DLC_Annotations/flap1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test df function\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step through list of videos/csv ids and create a list of dfs\n",
    "list_of_kp_df_raw = []\n",
    "\n",
    "# step through the list of ids and load each csv into a df and add to list\n",
    "for _id in list_of_vids:\n",
    "    \n",
    "    # load csv to a temp df\n",
    "    print(_id)\n",
    "    df = pd.read_csv(f'/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/DLC_Annotations/{_id}.csv')\n",
    "    list_of_kp_df_raw.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list_of_kp_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append master df from csv to df with correct kp and column names\n",
    "######  THIS WILL HAVE TO BE UPDATED WHEN HAVE LOTS OF PENGUINS. JUST ADD AN IF STATEMENT TO PUT ADDITIONAL COLUMNS\n",
    "######  AS A ADDITIONAL ENTRY AND ADD A BOUNDING BBOX NUMBER COLUMN. THIS WILL LEAD TO SOME EMPTY ROWS IF A PENGUIN\n",
    "######  ENTRERS THE FRAME. SO FINALLY REMOVE ANY EMPTY ROWS\n",
    "def consolidate_dataframes(source_dfs):\n",
    "    \"\"\"\n",
    "    Consolidates data from multiple source DataFrames into a single DataFrame with specific columns.\n",
    "    \n",
    "    Parameters:\n",
    "    source_dfs (list of pd.DataFrame): List of source DataFrames to be consolidated.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A consolidated DataFrame with the selected columns.\n",
    "    \"\"\"\n",
    "    consolidated_df = pd.DataFrame(columns=[\n",
    "        'vid_id', 'image_id', 'Head_x', 'Head_y', 'Beak_x', 'Beak_y',\n",
    "        'Body_top_x', 'Body_top_y', 'RFlipper_mid_x', 'RFlipper_mid_y',\n",
    "        'LFlipper_mid_x', 'LFlipper_mid_y', 'Body_bottom_x', 'Body_bottom_y',\n",
    "        'RFoot_x', 'RFoot_y', 'LFoot_x', 'LFoot_y'\n",
    "    ])\n",
    "\n",
    "    for df in source_dfs:\n",
    "        # Skip the first 4 rows (headers)\n",
    "        df = df.iloc[3:]\n",
    "        \n",
    "        # Create a temporary DataFrame to hold the required columns\n",
    "        temp_df = pd.DataFrame({\n",
    "            'vid_id': df.iloc[:, 1],  # Column 2 (index 1)\n",
    "            'image_id': range(len(df)),  # Sequential image_id starting from 0\n",
    "            'Head_x': df.iloc[:, 3],  # Column 4 (index 3)\n",
    "            'Head_y': df.iloc[:, 4],  # Column 5 (index 4)\n",
    "            'Beak_x': df.iloc[:, 5],  # Column 6 (index 5)\n",
    "            'Beak_y': df.iloc[:, 6],  # Column 7 (index 6)\n",
    "            'Body_top_x': df.iloc[:, 7],  # Column 8 (index 7)\n",
    "            'Body_top_y': df.iloc[:, 8],  # Column 9 (index 8)\n",
    "            'RFlipper_mid_x': df.iloc[:, 13],  # Column 14 (index 13)\n",
    "            'RFlipper_mid_y': df.iloc[:, 14],  # Column 15 (index 14)\n",
    "            'LFlipper_mid_x': df.iloc[:, 15],  # Column 16 (index 15)\n",
    "            'LFlipper_mid_y': df.iloc[:, 16],  # Column 17 (index 16)\n",
    "            'Body_bottom_x': df.iloc[:, 23],  # Column 24 (index 23)\n",
    "            'Body_bottom_y': df.iloc[:, 24],  # Column 25 (index 24)\n",
    "            'RFoot_x': df.iloc[:, 27],  # Column 28 (index 27)\n",
    "            'RFoot_y': df.iloc[:, 28],  # Column 29 (index 28)\n",
    "            'LFoot_x': df.iloc[:, 29],  # Column 30 (index 29)\n",
    "            'LFoot_y': df.iloc[:, 30]  # Column 31 (index 30)\n",
    "        })\n",
    "\n",
    "        # Append the temp_df to the consolidated DataFrame\n",
    "        consolidated_df = pd.concat([consolidated_df, temp_df], ignore_index=True)\n",
    "\n",
    "    return consolidated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_kp_df = consolidate_dataframes(list_of_kp_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_kp_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_kp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to json\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/reduced_kp_raw_Simple.json'\n",
    "df_to_json(master_kp_df, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Save df as a json (and vice versa) and set the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_json(df, path):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame to a .json file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be converted to JSON.\n",
    "    path (str): The path (including file name) where the .json file will be saved.\n",
    "    \"\"\"\n",
    "    df.to_json(path, orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_to_df(path):\n",
    "    \"\"\"\n",
    "    Converts a .json file to a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to the .json file that will be read.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame created from the JSON file.\n",
    "    \"\"\"\n",
    "    print(path)\n",
    "    df = pd.read_json(path, orient='records')\n",
    "    print(f\"JSON file has been successfully converted to DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dtypes_df_full_annotation_abs(df):\n",
    "    df['vid_id'] = df['vid_id'].astype(str)\n",
    "    df['img_id'] = df['img_id'].astype(str)\n",
    "    df['bbox_id'] = df['bbox_id'].astype(str)\n",
    "    df['bbox_c_x'] = df['bbox_c_x'].astype('float32')\n",
    "    df['bbox_c_y'] = df['bbox_c_y'].astype('float32')\n",
    "    df['bbox_w'] = df['bbox_w'].astype('float32')\n",
    "    df['bbox_h'] = df['bbox_h'].astype('float32')\n",
    "    df['Head_x'] = df['Head_x'].astype('float32')\n",
    "    df['Head_y'] = df['Head_y'].astype('float32')\n",
    "    df['Beak_x'] = df['Beak_x'].astype('float32')\n",
    "    df['Beak_y'] = df['Beak_y'].astype('float32')\n",
    "    df['Body_top_x'] = df['Body_top_x'].astype('float32')\n",
    "    df['Body_top_y'] = df['Body_top_y'].astype('float32')\n",
    "    df['RFlipper_mid_x'] = df['RFlipper_mid_x'].astype('float32')\n",
    "    df['RFlipper_mid_y'] = df['RFlipper_mid_y'].astype('float32')\n",
    "    df['LFlipper_mid_x'] = df['LFlipper_mid_x'].astype('float32')\n",
    "    df['LFlipper_mid_y'] = df['LFlipper_mid_y'].astype('float32')\n",
    "    df['Body_bottom_x'] = df['Body_bottom_x'].astype('float32')\n",
    "    df['Body_bottom_y'] = df['Body_bottom_y'].astype('float32')\n",
    "    df['RFoot_x'] = df['RFoot_x'].astype('float32')\n",
    "    df['RFoot_y'] = df['RFoot_y'].astype('float32')\n",
    "    df['LFoot_x'] = df['LFoot_x'].astype('float32')\n",
    "    df['LFoot_y'] = df['LFoot_y'].astype('float32')\n",
    "    df['kp_outside_best_bbox'] = df['kp_outside_best_bbox'].astype('float32')\n",
    "    df['kp_missing'] = df['kp_missing'].astype('float32')\n",
    "    df['kp_primary_missing'] = df['kp_primary_missing'].astype(bool)\n",
    "    df['img_width'] = df['img_width'].astype('float32')\n",
    "    df['img_height'] = df['img_height'].astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Create a single annotation with bbox and keypoints in the correct form and linked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load keypoints df and make them the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reduced_kp_raw_Simple_df\n",
    "df_reduced_kp_raw = json_to_df('/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/reduced_kp_raw_Simple.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_kp_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the format of the keypoints\n",
    "    # 1st string\n",
    "df_reduced_kp_raw.iloc[:, 0] = df_reduced_kp_raw.iloc[:, 0].astype(str)\n",
    "\n",
    "# Ensure the second column is an integer\n",
    "df_reduced_kp_raw.iloc[:, 1] = df_reduced_kp_raw.iloc[:, 1].astype(str)\n",
    "\n",
    "# Format the remaining columns as floats with minimal decimal points\n",
    "for col in df_reduced_kp_raw.columns[2:]:\n",
    "    df_reduced_kp_raw[col] = df_reduced_kp_raw[col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_kp_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load bboxes into a df to be used and correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step through bounding box text files and create a df with the following output\n",
    "# vid_id,img_id,bbox_c_x, bbox_c_y, bbox_w, bbox_h\n",
    "def bbox_txt_files_to_df(directory):\n",
    "    \"\"\"\n",
    "    Processes all text files in the given directory and returns a DataFrame with the columns:\n",
    "    vid_id, img_id, bbox_c_x, bbox_c_y, bbox_w, bbox_h.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): Path to the directory containing the text files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    #count = 0\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            # Extract vid_id and img_id from the filename\n",
    "            parts = filename.split('_')\n",
    "            vid_id = parts[1].split('.')[0]\n",
    "            img_id = parts[-1].split('.')[0]\n",
    "            #print(img_id)\n",
    "\n",
    "            # Read the text file\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                for line in file:\n",
    "                    figures = line.strip().split()\n",
    "                    if len(figures) == 5:\n",
    "                        bbox_c_x, bbox_c_y, bbox_w, bbox_h = map(float, figures[1:])\n",
    "                        data.append([vid_id, img_id, np.float32(bbox_c_x), np.float32(bbox_c_y), np.float32(bbox_w), np.float32(bbox_h)])\n",
    "                        #count += 1\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=['vid_id', 'img_id', 'bbox_c_x', 'bbox_c_y', 'bbox_w', 'bbox_h'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_annotations'\n",
    "\n",
    "bbox_df_raw = bbox_txt_files_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see where there are more than one bounding box per image\n",
    "duplicates = bbox_df_raw[bbox_df_raw.duplicated(['vid_id', 'img_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image size stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step through image files and create a df with the following output\n",
    "# vid_id,img_id,img_wid,img_height\n",
    "\n",
    "def image_files_to_df(directory):\n",
    "    \"\"\"\n",
    "    Processes all .jpg image files in the given directory and returns a DataFrame with the columns:\n",
    "    vid_id, img_id, img_wid, img_height.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): Path to the directory containing the image files.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Extract vid_id and img_id from the filename\n",
    "            parts = filename.split('_')\n",
    "            vid_id = parts[1].split('.')[0]\n",
    "            img_id = parts[-1].split('.')[0]\n",
    "\n",
    "            # Read the image file and get its dimensions\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with Image.open(filepath) as img:\n",
    "                img_wid, img_height = img.size\n",
    "\n",
    "            # Append the data to the list\n",
    "            data.append([vid_id, img_id, np.float32(img_wid), np.float32(img_height)])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=['vid_id', 'img_id', 'img_wid', 'img_height'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_images'\n",
    "\n",
    "imgsize_df_raw = image_files_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsize_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgsize_df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match keypoint to bbox, check for keypoints outside of bbox, match bbox ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all keypoint entries in df\n",
    "# for each keypoint filter the bbox df to have only those ids\n",
    "# do the same for the image df\n",
    "# find the bbox that will contain the most keypoints from the bbox df\n",
    "#   this will require the rescaling of the bbox\n",
    "#   find how many keypoints are outside the bbox\n",
    "#   find how many keypoints are missing\n",
    "#   find whether the primary kp are missing (True/False)\n",
    "# check if this is img_id = 0 \n",
    "#   yes: increment bbox_id starting at 0\n",
    "#   no: find bbox from previous vid_id, img_id - 1 in final df that has the best fit and make bbox id = to that bbox_id, unless distance is over 20% of img size, then make bbox_id last bbox_id + 1\n",
    "# remove the bounding box from the original bbox df - I REMOVED THIS STEP AS UNNECESSARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each keypoint filter the bbox df to have only those ids\n",
    "\n",
    "def filter_dataframe_based_on_another(vid_id, img_id, df_to_filter):\n",
    "    \"\"\"\n",
    "    filters df_to_filter to show entries with the same vid_id and img_id.\n",
    "\n",
    "    Parameters:\n",
    "    vid_id: string with vid_id\n",
    "    image_id: string with img_id\n",
    "    df_to_filter (pd.DataFrame): The DataFrame to filter based on vid_id and img_id.\n",
    "\n",
    "    Returns:\n",
    "    list of pd.DataFrame: A list of filtered DataFrames, one for each row in df_main.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Filter df_to_filter based on the current row's vid_id and img_id\n",
    "    filtered_df = df_to_filter[(df_to_filter['vid_id'] == vid_id) & (df_to_filter['img_id'] == img_id)]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the bounding box\n",
    "def denorm_bbox_df(df_bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Denormalizes bounding boxes in a DataFrame from normalized values to absolute pixel values.\n",
    "\n",
    "    Parameters:\n",
    "    df_bboxes (pd.DataFrame): The DataFrame containing bounding box coordinates.\n",
    "                              Expected columns: ['vid_id', 'image_id', 'bbox_c_x', 'bbox_c_y', 'bbox_w', 'bbox_h']\n",
    "    img_width (int): The width of the image.\n",
    "    img_height (int): The height of the image.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with denormalized bounding boxes.\n",
    "                  Columns: ['vid_id', 'image_id', 'bbox_c_x', 'bbox_c_y', 'bbox_w', 'bbox_h']\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original DataFrame\n",
    "    denorm_df = df_bbox.copy()\n",
    "    #print(denorm_df)\n",
    "    #print(img_width)\n",
    "\n",
    "    # Denormalize the bounding box coordinates\n",
    "    #print(denorm_df['bbox_c_x'])# * img_width)\n",
    "    denorm_df['bbox_c_x'] = denorm_df['bbox_c_x'] * img_width\n",
    "    denorm_df['bbox_c_y'] = denorm_df['bbox_c_y'] * img_height\n",
    "    denorm_df['bbox_w'] = denorm_df['bbox_w'] * img_width\n",
    "    denorm_df['bbox_h'] = denorm_df['bbox_h'] * img_height\n",
    "\n",
    "    return denorm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the bbox that will contain the most keypoints from the bbox df\n",
    "#   find how many keypoints are outside the bbox\n",
    "#   find how many keypoints are missing\n",
    "#   find whether the primary kp are missing (True/False)\n",
    "\n",
    "def find_best_bbox(bbox_df, keypoints_df):\n",
    "    \"\"\"\n",
    "    Finds the bounding box that contains the most keypoints and returns it along with the number\n",
    "    of keypoints that fall outside that bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    bbox_df (pd.DataFrame): DataFrame with bounding boxes in absolute coordinates. \n",
    "                            \n",
    "    keypoints_df (pd.DataFrame): DataFrame with keypoints.\n",
    "                                \n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary containing the best bounding box and the number of keypoints outside it.\n",
    "    \"\"\"\n",
    "    best_bbox = None\n",
    "    max_keypoints_inside = -1\n",
    "    min_distance_to_origin = float('inf')\n",
    "    keypoints_outside_best_bbox = 0\n",
    "    nan_keypoint_pairs = 0\n",
    "    missing_primary_keypoint = False\n",
    "\n",
    "    # Extract keypoints and check for NaN pairs and missing primary keypoints\n",
    "    keypoints = []\n",
    "    for i in range(0, 16, 2):  # Since there are 8 keypoints (16 columns), we step by 2\n",
    "        #print(i)\n",
    "        x = keypoints_df.iloc[i+2]  \n",
    "        y = keypoints_df.iloc[i+3]\n",
    "        keypoints.append((x, y))\n",
    "\n",
    "        # Check if either x or y is NaN\n",
    "        if pd.isna(x) or pd.isna(y):\n",
    "            nan_keypoint_pairs += 1\n",
    "            if i == 4 or i == 10:\n",
    "                missing_primary_keypoint = True\n",
    "\n",
    "        #break\n",
    "    count =0\n",
    "    for _, bbox in bbox_df.iterrows():\n",
    "        #vid_id, img_id = bbox['vid_id'], bbox['img_id']\n",
    "        count=+1\n",
    "        #print(count)\n",
    "        bbox_c_x, bbox_c_y, bbox_w, bbox_h = bbox['bbox_c_x'], bbox['bbox_c_y'], bbox['bbox_w'], bbox['bbox_h']\n",
    "        \n",
    "        # Calculate the bounding box corners (x_min, y_min, x_max, y_max)\n",
    "        x_min = bbox_c_x - bbox_w / 2\n",
    "        y_min = bbox_c_y - bbox_h / 2\n",
    "        x_max = bbox_c_x + bbox_w / 2\n",
    "        y_max = bbox_c_y + bbox_h / 2\n",
    "\n",
    "        # print('xy minmax')\n",
    "        # print(x_min, y_min, x_max, y_max)\n",
    "        # print('keypoints')\n",
    "        # print(keypoints)\n",
    "        \n",
    "        # Count keypoints inside the current bbox\n",
    "        keypoints_inside = sum(x_min <= x <= x_max and y_min <= y <= y_max for x, y in keypoints)\n",
    "        #print('keypoint inside')\n",
    "        #print(keypoints_inside)\n",
    "        \n",
    "        # Calculate the distance of the bbox to the origin (0,0)\n",
    "        distance_to_origin = (x_min**2 + y_min**2)**0.5\n",
    "        \n",
    "        # Update the best bbox if this one has more keypoints inside, or the same number but is closer to the origin\n",
    "        if (keypoints_inside > max_keypoints_inside) or \\\n",
    "           (keypoints_inside == max_keypoints_inside and distance_to_origin < min_distance_to_origin):\n",
    "            best_bbox = bbox\n",
    "            max_keypoints_inside = keypoints_inside\n",
    "            min_distance_to_origin = distance_to_origin\n",
    "            \n",
    "            keypoints_outside_best_bbox = len(keypoints) - nan_keypoint_pairs - keypoints_inside\n",
    "    \n",
    "    # Convert the best bbox to a DataFrame or a list\n",
    "    if best_bbox is not None:\n",
    "        best_bbox_df = pd.DataFrame([{\n",
    "            'vid_id': best_bbox['vid_id'],\n",
    "            'img_id': best_bbox['img_id'],\n",
    "            'bbox_c_x': best_bbox['bbox_c_x'],\n",
    "            'bbox_c_y': best_bbox['bbox_c_y'],\n",
    "            'bbox_w': best_bbox['bbox_w'],\n",
    "            'bbox_h': best_bbox['bbox_h'],\n",
    "        }])\n",
    "        return best_bbox_df, keypoints_outside_best_bbox, nan_keypoint_pairs, missing_primary_keypoint\n",
    "    else:\n",
    "        return None, 8, 0, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_bbox_id(best_bbox_df, final_df_prev):\n",
    "    \"\"\"\n",
    "    Finds the bbox_id in final_df_prev that is closest in distance to the bounding box in best_bbox_df \n",
    "    UNLESS it is more that 20% of image size off, then it returns max bbox_id +1.\n",
    "\n",
    "    Parameters:\n",
    "    best_bbox_df (pd.DataFrame): DataFrame with a single entry for the best bounding box.\n",
    "    final_df_prev (pd.DataFrame): DataFrame with multiple entries, each having a bounding box.\n",
    "\n",
    "    Returns:\n",
    "    str: The bbox_id of the closest bounding box in final_df_prev UNLESS \n",
    "    \"\"\"\n",
    "    # Extract the values from the single entry in best_bbox_df\n",
    "    best_bbox_c_x = best_bbox_df['bbox_c_x'].iloc[0]\n",
    "    best_bbox_c_y = best_bbox_df['bbox_c_y'].iloc[0]\n",
    "    best_bbox_w = best_bbox_df['bbox_w'].iloc[0]\n",
    "    best_bbox_h = best_bbox_df['bbox_h'].iloc[0]\n",
    "\n",
    "    # Initialize variables to track the closest bbox\n",
    "    min_distance = float('inf')\n",
    "    closest_bbox_id = None\n",
    "\n",
    "    # Find the max distance can be (rsm of the image size x 0.25 - this is 25% of image size)\n",
    "    max_distance = np.sqrt(\n",
    "        final_df_prev['img_width'].iloc[0] ** 2 +\n",
    "        final_df_prev['img_height'].iloc[0] ** 2\n",
    "    ) * 0.25\n",
    "\n",
    "    # Iterate through each entry in final_df_prev to calculate the distance\n",
    "    for index, row in final_df_prev.iterrows():\n",
    "        # Calculate the Euclidean distance (root squared mean)\n",
    "        distance = np.sqrt(\n",
    "            (row['bbox_c_x'] - best_bbox_c_x) ** 2 +\n",
    "            (row['bbox_c_y'] - best_bbox_c_y) ** 2 +\n",
    "            (row['bbox_w'] - best_bbox_w) ** 2 +\n",
    "            (row['bbox_h'] - best_bbox_h) ** 2\n",
    "        )\n",
    "        \n",
    "        # Update the closest_bbox_id if this distance is the smallest found\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_bbox_id = row['bbox_id']\n",
    "    \n",
    "    # return max bbox_id + 1 if the distance is greater than the max distance\n",
    "    if min_distance > max_distance:\n",
    "        closest_bbox_id = str(int(final_df_prev['bbox_id'].max())+1)\n",
    "\n",
    "    return closest_bbox_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all keypoint entries in df and use the above functions to create final df\n",
    "def process_dataframe(df_kp, df_bbox, df_imgsize):\n",
    "    \"\"\"\n",
    "    Iterates over each row in the DataFrame and processes the data.\n",
    "\n",
    "    Parameters:\n",
    "    df_kp, df_bbox, df_imgsize: keypoint df, bbox df, img size df \n",
    "\n",
    "    Returns:\n",
    "    df_full_annotation: Full annotation compiled df\n",
    "    \"\"\"\n",
    "    #test\n",
    "    count = 0\n",
    "    bbox_count = 0\n",
    "    prev_img_id = -1\n",
    "    df_final = pd.DataFrame(columns=[\n",
    "        'vid_id', 'img_id', 'bbox_id', 'bbox_c_x', 'bbox_c_y', 'bbox_w', 'bbox_h',\n",
    "        'Head_x', 'Head_y', 'Beak_x', 'Beak_y','Body_top_x', 'Body_top_y','RFlipper_mid_x',\t\n",
    "        'RFlipper_mid_y', 'LFlipper_mid_x', 'LFlipper_mid_y', 'Body_bottom_x', 'Body_bottom_y', \n",
    "        'RFoot_x', 'RFoot_y', 'LFoot_x', 'LFoot_y','kp_outside_best_bbox', 'kp_missing', 'kp_primary_missing',\n",
    "        'img_width', 'img_height',\n",
    "    ])\n",
    "\n",
    "    for index, row in df_kp.iterrows():\n",
    "        #test\n",
    "        count += 1\n",
    "\n",
    "        # Access data in each row using row['column_name'] - get the vid_id and img_id\n",
    "        vid_id = row['vid_id']\n",
    "        img_id = row['image_id']\n",
    "\n",
    "        # print(row)\n",
    "\n",
    "        #filter the bbox and img_size df to only have specific img and vid id\n",
    "        df_bbox_filtered = filter_dataframe_based_on_another(vid_id, img_id, df_bbox)\n",
    "        df_imgsize_filtered = filter_dataframe_based_on_another(vid_id, img_id, df_imgsize)\n",
    "\n",
    "        # get image size \n",
    "        img_width = df_imgsize_filtered['img_wid']\n",
    "        img_height = df_imgsize_filtered['img_height']\n",
    "        # convert them to scalars that can be used in math operations\n",
    "        img_width = img_width.iloc[0]  # Convert to scalar\n",
    "        img_height = img_height.iloc[0]  # Convert to scalar\n",
    "\n",
    "        # denormalise the bbox so that the they are absolute coords\n",
    "        df_bbox_filtered_abs = denorm_bbox_df(df_bbox_filtered, img_width, img_height)\n",
    "\n",
    "        # find the bbox that will contain the most keypoints from the bbox df\n",
    "        # and find how many keypoints are outside the bbox\n",
    "        df_best_bbox, kp_outside_best_bbox, kp_missing, kp_primary_missing = find_best_bbox(df_bbox_filtered_abs, row)\n",
    "\n",
    "        # check if first image in video sequence (for matching bboxes and kp, if it is first then we don't need matching)\n",
    "        if img_id == '0':\n",
    "            #yes: just increment bbox_id starting at 0\n",
    "            if prev_img_id != img_id: # if we are on the first bbox of an img\n",
    "                bbox_count = 0\n",
    "            else: # if we not on the first one\n",
    "                bbox_count += 1\n",
    "            # set the bbox id\n",
    "            bbox_id = str(bbox_count)  \n",
    "        \n",
    "        else:\n",
    "            # no: find bbox from previous vid_id, img_id - 1 in final df that has the best fit \n",
    "            # and make bbox id = to that bbox_id, unless distance is over 20% of img size, \n",
    "            # then make bbox_id last bbox_id + 1\n",
    "\n",
    "            # 1. filter for all the entries in the df_final that are from the previous image\n",
    "            df_final_filtered_prev = filter_dataframe_based_on_another(prev_vid_id, prev_img_id, df_final)\n",
    "\n",
    "            # 2. find bbox df_final_filtered_prev that has the best fit to current best bbox \n",
    "            # and make bbox id = to that bbox_id, unless distance is over 25% of img size, \n",
    "            # then make bbox_id last bbox_id + 1\n",
    "            bbox_id = find_closest_bbox_id(df_best_bbox, df_final_filtered_prev)\n",
    "\n",
    "\n",
    "        # Store the result in a dictionary and then append to the DataFrame\n",
    "        result = {\n",
    "            'vid_id': vid_id,\n",
    "            'img_id': img_id,\n",
    "            'bbox_id': bbox_id,\n",
    "            'bbox_c_x': df_best_bbox['bbox_c_x'].iloc[0],\n",
    "            'bbox_c_y': df_best_bbox['bbox_c_y'].iloc[0],\n",
    "            'bbox_w': df_best_bbox['bbox_w'].iloc[0],\n",
    "            'bbox_h': df_best_bbox['bbox_h'].iloc[0],\n",
    "            'Head_x': row.iloc[2],\n",
    "            'Head_y': row.iloc[3],\n",
    "            'Beak_x': row.iloc[4],\n",
    "            'Beak_y': row.iloc[5],\n",
    "            'Body_top_x': row.iloc[6],\n",
    "            'Body_top_y': row.iloc[7],\n",
    "            'RFlipper_mid_x': row.iloc[8],\n",
    "            'RFlipper_mid_y': row.iloc[9],\n",
    "            'LFlipper_mid_x': row.iloc[10],\n",
    "            'LFlipper_mid_y': row.iloc[11],\n",
    "            'Body_bottom_x': row.iloc[12],\n",
    "            'Body_bottom_y': row.iloc[13],\n",
    "            'RFoot_x': row.iloc[14],\n",
    "            'RFoot_y': row.iloc[15],\n",
    "            'LFoot_x': row.iloc[16],\n",
    "            'LFoot_y': row.iloc[17],\n",
    "            'kp_outside_best_bbox': float(kp_outside_best_bbox),\n",
    "            'kp_missing': float(kp_missing),\n",
    "            'kp_primary_missing': kp_primary_missing,\n",
    "            'img_width': img_width,\n",
    "            'img_height': img_height\n",
    "        }\n",
    "        \n",
    "        df_final = df_final.append(result, ignore_index=True)\n",
    "\n",
    "        # keep track of the last img_id so if we are on the second bbox for an image we know\n",
    "        prev_img_id = img_id\n",
    "        prev_vid_id = vid_id\n",
    "        \n",
    "    return df_final\n",
    "        \n",
    "\n",
    "\n",
    "        #test\n",
    "        # if count == 50:\n",
    "        #     return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs = process_dataframe(df_reduced_kp_raw, bbox_df_raw, imgsize_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check that all kp are contained in the bbox\n",
    "A. in the simple we will adjust bbox \n",
    "B. in others we will adjust bboxs to make them slightly bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bboxs that have kps outside of the box\n",
    "df_kp_outside_bbox = df_full_annotation_abs[(df_full_annotation_abs['kp_outside_best_bbox'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_outside_bbox.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple\n",
    "we will just show all the bbox that are an issue and adjust the bbox and save those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all the issue bbox rows\n",
    "df_kp_outside_bbox.head(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTANT: display all cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_kp_outside_bbox.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i need to adjust the Head_y value of row 390 as this is a negative (which it cant be)\n",
    "# first lets see that we have the right row number (390) -> seen in the above output\n",
    "print(df_full_annotation_abs.loc[390, 'Head_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay now just set it to 1.5\n",
    "df_full_annotation_abs.loc[390, 'Head_y'] = float(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the kp_outside flag\n",
    "df_full_annotation_abs.loc[390, 'kp_outside_best_bbox'] = float(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_full_annotation_abs.loc[390])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just check that it is the correct dtype\n",
    "df_full_annotation_abs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save df_final as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/df_full_annotation_abs_Simple.json'\n",
    "df_to_json(df_full_annotation_abs, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Get json annotation abs to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/df_full_annotation_abs_Simple.json'\n",
    "df_full_annotation_abs = json_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs = set_dtypes_df_full_annotation_abs(df_full_annotation_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_abs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Crop images by bbox\n",
    "save them with the name vid_id_img_id_bbox_id_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all kp entries in the df_full_annotation_abs\n",
    "# for each entry crop and save image with the naming criteria using a function that takes bbox coords as input and ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to crop image by bbox and save using id naming convention\n",
    "def crop_and_save_image(image_path, save_directory, vid_id, img_id, bbox_id, bbox_c_x, bbox_c_y, bbox_w, bbox_h):\n",
    "    \"\"\"\n",
    "    Crops an image based on the provided bounding box coordinates and saves it with a specific naming convention.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path (str): Path to the input image.\n",
    "    - save_directory (str): Directory where the cropped image will be saved.\n",
    "    - vid_id (str): Video ID used for naming the cropped image.\n",
    "    - img_id (str): Image ID used for naming the cropped image.\n",
    "    - bbox_id (str): Bounding box ID used for naming the cropped image.\n",
    "    - bbox_c_x (float): X-coordinate of the bounding box center.\n",
    "    - bbox_c_y (float): Y-coordinate of the bounding box center.\n",
    "    - bbox_w (float): Width of the bounding box.\n",
    "    - bbox_h (float): Height of the bounding box.\n",
    "    \n",
    "    The cropped image will be saved as `vid_id_img_id_bbox_id_crop_raw.jpg` in the save directory.\n",
    "    \"\"\"\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Calculate the bounding box corners\n",
    "    left = bbox_c_x - (bbox_w / 2)\n",
    "    top = bbox_c_y - (bbox_h / 2)\n",
    "    right = bbox_c_x + (bbox_w / 2)\n",
    "    bottom = bbox_c_y + (bbox_h / 2)\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.makedirs(save_directory)\n",
    "    \n",
    "    # Create the file name\n",
    "    save_filename = f\"{vid_id}_{img_id}_{bbox_id}_crop_raw.jpg\"\n",
    "    save_path = os.path.join(save_directory, save_filename)\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cropped_image.save(save_path, format='JPEG')\n",
    "    \n",
    "    print(f\"Cropped image saved as {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets the path to the image \n",
    "def find_image_path(image_directory, vid_id, img_id):\n",
    "    \"\"\"\n",
    "    Searches through all .jpg files in the specified directory and returns the path to the image\n",
    "    that matches the provided vid_id and img_id.\n",
    "\n",
    "    Parameters:\n",
    "    - image_directory (str): Path to the directory containing the images.\n",
    "    - vid_id (str): The video ID to match in the image file name.\n",
    "    - img_id (str): The image ID to match in the image file name.\n",
    "\n",
    "    Returns:\n",
    "    - str: The path to the matching image file, or None if no match is found.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(image_directory):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Split the filename and check if it matches the vid_id and img_id\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) >= 3:  # Ensure there are enough parts to avoid index errors\n",
    "                file_vid_id = parts[1].split('.')[0]\n",
    "                file_img_id = parts[-1].split('.')[0]\n",
    "                if file_vid_id == vid_id and file_img_id == img_id:\n",
    "                    return os.path.join(image_directory, filename)\n",
    "    \n",
    "    # If no matching image is found, return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that steps through df and calls above function\n",
    "def crop_img_from_df(df, img_dir, save_dir):\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # Access data in each row using row['column_name'] - get the vid_id and img_id\n",
    "        vid_id = row['vid_id']\n",
    "        img_id = row['img_id']\n",
    "        bbox_id = row['bbox_id']\n",
    "        bbox_c_x = row['bbox_c_x']\n",
    "        bbox_c_y = row['bbox_c_y']\n",
    "        bbox_w = row['bbox_w']\n",
    "        bbox_h = row['bbox_h']\n",
    "\n",
    "        #print(type(vid_id))\n",
    "        #print(type(img_id))\n",
    "\n",
    "        # get the relevant image path\n",
    "        img_path = find_image_path(img_dir, vid_id, img_id)\n",
    "        #print(img_path)\n",
    "\n",
    "        #crop and save the relevant bbox in the save directory\n",
    "        crop_and_save_image(img_path, save_dir, vid_id, img_id, bbox_id, bbox_c_x, bbox_c_y, bbox_w, bbox_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/Simple_ObjectDetect1/raw_images'\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_raw'\n",
    "#df_full_annotation_abs.info()\n",
    "\n",
    "crop_img_from_df(df_full_annotation_abs, img_dir, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Resize cropped images and add padding\n",
    "resize bbox_img to fit into 220x220 but do not allow distortion of the img. Use padding rather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_pad_images(source_dir, save_dir):\n",
    "    \"\"\"\n",
    "    Resizes and pads images from the source directory to 220x220 pixels and saves them to the save directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - source_dir (str): Path to the directory containing the source images.\n",
    "    - save_dir (str): Path to the directory where the resized images will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Process each image in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            img_path = os.path.join(source_dir, filename)\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # Resize while maintaining aspect ratio\n",
    "            img.thumbnail((220, 220), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Calculate padding to make the image 220x220\n",
    "            delta_w = 220 - img.size[0]\n",
    "            delta_h = 220 - img.size[1]\n",
    "            padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "            \n",
    "            # Add padding to the image\n",
    "            padded_img = ImageOps.expand(img, padding, fill='black')\n",
    "            \n",
    "            # Rename the image\n",
    "            parts = filename.split('_')\n",
    "            base_name = '_'.join(parts[:-1])\n",
    "            extension = filename.split('.')[-1]\n",
    "            new_filename = f\"{base_name}_220x220.{extension}\"\n",
    "            \n",
    "            # Save the new image\n",
    "            save_path = os.path.join(save_dir, new_filename)\n",
    "            padded_img.save(save_path, format='JPEG')\n",
    "            print(f\"Saved resized image as {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_raw'\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_crop_220'\n",
    "resize_and_pad_images(source_dir, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Normalise the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the keypoints (normalise by the abs value of the bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max(w/h) of the bbox\n",
    "# shift x and y coords for each annotation by the centre of the bbox\n",
    "# devide by the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_kp_by_bbox_df(df_orginal):\n",
    "\n",
    "    # copy so don't effect the original df\n",
    "    df = df_orginal.copy()\n",
    "    \n",
    "    # first create a new col that is the max value of the height and width\n",
    "    df['bbox_max_h_w'] = df[['bbox_w', 'bbox_h']].max(axis=1) \n",
    "\n",
    "    ## shift coords \n",
    "    # list of kp y cols\n",
    "    y_columns = [\n",
    "        'Head_y', 'Beak_y', 'Body_top_y', 'RFlipper_mid_y', \n",
    "        'LFlipper_mid_y', 'Body_bottom_y', 'RFoot_y', 'LFoot_y'\n",
    "    ]\n",
    "    # list of kp x cols\n",
    "    x_columns = [\n",
    "        'Head_x', 'Beak_x', 'Body_top_x', 'RFlipper_mid_x', \n",
    "        'LFlipper_mid_x', 'Body_bottom_x', 'RFoot_x', 'LFoot_x'\n",
    "    ]\n",
    "    # Subtract bbox_c_y from the selected '_y' columns\n",
    "    df[y_columns] = df[y_columns].subtract(df['bbox_c_y'], axis=0)\n",
    "    # Subtract bbox_c_x from the selected '_x' columns\n",
    "    df[x_columns] = df[x_columns].subtract(df['bbox_c_x'], axis=0)\n",
    "\n",
    "    # scale (devide) by the max of bbox width and hight (bbox_max_h_w)\n",
    "    df[y_columns] = df[y_columns].div(df['bbox_max_h_w'], axis=0)\n",
    "    df[x_columns] = df[x_columns].div(df['bbox_max_h_w'], axis=0)\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_kpnorm = norm_kp_by_bbox_df(df_full_annotation_abs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     print(df_full_annotation_abs.head(2))\n",
    "\n",
    "# with pd.option_context('display.max_columns', None):\n",
    "#     print(df_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the bbox (normalise by the size of the img)\n",
    "normalising how it is done in the obj dect (between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_bbox_by_img_df(df_orginal):\n",
    "\n",
    "    # copy so don't effect the original df\n",
    "    df = df_orginal.copy()\n",
    "\n",
    "    ## shift coords \n",
    "    # list of kp y cols\n",
    "    y_columns = [\n",
    "        'bbox_c_y', 'bbox_h'\n",
    "    ]\n",
    "    # list of kp x cols \n",
    "    # I AM NORMILISING THE bbox_max_h_w BY THE IMAGE WIDTH\n",
    "    x_columns = [\n",
    "        'bbox_c_x', 'bbox_w', 'bbox_max_h_w'\n",
    "    ]\n",
    "\n",
    "    # scale (devide) by the width and hight of the image\n",
    "    df[y_columns] = df[y_columns].div(df['img_height'], axis=0)\n",
    "    df[x_columns] = df[x_columns].div(df['img_width'], axis=0)\n",
    "\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm = norm_bbox_by_img_df(df_full_annotation_kpnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_full_annotation_abs.head(2))\n",
    "\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    print(df_full_annotation_norm.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the norm full annotation df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/df_full_annotation_norm_Simple.json'\n",
    "df_to_json(df_full_annotation_norm, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build Basic Regression PE Model (DeepPose based)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. load the normalised annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/df_full_annotation_norm_Simple.json'\n",
    "df_full_annotation_norm = json_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm = set_dtypes_df_full_annotation_abs(df_full_annotation_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the db easier to work with I am going to create a list with the kp col names, bbox col names, id col names\n",
    "id_cols = df_full_annotation_norm.iloc[:, :3].columns.to_list()\n",
    "bbox_cols = df_full_annotation_norm.iloc[:, 3:7].columns.to_list()\n",
    "kp_cols = df_full_annotation_norm.iloc[:, 7:23].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_cols)\n",
    "print(bbox_cols)\n",
    "print(kp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Remove rows where too many (or primary) keypoints are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full_annotation_norm.iloc[359])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any examples with more NaN values than the chosen threshold\n",
    "# The nan values are there when a keypoint is occluded\n",
    "\n",
    "def remove_rows_with_too_many_nans(df, columns_to_check, nan_threshold):\n",
    "    \"\"\"\n",
    "    Remove rows from the DataFrame where the number of NaN values in specified columns exceeds the threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame to process.\n",
    "    - columns_to_check: A list of column names to check for NaN values.\n",
    "    - nan_threshold: The maximum allowed number of NaN values in the specified columns. Rows with more NaNs will be removed.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with rows exceeding the NaN threshold removed.\n",
    "    \"\"\"\n",
    "    # Count NaNs only in the specified columns\n",
    "    nan_counts = df[columns_to_check].isna().sum(axis=1)\n",
    "    print(type(nan_counts))\n",
    "\n",
    "    # Identify rows where NaN count is below or equal to the threshold\n",
    "    rows_to_keep = nan_counts <= nan_threshold\n",
    "    print(rows_to_keep[rows_to_keep==False].index)\n",
    "\n",
    "    # Filter the DataFrame to keep only the desired rows\n",
    "    filtered_df = df[rows_to_keep]\n",
    "\n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function to remove the rows with more than 14 keypoint coords missing\n",
    "# the number of keypoints is 14 and each has 2 coords so there are 28 coords\n",
    "df_full_annotation_norm = remove_rows_with_too_many_nans(df_full_annotation_norm, kp_cols, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full_annotation_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing any examples where the primary kp are missing. When these are missing we will not be able to use our PCK metric\n",
    "# The nan values are there when a keypoint is occluded\n",
    "\n",
    "def remove_rows_with_missing_primary_kp(df):\n",
    "    \"\"\"\n",
    "    Remove rows from the DataFrame where kp_primary_missing is set to true\n",
    "\n",
    "    Parameters:\n",
    "    - df: The DataFrame to process.\n",
    "\n",
    "    Returns:\n",
    "    - A new DataFrame with rows not missing the primary kp.\n",
    "    \"\"\"\n",
    "    with pd.option_context('display.max_columns', None):\n",
    "        print(df[df['kp_primary_missing'] == True])\n",
    "\n",
    "    # Identify rows where NaN count is below or equal to the threshold\n",
    "    rows_to_keep = df['kp_primary_missing'] == False\n",
    "\n",
    "    # Filter the DataFrame to keep only the desired rows\n",
    "    filtered_df = df[rows_to_keep]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm = remove_rows_with_missing_primary_kp(df_full_annotation_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Replace nan with out of range (-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to train the data keypoints cannot have the value nan\n",
    "# this function removes the value nan from the keypoint df\n",
    "def convert_nans_to_neg_ten(df, columns):\n",
    "\n",
    "    df_adjusted = df.copy()\n",
    "\n",
    "    # Iterate over the specified columns\n",
    "    for col in columns:\n",
    "        # Replace NaN values with -10\n",
    "        df_adjusted[col].fillna(-10, inplace=True)\n",
    "\n",
    "    return df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm = convert_nans_to_neg_ten(df_full_annotation_norm, kp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Split data into train, val and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1. get list of ids that are in each set from obj detect folder and save to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of ids from image_obj detect\n",
    "def extract_image_ids(folder_path):\n",
    "    \"\"\"\n",
    "    Extracts image IDs from filenames in the given folder. \n",
    "    The filenames are assumed to be in the format something_vidid.something_imgid.something.\n",
    "\n",
    "    Parameters:\n",
    "    folder_path (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of strings in the format 'vidid_imgid'.\n",
    "    \"\"\"\n",
    "    image_ids = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if os.path.isfile(os.path.join(folder_path, filename)):  # Ensure it's a file\n",
    "            parts = filename.split('_')  # Split by the underscore\n",
    "            vidid = parts[1].split('.')[0]  # Extract vidid (part after first underscore and before first dot)\n",
    "            imgid = parts[2].split('.')[0]  # Extract imgid (part after second underscore and before second dot)\n",
    "            image_ids.append(f'{vidid}_{imgid}')\n",
    "\n",
    "    return image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save unique ids list as a text file\n",
    "def save_list_to_file(list_data, file_path):\n",
    "    \"\"\"\n",
    "    Saves a list to a text file with each entry on a new line.\n",
    "\n",
    "    :param list_data: List of strings to be saved to a file.\n",
    "    :param file_path: Path to the file where the list should be saved.\n",
    "    \"\"\"\n",
    "    # Open the file for writing\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Write each item on a new line\n",
    "        for item in list_data:\n",
    "            file.write(f\"{item}\\n\")  # Add a newline after each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test imgs\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/YoloV8_dataset_Simple_parent/YoloV8_dataset_Simple/images/test'\n",
    "ids_test = extract_image_ids(path)\n",
    "print(ids_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val imgs\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/YoloV8_dataset_Simple_parent/YoloV8_dataset_Simple/images/val'\n",
    "ids_val = extract_image_ids(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train imgs\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/YoloV8_dataset_Simple_parent/YoloV8_dataset_Simple/images/train'\n",
    "ids_train = extract_image_ids(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lists to txt files\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_test.txt'\n",
    "save_list_to_file(ids_test, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_val.txt'\n",
    "\n",
    "save_list_to_file(ids_val, save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_train.txt'\n",
    "\n",
    "save_list_to_file(ids_train, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2. split df based on train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_id_parts(df, id_list, col1, col2):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to include only rows where:\n",
    "    - col1 matches idpart1\n",
    "    - col2 matches idpart2\n",
    "    The ID parts are derived from the id_list, where each ID is in the format 'idpart1_idpart2'.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be filtered.\n",
    "    id_list (list): The list of IDs in the format 'idpart1_idpart2'.\n",
    "    col1 (str): The name of the first column containing idpart1.\n",
    "    col2 (str): The name of the second column containing idpart2.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A filtered DataFrame containing only the rows matching the ID parts.\n",
    "    \"\"\"\n",
    "    # Split the IDs into idpart1 and idpart2\n",
    "    id_parts = [id.split('_') for id in id_list]\n",
    "    \n",
    "    # Convert the list of tuples into a DataFrame\n",
    "    id_df = pd.DataFrame(id_parts, columns=[col1, col2])\n",
    "    \n",
    "    # Perform an inner merge to filter the DataFrame\n",
    "    filtered_df = pd.merge(df, id_df, how='inner', on=[col1, col2])\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "df_full_annotation_norm_test = filter_df_by_id_parts(df_full_annotation_norm, ids_test, 'vid_id', 'img_id')\n",
    "\n",
    "print(df_full_annotation_norm_test.info())\n",
    "\n",
    "display_all_cols(df_full_annotation_norm_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val set\n",
    "df_full_annotation_norm_val = filter_df_by_id_parts(df_full_annotation_norm, ids_val, 'vid_id', 'img_id')\n",
    "\n",
    "print(df_full_annotation_norm_val.info())\n",
    "display_all_cols(df_full_annotation_norm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "df_full_annotation_norm_train = filter_df_by_id_parts(df_full_annotation_norm, ids_train, 'vid_id', 'img_id')\n",
    "\n",
    "print(df_full_annotation_norm_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_full_annotation_norm_test.info())\n",
    "\n",
    "display_all_cols(df_full_annotation_norm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3. Save the df annotations to the processed folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/test_annotation_simple.json'\n",
    "df_to_json(df_full_annotation_norm_test, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save val\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/val_annotation_simple.json'\n",
    "df_to_json(df_full_annotation_norm_val, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/train_annotation_simple.json'\n",
    "df_to_json(df_full_annotation_norm_train, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4. save imgs to the processed folder based on split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_by_ids(src_folder, dst_folder, id_list):\n",
    "    \"\"\"\n",
    "    Moves images from the source folder to the destination folder based on the specified IDs.\n",
    "    The image filenames are expected to be in the format 'something_vidid.something_imgid.something'.\n",
    "\n",
    "    Parameters:\n",
    "    src_folder (str): Path to the source folder containing the images.\n",
    "    dst_folder (str): Path to the destination folder where images will be moved.\n",
    "    id_list (list): List of IDs in the format 'idpart1_idpart2'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Ensure the destination directory exists\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "\n",
    "    for filename in os.listdir(src_folder):\n",
    "        if os.path.isfile(os.path.join(src_folder, filename)):  # Check if it's a file\n",
    "            parts = filename.split('_')\n",
    "            vidid = parts[0]\n",
    "            imgid = parts[1]\n",
    "            \n",
    "            # Check if the extracted id combination is in the list\n",
    "            if f'{vidid}_{imgid}' in id_list:\n",
    "                src_path = os.path.join(src_folder, filename)\n",
    "                dst_path = os.path.join(dst_folder, filename)\n",
    "                shutil.move(src_path, dst_path)\n",
    "                print(f'Moved: {filename} to {dst_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "src_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_crop_220'\n",
    "dst_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/test'\n",
    "\n",
    "move_images_by_ids(src_folder, dst_folder, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "src_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_crop_220'\n",
    "dst_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/val'\n",
    "\n",
    "move_images_by_ids(src_folder, dst_folder, ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "src_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/raw/PE_Simple/Cropped_bbox_img_crop_220'\n",
    "dst_folder = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/train'\n",
    "\n",
    "move_images_by_ids(src_folder, dst_folder, ids_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5. save final list of all vid_id, img_id, bbox_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of full ids\n",
    "def full_ids_to_list(df, cols_to_combine):\n",
    "    \"\"\"\n",
    "    Combines the values of specified columns in each row of the DataFrame, \n",
    "    separated by an underscore, and returns a list of these combined values.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    cols_to_combine (list): List of column names to combine.\n",
    "\n",
    "    Returns:\n",
    "    list: A list where each item is a combined string of the specified columns' values.\n",
    "    \"\"\"\n",
    "    # Use DataFrame's apply method to combine the columns row-wise\n",
    "    combined_list = df[cols_to_combine].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "    \n",
    "    # Convert the combined Series to a list\n",
    "    return combined_list.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ids_test_bbox = full_ids_to_list(df_full_annotation_norm_test, id_cols)\n",
    "print(ids_test_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ids_val_bbox = full_ids_to_list(df_full_annotation_norm_val, id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "ids_train_bbox = full_ids_to_list(df_full_annotation_norm_train, id_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lists to txt files\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_test_bbox.txt'\n",
    "save_list_to_file(ids_test_bbox, save_dir)\n",
    "\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_val_bbox.txt'\n",
    "\n",
    "save_list_to_file(ids_val_bbox, save_dir)\n",
    "\n",
    "save_dir = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_train_bbox.txt'\n",
    "\n",
    "save_list_to_file(ids_train_bbox, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Load image data into arr for train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. load ids to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ids into list \n",
    "def load_file_to_list(file_path):\n",
    "    \"\"\"\n",
    "    loads a text file to a list with each entry on a new line becoming a new entry in the list.\n",
    "\n",
    "    :param file_path: Path to the file where the list should be saved.\n",
    "    :return list of data from file\n",
    "    \"\"\"\n",
    "    # Open the file for writing\n",
    "    lst = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Write each item on a new line\n",
    "        for line in file:\n",
    "            lst.append(line.strip())\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_test_bbox.txt'\n",
    "ids_test_bbox = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_val_bbox.txt'\n",
    "ids_val_bbox = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_train_bbox.txt'\n",
    "ids_train_bbox = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_test.txt'\n",
    "ids_test = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_val.txt'\n",
    "ids_val = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/ids_train.txt'\n",
    "ids_train = load_file_to_list(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2. load image data to arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the image data into an arr\n",
    "# in the same order as the annotations and ids are stored (use id list for this)\n",
    "\n",
    "# The load image data function may take a while to run\n",
    "\n",
    "def load_image_data(ids_to_load, image_folder, crop_ext):\n",
    "\n",
    "  # list for loading image data\n",
    "  selected_imgs = []\n",
    "\n",
    "  # for loop for loading image data that is present in the list of ids\n",
    "  for i, img_id in enumerate(ids_to_load):\n",
    "\n",
    "    # load the image\n",
    "    img_path = os.path.join(image_folder, img_id+crop_ext)\n",
    "    print(img_path)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "    #print(img)\n",
    "\n",
    "    # change the img to RGB from BGR as plt uses RGB colour scale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # scaling the pixel values to [0, 1] (you don't need to scal them back)\n",
    "    img = img/255\n",
    "\n",
    "    selected_imgs.append(img)\n",
    "\n",
    "  # Convert the list of images to a NumPy array\n",
    "  selected_imgs_array = np.array(selected_imgs)\n",
    "  \n",
    "  return selected_imgs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "image_folder_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/test'\n",
    "crop_extension = '_crop_220x220.jpg'\n",
    "\n",
    "test_imgs_array = load_image_data(ids_test_bbox, image_folder_path, crop_extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "image_folder_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/val'\n",
    "crop_extension = '_crop_220x220.jpg'\n",
    "\n",
    "val_imgs_array = load_image_data(ids_val_bbox, image_folder_path, crop_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "image_folder_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/images/train'\n",
    "crop_extension = '_crop_220x220.jpg'\n",
    "\n",
    "train_imgs_array = load_image_data(ids_train_bbox, image_folder_path, crop_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3. load annotations to df and then keypoints to arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3.1. loading dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json to a df test\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/test_annotation_simple.json'\n",
    "df_full_annotation_norm_test = json_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm_test = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json to a df val\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/val_annotation_simple.json'\n",
    "df_full_annotation_norm_val = json_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm_val = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the json to a df train\n",
    "path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/data/processed/PE_Simple/annotation/train_annotation_simple.json'\n",
    "df_full_annotation_norm_train = json_to_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_annotation_norm_train = set_dtypes_df_full_annotation_abs(df_full_annotation_norm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make the db easier to work with I am going to create a list with the kp col names, bbox col names, id col names\n",
    "id_cols = df_full_annotation_norm_test.iloc[:, :3].columns.to_list()\n",
    "bbox_cols = df_full_annotation_norm_test.iloc[:, 3:7].columns.to_list()\n",
    "kp_cols = df_full_annotation_norm_test.iloc[:, 7:23].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3.2. loading the keypoint annotation into an arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_lists(df_to_list, list_of_cols):\n",
    "\n",
    "  # create temp lists\n",
    "  keypoints_temp = []\n",
    "\n",
    "  # step through the rows and\n",
    "  for _, row in df_to_list.iterrows():\n",
    "\n",
    "    # extract the data arrays\n",
    "    keypoints_data = row[list_of_cols].values\n",
    "\n",
    "    # adding data to the list\n",
    "    keypoints_temp.append(keypoints_data)\n",
    "\n",
    "  # Convert the list to a NumPy array and make sure that they are float32\n",
    "  keypoints_array = np.array(keypoints_temp, dtype=np.float32)\n",
    "  \n",
    "  return keypoints_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_kp_array = create_data_lists(df_full_annotation_norm_test, kp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val_kp_array = create_data_lists(df_full_annotation_norm_val, kp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_kp_array = create_data_lists(df_full_annotation_norm_train, kp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.51. Augment train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = train_imgs_array.shape[0]\n",
    "print(num_imgs)\n",
    "num_kp = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize keypoints for an array of images\n",
    "def unnorm_keypoints_arr(kp_arr, img_arr):\n",
    "    \"\"\"\n",
    "    Denormalizes keypoints for each image in the array based on the corresponding image size.\n",
    "    It converts normalized keypoints (range [-1, 1]) back to pixel coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - kp_arr: Array of normalized keypoints, where each entry is a list of keypoints for an image.\n",
    "              The keypoints are expected to be in the format [x1, y1, x2, y2, ...].\n",
    "    - img_arr: Array of images. The size of each image is used to scale the keypoints back \n",
    "               to their pixel coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - kp_abs_arr: Array of denormalized keypoints where each entry corresponds to the denormalized \n",
    "                  keypoints for the corresponding image in `img_arr`.\n",
    "    \"\"\"\n",
    "\n",
    "    kp_abs_list = []  # List to store the denormalized keypoints for each image\n",
    "\n",
    "    # Iterate through each set of keypoints and corresponding image\n",
    "    for i, kp in enumerate(kp_arr):\n",
    "        img_size = img_arr[i].shape  # Get the size of the current image (height, width, channels)\n",
    "\n",
    "        # Denormalize the keypoints based on the image size\n",
    "        kp_abs, missing_kp = unnorm_keypoints(img_size, kp_arr[i])\n",
    "\n",
    "        # Save the denormalized keypoints to the list\n",
    "        kp_abs_list.append(kp_abs)\n",
    "    \n",
    "    # Convert the list of denormalized keypoints to a NumPy array\n",
    "    kp_abs_arr = np.array(kp_abs_list)\n",
    "\n",
    "    return kp_abs_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize keypoints for an array of images\n",
    "def norm_keypoints_arr(kp_arr, img_arr):\n",
    "    \"\"\"\n",
    "    Normalizes keypoints for each image in the array based on the corresponding image size.\n",
    "    It converts keypoints from pixel coordinates back to normalized coordinates (range [-1, 1]).\n",
    "\n",
    "    Parameters:\n",
    "    - kp_arr: Array of keypoints, where each entry is a list of keypoints for an image.\n",
    "              The keypoints are expected to be in the format [x1, y1, x2, y2, ...] \n",
    "              with pixel coordinates.\n",
    "    - img_arr: Array of images. The size of each image is used to scale the keypoints \n",
    "               to normalized coordinates.\n",
    "\n",
    "    Returns:\n",
    "    - kp_norm_arr: Array of normalized keypoints where each entry corresponds to the normalized \n",
    "                   keypoints for the corresponding image in `img_arr`.\n",
    "    \"\"\"\n",
    "        \n",
    "    kp_norm_list = []  # List to store the normalized keypoints for each image\n",
    "\n",
    "    # Iterate through each set of keypoints and corresponding image\n",
    "    for i, kp in enumerate(kp_arr):\n",
    "        img_size = img_arr[i].shape  # Get the size of the current image (height, width, channels)\n",
    "\n",
    "        # Normalize the keypoints based on the image size\n",
    "        kp_norm = norm_keypoints(img_size, kp_arr[i])\n",
    "\n",
    "        # Save the normalized keypoints to the list\n",
    "        kp_norm_list.append(kp_norm)\n",
    "    \n",
    "    # Convert the list of normalized keypoints to a NumPy array\n",
    "    kp_norm_arr = np.array(kp_norm_list)  \n",
    "\n",
    "    return kp_norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation to images and keypoints\n",
    "def apply_aug(img_arr_orig, kp_arr_orig, aug, num_of_kp=8):\n",
    "    \"\"\"\n",
    "    Applies augmentation to a batch of images and their corresponding keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    - img_arr_orig: Original array of images. Shape should be (num_imgs, height, width, channels).\n",
    "    - kp_arr_orig: Original array of keypoints. Shape should be (num_imgs, num_of_kp*2), where each \n",
    "                   keypoint is represented by its x and y coordinates in pixel values.\n",
    "    - aug: An imgaug augmentation sequence or augmenter to apply to the images and keypoints.\n",
    "    - num_of_kp: Optional. Number of keypoints per image (default is 8).\n",
    "\n",
    "    Returns:\n",
    "    - img_arr_aug: Augmented array of images. Same shape as `img_arr_orig`.\n",
    "    - kp_arr_aug: Augmented array of keypoints. Same shape as `kp_arr_orig`.\n",
    "    \"\"\"\n",
    "    # print(img_arr_orig.shape)\n",
    "    #print(kp_arr_orig.shape)\n",
    "    \n",
    "    # Initialize lists to store augmented images and keypoints\n",
    "    aug_img = []  # List for augmented images\n",
    "    aug_kp = []   # List for augmented keypoints\n",
    "\n",
    "    # Get the number of images in the batch\n",
    "    num_imgs = img_arr_orig.shape[0]\n",
    "    #print(num_imgs)\n",
    "\n",
    "    # Loop over each image and its corresponding keypoints\n",
    "    for i in range(num_imgs):\n",
    "        image = img_arr_orig[i]  # Extract the i-th image\n",
    "        #print(image.shape)\n",
    "        \n",
    "        # Convert keypoints to KeypointsOnImage format for imgaug\n",
    "        keypoints = kp_arr_orig[i]\n",
    "        #print(keypoints)\n",
    "        kps = [Keypoint(x=keypoints[j*2], y=keypoints[j*2+1]) for j in range(num_of_kp)]\n",
    "        kps_on_image = KeypointsOnImage(kps, shape=image.shape)\n",
    "        \n",
    "        # Apply the augmentation to the image and keypoints\n",
    "        image_aug, kps_aug = aug(image=image, keypoints=kps_on_image)\n",
    "        \n",
    "        # Convert augmented keypoints back to the original flattened format [x1, y1, x2, y2, ...]\n",
    "        keypoints_aug = []\n",
    "        for kp in kps_aug.keypoints:\n",
    "            keypoints_aug.extend([kp.x, kp.y])\n",
    "        \n",
    "        # Append the augmented image and keypoints to their respective lists\n",
    "        aug_img.append(image_aug)\n",
    "        aug_kp.append(keypoints_aug)\n",
    "\n",
    "    # Convert the lists of augmented images and keypoints back to NumPy arrays\n",
    "    img_arr_aug = np.array(aug_img)\n",
    "    kp_arr_aug = np.array(aug_kp)\n",
    "\n",
    "    return img_arr_aug, kp_arr_aug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.51.1. Apply a lrflip to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify augmentation\n",
    "seq_lrflip = iaa.Sequential([\n",
    "    iaa.Fliplr(1.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply augmentation\n",
    "\n",
    "# unnorm kp\n",
    "train_kp_array_abs = unnorm_keypoints_arr(train_kp_array, train_imgs_array)\n",
    "\n",
    "# apply augmentation\n",
    "train_imgs_array_aug_lrflip, train_kp_array_aug_lrflip_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_lrflip)\n",
    "\n",
    "# norm the aug kp\n",
    "train_kp_array_aug_lrflip_norm = norm_keypoints_arr(train_kp_array_aug_lrflip_abs, train_imgs_array_aug_lrflip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check lrflip\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array_aug_lrflip[150], train_kp_array_aug_lrflip_abs[150], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check original\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array[150], train_kp_array_abs[150], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.51.2. Apply a random rotation (5:20 deg) clockwise and anticlockwise(-20:-5 deg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify augmentation\n",
    "seq_rotate_clock = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(5, 20)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply augmentation\n",
    "\n",
    "# unnorm kp\n",
    "train_kp_array_abs = unnorm_keypoints_arr(train_kp_array, train_imgs_array)\n",
    "\n",
    "# apply augmentation\n",
    "train_imgs_array_aug_rclock, train_kp_array_aug_rclock_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_rotate_clock)\n",
    "\n",
    "# norm the aug kp\n",
    "train_kp_array_aug_rclock_norm = norm_keypoints_arr(train_kp_array_aug_rclock_abs, train_imgs_array_aug_rclock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rclock\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array_aug_rclock[300], train_kp_array_aug_rclock_abs[300], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check original\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array[300], train_kp_array_abs[300], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify augmentation\n",
    "seq_rotate_anticlock = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-20, -5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply augmentation\n",
    "\n",
    "# unnorm kp\n",
    "train_kp_array_abs = unnorm_keypoints_arr(train_kp_array, train_imgs_array)\n",
    "\n",
    "# apply augmentation\n",
    "train_imgs_array_aug_ranticlock, train_kp_array_aug_ranticlock_abs = apply_aug(train_imgs_array, train_kp_array_abs, seq_rotate_anticlock)\n",
    "\n",
    "# norm the aug kp\n",
    "train_kp_array_aug_ranticlock_norm = norm_keypoints_arr(train_kp_array_aug_ranticlock_abs, train_imgs_array_aug_ranticlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rclock\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array_aug_ranticlock[300], train_kp_array_aug_ranticlock_abs[300], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check original\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array[300], train_kp_array_abs[300], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.51.3. Apply a translation either up and down or left and right by the amount of padding in img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD FUNCTION\n",
    "# def detect_padding(image):\n",
    "#     \"\"\"\n",
    "#     Detects if padding is on the x-axis (left and right) or y-axis (top and bottom) \n",
    "#     of the image and calculates the padding size on one side.\n",
    "\n",
    "#     Parameters:\n",
    "#     - image: A NumPy array representing the image. The shape should be (height, width, channels).\n",
    "\n",
    "#     Returns:\n",
    "#     - is_padding_x: True if padding is on the x-axis, False if padding is on the y-axis.\n",
    "#     - padding_size: The size of the padding on one side in pixels.\n",
    "#     \"\"\"\n",
    "\n",
    "#     height, width, _ = image.shape\n",
    "    \n",
    "#     # Check for padding along the x-axis (left and right)\n",
    "#     left_column = image[:, 0, :]  # The first column (left side)\n",
    "#     right_column = image[:, -1, :]  # The last column (right side)\n",
    "#     # Check for padding along the x-axis (left and right)\n",
    "#     top_row = image[0, :, :]  # The first column (left side)\n",
    "#     bottom_row = image[-1, :, :]  # The last column (right side)\n",
    "#     print(left_column)\n",
    "#     #print(right_column)\n",
    "    \n",
    "#     # Check if the columns are fully black (indicating padding)\n",
    "#     if np.all(left_column < 1) and np.all(right_column < 1):\n",
    "#         # Padding is along the x-axis\n",
    "#         is_padding_x = True\n",
    "#         # Calculate padding size\n",
    "#         print(image[:, 30, 0]*255)\n",
    "#         plot_img(image)\n",
    "#         padding_size = np.sum(image[:, 0, 0] < 1) // 2  # Count black pixels on one side\n",
    "#     else:\n",
    "#         #plot_img(image)\n",
    "#         # Padding is along the y-axis (top and bottom)\n",
    "#         is_padding_x = False\n",
    "#         # Calculate padding size\n",
    "#         padding_size = np.sum(image[0, :, 0] < 1) // 2  # Count black pixels on one side\n",
    "#         #print(padding_size)\n",
    "\n",
    "#     return is_padding_x, padding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_padding(image):\n",
    "    \"\"\"\n",
    "    Detects if padding is on the x-axis (left and right) or y-axis (top and bottom)\n",
    "    of the image and calculates the padding size on one side.\n",
    "\n",
    "    Parameters:\n",
    "    - image: A NumPy array representing the image. The shape should be (width, height, channels).\n",
    "\n",
    "    Returns:\n",
    "    - is_padding_x: True if padding is on the x-axis, False if padding is on the y-axis.\n",
    "    - padding_size: The size of the padding on one side in pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    width, height, _ = image.shape\n",
    "    \n",
    "    # Check for padding along the x-axis (left and right)\n",
    "    left_column = image[:, 0, :]#image[0, :, :]  # The first column (left side)\n",
    "    right_column = image[:, -1, :] #image[-1, :, :]  # The last column (right side)\n",
    "\n",
    "    # Check for padding along the y-axis (top and bottom)\n",
    "    top_row = image[:, 0, :]  # The first row (top side)\n",
    "    bottom_row = image[:, -1, :]  # The last row (bottom side)\n",
    "    #print(image[:, 5, :] *255)\n",
    "    #print(left_column*255)\n",
    "    \n",
    "    # Check if the columns are fully black (indicating padding)\n",
    "    if np.all(left_column*255 < 30) and np.all(right_column*255 < 30):\n",
    "        # Padding is along the x-axis\n",
    "        is_padding_x = True\n",
    "        #plot_img(image)\n",
    "        # Calculate padding size\n",
    "        #padding_size = np.sum(image[0, :, 0]*255 < 30) // 2  # Count black pixels on one side\n",
    "        # if padding_size > 60:\n",
    "        sum1 = np.sum(image[5, :, 0]*255 < 20) // 2\n",
    "        sum2 = np.sum(image[10, :, 0]*255 < 20) // 2\n",
    "        sum3 = np.sum(image[60, :, 0]*255 < 20) // 2\n",
    "        sum4 = np.sum(image[110, :, 0]*255 < 20) // 2\n",
    "        sum5 = np.sum(image[-60, :, 0]*255 < 20) // 2\n",
    "        sum6 = np.sum(image[-10, :, 0]*255 < 20) // 2\n",
    "        sum7 = np.sum(image[-5, :, 0]*255 < 20) // 2\n",
    "        padding_size = min(sum1, sum2, sum3, sum4, sum5, sum6, sum7)\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        # if padding_size > 60:\n",
    "        #     sum1 = np.sum(image[5, :, 0]*255 < 10) // 2\n",
    "        #     sum2 = np.sum(image[10, :, 0]*255 < 10) // 2\n",
    "        #     sum3 = np.sum(image[60, :, 0]*255 < 10) // 2\n",
    "        #     sum4 = np.sum(image[110, :, 0]*255 < 10) // 2\n",
    "        #     sum5 = np.sum(image[-60, :, 0]*255 < 10) // 2\n",
    "        #     sum6 = np.sum(image[-10, :, 0]*255 < 10) // 2\n",
    "        #     sum7 = np.sum(image[-5, :, 0]*255 < 10) // 2\n",
    "        #     average = (sum1 + sum2 + sum3 + sum4 + sum5 + sum6 + sum7) // 7  # Floor division for rounding down\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        if padding_size > 20: \n",
    "            padding_size = 20\n",
    "\n",
    "    else:\n",
    "        # Padding is along the y-axis (top and bottom)\n",
    "        is_padding_x = False\n",
    "        # Calculate padding size\n",
    "        padding_size = np.sum(image[:, 0, 0]*255 < 30) // 2  # Count black pixels on one side\n",
    "        # if padding_size > 60:\n",
    "        sum1 = np.sum(image[:, 5, 0]*255 < 20) // 2\n",
    "        sum2 = np.sum(image[:, 10, 0]*255 < 20) // 2\n",
    "        sum3 = np.sum(image[:, 60, 0]*255 < 20) // 2\n",
    "        sum4 = np.sum(image[:, 110, 0]*255 < 20) // 2\n",
    "        sum5 = np.sum(image[:, -60, 0]*255 < 20) // 2\n",
    "        sum6 = np.sum(image[:, -10, 0]*255 < 20) // 2\n",
    "        sum7 = np.sum(image[:, -5, 0]*255 < 20) // 2\n",
    "        padding_size = min(sum1, sum2, sum3, sum4, sum5, sum6, sum7)\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        # if padding_size > 60:\n",
    "        #     sum1 = np.sum(image[:, 5, 0]*255 < 10) // 2\n",
    "        #     sum2 = np.sum(image[:, 10, 0]*255 < 10) // 2\n",
    "        #     sum3 = np.sum(image[:, 60, 0]*255 < 10) // 2\n",
    "        #     sum4 = np.sum(image[:, 110, 0]*255 < 10) // 2\n",
    "        #     sum5 = np.sum(image[:, -60, 0]*255 < 10) // 2\n",
    "        #     sum6 = np.sum(image[:, -10, 0]*255 < 10) // 2\n",
    "        #     sum7 = np.sum(image[:, -5, 0]*255 < 10) // 2\n",
    "        #     average = (sum1 + sum2 + sum3 + sum4 + sum5 + sum6 + sum7) // 7  # Floor division for rounding down\n",
    "        #     padding_size = max(average - 5, 1)\n",
    "        if padding_size > 20: \n",
    "            padding_size = 20\n",
    "\n",
    "    return is_padding_x, padding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_arr = train_imgs_array[0:2]\n",
    "# test_img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_kp_arr = train_kp_array[0:2]\n",
    "# test_kp_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnorm kp\n",
    "train_kp_array_abs = unnorm_keypoints_arr(train_kp_array, train_imgs_array)\n",
    "# print(train_kp_array_abs)\n",
    "# apply augmentation\n",
    "\n",
    "# Get the number of images in the batch\n",
    "num_imgs = train_imgs_array.shape[0]\n",
    "# print(num_imgs)\n",
    "\n",
    "# creat empty arrays\n",
    "train_imgs_array_aug_trans = np.empty((0, train_imgs_array.shape[1], train_imgs_array.shape[2], train_imgs_array.shape[3]), dtype=train_imgs_array.dtype)\n",
    "train_kp_array_aug_trans = np.empty((0, train_kp_array_abs.shape[1]), dtype=train_kp_array_abs.dtype)\n",
    "\n",
    "# print(train_imgs_array_aug_trans.shape)\n",
    "# print(train_kp_array_aug_trans.shape)\n",
    "\n",
    "# Loop over each image and its corresponding keypoints\n",
    "for i in range(num_imgs):\n",
    "    image = train_imgs_array[i]  # Extract the i-th image\n",
    "    kp = train_kp_array_abs[i]\n",
    "    # print(i)\n",
    "    # print(image.shape)\n",
    "    # print(kp.shape)\n",
    "\n",
    "    is_padding_x, padding_size = detect_padding(image)\n",
    "    print(f'this: {i}')\n",
    "    print(is_padding_x)\n",
    "    print(padding_size)\n",
    "\n",
    "    if is_padding_x:\n",
    "        seq_trans_x_left = iaa.Sequential([\n",
    "            iaa.TranslateX(px=(-padding_size, -padding_size)),\n",
    "        ])\n",
    "        seq_trans_x_right = iaa.Sequential([\n",
    "            iaa.TranslateX(px=(padding_size, padding_size)),\n",
    "        ])\n",
    "\n",
    "        # Convert to shape (1, 220, 220, 3) and (1, 16)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #print(is_padding_x)\n",
    "        #print(image.shape)\n",
    "        #print(i)\n",
    "        kp = np.expand_dims(kp, axis=0)\n",
    "\n",
    "        # apply augmentations\n",
    "        single_trans_x_left_img_arr, single_trans_x_left_kp_arr = apply_aug(image, kp, seq_trans_x_left)\n",
    "        single_trans_x_right_img_arr, single_trans_x_right_kp_arr = apply_aug(image, kp, seq_trans_x_right)\n",
    "\n",
    "        #save to image array\n",
    "        train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_x_left_img_arr), axis=0)\n",
    "        train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_x_right_img_arr), axis=0)\n",
    "        #save to kp array\n",
    "        train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_x_left_kp_arr), axis=0)\n",
    "        train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_x_right_kp_arr), axis=0)\n",
    "\n",
    "    else :\n",
    "        seq_trans_y_up = iaa.Sequential([\n",
    "            iaa.TranslateY(px=(-padding_size, -padding_size)),\n",
    "        ])\n",
    "        seq_trans_y_down = iaa.Sequential([\n",
    "            iaa.TranslateY(px=(padding_size, padding_size)),\n",
    "        ])\n",
    "\n",
    "        # Convert to shape (1, 220, 220, 3) and (1, 16)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #print(is_padding_x)\n",
    "        #print(image.shape)\n",
    "        #print(i)\n",
    "        kp = np.expand_dims(kp, axis=0)\n",
    "\n",
    "        # apply augmentations\n",
    "        single_trans_y_up_img_arr, single_trans_y_up_kp_arr = apply_aug(image, kp, seq_trans_y_up)\n",
    "        single_trans_y_down_img_arr, single_trans_y_down_kp_arr = apply_aug(image, kp, seq_trans_y_down)\n",
    "\n",
    "        #save to image array\n",
    "        train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_y_up_img_arr), axis=0)\n",
    "        train_imgs_array_aug_trans = np.concatenate((train_imgs_array_aug_trans, single_trans_y_down_img_arr), axis=0)\n",
    "        #save to kp array\n",
    "        train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_y_up_kp_arr), axis=0)\n",
    "        train_kp_array_aug_trans = np.concatenate((train_kp_array_aug_trans, single_trans_y_down_kp_arr), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_check = 231\n",
    "\n",
    "# print(train_imgs_array[image_check,:, -1, :]*255)\n",
    "# print(train_imgs_array[image_check,0, :, :]*255)\n",
    "# print(np.sum(train_imgs_array[image_check, :, 0, 0]*255 < 30))\n",
    "# print(np.sum(train_imgs_array[image_check, :, 0, 0]*255 < 30)//2)\n",
    "# plot_img(train_imgs_array[image_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_imgs_array_aug_trans.shape)\n",
    "print(train_kp_array_aug_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm the aug kp\n",
    "train_kp_array_aug_trans_norm = norm_keypoints_arr(train_kp_array_aug_trans, train_imgs_array_aug_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trans\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array_aug_trans[561], train_kp_array_aug_trans[561], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trans\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array_aug_trans[560], train_kp_array_aug_trans[560], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check original\n",
    "labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "plot_img_and_keypoint(train_imgs_array[280], train_kp_array_abs[280], nkeypoints=8, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.51.4 Combine the simple augmentation datasets with the original dataset to create simple_aug_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat empty arrays\n",
    "#train_imgs_array_aug_simple = np.empty((0, train_imgs_array.shape[1], train_imgs_array.shape[2], train_imgs_array.shape[3]), dtype=train_imgs_array.dtype)\n",
    "#train_kp_array_aug_simple = np.empty((0, train_kp_array_abs.shape[1]), dtype=train_kp_array_abs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine arrays\n",
    "#save to image array\n",
    "train_imgs_array_aug_simple = np.concatenate((train_imgs_array, train_imgs_array_aug_lrflip), axis=0)\n",
    "train_imgs_array_aug_simple = np.concatenate((train_imgs_array_aug_simple, train_imgs_array_aug_rclock), axis=0)\n",
    "train_imgs_array_aug_simple = np.concatenate((train_imgs_array_aug_simple, train_imgs_array_aug_ranticlock), axis=0)\n",
    "train_imgs_array_aug_simple = np.concatenate((train_imgs_array_aug_simple, train_imgs_array_aug_trans), axis=0)\n",
    "#save to kp array\n",
    "train_kp_array_aug_simple = np.concatenate((train_kp_array, train_kp_array_aug_lrflip_norm), axis=0)\n",
    "train_kp_array_aug_simple = np.concatenate((train_kp_array_aug_simple, train_kp_array_aug_rclock_norm), axis=0)\n",
    "train_kp_array_aug_simple = np.concatenate((train_kp_array_aug_simple, train_kp_array_aug_ranticlock_norm), axis=0)\n",
    "train_kp_array_aug_simple = np.concatenate((train_kp_array_aug_simple, train_kp_array_aug_trans_norm), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_imgs_array_aug_simple.shape)\n",
    "print(train_kp_array_aug_simple.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.51.5. Ensure that all kp are within the image frame and shift them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_out_of_img_kp_rows(arr):\n",
    "    \"\"\"\n",
    "    Finds the number and positions of rows that contain numbers lower than -0.5 but not -10 and greater than 0.5\n",
    "    THese are keypoints that are outside the frame but not the missing ones.\n",
    "\n",
    "    Parameters:\n",
    "    - arr: A NumPy array of shape (n, 16).\n",
    "\n",
    "    Returns:\n",
    "    - count_neg_rows: The number of rows that contain negative numbers.\n",
    "    - neg_row_indices: A list of indices of rows that contain negative numbers.\n",
    "    \"\"\"\n",
    "    # Check which rows contain negative numbers\n",
    "    neg_row_mask = np.any(((arr < -0.5) & (arr > -9.0)) | (arr > 0.5), axis=1)\n",
    "    \n",
    "    # Get the indices of rows that contain negative numbers\n",
    "    neg_row_indices = np.where(neg_row_mask)[0]\n",
    "    \n",
    "    # Count the number of rows with negative numbers\n",
    "    count_neg_rows = len(neg_row_indices)\n",
    "    \n",
    "    return count_neg_rows, neg_row_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = set(type(element) for element in train_kp_array_aug_simple.flatten())\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datatypes\n",
    "train_kp_array_aug_simple.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all the kp are within the image\n",
    "print(find_out_of_img_kp_rows(train_kp_array_aug_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_out_of_img_kp(arr):\n",
    "    \"\"\"\n",
    "    Finds and replaces the elements in the array that are outside the frame but not the missing ones.\n",
    "    Specifically, elements greater than 0.5 are replaced with 0.5, and elements less than -0.5 but \n",
    "    greater than -9.0 are replaced with -0.5.\n",
    "\n",
    "    Parameters:\n",
    "    - arr: A NumPy array of shape (n, 16).\n",
    "\n",
    "    Returns:\n",
    "    - modified_arr: The modified NumPy array with replaced values.\n",
    "    - count_replacements: The number of elements that were replaced.\n",
    "    \"\"\"\n",
    "    # Make a copy of the array to avoid modifying the original array\n",
    "    modified_arr = arr.copy()\n",
    "\n",
    "    # Replace elements greater than 0.5 with 0.5\n",
    "    count_pos_replacements = np.sum(modified_arr > 0.5)\n",
    "    modified_arr[modified_arr > 0.5] = 0.49\n",
    "\n",
    "    # Replace elements less than -0.5 but greater than -9.0 with -0.5\n",
    "    count_neg_replacements = np.sum((modified_arr < -0.5) & (modified_arr > -9.0))\n",
    "    modified_arr[(modified_arr < -0.5) & (modified_arr > -9.0)] = -0.49\n",
    "\n",
    "    # Total count of replacements\n",
    "    count_replacements = count_pos_replacements + count_neg_replacements\n",
    "\n",
    "    return modified_arr, count_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kp_array_aug_simple, num_replacements = replace_out_of_img_kp(train_kp_array_aug_simple)\n",
    "print(num_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_out_of_img_kp_rows(train_kp_array_aug_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(img):\n",
    "  fig = plt.figure(figsize=(8, 25), dpi=100)\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_and_keypoint(img, keypoints, nkeypoints, keypoint_labels):\n",
    "  fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "  plt.imshow(img)\n",
    "  x_keypoints = keypoints[::2]\n",
    "  y_keypoints = keypoints[1::2]\n",
    "  plt.scatter(x_keypoints, y_keypoints, marker='.', c=np.arange(nkeypoints), cmap='jet')\n",
    "\n",
    "    # If labels are provided, add them to the plot\n",
    "  if keypoint_labels is not None:\n",
    "      for i, (x, y) in enumerate(zip(x_keypoints, y_keypoints)):\n",
    "          plt.text(x, y, keypoint_labels[i], fontsize=12, color='white', \n",
    "                    bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unnorm_keypoints(img_size, keypoints, kp_to_null=None):\n",
    "\n",
    "#   readjust_x = img_size[0]\n",
    "#   readjust_y = img_size[1]\n",
    "#   #print(readjust_x)\n",
    "#   #print(readjust_y)\n",
    "#   new_keypoints = []\n",
    "#   missing_kp = []\n",
    "\n",
    "#   for i, keypoint in enumerate(keypoints):\n",
    "#     # Null keypoints at specified indices\n",
    "#     #print(kp_to_null)\n",
    "#     if keypoint == -10 or (kp_to_null and i in kp_to_null):\n",
    "#       keypoint = np.nan\n",
    "#       #print(missing_kp)\n",
    "#       missing_kp.append(i)\n",
    "\n",
    "#     if i % 2 == 0:\n",
    "#       keypoint = keypoint * readjust_x + readjust_x/2\n",
    "#       #print(i, keypoint, 'x')\n",
    "#     else:\n",
    "#       keypoint = keypoint * readjust_y + readjust_y/2\n",
    "#       #print(i, keypoint, 'y')\n",
    "#     #print(keypoint)\n",
    "#     new_keypoints.append(keypoint)\n",
    "#   #print(new_keypoints)\n",
    "#   return new_keypoints, missing_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img = 259\n",
    "chosen_img = train_imgs_array[display_img]\n",
    "chosen_img_size = chosen_img.shape\n",
    "print(chosen_img_size)\n",
    "#print(original_img_shape)\n",
    "chosen_img_keypoints = train_kp_array[display_img]\n",
    "nkeypoints = 8\n",
    "keypoint_labels = kp_cols[::2]\n",
    "\n",
    "display_keypoints, missing_kp = unnorm_keypoints(chosen_img_size, chosen_img_keypoints)\n",
    "\n",
    "plot_img_and_keypoint(chosen_img, display_keypoints, 8, keypoint_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_img = 1013\n",
    "chosen_img = train_imgs_array_aug_simple[display_img]\n",
    "chosen_img_size = chosen_img.shape\n",
    "print(chosen_img_size)\n",
    "print(chosen_img_size)\n",
    "#print(original_img_shape)\n",
    "chosen_img_keypoints = train_kp_array_aug_simple_adjust[display_img]\n",
    "nkeypoints = 8\n",
    "keypoint_labels = kp_cols[::2]\n",
    "\n",
    "display_keypoints, missing_kp = unnorm_keypoints(chosen_img_size, chosen_img_keypoints)\n",
    "\n",
    "plot_img_and_keypoint(chosen_img, display_keypoints, 8, keypoint_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1. Define the Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error, ignoring the invisible keypoints.\n",
    "    Assuming that -10.0 indicates an invisible keypoint.\n",
    "    \"\"\"\n",
    "    # Create a mask where keypoints are visible\n",
    "    mask = (y_true != -10.0).float().to(y_true.device)\n",
    "\n",
    "    # Apply the mask to filter out invisible keypoints from both\n",
    "    # the predictions and the true values\n",
    "    y_true_masked = y_true * mask\n",
    "    y_pred_masked = y_pred * mask\n",
    "\n",
    "    # Compute the Mean Squared Error only on the visible keypoints\n",
    "    mse = F.mse_loss(y_pred_masked, y_true_masked, reduction='sum') / mask.sum()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL IMPLEMENTATION OF THE ABOVE\n",
    "# def masked_rmse_loss(y_true, y_pred):\n",
    "#     \"\"\"\n",
    "#     Computes the Root Mean Square Error (RMSE) loss, ignoring the invisible keypoints (denoted by -10).\n",
    "    \n",
    "#     Parameters:\n",
    "#     y_true (torch.Tensor): The ground truth keypoints (batch_size, num_keypoints*2).\n",
    "#     y_pred (torch.Tensor): The predicted keypoints (batch_size, num_keypoints*2).\n",
    "\n",
    "#     Returns:\n",
    "#     torch.Tensor: The computed RMSE loss.\n",
    "#     \"\"\"\n",
    "#     # Create a mask where keypoints are visible (not equal to -10)\n",
    "#     mask = (y_true != -10.0).float()\n",
    "\n",
    "#     # Apply the mask to filter out invisible keypoints\n",
    "#     y_true_masked = y_true * mask\n",
    "#     y_pred_masked = y_pred * mask\n",
    "\n",
    "#     # Compute the squared differences\n",
    "#     squared_diff = (y_pred_masked - y_true_masked) ** 2\n",
    "\n",
    "#     # Compute the mean of squared differences for visible keypoints\n",
    "#     loss = torch.sum(squared_diff) / torch.sum(mask)\n",
    "\n",
    "#     # Return the square root of the loss to get RMSE\n",
    "#     return torch.sqrt(loss)\n",
    "\n",
    "# # Example usage:\n",
    "# # Assume y_true and y_pred are your ground truth and predicted keypoints, respectively.\n",
    "# # y_true = torch.tensor([...])\n",
    "# # y_pred = torch.tensor([...])\n",
    "# # loss = masked_rmse_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.2. Define the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCK\n",
    "# put in a function that will use the max bbox if primary kp is missing\n",
    "def pck_metric(y_true, y_pred, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Computes the Percentage of Correct Keypoints (PCK) metric.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (torch.Tensor): The ground truth keypoints (batch_size, num_keypoints*2).\n",
    "    y_pred (torch.Tensor): The predicted keypoints (batch_size, num_keypoints*2).\n",
    "    threshold (float): The distance threshold for a keypoint to be considered correct.\n",
    "                       Typically set relative to the size of the bounding box (e.g., 0.2).\n",
    "    \n",
    "    Returns:\n",
    "    float: The percentage of correct keypoints.\n",
    "    \"\"\"\n",
    "    # Create a mask where keypoints are visible (not equal to -10)\n",
    "    mask = (y_true != -10.0).float().to(y_true.device)\n",
    "    #print(mask)\n",
    "\n",
    "    # Apply the mask to filter out invisible keypoints\n",
    "    y_true_masked = y_true * mask\n",
    "    y_pred_masked = y_pred * mask\n",
    "\n",
    "    # print(y_true_masked)\n",
    "    # print(y_pred_masked)\n",
    "\n",
    "    # Compute the Euclidean distance between the predicted and true keypoints\n",
    "    distances = torch.sqrt((y_pred_masked[:, ::2] - y_true_masked[:, ::2]) ** 2 +\n",
    "                           (y_pred_masked[:, 1::2] - y_true_masked[:, 1::2]) ** 2)\n",
    "    \n",
    "    #print(distances)\n",
    "    \n",
    "    # Normalize the distances (relative to the max and min y coord)\n",
    "    Norm_max_min_kp = torch.max(y_true_masked[:, 1::2], dim=1)[0] - torch.min(y_true_masked[:, 1::2], dim=1)[0]\n",
    "    # Normalise based on the distance between the head and the bottom of the body (position 0, 1 and )\n",
    "    #print(y_true[:, 0],y_true[:,10],y_true[:, 1],y_true[:, 11])\n",
    "    #print((y_true[:, 0] - y_true[:,10]) ** 2)\n",
    "    #print((y_true[:, 1] - y_true[:, 11]) ** 2)\n",
    "    Norm_head_lowerbody = torch.sqrt((y_true[:, 0] - y_true[:,10]) ** 2 +\n",
    "                        (y_true[:, 1] - y_true[:, 11]) ** 2)\n",
    "    #print(Norm_head_lowerbody)\n",
    "    normalized_distances = distances / Norm_head_lowerbody[:, None]\n",
    "    #print(distances)\n",
    "    #print(normalized_distances)\n",
    "\n",
    "    # Count the correct keypoints (distance <= threshold)\n",
    "    correct_keypoints = (normalized_distances <= threshold).float() * mask[:, ::2]\n",
    "    #print(correct_keypoints)\n",
    "\n",
    "    # Calculate the PCK as the percentage of correct keypoints\n",
    "    pck = correct_keypoints.sum() / mask[:, ::2].sum()\n",
    "    return pck#.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create two tensors to check pck\n",
    "\n",
    "# # Create two PyTorch tensors with the sizes (1, 16)\n",
    "# # Initialize them with random values between -1 and 1\n",
    "# tensor1_true = torch.rand(1, 16) * 2 - 1\n",
    "# tensor2_pred = tensor1_true.clone()\n",
    "\n",
    "# # creating a tensor with 2 predictions for an image (test that it will work for multiple inputs)\n",
    "# # tensor2_pred = tensor1_true.clone()\n",
    "\n",
    "# # Introduce some differences in tensor2\n",
    "# tensor2_pred[0, :8] += torch.randn(8) * 0.1  # Slightly off for the first element of the first row\n",
    "\n",
    "# tensor2_pred[0, :8] += torch.randn(8) * 0.1  # Slightly off for the first 8 elements of the first row\n",
    "# #tensor2_pred[1, 8:] += torch.randn(8) * 0.1  # Slightly off for the last 8 elements of the second row\n",
    "\n",
    "# # Ensure the values are still within the range [-1, 1]\n",
    "# tensor2_pred = torch.clamp(tensor2_pred, min=-1, max=1)\n",
    "\n",
    "# print(tensor1_true, tensor2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tensor1_true, tensor2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor1_true[0, 5] = -10\n",
    "# tensor1_true[0, 4] = -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pck_metric(tensor1_true, tensor2_pred, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.3. Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First model (not correct sizes)\n",
    "# class DeepPoseModel(nn.Module):\n",
    "#     def __init__(self, nkeypoints=8):\n",
    "#         # Initializes the DeepPoseModel with the dataset and training configuration.\n",
    "#         super(DeepPoseModel, self).__init__()\n",
    "        \n",
    "#         # The feature extractor part of the model, composed of several convolutional layers.\n",
    "#         self.features = nn.Sequential(\n",
    "#             # Conv2d: Input channels = 3 (RGB image), Output channels = 96, kernel size = 11x11,\n",
    "#             # stride = 4, padding = 4. \n",
    "#             # Input: (batch_size, 3, 220, 220)\n",
    "#             # Output: (batch_size, 96, 55, 55)\n",
    "#             nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=4),\n",
    "            \n",
    "#             # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "#             nn.LocalResponseNorm(5),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             # output size: (batch_size, 96, 27, 27)\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             # Conv2d: Input channels = 96, Output channels = 256, kernel size = 5x5,\n",
    "#             # stride = 2, padding = 2.\n",
    "#             # Input: (batch_size, 96, 27, 27)\n",
    "#             # Output: (batch_size, 256, 27, 27)\n",
    "#             nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            \n",
    "#             # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "#             nn.LocalResponseNorm(5),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             # output size: (batch_size, 96, 13, 13)\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             # Conv2d: Input channels = 256, Output channels = 384, kernel size = 3x3,\n",
    "#             # stride = 1, padding = 1.\n",
    "#             # Input: (batch_size, 256, 13, 13)\n",
    "#             # Output: (batch_size, 384, 13, 13)\n",
    "#             nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # Conv2d: Input channels = 384, Output channels = 384, kernel size = 3x3,\n",
    "#             # stride = 1, padding = 1.\n",
    "#             # Input: (batch_size, 384, 13, 13)\n",
    "#             # Output: (batch_size, 384, 13, 13)\n",
    "#             nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # Conv2d: Input channels = 384, Output channels = 256, kernel size = 3x3,\n",
    "#             # stride = 1, padding = 1.\n",
    "#             # Input: (batch_size, 384, 13, 13)\n",
    "#             # Output: (batch_size, 256, 13, 13)\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # MaxPool2d: Kernel size = 3x3, stride = 2.\n",
    "#             # Input: (batch_size, 256, 13, 13)\n",
    "#             # Output: (batch_size, 256, 6, 6)\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#         )\n",
    "        \n",
    "#         # The classifier part of the model, composed of fully connected layers.\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             # Flatten the input tensor\n",
    "#             # Input: (batch_size, 256, 6, 6)\n",
    "#             # Output: (batch_size, 256 * 6 * 6) = (batch_size, 9216)\n",
    "#             nn.Flatten(),\n",
    "            \n",
    "#             # Linear layer with input size 6400 and output size 4096\n",
    "#             # Input: (batch_size, 6400)\n",
    "#             # Output: (batch_size, 4096)\n",
    "#             nn.Linear(256 * 6 * 6, 4096),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # Dropout layer with 60% dropout rate\n",
    "#             nn.Dropout(0.6),\n",
    "            \n",
    "#             # Linear layer with input size 4096 and output size 4096\n",
    "#             # Input: (batch_size, 4096)\n",
    "#             # Output: (batch_size, 4096)\n",
    "#             nn.Linear(4096, 4096),\n",
    "            \n",
    "#             # ReLU activation function applied in place (no extra memory allocation)\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # Dropout layer with 60% dropout rate\n",
    "#             nn.Dropout(0.6),\n",
    "            \n",
    "#             # Final linear layer with input size 4096 and output size nkeypoints * 2\n",
    "#             # Output is (nkeypoints * 2) coordinates (x, y) for each keypoint\n",
    "#             # Input: (batch_size, 4096)\n",
    "#             # Output: (batch_size, nkeypoints * 2)\n",
    "#             nn.Linear(4096, nkeypoints * 2)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Define the forward pass through the network.\n",
    "#         # Pass input `x` through the feature extractor\n",
    "#         x = self.features(x)\n",
    "#         # Pass the result through the classifier to get the final output\n",
    "#         x = self.classifier(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepPoseModel(nn.Module):\n",
    "    def __init__(self, nkeypoints=8):\n",
    "        # Initializes the DeepPoseModel with the dataset and training configuration.\n",
    "        super(DeepPoseModel, self).__init__()\n",
    "        \n",
    "        # The feature extractor part of the model, composed of several convolutional layers.\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv2d: Input channels = 3 (RGB image), Output channels = 48, kernel size = 11x11,\n",
    "            # stride = 4, padding = 4. \n",
    "            # Input: (batch_size, 3, 220, 220)\n",
    "            # Output: (batch_size, 48, 55, 55)\n",
    "            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=4),\n",
    "            \n",
    "            # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "            nn.LocalResponseNorm(5),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            # output size: (batch_size, 96, 27, 27)\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv2d: Input channels = 96, Output channels = 256, kernel size = 5x5,\n",
    "            # stride = 2, padding = 2.\n",
    "            # Input: (batch_size, 48, 27, 27)\n",
    "            # Output: (batch_size, 128, 27, 27)\n",
    "            nn.Conv2d(48, 128, kernel_size=5, stride=1, padding=2),\n",
    "            \n",
    "            # Local Response Normalization (LRN) over 5 neighboring channels\n",
    "            nn.LocalResponseNorm(5),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            # output size: (batch_size, 96, 13, 13)\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            # Conv2d: Input channels = 256, Output channels = 384, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 256, 13, 13)\n",
    "            # Output: (batch_size, 384, 13, 13)\n",
    "            nn.Conv2d(128, 192, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv2d: Input channels = 384, Output channels = 384, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 384, 13, 13)\n",
    "            # Output: (batch_size, 384, 13, 13)\n",
    "            nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv2d: Input channels = 384, Output channels = 256, kernel size = 3x3,\n",
    "            # stride = 1, padding = 1.\n",
    "            # Input: (batch_size, 384, 13, 13)\n",
    "            # Output: (batch_size, 256, 13, 13)\n",
    "            nn.Conv2d(192, 128, kernel_size=3, stride=1, padding=1),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # MaxPool2d: Kernel size = 3x3, stride = 2.\n",
    "            # Input: (batch_size, 256, 13, 13)\n",
    "            # Output: (batch_size, 256, 6, 6)\n",
    "            # Max pooling with 3x3 kernel and stride 2\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        # The classifier part of the model, composed of fully connected layers.\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Flatten the input tensor\n",
    "            # Input: (batch_size, 256, 6, 6)\n",
    "            # Output: (batch_size, 256 * 6 * 6) = (batch_size, 9216)\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # Linear layer with input size 6400 and output size 4096\n",
    "            # Input: (batch_size, 6400)\n",
    "            # Output: (batch_size, 4096)\n",
    "            nn.Linear(128 * 6 * 6, 4096),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Dropout layer with 60% dropout rate\n",
    "            nn.Dropout(0.6),\n",
    "            \n",
    "            # Linear layer with input size 4096 and output size 4096\n",
    "            # Input: (batch_size, 4096)\n",
    "            # Output: (batch_size, 4096)\n",
    "            nn.Linear(4096, 4096),\n",
    "            \n",
    "            # ReLU activation function applied in place (no extra memory allocation)\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Dropout layer with 60% dropout rate\n",
    "            nn.Dropout(0.6),\n",
    "            \n",
    "            # Final linear layer with input size 4096 and output size nkeypoints * 2\n",
    "            # Output is (nkeypoints * 2) coordinates (x, y) for each keypoint\n",
    "            # Input: (batch_size, 4096)\n",
    "            # Output: (batch_size, nkeypoints * 2)\n",
    "            nn.Linear(4096, nkeypoints * 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Define the forward pass through the network.\n",
    "        # Pass input `x` through the feature extractor\n",
    "        x = self.features(x)\n",
    "        # Pass the result through the classifier to get the final output\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepPose Model Summary\n",
    "# model = DeepPoseModel()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)  # Move model to GPU\n",
    "# summary(model, input_size=(3, 220, 220), device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original ALexNet model\n",
    "# class AlexNet(nn.Module):\n",
    "#     def __init__(self, num_classes=1000):\n",
    "#         super(AlexNet, self).__init__()\n",
    "        \n",
    "#         # Define the feature extractor part of the network\n",
    "#         self.features = nn.Sequential(\n",
    "#             # 1st Convolutional Layer: 3 input channels (RGB), 64 output channels, 11x11 kernel size, stride 4, padding 2\n",
    "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             # 2nd Convolutional Layer: 64 input channels, 192 output channels, 5x5 kernel size, stride 1, padding 2\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "#             # 3rd Convolutional Layer: 192 input channels, 384 output channels, 3x3 kernel size, stride 1, padding 1\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # 4th Convolutional Layer: 384 input channels, 256 output channels, 3x3 kernel size, stride 1, padding 1\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            \n",
    "#             # 5th Convolutional Layer: 256 input channels, 256 output channels, 3x3 kernel size, stride 1, padding 1\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             # Max pooling with 3x3 kernel and stride 2\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#         )\n",
    "        \n",
    "#         # Define the classifier part of the network\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             # Flatten the input\n",
    "#             nn.Flatten(),\n",
    "#             # 1st Fully Connected Layer: input size 256 * 6 * 6, output size 4096\n",
    "#             nn.Linear(256 * 6 * 6, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "            \n",
    "#             # 2nd Fully Connected Layer: input size 4096, output size 4096\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.5),\n",
    "            \n",
    "#             # 3rd Fully Connected Layer (output layer): input size 4096, output size num_classes\n",
    "#             nn.Linear(4096, num_classes)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # Pass the input through the feature extractor\n",
    "#         x = self.features(x)\n",
    "#         # Pass the result through the classifier to get the final output\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet Summary\n",
    "# model = AlexNet(num_classes=1000)  # Example model\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)  # Move model to GPU\n",
    "# summary(model, input_size=(3, 224, 224), device=str(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.0 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_PyTorch(img_arr, kp_arr, batch_size, train_flag=True):\n",
    "    '''\n",
    "    Load data into PT dataset and dataLoader in specified batch size\n",
    "    \n",
    "    Params\n",
    "    img_arr: images loaded into an array (i,255,255,3) and are converted to (i,3,255,255)\n",
    "    kp_arr: array of keypoints (i, num_kp*2)\n",
    "    batch_size: batch size \n",
    "\n",
    "    Return:\n",
    "    PT_Dataset: containing input (x) and groundtruth (y)\n",
    "    PT_DataLoader: Dataloader containing dataset and batch size\n",
    "\n",
    "    '''\n",
    "\n",
    "    # create tensors from arrays and load them to the GPU\n",
    "    img_tensor = torch.tensor(img_arr, dtype=torch.float32).permute(0, 3, 1, 2).to('cuda')\n",
    "    kp_tensor = torch.tensor(kp_arr, dtype=torch.float32).to('cuda')\n",
    "\n",
    "    # Create a TensorDataset and DataLoader for training data\n",
    "    dataset = TensorDataset(img_tensor, kp_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=train_flag)\n",
    "\n",
    "    return dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamped_dir(descriptor, base_dir='/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/'):\n",
    "    \"\"\"\n",
    "    Creates a directory with a timestamp appended to the base directory name.\n",
    "    Returns the path to the created directory.\n",
    "    \n",
    "    Parameters:\n",
    "    descriptor: string describing the run generally model_dataDescriptor\n",
    "    base_dir (str): The base directory name. Default is './training_results'.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the created directory.\n",
    "    \"\"\"\n",
    "    # Get the current datetime and format it as YYYY-MM-DD_HH-MM-SS\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    base_dir_descriptor = f\"{base_dir}{descriptor}\"\n",
    "    \n",
    "    # Create the final directory name with the timestamp\n",
    "    final_dir = f\"{base_dir_descriptor}_{timestamp}\"\n",
    "    \n",
    "    # Create the directory\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "    \n",
    "    return final_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_data, val_data, save_dir, data_descriptor='Loss', show_plot=False):\n",
    "    # Plot the loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_data, label=f'Training {data_descriptor}')\n",
    "    plt.plot(val_data, label=f'Validation {data_descriptor}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(f'{data_descriptor}')\n",
    "    plt.title(f'Training and Validation {data_descriptor} Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(save_dir, f'{data_descriptor}_plot.png')\n",
    "    plt.savefig(plot_path)\n",
    "    print(f'{data_descriptor} plot saved to {plot_path}')\n",
    "\n",
    "    # Optionally, display the plot\n",
    "    if show_plot == True:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats_and_models(model, epoch, val_loss, val_pck, save_dir, \n",
    "                     best_val_loss=None, best_val_pck=None, \n",
    "                     final_model=False, train_loss_list=None, val_loss_list=None, train_pck_list=None, val_pck_list=None):\n",
    "    \"\"\"\n",
    "    Saves the best models based on validation loss, PCK value, and final model.\n",
    "    Saves the train and val curves and results for training\n",
    "    \n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The PyTorch model to be saved.\n",
    "    - epoch (int): The current epoch number.\n",
    "    - val_loss (float): The current validation loss.\n",
    "    - val_pck (float): The current validation PCK value.\n",
    "    - save_dir (str): The directory where the models will be saved.\n",
    "    - best_val_loss (float): The best validation loss seen so far.\n",
    "    - best_val_pck (float): The best validation PCK value seen so far.\n",
    "    - final_model (bool): If True, saves the final model after all epochs.\n",
    "    - train_loss_list (list): List of all the loss values from each epoch\n",
    "    \n",
    "    Returns:\n",
    "    - best_val_loss (float): Updated best validation loss.\n",
    "    - best_val_pck (float): Updated best validation PCK value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the current model has the lowest validation loss\n",
    "    if best_val_loss is None or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model_name = f'best_val_loss_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth'\n",
    "        model_save_path_best_val_loss = os.path.join(save_dir, model_name)\n",
    "        torch.save(model.state_dict(), model_save_path_best_val_loss)\n",
    "        print(f'New best model saved with lowest validation loss to {model_save_path_best_val_loss}')\n",
    "    \n",
    "    # Check if the current model has the highest validation PCK\n",
    "    if best_val_pck is None or val_pck > best_val_pck:\n",
    "        best_val_pck = val_pck\n",
    "        model_save_path_best_val_pck = os.path.join(save_dir, f'best_val_pck_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth')\n",
    "        torch.save(model.state_dict(), model_save_path_best_val_pck)\n",
    "        print(f'New best model saved with highest validation PCK to {model_save_path_best_val_pck}')\n",
    "    \n",
    "    # Save the final model and perform final stats evaluation and save\n",
    "    if final_model:\n",
    "        final_model_path = os.path.join(save_dir, f'final_model_epoch_{epoch}_PCK_{val_pck:.4f}_loss_{val_loss:.4f}.pth')\n",
    "        torch.save(model.state_dict(), final_model_path)\n",
    "        print(f'Final model saved to {final_model_path}')\n",
    "        plot_training_curves(train_loss_list, val_loss_list, save_dir, 'Loss', show_plot=True)\n",
    "        plot_training_curves(train_pck_list, val_pck_list, save_dir, data_descriptor='PCK@0.1', show_plot=True)\n",
    "    \n",
    "    return best_val_loss, best_val_pck, model_save_path_best_val_loss, model_save_path_best_val_pck, final_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# this is where the training loop will go \n",
    "def train_loop(model, optimizer, train_dataloader, val_dataloader, num_epochs, descriptor):\n",
    "    # Create the directory to save the results to\n",
    "    save_dir = create_timestamped_dir(descriptor)\n",
    "\n",
    "    # Assuming the model, loss function, and optimizer are already defined\n",
    "    #model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "\n",
    "    # Define your optimizer\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    # Load data into PT dataset and dataloader\n",
    "    #train_dataset, train_dataloader = load_data_PyTorch(train_imgs_array, train_kp_array, 8)\n",
    "    #val_dataset, val_dataloader = load_data_PyTorch(val_imgs_array, val_kp_array, 8, train_flag=False)\n",
    "\n",
    "    # Training loop (variables)\n",
    "    #num_epochs = 30  # Adjust the number of epochs as needed\n",
    "\n",
    "    # Lists to store the training and validation loss for each epoch\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_pck_list = []\n",
    "    val_pck_list = []\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_val_pck = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        running_pck_005 = 0.0\n",
    "        running_pck_01 = 0.0\n",
    "        running_pck_02 = 0.0\n",
    "        running_pck_val_005 = 0.0\n",
    "        running_pck_val_01 = 0.0\n",
    "        running_pck_val_02 = 0.0\n",
    "        \n",
    "        for batch_images, batch_keypoints in train_dataloader:\n",
    "            # Move the data to the GPU\n",
    "            batch_images = batch_images.to('cuda')\n",
    "            batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(batch_images)\n",
    "            # Compute the loss\n",
    "            loss = masked_mse(batch_keypoints, outputs)\n",
    "            #print(loss)\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Accumulate the loss\n",
    "            running_train_loss += loss.item()\n",
    "            #print(running_train_loss)\n",
    "\n",
    "            # compute metrics\n",
    "            #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "            pck_01 = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "            #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "            #running_pck_005 += pck_005.item()\n",
    "            running_pck_01 += pck_01.item()\n",
    "            #running_pck_02 += pck_02.item()\n",
    "\n",
    "                \n",
    "        avg_train_loss = running_train_loss / len(train_dataloader)\n",
    "        #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "        avg_pck_01 = running_pck_01 / len(train_dataloader)\n",
    "        #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "        # populate train losses list for evaluation\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        train_pck_list.append(avg_pck_01)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_keypoints in val_dataloader:\n",
    "                # Move the data to the GPU\n",
    "                batch_images = batch_images.to('cuda')\n",
    "                batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "                outputs = model(batch_images)\n",
    "                loss = masked_mse(batch_keypoints, outputs)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # compute metrics\n",
    "                #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "                pck_01_val = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "                #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "                #running_pck_val_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "                running_pck_val_01 += pck_01_val.item()\n",
    "                #running_pck_val_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(val_dataloader)\n",
    "        #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "        avg_val_pck_01 = running_pck_val_01 / len(val_dataloader)\n",
    "        #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "        # populate val losses list for evaluation\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        val_pck_list.append(avg_val_pck_01)\n",
    "\n",
    "        # save best performing models based on the PCK and loss as well as the stats\n",
    "        best_val_loss, best_val_pck = save_stats_and_models(\n",
    "        model, epoch + 1, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "        best_val_loss, best_val_pck)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Train PCK0.1: {avg_pck_01:.4f}, Val PCK0.1: {avg_val_pck_01:.4f}')\n",
    "        \n",
    "    save_stats_and_models(model, num_epochs, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "                    best_val_loss, best_val_pck, final_model=True, train_loss_list=train_losses, \n",
    "                    val_loss_list=val_losses, train_pck_list=train_pck_list, val_pck_list=val_pck_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# this is where the training loop will go \n",
    "def train_loop_mixed_precision(model, optimizer, train_dataloader, val_dataloader, num_epochs, descriptor):\n",
    "    # Create the directory to save the results to\n",
    "    save_dir = create_timestamped_dir(descriptor)\n",
    "\n",
    "    # Assuming the model, loss function, and optimizer are already defined\n",
    "    #model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "\n",
    "    # Define your optimizer\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    # Load data into PT dataset and dataloader\n",
    "    #train_dataset, train_dataloader = load_data_PyTorch(train_imgs_array, train_kp_array, 8)\n",
    "    #val_dataset, val_dataloader = load_data_PyTorch(val_imgs_array, val_kp_array, 8, train_flag=False)\n",
    "\n",
    "    # Training loop (variables)\n",
    "    #num_epochs = 30  # Adjust the number of epochs as needed\n",
    "\n",
    "    # Lists to store the training and validation loss for each epoch\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_pck_list = []\n",
    "    val_pck_list = []\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_val_pck = None\n",
    "\n",
    "    scaler = GradScaler() \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        running_pck_005 = 0.0\n",
    "        running_pck_01 = 0.0\n",
    "        running_pck_02 = 0.0\n",
    "        running_pck_val_005 = 0.0\n",
    "        running_pck_val_01 = 0.0\n",
    "        running_pck_val_02 = 0.0\n",
    "        \n",
    "        for batch_images, batch_keypoints in train_dataloader:\n",
    "            # Move the data to the GPU\n",
    "            batch_images = batch_images.to('cuda')\n",
    "            batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                # Forward pass\n",
    "                outputs = model(batch_images)\n",
    "                # Compute the loss\n",
    "                loss = masked_mse(batch_keypoints, outputs)\n",
    "                #print(loss)\n",
    "\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update\n",
    "            # Accumulate the loss\n",
    "            running_train_loss += loss.item()\n",
    "            #print(running_train_loss)\n",
    "\n",
    "            # compute metrics\n",
    "            #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "            pck_01 = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "            #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "            #running_pck_005 += pck_005.item()\n",
    "            running_pck_01 += pck_01.item()\n",
    "            #running_pck_02 += pck_02.item()\n",
    "\n",
    "                \n",
    "        avg_train_loss = running_train_loss / len(train_dataloader)\n",
    "        #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "        avg_pck_01 = running_pck_01 / len(train_dataloader)\n",
    "        #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "        # populate train losses list for evaluation\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        train_pck_list.append(avg_pck_01)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_keypoints in val_dataloader:\n",
    "                # Move the data to the GPU\n",
    "                batch_images = batch_images.to('cuda')\n",
    "                batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "                outputs = model(batch_images)\n",
    "                loss = masked_mse(batch_keypoints, outputs)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                # compute metrics\n",
    "                #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "                pck_01_val = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "                #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "                #running_pck_val_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "                running_pck_val_01 += pck_01_val.item()\n",
    "                #running_pck_val_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "        \n",
    "        avg_val_loss = running_val_loss / len(val_dataloader)\n",
    "        #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "        avg_val_pck_01 = running_pck_val_01 / len(val_dataloader)\n",
    "        #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "        # populate val losses list for evaluation\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        val_pck_list.append(avg_val_pck_01)\n",
    "\n",
    "        # save best performing models based on the PCK and loss as well as the stats\n",
    "        best_val_loss, best_val_pck = save_stats_and_models(\n",
    "        model, epoch + 1, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "        best_val_loss, best_val_pck)\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Train PCK0.1: {avg_pck_01:.4f}, Val PCK0.1: {avg_val_pck_01:.4f}')\n",
    "        \n",
    "    save_stats_and_models(model, num_epochs, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "                    best_val_loss, best_val_pck, final_model=True, train_loss_list=train_losses, \n",
    "                    val_loss_list=val_losses, train_pck_list=train_pck_list, val_pck_list=val_pck_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.1. Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the model, loss function, and optimizer are already defined\n",
    "model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Load data into PT dataset and dataloader\n",
    "bacth_size = 2 #batch_size\n",
    "train_dataset, train_dataloader = load_data_PyTorch(train_imgs_array_aug_simple, train_kp_array_aug_simple, bacth_size)\n",
    "val_dataset, val_dataloader = load_data_PyTorch(val_imgs_array, val_kp_array, bacth_size, train_flag=False)\n",
    "\n",
    "# Training loop (variables)\n",
    "num_epochs = 30  # Adjust the number of epochs as needed\n",
    "\n",
    "descriptor = 'DeepPose_Simple_SimpleAug'\n",
    "\n",
    "#train_loop(model, optimizer, train_dataloader, val_dataloader, num_epochs, descriptor)\n",
    "\n",
    "train_loop_mixed_precision(model, optimizer, train_dataloader, val_dataloader, num_epochs, descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop test\n",
    "# Assuming the model, loss function, and optimizer are already defined\n",
    "print('start loop')\n",
    "model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Load data into PT dataset and dataloader\n",
    "batch_size = 32 #batch_size\n",
    "# create tensors from arrays \n",
    "img_tensor = torch.tensor(train_imgs_array_aug_simple, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "kp_tensor = torch.tensor(train_kp_array_aug_simple, dtype=torch.float32)#.to('cuda')\n",
    "\n",
    "# Create a TensorDataset and DataLoader for training data\n",
    "dataset = TensorDataset(img_tensor, kp_tensor)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "img_tensor = torch.tensor(val_imgs_array, dtype=torch.float32).permute(0, 3, 1, 2)#.to('cuda')\n",
    "kp_tensor = torch.tensor(val_kp_array, dtype=torch.float32)#.to('cuda')\n",
    "\n",
    "# Create a TensorDataset and DataLoader for training data\n",
    "dataset = TensorDataset(img_tensor, kp_tensor)\n",
    "val_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#train_dataset, train_dataloader = load_data_PyTorch(train_imgs_array_aug_simple, train_kp_array_aug_simple, bacth_size)\n",
    "#val_dataset, val_dataloader = load_data_PyTorch(val_imgs_array, val_kp_array, bacth_size, train_flag=False)\n",
    "\n",
    "# Training loop (variables)\n",
    "num_epochs = 30  # Adjust the number of epochs as needed\n",
    "\n",
    "descriptor = 'DeepPose_Simple_SimpleAug'\n",
    "\n",
    "#train_loop(model, optimizer, train_dataloader, val_dataloader, num_epochs, descriptor)\n",
    "\n",
    "save_dir = create_timestamped_dir(descriptor)\n",
    "\n",
    "# Assuming the model, loss function, and optimizer are already defined\n",
    "#model = DeepPoseModel(nkeypoints=8).to('cuda')  # Move the model to GPU\n",
    "\n",
    "# Define your optimizer\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Load data into PT dataset and dataloader\n",
    "#train_dataset, train_dataloader = load_data_PyTorch(train_imgs_array, train_kp_array, 8)\n",
    "#val_dataset, val_dataloader = load_data_PyTorch(val_imgs_array, val_kp_array, 8, train_flag=False)\n",
    "\n",
    "# Training loop (variables)\n",
    "#num_epochs = 30  # Adjust the number of epochs as needed\n",
    "\n",
    "# Lists to store the training and validation loss for each epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_pck_list = []\n",
    "val_pck_list = []\n",
    "\n",
    "best_val_loss = None\n",
    "best_val_pck = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    running_pck_005 = 0.0\n",
    "    running_pck_01 = 0.0\n",
    "    running_pck_02 = 0.0\n",
    "    running_pck_val_005 = 0.0\n",
    "    running_pck_val_01 = 0.0\n",
    "    running_pck_val_02 = 0.0\n",
    "    \n",
    "    for batch_images, batch_keypoints in train_dataloader:\n",
    "        #print(batch_images.shape)\n",
    "        # Move the data to the GPU\n",
    "        batch_images = batch_images.to('cuda')\n",
    "        batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(batch_images)\n",
    "        # Compute the loss\n",
    "        loss = masked_mse(batch_keypoints, outputs)\n",
    "        #print(loss)\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Accumulate the loss\n",
    "        running_train_loss += loss.item()\n",
    "        #print(running_train_loss)\n",
    "\n",
    "        # compute metrics\n",
    "        #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "        pck_01 = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "        #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "        #running_pck_005 += pck_005.item()\n",
    "        running_pck_01 += pck_01.item()\n",
    "        #running_pck_02 += pck_02.item()\n",
    "\n",
    "            \n",
    "    avg_train_loss = running_train_loss / len(train_dataloader)\n",
    "    #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "    avg_pck_01 = running_pck_01 / len(train_dataloader)\n",
    "    #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "    # populate train losses list for evaluation\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_pck_list.append(avg_pck_01)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_keypoints in val_dataloader:\n",
    "            # Move the data to the GPU\n",
    "            batch_images = batch_images.to('cuda')\n",
    "            batch_keypoints = batch_keypoints.to('cuda')\n",
    "\n",
    "            outputs = model(batch_images)\n",
    "            loss = masked_mse(batch_keypoints, outputs)\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # compute metrics\n",
    "            #pck_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "            pck_01_val = pck_metric(batch_keypoints, outputs, 0.1)\n",
    "            #pck_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "            #running_pck_val_005 = pck_metric(batch_keypoints, outputs, 0.05)\n",
    "            running_pck_val_01 += pck_01_val.item()\n",
    "            #running_pck_val_02 = pck_metric(batch_keypoints, outputs, 0.2)\n",
    "\n",
    "    \n",
    "    avg_val_loss = running_val_loss / len(val_dataloader)\n",
    "    #avg_pck_005 = running_pck_005 / len(train_dataloader)\n",
    "    avg_val_pck_01 = running_pck_val_01 / len(val_dataloader)\n",
    "    #avg_pck_02 = running_pck_02 / len(train_dataloader)\n",
    "\n",
    "    # populate val losses list for evaluation\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    val_pck_list.append(avg_val_pck_01)\n",
    "\n",
    "    # save best performing models based on the PCK and loss as well as the stats\n",
    "    best_val_loss, best_val_pck = save_stats_and_models(\n",
    "    model, epoch + 1, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "    best_val_loss, best_val_pck)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Train PCK0.1: {avg_pck_01:.4f}, Val PCK0.1: {avg_val_pck_01:.4f}')\n",
    "    \n",
    "save_stats_and_models(model, num_epochs, avg_val_loss, avg_val_pck_01, save_dir, \n",
    "                best_val_loss, best_val_pck, final_model=True, train_loss_list=train_losses, \n",
    "                val_loss_list=val_losses, train_pck_list=train_pck_list, val_pck_list=val_pck_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Evaluating the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, model_class, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads a PyTorch model from a .pth file.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path (str): The path to the .pth model file.\n",
    "    - model_class (torch.nn.Module): The class of the model to instantiate.\n",
    "    - device (str): The device to load the model onto ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - model (torch.nn.Module): The loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    # Instantiate the model class\n",
    "    model = model_class().to(device)\n",
    "    \n",
    "    # Load the state dictionary into the model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, images, img_is_tensor=False, device='cuda'):\n",
    "    \"\"\"\n",
    "    Generates predictions from a PyTorch model given an array of images.\n",
    "\n",
    "    Parameters:\n",
    "    - model (torch.nn.Module): The PyTorch model to use for predictions.\n",
    "    - images (np.array): Array of images (e.g., shape: (num_images, 220, 220, 3)).\n",
    "    - device (str): The device to run the model on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - predictions (np.array): Array of predictions (e.g., keypoints for each image).\n",
    "    \"\"\"\n",
    "    # Convert images to PyTorch tensor and move to the specified device\n",
    "    if not img_is_tensor:\n",
    "        images_tensor = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
    "    \n",
    "    # Forward pass through the model to get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images_tensor)\n",
    "    \n",
    "    # Convert predictions back to a NumPy array and move to CPU if necessary\n",
    "    predictions = predictions.cpu().numpy() if device == 'cuda' else predictions.numpy()\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(img, pred_keypoints, true_keypoints, save_dir, img_num, nkeypoints=8, keypoint_labels=None, connections = [(0, 1), (0, 2), (2, 3), (2, 4), (2, 5), (5, 6), (5, 7)]):\n",
    "    \"\"\"\n",
    "    Plots predicted keypoints vs. ground truth keypoints on the same image.\n",
    "\n",
    "    Parameters:\n",
    "    - img: The image on which to plot the keypoints.\n",
    "    - pred_keypoints: The predicted keypoints (flattened x, y coordinates).\n",
    "    - true_keypoints: The ground truth keypoints (flattened x, y coordinates).\n",
    "    - save_dir: Directory to save the result to\n",
    "    - img_num: image number that is getting compared\n",
    "    - nkeypoints:  Optional The number of keypoints (default=8).\n",
    "    - keypoint_labels: Optional list of keypoint labels to display next to the keypoints.\n",
    "    - connections: OPtional list of tupels defining the connections between kps\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=100)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    # Extract x and y coordinates for predicted keypoints\n",
    "    pred_x_keypoints = pred_keypoints[::2]\n",
    "    pred_y_keypoints = pred_keypoints[1::2]\n",
    "    \n",
    "    # Extract x and y coordinates for ground truth keypoints\n",
    "    true_x_keypoints = true_keypoints[::2]\n",
    "    true_y_keypoints = true_keypoints[1::2]\n",
    "\n",
    "    # Plot skeleton for true keypoints\n",
    "    for (i, j) in connections:\n",
    "        plt.plot([true_x_keypoints[i], true_x_keypoints[j]], \n",
    "                 [true_y_keypoints[i], true_y_keypoints[j]], \n",
    "                 'r-', linewidth=1)\n",
    "\n",
    "    # Plot skeleton for predicted keypoints\n",
    "    for (i, j) in connections:\n",
    "        plt.plot([pred_x_keypoints[i], pred_x_keypoints[j]], \n",
    "                 [pred_y_keypoints[i], pred_y_keypoints[j]], \n",
    "                 'g-', linewidth=1)\n",
    "    \n",
    "    # Plot predicted keypoints\n",
    "    plt.scatter(pred_x_keypoints, pred_y_keypoints, marker='o', c='g', s=100, label='Predicted', edgecolor='black')\n",
    "    \n",
    "    # Plot ground truth keypoints\n",
    "    plt.scatter(true_x_keypoints, true_y_keypoints, marker='x', c='r', s=100, label='Ground Truth')\n",
    "    \n",
    "    # If labels are provided, add them to the plot\n",
    "    if keypoint_labels is not None:\n",
    "        for i, (x, y) in enumerate(zip(true_x_keypoints, true_y_keypoints)):\n",
    "            plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "                     bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "    # If labels are provided, add them to the plot\n",
    "    if keypoint_labels is not None:\n",
    "        for i, (x, y) in enumerate(zip(pred_x_keypoints, pred_y_keypoints)):\n",
    "            plt.text(x, y, keypoint_labels[i], fontsize=8, color='white',\n",
    "                     bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3'))\n",
    "\n",
    "    # Add a legend to differentiate between predicted and ground truth keypoints\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(save_dir, f'Comparison of predicted and ground truth for img {img_num}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    #print(f'{data_descriptor} plot saved to {plot_path}')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(model_path, start_img, end_img, model_class=DeepPoseModel, device='cuda'):\n",
    "    \"\"\"\n",
    "    Loads a model, predicts keypoints for a range of images, and plots the predicted keypoints \n",
    "    versus ground truth keypoints on the same image. The images with plotted keypoints are then \n",
    "    saved to a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: The file path to the saved model's .pth file.\n",
    "    - start_img: The starting index of the images in the validation set to process.\n",
    "    - end_img: The ending index of the images in the validation set to process (exclusive).\n",
    "    - model_class: Optional. The class of the model architecture to instantiate and load \n",
    "                   with the saved weights (default=DeepPoseModel).\n",
    "    - device: Optional. The device to run the model on ('cuda' for GPU, 'cpu' for CPU; default='cuda').\n",
    "    \n",
    "    Returns:\n",
    "    - None. The function saves the images with plotted keypoints to the directory derived from the \n",
    "            model path.\n",
    "    \"\"\"\n",
    "\n",
    "    # get img lists\n",
    "    img_arr = val_imgs_array[start_img:end_img,:,:,:]\n",
    "    true_kp_arr = val_kp_array[start_img:end_img,:]\n",
    "\n",
    "    # Load the model\n",
    "    model = load_model(model_path, model_class, device=device)\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = predict(model, img_arr, device=device)\n",
    "    #print(predictions)\n",
    "\n",
    "    # DeNorm predictions \n",
    "    predictions_abs = []\n",
    "    true_kp_arr_abs = []\n",
    "    for i, kp in enumerate(predictions):\n",
    "\n",
    "        img_size = img_arr[i].shape\n",
    "        #print(img_size)\n",
    "\n",
    "        #unNorm each prediction\n",
    "        true_kp_abs, missing_kp = unnorm_keypoints(img_size, true_kp_arr[i])\n",
    "        #print(missing_kp)\n",
    "        kp_abs, missing_kp = unnorm_keypoints(img_size, kp, kp_to_null=missing_kp)\n",
    "        #print(missing_kp)\n",
    "        \n",
    "\n",
    "        # save result to new list\n",
    "        predictions_abs.append(kp_abs)\n",
    "        true_kp_arr_abs.append(true_kp_abs)\n",
    "\n",
    "    #print(predictions_abs)\n",
    "\n",
    "    # get the save directory parent (where the images will be saved)\n",
    "    save_dir = model_path.rsplit('/',1)[0]\n",
    "\n",
    "    # labels\n",
    "    labels = ['Head', 'Beak', 'Body_top', 'RFlipper', 'LFlipper', 'Body_bottom', 'LFoot', 'RFoot']\n",
    "\n",
    "    for i, kp in enumerate(predictions_abs):\n",
    "\n",
    "        plot_comparison(img_arr[i], predictions_abs[i], true_kp_arr_abs[i], save_dir, img_num=i+start_img)#, keypoint_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions and draw them \n",
    "model_path = '/home/matthew/Desktop/Master_Dev/masters_penguin_pose_estimation/runs/PE/DeepPose_Simple_SimpleAug_2024-08-22_15-17-20/final_model_epoch_30_PCK_0.5700_loss_0.0083.pth'\n",
    "start_img = 55\n",
    "end_img = 58\n",
    "\n",
    "predict_and_plot(model_path, start_img, end_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare some poses\n",
    "val_imgs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_kp_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
